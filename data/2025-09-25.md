<div id=toc></div>

# Table of Contents

- [cs.IT](#cs.IT) [Total: 5]
- [eess.SP](#eess.SP) [Total: 42]


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [1] [Analyzing α-divergence in Gaussian Rate-Distortion-Perception Theory](https://arxiv.org/abs/2509.19572)
*Martha V. Sourla,Giuseppe Serra,Photios A. Stavrou,Marios Kountouris*

Main category: cs.IT

TL;DR: 本文研究了高斯源在均方误差失真和α散度感知度量下的信息率失真感知函数（RDPF）估计问题，提出了参数化解决方案并建立了数值计算方法。


<details>
  <summary>Details</summary>
Motivation: 研究RDPF在目标导向的有损压缩和语义信息重建中的重要性，特别是在高斯源和特定感知度量下的理论分析需求。

Method: 假设联合高斯RDPF形成凸优化问题，推导出参数化解的上界，将最优参数求解转化为寻找α次简化指数多项式的根，并使用二分法进行数值计算。

Result: 成功表征了RDPF的上界，建立了参数化解决方案，并验证了数值结果与理论分析的一致性。

Conclusion: 提出的方法有效解决了高斯源RDPF估计问题，并与现有结果建立了联系，为相关应用提供了理论支持。

Abstract: The problem of estimating the information rate distortion perception function
(RDPF), which is a relevant information-theoretic quantity in goal-oriented
lossy compression and semantic information reconstruction, is investigated
here. Specifically, we study the RDPF tradeoff for Gaussian sources subject to
a mean-squared error (MSE) distortion and a perception measure that belongs to
the family of {\alpha} divergences. Assuming a jointly Gaussian RDPF, which
forms a convex optimization problem, we characterize an upper bound for which
we find a parametric solution. We show that evaluating the optimal parameters
of this parametric solution is equivalent to finding the roots of a reduced
exponential polynomial of degree {\alpha}. Additionally, we determine which
disjoint sets contain each root, which enables us to evaluate them numerically
using the well-known bisection method. Finally, we validate our analytical
findings with numerical results and establish connections with existing
results.

</details>


### [2] [Efficient $\varepsilon$-approximate minimum-entropy couplings](https://arxiv.org/abs/2509.19598)
*Spencer Compton*

Main category: cs.IT

TL;DR: 该论文提出了一个针对最小熵耦合问题的多项式时间近似方案（PTAS），在输入分布数量m为常数时，能够在多项式时间内找到熵值不超过最优解加ε的耦合。


<details>
  <summary>Details</summary>
Motivation: 最小熵耦合问题是NP难问题，之前最好的多项式时间算法只能达到常数近似保证（c≈0.53对于m=2，c≈1.22对于一般m）。主要开放问题是该问题是否是APX难的，或者是否存在PTAS。

Method: 设计了一个算法，在运行时间为n^O(poly(1/ε)·exp(m))的情况下，能够产生熵值不超过最优解加ε的耦合。这表明对于常数m存在PTAS。

Result: 证明了对于常数m，最小熵耦合问题存在多项式时间近似方案，解决了该领域的一个主要开放问题。

Conclusion: 该工作首次展示了最小熵耦合问题在输入分布数量为常数时存在PTAS，为这一NP难问题提供了重要的理论进展。

Abstract: Given $m \ge 2$ discrete probability distributions over $n$ states each, the
minimum-entropy coupling is the minimum-entropy joint distribution whose
marginals are the same as the input distributions. Computing the
minimum-entropy coupling is NP-hard, but there has been significant progress in
designing approximation algorithms; prior to this work, the best known
polynomial-time algorithms attain guarantees of the form $H(\operatorname{ALG})
\le H(\operatorname{OPT}) + c$, where $c \approx 0.53$ for $m=2$, and $c
\approx 1.22$ for general $m$ [CKQGK '23].
  A main open question is whether this task is APX-hard, or whether there
exists a polynomial-time approximation scheme (PTAS). In this work, we design
an algorithm that produces a coupling with entropy $H(\operatorname{ALG}) \le
H(\operatorname{OPT}) + \varepsilon$ in running time
$n^{O(\operatorname{poly}(1/\varepsilon) \cdot \operatorname{exp}(m) )}$:
showing a PTAS exists for constant $m$.

</details>


### [3] [Agentic AI for Low-Altitude Semantic Wireless Networks: An Energy Efficient Design](https://arxiv.org/abs/2509.19791)
*Zhouxiang Zhao,Ran Yi,Yihan Cang,Boyang Jin,Zhaohui Yang,Mingzhe Chen,Chongwen Huang,Zhaoyang Zhang*

Main category: cs.IT

TL;DR: 本文提出了一种基于智能AI的低空语义无线网络框架，通过优化UAV位置、语义压缩比、传输功率和AI推理任务卸载决策等关键变量，解决无人机辅助自主系统中的能效问题。


<details>
  <summary>Details</summary>
Motivation: 解决无人机辅助自主系统中的能源效率问题，提升任务续航能力。

Method: 构建系统级能耗最小化问题，开发低复杂度算法通过二维搜索获得全局最优解。

Result: 仿真结果表明，与传统的基线方法相比，所提出的设计能显著降低总能耗。

Conclusion: 提出的智能AI驱动的低空语义无线网络框架能有效优化无人机系统的能效，提升任务执行效率。

Abstract: This letter addresses the energy efficiency issue in unmanned aerial vehicle
(UAV)-assisted autonomous systems. We propose a framework for an agentic
artificial intelligence (AI)-powered low-altitude semantic wireless network,
that intelligently orchestrates a sense-communicate-decide-control workflow. A
system-wide energy consumption minimization problem is formulated to enhance
mission endurance. This problem holistically optimizes key operational
variables, including UAV's location, semantic compression ratio, transmit power
of the UAV and a mobile base station, and binary decision for AI inference task
offloading, under stringent latency and quality-of-service constraints. To
tackle the formulated mixed-integer non-convex problem, we develop a
low-complexity algorithm which can obtain the globally optimal solution with
two-dimensional search. Simulation results validate the effectiveness of our
proposed design, demonstrating significant reductions in total energy
consumption compared to conventional baseline approaches.

</details>


### [4] [Understanding the ratio of the partition sum to its Bethe approximation via double covers](https://arxiv.org/abs/2509.19910)
*Pascal O. Vontobel*

Main category: cs.IT

TL;DR: 该论文研究了图模型中配分函数与其Bethe近似之间的比率关系，特别是发现配分函数与Bethe近似的比率通常接近配分函数与二阶Bethe近似的比率的平方。作者对这一观察到的关系进行了理论解释，并针对两类对数超模图模型分析了这些比率。


<details>
  <summary>Details</summary>
Motivation: 研究图模型中配分函数与其近似方法之间比率关系的规律性，因为二阶Bethe近似的比率通常比一阶Bethe近似的比率更容易分析和量化。

Method: 作者首先对观察到的比率关系进行理论解释和论证，然后针对两类具体的对数超模图模型（log-supermodular graphical models）进行详细的比率分析。

Result: 论文证实了配分函数与Bethe近似的比率确实接近配分函数与二阶Bethe近似的比率的平方这一观察结果，并为这一现象提供了理论依据。

Conclusion: 该研究为图模型中配分函数近似方法之间的关系提供了理论支持，特别强调二阶Bethe近似在分析配分函数时的实用价值，因为其比率关系更容易被量化和分析。

Abstract: For various classes of graphical models it has been observed that the ratio
of the partition sum to its Bethe approximation is often close to being the
square of the ratio of the partition sum to its degree-2 Bethe approximation.
This is of relevance because the latter ratio can often better be analyzed
and/or quantified than the former ratio. In this paper, we give some
justifications for the observed relationship between these two ratios and then
analyze these ratios for two classes of log-supermodular graphical models.

</details>


### [5] [Constrained Higher-Order Binary Optimization for Wireless Communications Systems Using Ising Machines](https://arxiv.org/abs/2509.20092)
*Gan Zheng,Ioannis Krikidis*

Main category: cs.IT

TL;DR: 本文提出了一种基于Ising机器的迭代算法，用于解决无线通信系统中具有不等式约束的大规模高阶二进制优化问题，通过增强拉格朗日方法和泰勒展开将高阶多项式近似为二次型。


<details>
  <summary>Details</summary>
Motivation: 无线通信中的资源优化问题通常包含高阶多项式项和严格不等式约束，传统QUBO方法应用受限。为了利用Ising机器的最新进展，需要克服这些瓶颈。

Method: 提出基于增强拉格朗日方法的迭代算法，使用泰勒展开将高阶多项式近似为二次型，每次迭代只需解决单个QUBO问题，无需辅助变量。

Result: 在同时无线信息和能量传输系统的相位优化案例研究中，仿真结果表明所提算法性能令人满意，优于启发式基准方案。

Conclusion: 该算法成功解决了无线通信中的高阶二进制优化问题，为Ising机器在复杂资源优化中的应用提供了有效解决方案。

Abstract: This paper develops an algorithmic solution using Ising machines to solve
large-scale higher-order binary optimization (HOBO) problems with inequality
constraints for resource optimization in wireless communications systems.
Quadratic unconstrained binary optimization (QUBO) aims to solve a special
category of these problems widely encountered in engineering and science. To
solve QUBO instances, specialized Ising machines have been designed, while
sophisticated quantum annealing algorithm and quantum-inspired classical
heuristics have been developed. However, the application of QUBO in wireless
communications has limited practical interest mainly due to the complexity of
resource optimization problems which are often characterized by high-order
polynomial terms and strict inequality constraints. To overcome these
bottlenecks and take advantage of recent advancements in Ising machines, in
this paper, we propose an iterative algorithmic solution to solve HOBO
problems, which is based on the augmented Lagrangian method to handle
constraints. Specifically, Taylor expansion is employed to approximate
higher-order polynomials to quadratic ones in the augmented Lagrangian
function, which enables the solution of a single QUBO problem at each iteration
without auxiliary variables. As an illustrative case study, we consider the
problem of phase optimization in a simultaneous wireless information and power
transfer system, where a reconfigurable intelligent surface with 1-bit phase
resolution is used to facilitate information/energy transfer. Simulation
results verify that the proposed algorithm achieves satisfactory performance
and outperforms heuristic benchmark schemes.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [6] [Raspberry Pi Pico as a Radio Transmitter](https://arxiv.org/abs/2509.19304)
*M. Andrecut*

Main category: eess.SP

TL;DR: 将树莓派Pico微控制器通过简单方法和廉价组件转换为无线电发射器，可能带来安全风险


<details>
  <summary>Details</summary>
Motivation: 探讨如何将常见微控制器转变为无线电发射器的可能性，并分析其潜在的安全隐患

Method: 使用廉价现成的电子组件和开源软件，通过简单方法改造树莓派Pico微控制器

Result: 成功将树莓派Pico转换为无线电发射器，能够建立多个本地隐蔽无线电通信通道

Conclusion: 这种看似无害的技术改造在极端情况下可能构成安全威胁，需要引起重视

Abstract: In this paper we discuss several surprisingly simple methods for transforming
the Raspberry Pi Pico (RP2) microcontroller into a radio transmitter, by using
only cheap off the shelf electronic components, and open source software. While
initially this transformation may look as a harmless curiosity, in some extreme
cases it can also pose security risks, since it can be used to open a large
number of local stealth radio communication channels.

</details>


### [7] [A Federated Fine-Tuning Paradigm of Foundation Models in Heterogenous Wireless Networks](https://arxiv.org/abs/2509.19306)
*Jingyi Wang,Zhongyuan Zhao,Qingtian Wang,Zexu Li,Yue Wang,Tony Q. S. Quek*

Main category: eess.SP

TL;DR: 该论文提出了一种基于在线学习的优化方法，用于解决异构无线网络中联邦微调面临的设备异构性和资源约束问题。通过动态切换LoRA模块、功率控制和带宽分配，提高了边缘智能的泛化能力和能效。


<details>
  <summary>Details</summary>
Motivation: 边缘智能在移动设备上提供低延迟和泛在服务具有潜力，但无线网络中的设备异构性和资源约束对联邦微调性能构成威胁。

Method: 提出了基于切换的联邦微调框架，设备动态切换LoRA模块与基站协作；推导了推理风险间隙的上界；将非凸混合整数规划问题分解为模型切换、功率控制和带宽分配子问题；开发了多项式复杂度的在线优化算法。

Result: 在SST-2和QNLI数据集上的仿真结果显示，该方法在测试准确率和能效方面取得了性能提升。

Conclusion: 所提出的在线优化方法有效解决了异构无线网络中联邦微调的挑战，提高了边缘智能的性能和效率。

Abstract: Edge intelligence has emerged as a promising strategy to deliver low-latency
and ubiquitous services for mobile devices. Recent advances in fine-tuning
mechanisms of foundation models have enabled edge intelligence by integrating
low-rank adaptation (LoRA) with federated learning. However, in wireless
networks, the device heterogeneity and resource constraints on edge devices
pose great threats to the performance of federated fine-tuning. To tackle these
issues, we propose to optimize federated fine-tuning in heterogenous wireless
networks via online learning. First, the framework of switching-based federated
fine-tuning in wireless networks is provided. The edge devices switches to LoRA
modules dynamically for federated fine-tuning with base station to jointly
mitigate the impact of device heterogeneity and transmission unreliability.
Second, a tractable upper bound on the inference risk gap is derived based on
theoretical analysis. To improve the generalization capability, we formulate a
non-convex mixed-integer programming problem with long-term constraints, and
decouple it into model switching, transmit power control, and bandwidth
allocation subproblems. An online optimization algorithm is developed to solve
the problems with polynomial computational complexity. Finally, the simulation
results on the SST-2 and QNLI data sets demonstrate the performance gains in
test accuracy and energy efficiency.

</details>


### [8] [Bandwidth of Gamma-Distribution-Shaped Functions via Lambert W Function](https://arxiv.org/abs/2509.19307)
*Anthony LoPrete,Johannes Burge*

Main category: eess.SP

TL;DR: 本文推导了伽马分布函数半高全宽(FWHM)的精确解析表达式，使用Lambert W函数计算伽马分布PDF的逆函数，并比较了伽马形状函数与高斯近似的FWHM差异。


<details>
  <summary>Details</summary>
Motivation: 伽马形状函数的半高全宽(FWHM)是表征单峰函数带宽的重要参数，但目前缺乏闭式表达式。本文旨在填补这一空白。

Method: 使用Lambert W函数计算伽马分布概率密度函数(PDF)的逆函数，基于此推导出任意比例最大值的伽马分布宽度精确解析表达式。

Result: 成功推导出伽马形状函数FWHM的精确解析表达式，并提供了倍频带宽的表达式。通过比较发现伽马形状函数与高斯近似在FWHM上存在差异。

Conclusion: 本文提供了伽马分布函数FWHM的闭式解析解，为相关领域的研究提供了实用的数学工具，并讨论了与高斯近似的对比结果。

Abstract: The full width at half maximum (FWHM) is a useful quantity for characterizing
the bandwidth of unimodal functions. However, a closed-form expression for the
FWHM of gamma-shaped functions-i.e. functions that are shaped like the gamma
distribution probability density function (PDF)-is not widely available. Here,
we derive and present just such an expression. To do so, we use the Lambert W
function to compute the inverse of the gamma PDF. We use this inverse to derive
an exact analytic expression for the width of a gamma distribution at an
arbitrary proportion of the maximum, from which the FWHM follows trivially. (An
expression for the octave bandwidth of gamma-shaped functions is also
provided.) The FWHM is then compared to the Gaussian approximation of
gamma-shaped functions. A few other related issues are discussed.

</details>


### [9] [A Novel Two-Dimensional Wigner Distribution Framework via the Quadratic Phase Fourier Transform with a Non-Separable Kernel](https://arxiv.org/abs/2509.19310)
*Mukul Chauhan,Waseem Z. Lone,Amit K. Verma*

Main category: eess.SP

TL;DR: 本文提出了一种基于二维不可分离二次相位傅里叶变换的新型时频分布——二维不可分离二次相位维格纳分布，能够有效捕捉复杂的不可分离信号结构，并在二维线性调频信号处理中表现出优越的交叉项抑制和信号定位性能。


<details>
  <summary>Details</summary>
Motivation: 传统维格纳分布难以有效处理复杂的不可分离信号结构，需要开发一种更通用的时频分布方法来更好地分析和表征这类信号。

Method: 通过用不可分离二次相位傅里叶变换核替换经典傅里叶核，构建了二维不可分离二次相位维格纳分布，并严格证明了其关键数学性质。

Result: 该分布对单分量、双分量和三分量二维线性调频信号的处理显示出优越的交叉项抑制能力和信号定位精度。

Conclusion: 2D-NSQPWD是一种有效的时频分析工具，特别适用于处理具有复杂结构的二维信号，为信号处理领域提供了新的分析手段。

Abstract: This paper introduces a novel time-frequency distribution, referred to as the
Two-Dimensional Non-Separable Quadratic Phase Wigner Distribution (2D-NSQPWD),
formulated within the framework of the Two-Dimensional Non-Separable Quadratic
Phase Fourier Transform (2D-NSQPFT). By replacing the classical Fourier kernel
with the NSQPFT kernel, the proposed distribution generalizes the classical
Wigner distribution and effectively captures complex, non-separable signal
structures. We rigorously establish several key properties of the 2D-NSQPWD,
including time and frequency shift invariance, marginal behavior, conjugate
symmetry, convolution relations, and Moyal's identity. Furthermore, the
connection between the 2D-NSQPWD and the two-dimensional short-time Fourier
transform (2D-STFT) is explored. The distribution's effectiveness is
demonstrated through its application to single-, bi-, and tri-component
two-dimensional linear frequency modulated (2D-LFM) signals, where it shows
superior performance in cross-term suppression and signal localization.

</details>


### [10] [Graph-Based Spatio-temporal Attention and Multi-Scale Fusion for Clinically Interpretable, High-Fidelity Fetal ECG Extraction](https://arxiv.org/abs/2509.19308)
*Chang Wang,Ming Zhu,Shahram Latifi,Buddhadeb Dawn,Shengjie Zhai*

Main category: eess.SP

TL;DR: FHNet是一个深度学习框架，结合图神经网络和多尺度增强transformer，用于从腹部心电图中提取干净的胎儿心电信号，在低信噪比条件下显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 先天性心脏病是最常见的新生儿异常，需要早期检测来改善预后。但胎儿心电信号在腹部心电图中常被母体心电和噪声掩盖，传统方法在低信噪比条件下效果不佳。

Method: 提出FetalHealthNet框架，集成图神经网络和多尺度增强transformer，动态建模导联间的时空相关性，提取干净的胎儿心电信号。

Result: 在基准数据集上，FHNet始终优于LSTM模型、标准transformer和最先进模型，R2>0.99，RMSE=0.015，即使在严重噪声条件下也表现优异。可解释性分析显示具有生理意义的时空和导联贡献。

Conclusion: FHNet展示了AI驱动建模在推进胎儿监测和实现早期先天性心脏病筛查方面的潜力，强调了新一代生物医学信号处理的变革性影响。

Abstract: Congenital Heart Disease (CHD) is the most common neonatal anomaly,
highlighting the urgent need for early detection to improve outcomes. Yet,
fetal ECG (fECG) signals in abdominal ECG (aECG) are often masked by maternal
ECG and noise, challenging conventional methods under low signal-to-noise ratio
(SNR) conditions. We propose FetalHealthNet (FHNet), a deep learning framework
that integrates Graph Neural Networks with a multi-scale enhanced transformer
to dynamically model spatiotemporal inter-lead correlations and extract clean
fECG signals. On benchmark aECG datasets, FHNet consistently outperforms long
short-term memory (LSTM) models, standard transformers, and state-of-the-art
models, achieving R2>0.99 and RMSE = 0.015 even under severe noise.
Interpretability analyses highlight physiologically meaningful temporal and
lead contributions, supporting model transparency and clinical trust. FHNet
illustrates the potential of AI-driven modeling to advance fetal monitoring and
enable early CHD screening, underscoring the transformative impact of
next-generation biomedical signal processing.

</details>


### [11] [E2E Learning Massive MIMO for Multimodal Semantic Non-Orthogonal Transmission and Fusion](https://arxiv.org/abs/2509.19312)
*Minghui Wu,Zhen Gao*

Main category: eess.SP

TL;DR: 本文提出了一种端到端的上下行CSI融合预编码网络，通过联合建模下行CSI参考信号设计、CSI反馈和基站预编码，有效利用SRS信息和UE反馈来提升大规模MIMO系统的性能。


<details>
  <summary>Details</summary>
Motivation: 大规模MIMO系统虽然能提供高频谱效率，但高维下行信道状态信息(CSI)使得实时信道获取和预编码变得复杂。传统方法难以有效融合上行SRS信息和下行CSI反馈。

Method: 构建基于MAXIM架构的投影网络，设计下行CSI-RS；UE压缩/量化CSI-RS观测值并反馈；BS端通过反馈专用预编码网络和SRS专用预编码网络生成候选预编码器，最后由融合预编码网络结合两者生成最终预编码器。所有模块采用三阶段训练策略，以频谱效率为导向进行优化。

Result: 仿真结果表明，该方法能有效利用SRS信息和UE反馈，相比传统基线方法取得了显著更好的性能。

Conclusion: 所提出的端到端融合预编码网络能够有效解决大规模MIMO系统中的信道获取和预编码问题，为实际系统部署提供了有前景的解决方案。

Abstract: Massive multiple-input multiple-output (MIMO) promises high spectral
efficiency but also leads to high-dimensional downlink channel state
information (CSI), which complicates real-time channel acquisition and
precoding. To address this, we propose an end-to-end (E2E) uplink-downlink CSI
fusion precoding network that jointly models downlink CSI reference signal
(CSI-RS) design, CSI feedback, and base-station (BS) precoding within a single
E2E neural architecture. Concretely, a projection network built on the MAXIM
architecture takes uplink sounding reference signals (SRS) as input and outputs
frequency-, beam-, and port-domain projection matrices for designing downlink
CSI-RS. User equipment (UE) then compresses/quantizes the resulting CSI-RS
observations and feeds back a compact representation. At the base station (BS),
two complementary branches produce candidate precoders: one is a feedback-only
precoding network driven by quantized downlink observations, and the other is
an SRS-only precoding network driven by uplink SRS. These candidate precoders
are subsequently combined by a fusion precoding network to yield the final
transmit precoder. All the modules are trained with a
spectral-efficiency-oriented loss under a three-stage schedule. Simulation
results show that the proposed approach effectively harnesses both SRS-derived
information and UE feedback, achieving markedly better performance than
conventional baselines.

</details>


### [12] [Joint Channel Estimation and Computation Offloading in Fluid Antenna-assisted MEC Networks](https://arxiv.org/abs/2509.19340)
*Ying Ju,Mingdong Li,Haoyu Wang,Lei Liu,Youyang Qu,Mianxiong Dong,Victor C. M. Leung,Chau Yuen*

Main category: eess.SP

TL;DR: 提出了一种流体天线辅助移动边缘计算卸载框架，通过改进的信道估计和分层多智能体算法来最小化系统延迟。


<details>
  <summary>Details</summary>
Motivation: 流体天线的动态端口配置能力为移动边缘计算系统提供了空间多样性和频谱效率优势，但面临信道估计复杂度和联合优化非凸性的挑战。

Method: 提出IBM-CCS信道估计算法整合信息相关性，以及基于博弈论的分层双决斗多智能体算法HiTDMA来优化端口选择、波束成形、功率控制和资源分配。

Result: 数值结果表明所提方案显著降低系统延迟，提升卸载性能，且信道估计在不同端口密度下表现出优越的准确性和鲁棒性。

Conclusion: 该框架有效解决了流体天线辅助MEC系统中的关键挑战，为高效通信和资源优化提供了可行方案。

Abstract: With the emergence of fluid antenna (FA) in wireless communications, the
capability to dynamically adjust port positions offers substantial benefits in
spatial diversity and spectrum efficiency, which are particularly valuable for
mobile edge computing (MEC) systems. Therefore, we propose an FA-assisted MEC
offloading framework to minimize system delay. This framework faces two severe
challenges, which are the complexity of channel estimation due to dynamic port
configuration and the inherent non-convexity of the joint optimization problem.
Firstly, we propose Information Bottleneck Metric-enhanced Channel Compressed
Sensing (IBM-CCS), which advances FA channel estimation by integrating
information relevance into the sensing process and capturing key features of FA
channels effectively. Secondly, to address the non-convex and high-dimensional
optimization problem in FA-assisted MEC systems, which includes FA port
selection, beamforming, power control, and resource allocation, we propose a
game theory-assisted Hierarchical Twin-Dueling Multi-agent Algorithm (HiTDMA)
based offloading scheme, where the hierarchical structure effectively decouples
and coordinates the optimization tasks between the user side and the base
station side. Crucially, the game theory effectively reduces the dimensionality
of power control variables, allowing deep reinforcement learning (DRL) agents
to achieve improved optimization efficiency. Numerical results confirm that the
proposed scheme significantly reduces system delay and enhances offloading
performance, outperforming benchmarks. Additionally, the IBM-CCS channel
estimation demonstrates superior accuracy and robustness under varying port
densities, contributing to efficient communication under imperfect CSI.

</details>


### [13] [A Measurement Report Data-Driven Framework for Localized Statistical Channel Modeling](https://arxiv.org/abs/2509.19342)
*Xinyu Qin,Ye Xue,Qi Yan,Shutao Zhang,Bingsheng Peng,Tsung-Hui Chang*

Main category: eess.SP

TL;DR: 本文提出了一种基于测量报告（MR）数据的局部统计信道建模框架，利用低成本的MR数据实现信道角度功率谱（APS）估计，解决了传统方法依赖高成本路测数据的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的局部统计信道建模方法严重依赖高成本、空间覆盖有限的路测数据，而MR数据具有低成本、广泛采集的优势，但存在位置信息缺失和空间数据分布不均匀的挑战。

Method: 框架包含两个核心模块：1）基于超图神经网络的半监督MR定位模块，通过距离感知超图建模和超图卷积提取位置信息；2）联合网格构建和信道APS估计模块，交替优化网格划分和APS估计，使用聚类和改进的稀疏恢复方法处理病态测量矩阵和不完整观测。

Result: 在真实世界MR数据集上的综合实验表明，该框架在定位和信道建模方面具有优越的性能和鲁棒性。

Conclusion: 该MR数据驱动的框架能够有效利用低成本MR数据进行局部统计信道建模，在复杂环境中表现出良好的鲁棒性和性能。

Abstract: Localized statistical channel modeling (LSCM) is crucial for effective
performance evaluation in digital twin-assisted network optimization. Solely
relying on the multi-beam reference signal receiving power (RSRP), LSCM aims to
model the localized statistical propagation environment by estimating the
channel angular power spectrum (APS). However, existing methods rely heavily on
drive test data with high collection costs and limited spatial coverage. In
this paper, we propose a measurement report (MR) data-driven framework for
LSCM, exploiting the low-cost and extensive collection of MR data. The
framework comprises two novel modules. The MR localization module addresses the
issue of missing locations in MR data by introducing a semi-supervised method
based on hypergraph neural networks, which exploits multi-modal information via
distance-aware hypergraph modeling and hypergraph convolution for location
extraction. To enhance the computational efficiency and solution robustness,
LSCM operates at the grid level. Compared to independently constructing
geographically uniform grids and estimating channel APS, the joint grid
construction and channel APS estimation module enhances robustness in complex
environments with spatially non-uniform data by exploiting their correlation.
This module alternately optimizes grid partitioning and APS estimation using
clustering and improved sparse recovery for the ill-conditioned measurement
matrix and incomplete observations. Through comprehensive experiments on a
real-world MR dataset, we demonstrate the superior performance and robustness
of our framework in localization and channel modeling.

</details>


### [14] [STL-FFT-STFT-TCN-LSTM: An Effective Wave Height High Accuracy Prediction Model Fusing Time-Frequency Domain Features](https://arxiv.org/abs/2509.19313)
*Huipeng Liu,Zhichao Zhu,Yuan Zhou,Changlu Li*

Main category: eess.SP

TL;DR: 该研究提出了一种结合STL-FFT-STFT-TCN-LSTM的混合模型，用于精确预测有效波高，解决了波浪能信号的非线性、突变、多尺度周期性等挑战，在极端波高捕获和高频噪声抑制方面表现出显著优势。


<details>
  <summary>Details</summary>
Motivation: 传统能源消耗加剧且环境影响显著，波浪能因其高能量密度、稳定性、分布广泛和环境友好性成为有前景的可再生能源。精确预测有效波高是开发的关键，但波浪能信号具有强非线性、突变、多尺度周期性、数据稀疏和高频噪声干扰等特点，物理模型计算成本极高。

Method: 提出STL-FFT-STFT-TCN-LSTM混合模型，利用季节性趋势分解(STL)、快速傅里叶变换(FFT)、短时傅里叶变换(STFT)、时序卷积网络(TCN)和长短期记忆网络(LSTM)技术，优化多尺度特征融合，捕获极端波高，解决高频噪声和周期信号问题。

Result: 使用NOAA Station 41008和41047的2019-2022小时数据进行实验，相比其他单模型和混合模型，该模型在捕获极端波高和抑制高频噪声方面预测精度显著提高，MAE降低15.8%-40.5%，SMAPE降低8.3%-20.3%，R增加1.31%-2.9%。消融实验验证了各组件步骤的不可或缺性。

Conclusion: STL-FFT-STFT-TCN-LSTM模型在多尺度特征融合方面具有优越性，能够高效准确地预测有效波高，为波浪能开发提供了可靠的技术支持。

Abstract: As the consumption of traditional energy sources intensifies and their
adverse environmental impacts become more pronounced, wave energy stands out as
a highly promising member of the renewable energy family due to its high energy
density, stability, widespread distribution, and environmental friendliness.
The key to its development lies in the precise prediction of Significant Wave
Height (WVHT). However, wave energy signals exhibit strong nonlinearity, abrupt
changes, multi-scale periodicity, data sparsity, and high-frequency noise
interference; additionally, physical models for wave energy prediction incur
extremely high computational costs. To address these challenges, this study
proposes a hybrid model combining STL-FFT-STFT-TCN-LSTM. This model exploits
the Seasonal-Trend Decomposition Procedure based on Loess (STL), Fast Fourier
Transform (FFT), Short-Time Fourier Transform (STFT), Temporal Convolutional
Network (TCN), and Long Short-Term Memory (LSTM) technologies. The model aims
to optimize multi-scale feature fusion, capture extreme wave heights, and
address issues related to high-frequency noise and periodic signals, thereby
achieving efficient and accurate prediction of significant wave height.
Experiments were conducted using hourly data from NOAA Station 41008 and 41047
spanning 2019 to 2022. The results showed that compared with other single
models and hybrid models, the STL-FFT-STFT-TCN-LSTM model achieved
significantly higher prediction accuracy in capturing extreme wave heights and
suppressing high-frequency noise, with MAE reduced by 15.8\%-40.5\%, SMAPE
reduced by 8.3\%-20.3\%, and R increased by 1.31\%-2.9\%; in ablation
experiments, the model also demonstrated the indispensability of each component
step, validating its superiority in multi-scale feature fusion.

</details>


### [15] [Neural Network Based Framework for Passive Intermodulation Cancellation in MIMO Systems](https://arxiv.org/abs/2509.19382)
*Xiaolong Li,Zhi-qin John Xu,Peiting You,Yifei Zhu*

Main category: eess.SP

TL;DR: 提出了一种基于深度学习的轻量级PIM消除框架，使用深度可分离卷积和扩张卷积来高效捕获天线和子载波间的非线性依赖关系，在MIMO实验设置中实现了29dB的平均功率误差消除效果。


<details>
  <summary>Details</summary>
Motivation: 被动互调(PIM)已成为现代MIMO-OFDM系统中的关键自干扰源，特别是在5G及更高标准的严格要求下。传统消除方法依赖复杂的非线性模型，存在可扩展性有限和计算成本高的问题。

Method: 采用轻量级深度学习框架，结合深度可分离卷积和扩张卷积来高效捕获非线性依赖关系，并使用循环学习率调度和梯度裁剪来增强收敛性。

Result: 在受控MIMO实验设置中，该方法有效抑制了三阶被动互调失真，仅使用11k可训练参数就实现了高达29dB的平均功率误差消除。

Conclusion: 结果表明紧凑的神经网络架构在未来无线通信系统中具有可扩展干扰抑制的潜力。

Abstract: Passive intermodulation (PIM) has emerged as a critical source of
self-interference in modern MIMO-OFDM systems, especially under the stringent
requirements of 5G and beyond. Conventional cancellation methods often rely on
complex nonlinear models with limited scalability and high computational cost.
In this work, we propose a lightweight deep learning framework for PIM
cancellation that leverages depthwise separable convolutions and dilated
convolutions to efficiently capture nonlinear dependencies across antennas and
subcarriers. To further enhance convergence, we adopt a cyclic learning rate
schedule and gradient clipping. In a controlled MIMO experimental setup, the
method effectively suppresses third-order passive intermodulation (PIM)
distortion, achieving up to 29dB of average power error (APE) with only 11k
trainable parameters. These results highlight the potential of compact neural
architectures for scalable interference mitigation in future wireless
communication systems.

</details>


### [16] [Advancing Few-Shot Pediatric Arrhythmia Classification with a Novel Contrastive Loss and Multimodal Learning](https://arxiv.org/abs/2509.19315)
*Yiqiao Chen,Zijian Huang,Zhenghui Feng*

Main category: eess.SP

TL;DR: 提出了一种多模态端到端深度学习框架，结合双分支卷积编码器、语义注意力和轻量级Transformer，用于儿科心律失常自动分类，在Leipzig心脏中心数据集上取得了显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 儿科心律失常是导致残疾和心源性猝死的主要风险因素，但由于类别不平衡、少样本类别和复杂信号特征，其自动分类面临挑战，限制了早期筛查和临床干预的效率与可靠性。

Method: 采用多模态端到端深度学习框架，包括ECG和IEGM的双分支卷积编码器、跨模态特征对齐的语义注意力、全局依赖建模的轻量级Transformer编码器，以及新的对比损失函数AGCACL来增强类内紧凑性和类间可分性。

Result: 在Leipzig心脏中心儿科/先天性ECG+IEGM数据集上，该方法取得了97.76% Top-1准确率、94.08%宏精确率、91.97%宏召回率、92.97%宏F1和92.36%宏F2，相比最强基线分别提升了13.64、15.96、19.82和19.44个百分点。

Conclusion: 该框架显著提高了少数心律失常类别的检测能力和鲁棒性，为儿科和先天性心脏病人群的心律筛查、术前评估和术后随访提供了潜在的临床价值。

Abstract: Pediatric arrhythmias are a major risk factor for disability and sudden
cardiac death, yet their automated classification remains challenging due to
class imbalance, few-shot categories, and complex signal characteristics, which
severely limit the efficiency and reliability of early screening and clinical
intervention. To address this problem, we propose a multimodal end-to-end deep
learning framework that combines dual-branch convolutional encoders for ECG and
IEGM, semantic attention for cross-modal feature alignment, and a lightweight
Transformer encoder for global dependency modeling. In addition, we introduce a
new contrastive loss fucntion named Adaptive Global Class-Aware Contrastive
Loss (AGCACL) to enhance intra-class compactness and inter-class separability
through class prototypes and a global similarity matrix. To the best of our
knowledge, this is the first systematic study based on the Leipzig Heart Center
pediatric/congenital ECG+IEGM dataset, for which we also provide a complete and
reproducible preprocessing pipeline. Experimental results demonstrate that the
proposed method achieves the overall best performance on this dataset,
including 97.76\% Top-1 Accuracy, 94.08\% Macro Precision, 91.97\% Macro
Recall, 92.97\% Macro F1, and 92.36\% Macro F2, with improvements of +13.64,
+15.96, +19.82, and +19.44 percentage points over the strongest baseline in
Macro Precision/Recall/F1/F2, respectively. These findings indicate that the
framework significantly improves the detectability and robustness for minority
arrhythmia classes, offering potential clinical value for rhythm screening,
pre-procedural assessment, and postoperative follow-up in pediatric and
congenital heart disease populations.

</details>


### [17] [Impact of RHIs and ipSIC on Active RIS-NOMA Systems with Low-Precision ADCs](https://arxiv.org/abs/2509.19383)
*Qianqian Li,Hua Li,Shiya Hao,Lintao Li,Xiaoming Dai*

Main category: eess.SP

TL;DR: 本文研究了采用低精度ADC的主动可重构智能表面辅助非正交多址系统的性能，推导了考虑硬件损伤和干扰消除不完美的中断概率近似表达式，并证明主动RIS-NOMA系统在性能上优于被动RIS-NOMA系统。


<details>
  <summary>Details</summary>
Motivation: 研究主动RIS-NOMA系统在低精度ADC下的性能表现，探索如何通过优化发射功率和反射元件数量来缓解低精度ADC的负面影响。

Method: 推导了考虑残余硬件损伤和干扰消除不完美的中断概率分析近似表达式，分析了高信噪比下的渐近性能、系统吞吐量和分集阶数，并通过仿真验证理论分析。

Result: 仿真结果表明，量化ARIS-NOMA系统在中断概率和吞吐量方面优于被动PRIS-NOMA系统，且所需发射功率更低、反射元件更少。增加反射元件数量可显著改善两种系统的中断性能。

Conclusion: 通过优化发射功率和合理配置反射元件数量，可以有效缓解低精度ADC对主动RIS-NOMA系统的负面影响，实现更好的系统性能。

Abstract: This study evaluates the performance of an active reconfigurable intelligent
surface (ARIS)-assisted non-orthogonal multiple access (NOMA) system employing
low-precision analog-to-digital converters (ADCs). Analytical approximations
for the outage probability (OP) are derived, considering residual hardware
impairments (RHIs) and imperfect successive interference cancellation (ipSIC).
Additionally, we analyze the asymptotic OP, system throughput, and diversity
order at high signal-to-noise ratios (SNRs). Simulation results demonstrate
that the proposed quantized ARIS-NOMA system outperforms its passive
counterpart (PRIS-NOMA), achieving lower OP and higher throughput with reduced
transmit power requirements and fewer reflecting elements. Moreover, the outage
performance of both quantized ARIS-NOMA and PRIS-NOMA systems demonstrates
significant improvement as the number of reflecting elements increases. The
negative impacts of low-precision ADCs can be effectively mitigated by
optimizing transmit power and scaling the number of reflecting elements.

</details>


### [18] [Electric Vehicle Identification from Behind Smart Meter Data](https://arxiv.org/abs/2509.19316)
*Ammar Kamoona,Hui Song,Ali Moradi Amani,Mahdi Jalili,Xinghuo Yu,Peter McTaggart*

Main category: eess.SP

TL;DR: 本文提出了一种基于异常检测的无监督学习方法，用于从智能电表数据中识别电动汽车充电负荷，无需先验的EV充电配置文件知识。


<details>
  <summary>Details</summary>
Motivation: 当电动汽车充电发生在电表后端时，充电负荷被视为用户总负荷的一部分，不被配电网络运营商单独测量。配电网络运营商需要了解其网络中的EV存在情况，以更好地规划和管理配电网。

Method: 提出了一种深度时间卷积编码解码网络，采用无监督学习方法和异常检测技术，仅需非EV用户的真实功耗数据。

Result: 该方法应用于澳大利亚维多利亚州家庭的智能电表数据，在识别有EV的家庭方面表现出优越性能。

Conclusion: 该方法为配电网络运营商提供了一种有效的EV充电负荷识别解决方案，无需依赖监督学习方法或先验的EV充电配置文件。

Abstract: Electric vehicle (EV) charging loads identification from behind smart meter
recordings is an indispensable aspect that enables effective decision-making
for energy distributors to reach an informed and intelligent decision about the
power grid's reliability. When EV charging happens behind the meter (BTM), the
charging occurs on the customer side of the meter, which measures the overall
electricity consumption. In other words, the charging of the EV is considered
part of the customer's load and not separately measured by the Distribution
Network Operators (DNOs). DNOs require complete knowledge about the EV presence
in their network. Identifying the EV charging demand is essential to better
plan and manage the distribution grid. Unlike supervised methods, this paper
addresses the problem of EV charging load identification in a non-nonintrusive
manner from low-frequency smart meter using an unsupervised learning approach
based on anomaly detection technique. Our approach does not require prior
knowledge of EV charging profiles. It only requires real power consumption data
of non-EV users, which are abundant in practice. We propose a deep temporal
convolution encoding decoding (TAE) network. The TAE is applied to power
consumption from smart BTM from Victorian households in Australia, and the TAE
shows superior performance in identifying households with EVs.

</details>


### [19] [Scensory: Automated Real-Time Fungal Identification and Spatial Mapping](https://arxiv.org/abs/2509.19318)
*Yanbaihui Liu,Erica Babusci,Claudia K. Gunsch,Boyuan Chen*

Main category: eess.SP

TL;DR: Scensory是一个机器人驱动的嗅觉系统，使用低成本VOC传感器阵列和深度学习，能够同时识别真菌种类并定位其空间来源，实现实时、空间感知的真菌监测。


<details>
  <summary>Details</summary>
Motivation: 现有真菌检测方法速度慢、成本高且缺乏空间分辨率，不适合实时监测和大规模部署。需要一种能够实时、低成本监测室内真菌污染的方法。

Method: 利用机器人自动数据收集，通过分析VOC时间动态来解码化学和空间特征，使用神经网络架构进行训练。系统有两种操作模式：被动多阵列配置用于环境监测，移动单阵列配置用于主动源跟踪。

Result: 在五种真菌物种上，系统在环境条件下达到89.85%的物种检测准确率和87.31%的定位准确率，每个预测仅需3-7秒传感器输入。

Conclusion: 该方法实现了实时、空间感知的真菌监测，建立了可扩展且经济实惠的自主环境感知框架，无需额外实验室实验即可揭示关键生物化学特征。

Abstract: Indoor fungal contamination poses significant risks to public health, yet
existing detection methods are slow, costly, and lack spatial resolution.
Conventional approaches rely on laboratory analysis or high-concentration
sampling, making them unsuitable for real-time monitoring and scalable
deployment. We introduce \textbf{\textit{Scensory}}, a robot-enabled olfactory
system that simultaneously identifies fungal species and localizes their
spatial origin using affordable volatile organic compound (VOC) sensor arrays
and deep learning. Our key idea is that temporal VOC dynamics encode both
chemical and spatial signatures, which we decode through neural architectures
trained on robot-automated data collection. We demonstrate two operational
modes: a passive multi-array configuration for environmental monitoring, and a
mobile single-array configuration for active source tracking. Across five
fungal species, our system achieves up to 89.85\% accuracy in species detection
and 87.31\% accuracy in localization under ambient conditions, where each
prediction only takes 3--7\,s sensor inputs. Additionally, by computationally
analyzing model behavior, we can uncover key biochemical signatures without
additional laboratory experiments. Our approach enables real-time, spatially
aware fungal monitoring and establishes a scalable and affordable framework for
autonomous environmental sensing.

</details>


### [20] [Human Activity Recognition Based on Electrocardiogram Data Only](https://arxiv.org/abs/2509.19328)
*Sina Montazeri,Waltenegus Dargie,Yunhe Feng,Kewei Sha*

Main category: eess.SP

TL;DR: 本文首次证明仅使用心电图（ECG）就能在六种不同活动中实现稳健的活动识别，超越了传统依赖惯性测量单元（IMU）的方法。


<details>
  <summary>Details</summary>
Motivation: 传统活动识别依赖惯性测量单元（IMU），但IMU资源密集且需要校准。虽然基于心电图（ECG）的方法已被探索，但通常作为IMU的补充或仅限于粗略分类。本文旨在推进仅使用ECG进行多活动识别的能力。

Method: 设计并评估了三种新的深度学习模型：1）带有Squeeze-and-Excitation块的CNN分类器，用于通道级特征重校准；2）带有扩张卷积的ResNet分类器，用于多尺度时间依赖捕获；3）新颖的CNNTransformer混合模型，结合卷积特征提取和注意力机制，用于长程时间关系建模。

Result: 在54名受试者的六种活动数据上测试，所有三种模型对已见受试者的准确率超过94%，而CNNTransformer混合模型对未见受试者的准确率达到72%，这一结果可通过增加训练人群进一步改善。

Conclusion: 本研究首次成功实现了仅使用ECG的多身体活动分类，为开发下一代可穿戴设备提供了重要潜力，这些设备能够同时进行心脏监测和活动识别，无需额外的运动传感器。

Abstract: Human activity recognition is critical for applications such as early
intervention and health analytics. Traditional activity recognition relies on
inertial measurement units (IMUs), which are resource intensive and require
calibration. Although electrocardiogram (ECG)-based methods have been explored,
these have typically served as supplements to IMUs or have been limited to
broad categorical classification such as fall detection or active vs. inactive
in daily activities. In this paper, we advance the field by demonstrating, for
the first time, robust recognition of activity only with ECG in six distinct
activities, which is beyond the scope of previous work. We design and evaluate
three new deep learning models, including a CNN classifier with
Squeeze-and-Excitation blocks for channel-wise feature recalibration, a ResNet
classifier with dilated convolutions for multiscale temporal dependency
capture, and a novel CNNTransformer hybrid combining convolutional feature
extraction with attention mechanisms for long-range temporal relationship
modeling. Tested on data from 54 subjects for six activities, all three models
achieve over 94% accuracy for seen subjects, while CNNTransformer hybrid
reaching the best accuracy of 72% for unseen subjects, a result that can be
further improved by increasing the training population. This study demonstrates
the first successful ECG-only activity classification in multiple physical
activities, offering significant potential for developing next-generation
wearables capable of simultaneous cardiac monitoring and activity recognition
without additional motion sensors.

</details>


### [21] [LibEMER: A novel benchmark and algorithms library for EEG-based Multimodal Emotion Recognition](https://arxiv.org/abs/2509.19330)
*Zejun Liu,Yunshan Chen,Chengxi Xie,Huan Liu*

Main category: eess.SP

TL;DR: 本文介绍了LibEMER，一个用于EEG多模态情感识别的开源评估框架，旨在解决该领域缺乏开源实现、标准化基准和深入讨论的问题。


<details>
  <summary>Details</summary>
Motivation: EEG多模态情感识别领域存在三个关键问题：缺乏开源实现、缺少标准化透明基准、缺乏对主要挑战和未来方向的深入讨论。

Method: 开发了LibEMER框架，提供可复现的PyTorch实现，包含标准化的数据预处理、模型实现和实验设置协议。

Result: 该框架在三个广泛使用的公共数据集和两个学习任务上实现了无偏性能评估。

Conclusion: LibEMER为EEG多模态情感识别研究提供了统一的评估平台，有助于推动该领域的标准化发展。

Abstract: EEG-based multimodal emotion recognition(EMER) has gained significant
attention and witnessed notable advancements, the inherent complexity of human
neural systems has motivated substantial efforts toward multimodal approaches.
However, this field currently suffers from three critical limitations: (i) the
absence of open-source implementations. (ii) the lack of standardized and
transparent benchmarks for fair performance analysis. (iii) in-depth discussion
regarding main challenges and promising research directions is a notable
scarcity. To address these challenges, we introduce LibEMER, a unified
evaluation framework that provides fully reproducible PyTorch implementations
of curated deep learning methods alongside standardized protocols for data
preprocessing, model realization, and experimental setups. This framework
enables unbiased performance assessment on three widely-used public datasets
across two learning tasks. The open-source library is publicly accessible at:
https://anonymous.4open.science/r/2025ULUIUBUEUMUEUR485384

</details>


### [22] [Holographic Transformers for Complex-Valued Signal Processing: Integrating Phase Interference into Self-Attention](https://arxiv.org/abs/2509.19331)
*Enhao Huang,Zhiyu Zhang,Tianxiang Xu,Chunshu Xia,Kaichun Hu,Yuchen Yang,Tongtong Pan,Dong Dong,Zhan Qin*

Main category: eess.SP

TL;DR: Holographic Transformer是一种受物理启发的架构，将波干涉原理融入自注意力机制，通过相对相位调制交互并相干叠加值，确保幅度和相位的一致性。


<details>
  <summary>Details</summary>
Motivation: 大多数深度学习模型将注意力视为实值相关性，忽略了干涉效应，而复数信号同时编码幅度和相位信息。

Method: 引入全息注意力机制，通过相对相位调制交互并相干叠加值；采用双头解码器同时重建输入和预测任务输出，防止相位崩溃。

Result: 在PolSAR图像分类和无线信道预测任务中表现出色，实现了高分类精度和F1分数、低回归误差，以及对相位扰动的强鲁棒性。

Conclusion: 在注意力中强制执行物理一致性可以带来复数学习中的可泛化改进，为相干信号建模提供了一个统一的物理基础框架。

Abstract: Complex-valued signals encode both amplitude and phase, yet most deep models
treat attention as real-valued correlation, overlooking interference effects.
We introduce the Holographic Transformer, a physics-inspired architecture that
incorporates wave interference principles into self-attention. Holographic
attention modulates interactions by relative phase and coherently superimposes
values, ensuring consistency between amplitude and phase. A dual-headed decoder
simultaneously reconstructs the input and predicts task outputs, preventing
phase collapse when losses prioritize magnitude over phase. We demonstrate that
holographic attention implements a discrete interference operator and maintains
phase consistency under linear mixing. Experiments on PolSAR image
classification and wireless channel prediction show strong performance,
achieving high classification accuracy and F1 scores, low regression error, and
increased robustness to phase perturbations. These results highlight that
enforcing physical consistency in attention leads to generalizable improvements
in complex-valued learning and provides a unified, physics-based framework for
coherent signal modeling. The code is available at
https://github.com/EonHao/Holographic-Transformers.

</details>


### [23] [A Spatio-Temporal Feature Fusion EEG Virtual Channel Signal Generation Network and Its Application in Anxiety Assessment](https://arxiv.org/abs/2509.19334)
*Shangqing Yuan,Wenshuang Zhai,Shengwen Guo*

Main category: eess.SP

TL;DR: 本研究提出了一种基于时空特征融合的EEG虚拟通道信号生成网络，旨在解决便携式EEG设备通道有限的问题，通过4个额叶通道生成13个重要脑区的虚拟EEG信号。


<details>
  <summary>Details</summary>
Motivation: 解决便携式EEG设备通道有限、信息采集不足的问题，通过虚拟通道技术扩展脑电信号采集能力。

Method: 采用二维卷积神经网络架构，包含并行时空特征提取模块和特征融合模块，使用PRED+CT数据库的119名受试者多通道EEG数据进行验证。

Result: 生成的虚拟通道EEG信号与原始真实信号的平均相关系数为0.6724，平均绝对误差为3.9470；结合原始信号用于焦虑分类时显著提升了机器学习算法性能。

Conclusion: 该网络生成的虚拟EEG信号与真实信号具有高度一致性，能有效增强便携式EEG设备的信息获取能力，提升焦虑分类性能。

Abstract: To address the issue of limited channels and insufficient information
collection in portable EEG devices, this study explores an EEG virtual channel
signal generation network using a novel spatio-temporal feature fusion
strategy. Based on the EEG signals from four frontal lobe channels, the network
aims to generate virtual channel EEG signals for other 13 important brain
regions. The architecture of the network is a two-dimensional convolutional
neural network and it includes a parallel module for temporal and spatial
domain feature extraction, followed by a feature fusion module. The public
PRED+CT database, which includes multi-channel EEG signals from 119 subjects,
was selected to verify the constructed network. The results showed that the
average correlation coefficient between the generated virtual channel EEG
signals and the original real signals was 0.6724, with an average absolute
error of 3.9470. Furthermore, the 13 virtual channel EEG signals were combined
with the original EEG signals of four brain regions and then used for anxiety
classification with a support vector machine. The results indicate that the
virtual EEG signals generated by the constructed network not only have a high
degree of consistency with the real channel EEG signals but also significantly
enhance the performance of machine learning algorithms for anxiety
classification. This study effectively alleviates the problem of insufficient
information acquisition by portable EEG devices with few channels.

</details>


### [24] [CSIYOLO: An Intelligent CSI-based Scatter Sensing Framework for Integrated Sensing and Communication Systems](https://arxiv.org/abs/2509.19335)
*Xudong Zhang,Jingbo Tan,Zhizhen Ren,Jintao Wang,Yihua Ma,Jian Song*

Main category: eess.SP

TL;DR: CSIYOLO是一个基于CSI的散射体定位框架，仅使用单基站-用户设备对的CSI估计，无需修改波形或硬件，实现了高精度的散射体定位。


<details>
  <summary>Details</summary>
Motivation: 现有ISAC散射感知方法依赖波形/硬件修改或传统信号处理，导致与当前通信系统兼容性差且感知精度有限。

Method: 提出锚点式散射参数检测方法（基于YOLO架构），将散射参数提取建模为图像检测问题，然后推导CSI定位算法确定散射体位置，并设计可扩展网络结构和噪声注入训练策略。

Result: 实验表明该方法在不同散射体数量和估计误差下，显著优于现有方法，具有较低复杂度。

Conclusion: CSIYOLO可作为插件无缝集成到现有通信系统中，实现了高精度散射定位而不需要系统修改。

Abstract: ISAC is regarded as a promising technology for next-generation communication
systems, enabling simultaneous data transmission and target sensing. Among
various tasks in ISAC, scatter sensing plays a crucial role in exploiting the
full potential of ISAC and supporting applications such as autonomous driving
and low-altitude economy. However, most existing methods rely on either
waveform and hardware modifications or traditional signal processing schemes,
leading to poor compatibility with current communication systems and limited
sensing accuracy. To address these challenges, we propose CSIYOLO, a framework
that performs scatter localization only using estimated CSI from a single base
station-user equipment pair. This framework comprises two main components:
anchor-based scatter parameter detection and CSI-based scatter localization.
First, by formulating scatter parameter extraction as an image detection
problem, we propose an anchor-based scatter parameter detection method inspired
by You Only Look Once architectures. After that, a CSI-based localization
algorithm is derived to determine scatter locations with extracted parameters.
Moreover, to improve localization accuracy and implementation efficiency, we
design an extendable network structure with task-oriented optimizations,
enabling multi-scale anchor detection and better adaptation to CSI
characteristics. A noise injection training strategy is further designed to
enhance robustness against channel estimation errors. Since the proposed
framework operates solely on estimated CSI without modifying waveforms or
signal processing pipelines, it can be seamlessly integrated into existing
communication systems as a plugin. Experiments show that our proposed method
can significantly outperform existing methods in scatter localization accuracy
with relatively low complexities under varying numbers of scatters and
estimation errors.

</details>


### [25] [Low-Cost Sensor Fusion Framework for Organic Substance Classification and Quality Control Using Classification Methods](https://arxiv.org/abs/2509.19367)
*Borhan Uddin Chowdhury,Damian Valles,Md Raf E Ul Shougat*

Main category: eess.SP

TL;DR: 提出基于Arduino Mega 2560微控制器的传感器融合框架，结合机器学习方法实现有机物质的快速无损分类和质量控制


<details>
  <summary>Details</summary>
Motivation: 开发低成本、非破坏性的有机物质分类和质量控制方法，解决传统检测方法的局限性

Method: 使用三个商用环境传感器采集10种有机物质数据，采用相关性分析进行特征选择，应用PCA/LDA降维，训练SVM、决策树、随机森林、ANN和集成投票分类器

Result: 最优模型（调优随机森林、集成分类器和ANN）在测试集上达到93-94%的准确率

Conclusion: 基于Arduino的低成本多传感器平台结合机器学习和相关性驱动的特征工程，能够可靠地识别有机化合物并进行质量控制

Abstract: We present a sensor-fusion framework for rapid, non-destructive
classification and quality control of organic substances, built on a standard
Arduino Mega 2560 microcontroller platform equipped with three commercial
environmental and gas sensors. All data used in this study were generated
in-house: sensor outputs for ten distinct classes - including fresh and expired
samples of apple juice, onion, garlic, and ginger, as well as cinnamon and
cardamom - were systematically collected and labeled using this hardware setup,
resulting in a unique, application-specific dataset. Correlation analysis was
employed as part of the preprocessing pipeline for feature selection. After
preprocessing and dimensionality reduction (PCA/LDA), multiple supervised
learning models - including Support Vector Machine (SVM), Decision Tree (DT),
and Random Forest (RF), each with hyperparameter tuning, as well as an
Artificial Neural Network (ANN) and an ensemble voting classifier - were
trained and cross-validated on the collected dataset. The best-performing
models, including tuned Random Forest, ensemble, and ANN, achieved test
accuracies in the 93 to 94 percent range. These results demonstrate that
low-cost, multisensory platforms based on the Arduino Mega 2560, combined with
advanced machine learning and correlation-driven feature engineering, enable
reliable identification and quality control of organic compounds.

</details>


### [26] [Short-Term Regional Electricity Demand Forecasting in Argentina Using LSTM Networks](https://arxiv.org/abs/2509.19374)
*Oscar A. Oviedo*

Main category: eess.SP

TL;DR: 本研究开发并优化了基于LSTM网络的深度学习模型，用于预测阿根廷科尔多瓦的短期小时电力需求，整合历史消费数据和外部变量，取得了高预测精度。


<details>
  <summary>Details</summary>
Motivation: 为电网运营商提供优化的规划和控制策略，需要准确预测短期电力需求，特别是在考虑季节性模式和极端消费事件的情况下。

Method: 使用LSTM网络整合历史消费数据、气候因素、时间周期和人口统计等外部变量，进行模型设计和超参数优化，并辅以随机森林回归的可解释性研究和每日需求极值时间预测评估。

Result: 模型预测精度高，平均绝对百分比误差为3.20%，决定系数为0.95；在预测每日需求极值时间方面，超过三分之二的测试日达到精确小时准确度，90%以上案例误差在1小时内。

Conclusion: 该框架不仅具有高预测准确性，还具有操作相关性，为电网运营商在不同需求场景下提供了有价值的见解。

Abstract: This study presents the development and optimization of a deep learning model
based on Long Short-Term Memory (LSTM) networks to predict short-term hourly
electricity demand in C\'ordoba, Argentina. Integrating historical consumption
data with exogenous variables (climatic factors, temporal cycles, and
demographic statistics), the model achieved high predictive precision, with a
mean absolute percentage error of 3.20\% and a determination coefficient of
0.95. The inclusion of periodic temporal encodings and weather variables proved
crucial to capture seasonal patterns and extreme consumption events, enhancing
the robustness and generalizability of the model. In addition to the design and
hyperparameter optimization of the LSTM architecture, two complementary
analyses were carried out: (i) an interpretability study using Random Forest
regression to quantify the relative importance of exogenous drivers, and (ii)
an evaluation of model performance in predicting the timing of daily demand
maxima and minima, achieving exact-hour accuracy in more than two-thirds of the
test days and within abs(1) hour in over 90\% of cases. Together, these results
highlight both the predictive accuracy and operational relevance of the
proposed framework, providing valuable insights for grid operators seeking
optimized planning and control strategies under diverse demand scenarios.

</details>


### [27] [Data-Driven Reconstruction of Significant Wave Heights from Sparse Observations](https://arxiv.org/abs/2509.19384)
*Hongyuan Shi,Yilin Zhai,Ping Dong,Zaijin You,Chao Zhan,Qing Wang*

Main category: eess.SP

TL;DR: AUWave是一种混合深度学习框架，用于从稀疏浮标观测数据重建高分辨率区域有效波高场，通过多尺度U-Net和自注意力机制提升重建精度。


<details>
  <summary>Details</summary>
Motivation: 解决从稀疏不均匀的浮标观测数据重建高分辨率区域有效波高场的核心挑战，为海洋监测和风险评估提供支持。

Method: 结合站点序列编码器（MLP）和多尺度U-Net，使用瓶颈自注意力层恢复32×32区域有效波高场，通过贝叶斯超参数搜索优化学习率等关键参数。

Result: 在夏威夷区域的NDBC浮标观测和ERA5再分析数据上，验证损失最低为0.043285，空间误差在观测点附近最低，随距离增加而增大。

Conclusion: AUWave在数据较丰富配置下显著优于基线方法，多尺度和注意力组件在最小但非平凡空间锚定可用时带来精度提升，为网络设计提供可操作指导。

Abstract: Reconstructing high-resolution regional significant wave height fields from
sparse and uneven buoy observations remains a core challenge for ocean
monitoring and risk-aware operations. We introduce AUWave, a hybrid deep
learning framework that fuses a station-wise sequence encoder (MLP) with a
multi-scale U-Net enhanced by a bottleneck self-attention layer to recover
32$\times$32 regional SWH fields. A systematic Bayesian hyperparameter search
with Optuna identifies the learning rate as the dominant driver of
generalization, followed by the scheduler decay and the latent dimension. Using
NDBC buoy observations and ERA5 reanalysis over the Hawaii region, AUWave
attains a minimum validation loss of 0.043285 and a slightly right-skewed RMSE
distribution. Spatial errors are lowest near observation sites and increase
with distance, reflecting identifiability limits under sparse sampling.
Sensitivity experiments show that AUWave consistently outperforms a
representative baseline in data-richer configurations, while the baseline is
only marginally competitive in the most underdetermined single-buoy cases. The
architecture's multi-scale and attention components translate into accuracy
gains when minimal but non-trivial spatial anchoring is available. Error maps
and buoy ablations reveal key anchor stations whose removal disproportionately
degrades performance, offering actionable guidance for network design. AUWave
provides a scalable pathway for gap filling, high-resolution priors for data
assimilation, and contingency reconstruction.

</details>


### [28] [A Statistical Mixture-of-Experts Framework for EMG Artifact Removal in EEG: Empirical Insights and a Proof-of-Concept Application](https://arxiv.org/abs/2509.19385)
*Benjamin J. Choi,Griffin Milsap,Clara A. Scholl,Francesco Tenore,Mattson Ogg*

Main category: eess.SP

TL;DR: 本文提出了一种基于混合专家（MoE）框架的脑电图（EEG）去噪算法，专门针对高噪声环境下的肌电（EMG）伪影去除问题。该算法通过三个新的统计洞察和CNN-RNN网络组合，在EEGdenoiseNet数据集上实现了与现有最优方法竞争的整体性能，并在高噪声环境下表现出更优的下界性能。


<details>
  <summary>Details</summary>
Motivation: 当前神经接口控制受限于信号质量差的问题。虽然基于神经网络的EEG去噪方法近年来有所改进，但在高噪声环境下现有最优模型表现不佳。需要开发更有效的EMG伪影去除算法来提升神经接口的性能。

Method: 提出了基于混合专家（MoE）框架的信号滤波算法，包含三个关键创新：1）将EMG伪影划分为可量化的子类型以辅助MoE分类；2）在较窄信噪比范围内训练局部专家实现专业化提升；3）使用基于相关性的目标函数和重缩放算法加速神经网络收敛。算法结合了卷积神经网络（CNN）和循环神经网络（RNN）。

Result: 在包含67名受试者的EEGdenoiseNet基准数据集上进行测试，MoE去噪模型与现有最优机器学习去噪算法相比具有竞争性的整体性能，并在高噪声环境下表现出更优的下界性能。

Conclusion: 该MoE框架在EMG伪影去除方面显示出良好前景，特别是在高噪声环境下。未来需要进一步研究以评估该框架在更广泛真实场景中的应用潜力，探索其解锁更有效神经接口的下游潜力。

Abstract: Effective control of neural interfaces is limited by poor signal quality.
While neural network-based electroencephalography (EEG) denoising methods for
electromyogenic (EMG) artifacts have improved in recent years, current
state-of-the-art (SOTA) models perform suboptimally in settings with high
noise. To address the shortcomings of current machine learning (ML)-based
denoising algorithms, we present a signal filtration algorithm driven by a new
mixture-of-experts (MoE) framework. Our algorithm leverages three new
statistical insights into the EEG-EMG denoising problem: (1) EMG artifacts can
be partitioned into quantifiable subtypes to aid downstream MoE classification,
(2) local experts trained on narrower signal-to-noise ratio (SNR) ranges can
achieve performance increases through specialization, and (3) correlation-based
objective functions, in conjunction with rescaling algorithms, can enable
faster convergence in a neural network-based denoising context. We empirically
demonstrate these three insights into EMG artifact removal and use our findings
to create a new downstream MoE denoising algorithm consisting of convolutional
(CNN) and recurrent (RNN) neural networks. We tested all results on a major
benchmark dataset (EEGdenoiseNet) collected from 67 subjects. We found that our
MoE denoising model achieved competitive overall performance with SOTA ML
denoising algorithms and superior lower bound performance in high noise
settings. These preliminary results highlight the promise of our MoE framework
for enabling advances in EMG artifact removal for EEG processing, especially in
high noise settings. Further research and development will be necessary to
assess our MoE framework on a wider range of real-world test cases and explore
its downstream potential to unlock more effective neural interfaces.

</details>


### [29] [Hybrid Pipeline SWD Detection in Long-Term EEG Signals](https://arxiv.org/abs/2509.19387)
*Antonio Quintero Rincon,Nicolas Masino,Veronica Marsico,Hadj Batatia*

Main category: eess.SP

TL;DR: 提出了一种轻量级混合管道，结合分析特征和浅层人工神经网络，用于在长期单极脑电图中准确检测棘慢波放电（SWD），实现高灵敏度和特异性。


<details>
  <summary>Details</summary>
Motivation: 棘慢波放电是失神癫痫的脑电图标志，但在多天记录中手动识别既费时又容易出错，需要自动化检测方法。

Method: 使用双边移动平均滤波器抑制正常背景活动的高频成分，然后计算残差信号的均值和标准差作为二维特征向量，输入单隐藏层人工神经网络进行分类。

Result: 在12名患者的780个通道上评估，正确检测384个事件（灵敏度98%），特异性96.2%，总体准确率97.2%。

Conclusion: 正态分布描述符结合小型神经网络为扩展脑电图记录中的自动SWD筛查提供了有效且计算成本低的解决方案。

Abstract: Spike-and-wave discharges (SWDs) are the electroencephalographic hallmark of
absence epilepsy, yet their manual identification in multi-day recordings
remains labour-intensive and error-prone. We present a lightweight hybrid
pipeline that couples analytical features with a shallow artificial neural
network (ANN) for accurate, patient-specific SWD detection in long-term,
monopolar EEG. A two-sided moving-average (MA) filter first suppresses the
high-frequency components of normal background activity. The residual signal is
then summarised by the mean and the standard deviation of its normally
distributed samples, yielding a compact, two-dimensional feature vector for
every 20s window. These features are fed to a single-hidden-layer ANN trained
via back-propagation to classify each window as SWD or non-SWD. The method was
evaluated on 780 channels sampled at 256 Hz from 12 patients, comprising 392
annotated SWD events. It correctly detected 384 events (sensitivity: 98%) while
achieving a specificity of 96.2 % and an overall accuracy of 97.2%. Because
feature extraction is analytic, and the classifier is small, the pipeline runs
in real-time and requires no manual threshold tuning. These results indicate
that normal-distribution descriptors combined with a modest ANN provide an
effective and computationally inexpensive solution for automated SWD screening
in extended EEG recordings.

</details>


### [30] [Self-Alignment Learning to Improve Myocardial Infarction Detection from Single-Lead ECG](https://arxiv.org/abs/2509.19397)
*Jiarui Jin,Xiaocheng Fang,Haoyu Wang,Jun Li,Che Liu,Donglin Xie,Hongyan Li,Shenda Hong*

Main category: eess.SP

TL;DR: SelfMIS是一种通过潜在空间对齐来改进单导联心电图心肌梗死检测的框架，通过自切割策略将多导联心电图与对应的单导联片段配对，直接在潜在空间中对齐，从而丰富单导联表示。


<details>
  <summary>Details</summary>
Motivation: 单导联心电图检测心肌梗死具有挑战性，因为空间信息有限。传统方法在信号级别优化生成方法存在潜在空间差距，影响诊断性能。需要探索潜在空间对齐是否能帮助解决这一问题。

Method: 提出SelfMIS框架，摒弃手动数据增强，采用自切割策略将多导联心电图与对应的单导联片段配对，直接在潜在空间中对齐，使单导联心电图编码器能够从局部信号推断全局心脏上下文。

Result: 实验表明，SelfMIS在九种心肌梗死类型上均优于基线模型，同时保持更简单的架构和更低的计算开销。

Conclusion: 直接潜在空间对齐在改进单导联心电图心肌梗死检测方面具有显著效果，SelfMIS框架简单有效，验证了该方法的高效性。

Abstract: Myocardial infarction is a critical manifestation of coronary artery disease,
yet detecting it from single-lead electrocardiogram (ECG) remains challenging
due to limited spatial information. An intuitive idea is to convert single-lead
into multiple-lead ECG for classification by pre-trained models, but generative
methods optimized at the signal level in most cases leave a large latent space
gap, ultimately degrading diagnostic performance. This naturally raises the
question of whether latent space alignment could help. However, most prior ECG
alignment methods focus on learning transformation invariance, which mismatches
the goal of single-lead detection. To address this issue, we propose SelfMIS, a
simple yet effective alignment learning framework to improve myocardial
infarction detection from single-lead ECG. Discarding manual data
augmentations, SelfMIS employs a self-cutting strategy to pair multiple-lead
ECG with their corresponding single-lead segments and directly align them in
the latent space. This design shifts the learning objective from pursuing
transformation invariance to enriching the single-lead representation,
explicitly driving the single-lead ECG encoder to learn a representation
capable of inferring global cardiac context from the local signal.
Experimentally, SelfMIS achieves superior performance over baseline models
across nine myocardial infarction types while maintaining a simpler
architecture and lower computational overhead, thereby substantiating the
efficacy of direct latent space alignment. Our code and checkpoint will be
publicly available after acceptance.

</details>


### [31] [SpellerSSL: Self-Supervised Learning with P300 Aggregation for Speller BCIs](https://arxiv.org/abs/2509.19401)
*Jiazhen Hong,Geoff Mackellar,Soheila Ghane*

Main category: eess.SP

TL;DR: SpellerSSL框架结合自监督学习和P300聚合技术，解决了EEG P300拼写器的低信噪比、泛化性差和校准耗时三大挑战，显著提高了字符识别率和信息传输率。


<details>
  <summary>Details</summary>
Motivation: 解决EEG P300拼写器面临的三个主要挑战：低信噪比(SNR)、泛化性差以及耗时的校准过程。

Method: 1. 引入P300聚合策略增强信噪比；2. 使用定制的1D U-Net骨干网络，在跨域和域内EEG数据上进行预训练；3. 通过轻量级ERP-Head分类器进行微调，适应特定被试数据。

Result: 在II-B公开数据集上，域内自监督学习实现了94%的字符识别率（仅需7次重复）和21.86 bits/min的最高信息传输率。P300聚合将所需校准数据量减少60%，同时保持可比的识别性能。

Conclusion: 这是首个将自监督学习应用于P300拼写器的研究，展示了其在提高拼写器BCI效率和泛化性方面的潜力，为P300拼写器BCI的EEG基础模型铺平了道路。

Abstract: Electroencephalogram (EEG)-based P300 speller brain-computer interfaces
(BCIs) face three main challenges: low signal-to-noise ratio (SNR), poor
generalization, and time-consuming calibration. We propose SpellerSSL, a
framework that combines self-supervised learning (SSL) with P300 aggregation to
address these issues. First, we introduce an aggregation strategy to enhance
SNR. Second, to achieve generalization in training, we employ a customized 1D
U-Net backbone and pretrain the model on both cross-domain and in-domain EEG
data. The pretrained model is subsequently fine-tuned with a lightweight
ERP-Head classifier for P300 detection, which adapts the learned
representations to subject-specific data. Our evaluations on calibration time
demonstrate that combining the aggregation strategy with SSL significantly
reduces the calibration burden per subject and improves robustness across
subjects. Experimental results show that SSL learns effective EEG
representations in both in-domain and cross-domain, with in-domain achieving a
state-of-the-art character recognition rate of 94% with only 7 repetitions and
the highest information transfer rate (ITR) of 21.86 bits/min on the public
II-B dataset. Moreover, in-domain SSL with P300 aggregation reduces the
required calibration size by 60% while maintaining a comparable character
recognition rate. To the best of our knowledge, this is the first study to
apply SSL to P300 spellers, highlighting its potential to improve both
efficiency and generalization in speller BCIs and paving the way toward an EEG
foundation model for P300 speller BCIs.

</details>


### [32] [Online Adaptation via Dual-Stage Alignment and Self-Supervision for Fast-Calibration Brain-Computer Interfaces](https://arxiv.org/abs/2509.19403)
*Sheng-Bin Duan,Jian-Long Hao,Tian-Yu Xiang,Xiao-Hu Zhou,Mei-Jiang Gui,Xiao-Liang Xie,Shi-Qi Liu,Zeng-Guang Hou*

Main category: eess.SP

TL;DR: 该研究提出了一种针对未见受试者的在线自适应算法，通过双阶段对齐和自监督学习来解决脑电图（EEG）脑机接口（BCI）系统中个体差异的问题。


<details>
  <summary>Details</summary>
Motivation: 脑电图脑机接口系统中个体大脑活动的差异阻碍了其在线应用，需要一种能够快速适应新受试者的方法。

Method: 采用双阶段对齐方法：先在EEG数据空间进行欧几里得对齐，然后在表示空间更新批归一化统计量。同时设计自监督损失函数，使用解码器生成的软伪标签作为未知真实标签的代理，并通过香农熵校准以促进自监督训练。

Result: 在五个公共数据集和七个解码器上的实验表明，该算法可以无缝集成到不同的BCI范式和解码器架构中。每次迭代只需一个在线试验即可更新解码器，在稳态视觉诱发电位（SSVEP）上平均准确率提升4.9%，在运动想象上提升3.6%。

Conclusion: 该算法支持快速校准操作，在BCI应用中具有巨大潜力，能够有效解决个体差异问题。

Abstract: Individual differences in brain activity hinder the online application of
electroencephalogram (EEG)-based brain computer interface (BCI) systems. To
overcome this limitation, this study proposes an online adaptation algorithm
for unseen subjects via dual-stage alignment and self-supervision. The
alignment process begins by applying Euclidean alignment in the EEG data space
and then updates batch normalization statistics in the representation space.
Moreover, a self-supervised loss is designed to update the decoder. The loss is
computed by soft pseudo-labels derived from the decoder as a proxy for the
unknown ground truth, and is calibrated by Shannon entropy to facilitate
self-supervised training. Experiments across five public datasets and seven
decoders show the proposed algorithm can be integrated seamlessly regardless of
BCI paradigm and decoder architecture. In each iteration, the decoder is
updated with a single online trial, which yields average accuracy gains of 4.9%
on steady-state visual evoked potentials (SSVEP) and 3.6% on motor imagery.
These results support fast-calibration operation and show that the proposed
algorithm has great potential for BCI applications.

</details>


### [33] [Insights into Xona Pulsar LEO PNT: Constellation, Signals, and Receiver Design](https://arxiv.org/abs/2509.19551)
*Jérôme Leclère,Thyagaraja Marathe,Tyler G. R. Reid*

Main category: eess.SP

TL;DR: 本文分析了低地球轨道（LEO）卫星导航系统Pulsar的特性，通过与GPS对比，探讨了LEO系统对接收机设计的影响，并提出了优化策略以减少捕获时间和功耗。


<details>
  <summary>Details</summary>
Motivation: 随着LEO星座如Pulsar在导航系统中的重要性增加，需要理解其信号特性和星座几何变化对接收机设计的影响，以充分利用LEO系统的优势（如强信号、快速动态特性）。

Method: 使用GNSS模拟器分析Pulsar的参数（卫星通过时间、仰角、多普勒频移、多普勒变化率、距离和可见卫星数），进行时间演化、统计分布和极值分析，并在不同纬度进行评估。

Result: LEO系统相比GPS具有更短的卫星通过时间、更高的多普勒频移和变化率，以及独特的星座结构，这些特性对接收机设计提出了新的挑战。

Conclusion: 通过优化采集策略（如利用参数间依赖关系）和应用预测与优先级技术，可以显著减少捕获时间并降低接收机功耗，为LEO导航系统的接收机设计提供了重要指导。

Abstract: The landscape of global navigation satellite systems (GNSS) is expanding with
the emergence of low Earth orbit (LEO) constellations such as Pulsar, which are
expected to play a key role in the future of positioning, navigation, and
timing (PNT). LEO-based systems provide advantages including stronger signals
for greater robustness, faster dynamics that aid convergence and multipath
mitigation, and shorter time to first fix (TTFF) enabled by high data rates.
These benefits, however, come with changes in signal behavior and constellation
geometry that require careful consideration in receiver design. This paper
investigates Pulsar properties using a GNSS simulator, analyzing parameters
such as satellite pass duration, elevation, Doppler shift, Doppler rate, range,
and number of satellites in view. Comparisons with GPS highlight the
differences introduced by LEO operation. The analysis examines temporal
evolution, statistical distributions, and maximum and minimum values. Beyond
these statistical insights, the study explores interdependencies between
parameters and differences across satellites, providing additional perspective.
Evaluations are performed at multiple latitudes to ensure a worldwide
perspective, and the impact of applying different elevation masks is discussed
where relevant. Building on these findings, the paper assesses Pulsar's impact
on receiver design from two standpoints: design considerations, addressing
expanded Doppler ranges, higher Doppler rates, and unique constellation
structure; and design optimizations, exploiting parameter analyses and
interdependencies (e.g., Doppler rate vs Doppler) to refine acquisition
strategies and applying prediction and prioritization techniques to avoid
unnecessary computations. Together, these optimizations can reduce acquisition
time and lower receiver power consumption.

</details>


### [34] [DNN-Based Nulling Control Beam Focusing for Near-Field Multi-User Interference Mitigation](https://arxiv.org/abs/2509.19594)
*Mohammadhossein Karimi,Yuanzhe Gong,Tho Le-Ngoc*

Main category: eess.SP

TL;DR: 提出基于深度学习的近场零陷控制波束聚焦框架，用于超大规模MIMO系统中的多用户干扰抑制


<details>
  <summary>Details</summary>
Motivation: 解决超大规模MIMO系统中多用户干扰问题，实现实时有效的波束聚焦和干扰抑制

Method: 开发双估计器架构，包含两个全连接深度神经网络，分别预测NCBF权重的相位和幅度分量，使用期望用户和干扰用户的位置信息

Result: DNN模型预测精度高，相位估计误差0.067弧度，幅度估计误差0.206dB，平均MUI抑制达36.7dB，所有测试案例干扰抑制均超过17.5dB

Conclusion: 该方法能够实现可扩展的实时波束聚焦和有效干扰抑制，为未来近场多用户无线通信提供了有前景的解决方案

Abstract: This paper proposes a deep learning-based framework for near-field nulling
control beam focusing (NCBF) in extra-large MIMO (XL-MIMO) systems to mitigate
multi-user interference (MUI). A dual-estimator architecture comprising two
fully connected deep neural networks (FCDNNs) is developed to separately
predict the phase and magnitude components of NCBF weights, using locations of
both desired and interfering users. The models are trained on a large dataset
generated via a Linearly Constrained Minimum Variance (LCMV) beamforming
algorithm to accommodate diverse user configurations, including both collinear
and non-collinear scenarios. Illustrative results demonstrate that the proposed
DNN models achieve high prediction accuracy, with test errors of only 0.067
radians for phase estimation and 0.206 dB for magnitude estimation. Full-wave
simulations incorporating realistic element radiation patterns and
inter-element coupling confirm the close agreement between the beam patterns
produced by the DNN-predicted and LCMV-based NCBF schemes under practical
deployment conditions. An average MUI suppression of 36.7 dB is achieved, with
interference mitigation exceeding 17.5 dB across all tested cases. The proposed
approach enables scalable and real-time beam focusing with effective
interference suppression, offering a promising solution for future near-field
multi-user wireless communications.

</details>


### [35] [Non-locally averaged pruned reassigned spectrograms: a tool for glottal pulse visualization and analysis](https://arxiv.org/abs/2509.19686)
*Gabriel J. Griswold,Mark A. Griswold*

Main category: eess.SP

TL;DR: 提出了一种改进的重分配谱图方法NAPReS，通过堆叠、求和和修剪大量声门脉冲来简化说话人声门脉冲模式的视觉化，在高噪声环境下比传统LPC方法更具可重复性。


<details>
  <summary>Details</summary>
Motivation: 传统重分配谱图虽然具有精确的共振峰测量和说话人区分优势，但无法以易于理解和可重复的方式可视化大量数据。

Method: 开发了非局部平均修剪重分配谱图(NAPReS)，通过堆叠、求和和修剪大量声门脉冲来简化数据可视化，并结合高斯混合模型(GMM)进行共振峰拟合。

Result: NAPReS能够以易于理解和量化的方式显示大量数据，使低振幅循环结构的观察更加容易，在高噪声情况下比传统LPC拟合更具可重复性。

Conclusion: NAPReS方法为声门脉冲模式分析提供了简化的可视化工具，在高噪声环境下表现出比传统方法更好的性能，为语音分析提供了新的可能性。

Abstract: Reassigned spectrograms have shown advantages in precise formant measuring
and inter-speaker differentiation. However, reassigned spectrograms suffer from
their inability to visualize larger amounts of data in an easily comprehensible
and reproducible manner. Utilizing the techniques and tools developed by Fulop
and Fitz, a variation of the reassigned spectrogram is proposed. Non-locally
Averaged Pruned Reassigned Spectrograms (NAPReS) provide a simplified view into
the characteristics of a speaker's glottal pulsation patterns throughout the
centroid of a vowel through the stacking, summing, and pruning of large numbers
of glottal pulses. In this exploratory study, NAPReS has been shown to display
a large amount of data in an easily comprehensible and quantifiable manner,
while also making the observation of low-amplitude cyclical structures more
accessible. NAPReS also allows for alternative formant fitting methods such as
Gaussian mixture modeling. In this study, NAPReS with GMM was compared against
conventional LPC fitting of formant values and was shown to be more
reproducible than conventional LPC fitting in high-noise situations.

</details>


### [36] [Timeliness-Aware Joint Source and Channel Coding for Adaptive Image Transmission](https://arxiv.org/abs/2509.19754)
*Xiaolei Yang,Zijing Wang,Zhijin Qin,Xiaoming Tao*

Main category: eess.SP

TL;DR: 提出了一种基于价值信息(VoI)的自适应联合源信道编码方法，用于时间敏感应用中的图像传输，通过优化码长同时考虑重建质量和时效性。


<details>
  <summary>Details</summary>
Motivation: 现有无线系统带宽有限，难以同时满足高保真和低延迟的图像传输需求。语义通信通过传输目标导向的语义信息有望突破性能瓶颈。

Method: 设计自适应码长的JSCC框架，构建VoI最大化问题，并提出基于深度强化学习的算法来优化传输码长。

Result: 实验结果表明该方法在重建质量和时效性方面显著优于基线方案，特别是在低信噪比条件下表现优异。

Conclusion: 该方法为时间敏感无线网络中的高效鲁棒图像传输提供了有前景的解决方案。

Abstract: Accurate and timely image transmission is critical for emerging
time-sensitive applications such as remote sensing in satellite-assisted
Internet of Things. However, the bandwidth limitation poses a significant
challenge in existing wireless systems, making it difficult to fulfill the
requirements of both high-fidelity and low-latency image transmission. Semantic
communication is expected to break through the performance bottleneck by
focusing on the transmission of goal-oriented semantic information rather than
raw data. In this paper, we employ a new timeliness metric named the value of
information (VoI) and propose an adaptive joint source and channel coding
(JSCC) method for image transmission that simultaneously considers both
reconstruction quality and timeliness. Specifically, we first design a JSCC
framework for image transmission with adaptive code length. Next, we formulate
a VoI maximization problem by optimizing the transmission code length of the
adaptive JSCC under the reconstruction quality constraint. Then, a deep
reinforcement learning-based algorithm is proposed to solve the optimization
problem efficiently. Experimental results show that the proposed method
significantly outperforms baseline schemes in terms of reconstruction quality
and timeliness, particularly in low signal-to-noise ratio conditions, offering
a promising solution for efficient and robust image transmission in
time-sensitive wireless networks.

</details>


### [37] [Electromagnetics-Compliant Optimization of Dynamic Metasurface Antennas for Bistatic Sensing](https://arxiv.org/abs/2509.19801)
*Ioannis Gavras,George C. Alexandropoulos*

Main category: eess.SP

TL;DR: 本文提出了一种基于动态超表面天线（DMA）的优化传输方案，用于双基地感知。通过考虑物理约束（如互耦和波导损耗），设计了低复杂度的波束成形方法，在存在定位和同步不确定性的情况下仍能保持高定位精度。


<details>
  <summary>Details</summary>
Motivation: 现有DMA研究大多依赖理想化模型，忽略了超材料固有的结构约束和物理限制（如互耦效应和波导传播损耗）。本文旨在开发更符合实际物理约束的DMA优化方案。

Method: 1. 提出可处理的DMA响应近似模型；2. 构建鲁棒波束成形优化问题，最小化最坏情况位置误差界限；3. 设计两种低复杂度波束成形方法，基于新型波束码本进行离线搜索。

Result: 蒙特卡洛仿真表明：准确建模互耦效应对维持高定位性能至关重要；所提方法在定位和同步不确定性下，性能可与全数字和模拟方案相媲美，同时满足DMA结构约束。

Conclusion: 本文证明了在考虑实际物理约束的情况下，DMA能够实现高效的双基地感知，为下一代无线系统的低成本、可重构天线阵列架构提供了实用解决方案。

Abstract: Dynamic Metasurface Antennas (DMAs) are recently attracting considerable
research interests due to their potential to enable low-cost, reconfigurable,
and highly scalable antenna array architectures for next generation wireless
systems. However, most of the existing literature relies on idealized models
for the DMA operation, often overlooking critical structural and physical
constraints inherent to their constituent metamaterials. In this paper,
leveraging a recently proposed model for this antenna architecture
incorporating physically consistent modeling of mutual coupling and waveguide
propagation losses, we optimize DMA-based transmission for bistatic sensing. A
tractable approximation for the DMA response is first presented, which enables
efficient optimization of the dynamically reconfigurable Lorentzian-constrained
responses of the array's metamaterials. In particular, we formulate a robust
beamforming optimization problem with the objective to minimize the worst-case
position error bound, in the presence of spatial uncertainties for the
environment's scatterers as well as synchronization uncertainties at the analog
combining multi-antenna receiver. To address the resulting high computational
complexity due to the possibly excessive number of metamaterial-based antennas
and their operation constraints, two low complexity beamforming design
approaches are presented that perform offline searching over a novel beam
codebook. The accuracy of all presented DMA designs is assessed by means of
Monte Carlo simulations for various system parameters, confirming that
accurately modeling mutual coupling is essential for maintaining increased
localization performance. It is also shown that, even under positioning and
synchronization uncertainties, the proposed designs yield accuracy comparable
to their fully digital and analog counterparts, while adhering to the
structural DMA constraints.

</details>


### [38] [Generalized Nonnegative Structured Kruskal Tensor Regression](https://arxiv.org/abs/2509.19900)
*Xinjue Wang,Esa Ollila,Sergiy A. Vorobyov,Ammar Mian*

Main category: eess.SP

TL;DR: 本文提出了广义非负结构化Kruskal张量回归(NS-KTR)，这是一个通过模式特定的混合正则化和非负性约束来增强可解释性和性能的新型张量回归框架。


<details>
  <summary>Details</summary>
Motivation: 处理多维张量数据中的结构异质性，同时适应线性和逻辑回归公式，以应对不同的响应变量。

Method: 集成融合LASSO、总变差和岭正则化器，每个都针对特定的张量模式定制，并开发了基于交替方向乘子法(ADMM)的高效参数估计算法。

Result: 在合成信号和真实高光谱数据集上的综合实验表明，NS-KTR始终优于传统的张量回归方法。

Conclusion: 该框架能够在保持张量维度间不同结构特征的同时确保物理可解释性，使其特别适用于信号处理和高光谱图像分析应用。

Abstract: This paper introduces Generalized Nonnegative Structured Kruskal Tensor
Regression (NS-KTR), a novel tensor regression framework that enhances
interpretability and performance through mode-specific hybrid regularization
and nonnegativity constraints. Our approach accommodates both linear and
logistic regression formulations for diverse response variables while
addressing the structural heterogeneity inherent in multidimensional tensor
data. We integrate fused LASSO, total variation, and ridge regularizers, each
tailored to specific tensor modes, and develop an efficient alternating
direction method of multipliers (ADMM) based algorithm for parameter
estimation. Comprehensive experiments on synthetic signals and real
hyperspectral datasets demonstrate that NS-KTR consistently outperforms
conventional tensor regression methods. The framework's ability to preserve
distinct structural characteristics across tensor dimensions while ensuring
physical interpretability makes it especially suitable for applications in
signal processing and hyperspectral image analysis.

</details>


### [39] [Rotatable Antenna Enabled Spectrum Sharing: Joint Antenna Orientation and Beamforming Design](https://arxiv.org/abs/2509.19912)
*Xingxiang Peng,Qingqing Wu,Ziyuan Zheng,Wen Chen,Yanze Zhu,Ying Gao*

Main category: eess.SP

TL;DR: 该论文研究了可旋转天线在MISO干扰信道中的应用，通过联合优化发射波束成形和天线方向来最大化加权和速率，提出了交替优化框架和离散方向选择的交叉熵方法。


<details>
  <summary>Details</summary>
Motivation: 传统天线阵列通过增加元件数量来改善性能会导致硬件和功耗成本过高，可旋转天线通过调整元件方向引入新的自由度，在不扩大阵列规模的情况下提升空间灵活性。

Method: 采用交替优化框架，结合WMMSE波束成形和Frank-Wolfe方向更新；针对有限分辨率执行器，构建球面斐波那契码本并设计基于交叉熵方法的离散方向选择算法。

Result: 仿真表明，将可旋转天线与传统波束成形结合显著提高了加权和速率，增益随元件方向性增强而增加；在离散方向控制下，提出的CEM算法始终优于最近投影基线方法。

Conclusion: 可旋转天线为干扰信道中的空间控制提供了有效的解决方案，通过方向优化可以显著提升系统性能，特别是在高方向性天线场景下效果更佳。

Abstract: Conventional antenna arrays rely primarily on digital beamforming for spatial
control. While adding more elements can narrow beamwidth and suppress
interference, such scaling incurs prohibitive hardware and power costs.
Rotatable antennas (RAs), which allow mechanical or electronic adjustment of
element orientations, introduce a new degree of freedom to exploit spatial
flexibility without enlarging the array. By dynamically optimizing
orientations, RAs can substantially improve desired link alignment and
interference suppression. This paper investigates RA-enabled multiple-input
single-output (MISO) interference channels under co-channel spectrum sharing
and formulates a weighted sum-rate maximization problem that jointly optimizes
transmit beamforming and antenna orientations. To tackle this nonconvex
problem, we develop an alternating optimization (AO) framework that integrates
weighted minimum mean-square error (WMMSE)-based beamforming with
Frank-Wolfe-based orientation updates. To reduce complexity, we further study
orientation optimization under maximum-ratio transmission (MRT) and
zero-forcing (ZF) beamforming schemes. For finite-resolution actuators, we
construct spherical Fibonacci codebooks and design a cross-entropy method
(CEM)-based algorithm for discrete orientation selection. Simulations show that
integrating RAs with conventional beamforming markedly increases weighted
sum-rate, with gains rising with element directivity. Under discrete
orientation control, the proposed CEM algorithm consistently outperforms the
nearest-projection baseline.

</details>


### [40] [On the Invariance of Cross-Correlation Peak Positions Under Monotonic Signal Transformations, with Application to Fast Time Difference Estimation](https://arxiv.org/abs/2509.19974)
*Natsuki Ueno,Ryotaro Sato,Nobutaka Ono*

Main category: eess.SP

TL;DR: 本文提出了一种基于互相关峰值位置不变性定理的时间差估计新方法，该方法比传统的FFT方法更快，通过将信号量化为低比特整数并使用整数运算来提高计算效率。


<details>
  <summary>Details</summary>
Motivation: 传统基于FFT的时间差估计方法计算复杂度高，需要实数运算，限制了实时应用。本文旨在开发一种更快速的时间差估计算法。

Method: 利用互相关峰值位置在任意单调变换下保持不变的理论特性，将输入信号量化为低比特整数，设计基于整数运算的互相关函数估计算法。

Result: 数值实验表明，所提方法比传统FFT方法处理时间更短，计算效率更高。

Conclusion: 该理论结果为时间差估计提供了新的高效方法，特别适用于需要快速处理的实时应用场景。

Abstract: We present a theorem concerning the invariance of cross-correlation peak
positions, which provides a foundation for a new method for time difference
estimation that is potentially faster than the conventional fast Fourier
transform (FFT) approach for real/complex sequences. This theoretical result
shows that the peak position of the cross-correlation function between two
shifted discrete-time signals remains unchanged under arbitrary monotonic
transformations of the input signals. By exploiting this property, we design an
efficient estimation algorithm based on the cross-correlation function between
signals quantized into low-bit integers. The proposed method requires only
integer arithmetic instead of real-valued operations, and further computational
efficiency can be achieved through number-theoretic algorithms. Numerical
experiments demonstrate that the proposed method achieves a shorter processing
time than conventional FFT-based approaches.

</details>


### [41] [Near-field Spatial-domain Channel Extrapolation for XL-MIMO Systems](https://arxiv.org/abs/2509.20026)
*Jiayi Lu,Jiayi Zhang,Hao Lei,Huahua Xiao,Bo Ai,Derrick Wing Kwan Ng*

Main category: eess.SP

TL;DR: 提出了一种用于多子载波XL-MIMO系统的自适应近场信道外推框架，通过天线子集选择和相干性最小化模式实现高效准确的信道估计


<details>
  <summary>Details</summary>
Motivation: XL-MIMO系统需要低复杂度获取准确CSI，现有方法忽略近场球面波前或过度依赖稀疏先验，导致性能下降

Method: 开发了网格和离网格算法，离网格算法优化网格算法的估计精度；引入交叉验证方案降低复杂度；提出相干性最小化随机模式

Result: 数值结果表明所提算法在外推精度和可达速率上显著优于现有方法，同时保持低计算复杂度

Conclusion: 提出的CV比率在精度和效率之间提供灵活权衡，离网格算法以传统网格方法的复杂度实现高精度

Abstract: Extremely large-scale multiple-input multiple-output (XL-MIMO) systems are
pivotal to next-generation wireless communications, where dynamic RF chain
architectures offer enhanced performance. However, efficient precoding in such
systems requires accurate channel state information (CSI) obtained with low
complexity. To address this challenge, spatial-domain channel extrapolation has
attracted growing interest. Existing methods often overlook near-field
spherical wavefronts or rely heavily on sparsity priors, leading to performance
degradation. In this paper, we propose an adaptive near-field channel
extrapolation framework for multi-subcarrier XL-MIMO systems, leveraging a
strategically selected subset of antennas. Subsequently, we develop both
on-grid and off-grid algorithms, where the latter refines the former's
estimates for improved accuracy. To further reduce complexity, a
cross-validation (CV)-based scheme is introduced. Additionally, we analytically
formulate the mutual coherence of the sensing matrix and propose a
coherence-minimizing-based random pattern to ensure robust extrapolation.
Numerical results validate that the proposed algorithms significantly
outperform existing methods in both extrapolation accuracy and achievable rate,
while maintaining low computational complexity. In particular, our proposed CV
ratio offers a flexible trade-off between accuracy and efficiency, and the
corresponding off-grid algorithm achieves high accuracy with complexity
comparable to conventional on-grid methods.

</details>


### [42] [Multi-Stage CD-Kennedy Receiver for QPSK Modulated CV-QKD in Turbulent Channels](https://arxiv.org/abs/2509.20030)
*Renzhi Yuan,Zhixing Wang,Shouye Miao,Mufei Zhao,Haifeng Yao,Bin Cao,Mugen Peng*

Main category: eess.SP

TL;DR: 本文探讨了在多阶段CD-Kennedy量子接收器在湍流信道中增强QPSK调制CV-QKD协议安全密钥率的可能性，提出了三种不同类型的接收器，并证明其在误码率和安全密钥率方面优于经典相干接收器。


<details>
  <summary>Details</summary>
Motivation: 连续变量量子密钥分发协议具有高安全密钥率和与现有光通信基础设施良好兼容性的优势，但在卫星对地光通信链路中必须克服大气湍流的影响。量子接收器在标准量子极限下表现出优越的检测性能，但在湍流信道中的CV-QKD应用尚未充分探索。

Method: 首先推导了多阶段CD-Kennedy接收器在湍流信道中检测QPSK信号的误码概率，提出了三种具有不同位移选择的接收器类型（Type-I、Type-II和Type-III）。然后推导了使用多阶段CD-Kennedy接收器和后选择策略的QPSK调制CV-QKD协议在湍流信道中的安全密钥率。

Result: 数值结果表明，多阶段CD-Kennedy接收器在湍流信道中的误码率和安全密钥率性能均优于经典相干接收器，其中Type-II接收器在误码率性能方面能够容忍更差的信道条件。

Conclusion: 多阶段CD-Kennedy量子接收器能够有效提升CV-QKD协议在湍流信道中的性能，为卫星量子通信提供了有前景的技术方案。

Abstract: Continuous variable-quantum key distribution (CV-QKD) protocols attract
increasing attentions in recent years because they enjoy high secret key rate
(SKR) and good compatibility with existing optical communication
infrastructure. Classical coherent receivers are widely employed in coherent
states based CV-QKD protocols, whose detection performance is bounded by the
standard quantum limit (SQL). Recently, quantum receivers based on displacement
operators are experimentally demonstrated with detection performance
outperforming the SQL in various practical conditions. However, potential
applications of quantum receivers in CV-QKD protocols under turbulent channels
are still not well explored, while practical CV-QKD protocols must survive from
the atmospheric turbulence in satellite-to-ground optical communication links.
In this paper, we consider the possibility of using a quantum receiver called
multi-stage CD-Kennedy receiver to enhance the SKR performance of a quadrature
phase shift keying (QPSK) modulated CV-QKD protocol in turbulent channels. We
first derive the error probability of the multi-stage CD-Kennedy receiver for
detecting QPSK signals in turbulent channels and further propose three types of
multi-stage CD-Kennedy receiver with different displacement choices, i.e., the
Type-I, Type-II, and Type-III receivers. Then we derive the SKR of a QPSK
modulated CV-QKD protocol using the multi-stage CD-Kennedy receiver and
post-selection strategy in turbulent channels. Numerical results show that the
multi-stage CD-Kennedy receiver can outperform the classical coherent receiver
in turbulent channels in terms of both error probability and SKR performance
and the Type-II receiver can tolerate worse channel conditions compared with
Type-I and Type-III receivers in terms of error probability performance.

</details>


### [43] [Reproduction Number and Spatial Connectivity Structure Estimation via Graph Sparsity-Promoting Penalized Functional](https://arxiv.org/abs/2509.20034)
*Etienne Lasalle,Barbara Pascal*

Main category: eess.SP

TL;DR: 本文提出了一种联合估计有效再生数和空间连通性结构的方法，以解决COVID-19疫情期间由于感染数据质量差而导致的监测挑战。


<details>
  <summary>Details</summary>
Motivation: 在流行病爆发期间，决策者需要准确可靠的工具来监测病原体传播。有效再生数是量化疫情强度的关键指标，但COVID-19大流行监测面临前所未有的挑战，主要是全球报告的感染数据质量较差。当同时监测不同地区的疫情时，利用数据的空间结构可以显著提高再生数估计的准确性和鲁棒性，但这需要良好的空间结构估计。

Method: 提出了一种联合估计再生数和连通性结构的程序。该方法通过精心设计的合成数据进行了密集数值模拟评估，并在真实的COVID-19时空感染数据上进行了验证。

Result: 该方法能够同时估计有效再生数和空间连通性结构，提高了在数据质量不佳情况下的监测准确性。

Conclusion: 联合估计方法为解决流行病监测中的空间结构估计问题提供了有效解决方案，特别是在数据质量较差的现实监测场景中表现出良好的性能。

Abstract: During an epidemic outbreak, decision makers crucially need accurate and
robust tools to monitor the pathogen propagation. The effective reproduction
number, defined as the expected number of secondary infections stemming from
one contaminated individual, is a state-of-the-art indicator quantifying the
epidemic intensity. Numerous estimators have been developed to precisely track
the reproduction number temporal evolution. Yet, COVID-19 pandemic surveillance
raised unprecedented challenges due to the poor quality of worldwide reported
infection counts. When monitoring the epidemic in different territories
simultaneously, leveraging the spatial structure of data significantly enhances
both the accuracy and robustness of reproduction number estimates. However,
this requires a good estimate of the spatial structure. To tackle this major
limitation, the present work proposes a joint estimator of the reproduction
number and connectivity structure. The procedure is assessed through intensive
numerical simulations on carefully designed synthetic data and illustrated on
real COVID-19 spatiotemporal infection counts.

</details>


### [44] [A dual bistatic optical forward transceiver configuration for determining the position of an acoustic communication source detected by optical communication fibers](https://arxiv.org/abs/2509.20046)
*Knut H. Grythe,Jan Erik Håkegård*

Main category: eess.SP

TL;DR: 本文提出了一种基于双光纤布局的水声通信与定位集成系统，利用双向配置和双基地雷达原理实现声源定位。


<details>
  <summary>Details</summary>
Motivation: 传统分布式声学传感(DAS)在双向配置中缺乏源定位功能，而水下通信场景中源位置信息具有重要价值，需要开发集成通信和定位的方法。

Method: 采用双光纤布局，每端配备光学发射器和接收器，基于到达时间差(TDOA)原理进行源定位，使用交叉模糊函数作为最大似然估计器。

Result: 推导了Cramér-Rao界来表征定位精度的理论极限，分析表明增加声学带宽和载波频率可以提高空间分辨率。

Conclusion: 该方法为集成通信和定位提供了可行替代方案，但实际应用中仍需解决关键技术挑战。

Abstract: Optical fibers have long been employed as sensors in a wide range of
commercial systems. Distributed Acoustic Sensing (DAS) extends this concept by
enabling the detection and localization of acoustic sources along the fiber,
using backscattered light from small segments to achieve spatial resolution on
the order of meters. Recently, DAS has also been explored as a component in
underwater acoustic communication systems. Emerging interest in bidirectional
configurations where both transmitter and receiver are placed at opposite ends
of the fiber has opened new possibilities. However, in such setups, source
localization is not inherently integrated into the signal decoding process. For
scenarios where source positioning is valuable, we propose an approach inspired
by bi-static radar principles. This configuration utilizes acoustic signals
received at both ends of the fiber to estimate source position based on
propagation delay differences. Although the localization accuracy is lower than
that of DAS due to reduced sampling rates, the method offers a viable
alternative for integrated communication and positioning. We present the system
topology and configuration for a dual-fiber layout, each end equipped with
optical transmitters and receivers. The position estimation is derived from the
time difference of arrival (TDOA) between the two receivers. The Cram\'er-Rao
Bound is derived to characterize the theoretical limits of localization
accuracy, highlighting dependencies on system parameters such as optical power
loss. Our analysis shows that increased acoustic bandwidth and higher carrier
frequencies enhance spatial resolution. We formulate the Cross Ambiguity
Function as a maximum likelihood estimator for TDOA and provide simulation
results illustrating its performance under varying system conditions. Finally,
we discuss key challenges that must be addressed for practical implementation.

</details>


### [45] [Joint Ex-Post Location Calibration and Radio Map Construction under Biased Positioning Errors](https://arxiv.org/abs/2509.20059)
*Koki Kanzaki,Koya Sato*

Main category: eess.SP

TL;DR: 本文提出了一种针对位置信息存在突发性误差环境的高精度无线电地图构建方法，通过将定位误差和空间相关性建模为可调参数，实现事后校准。


<details>
  <summary>Details</summary>
Motivation: 现有无线电地图构建方法大多假设传感过程中位置信息无噪声，但实际设备定位系统（如GNSS）会产生几米到几十米的误差，忽略这些误差会导致无线电地图精度显著下降。

Method: 引入新颖框架，将定位误差与无线电传播的空间相关性一起建模，作为边际对数似然函数中的可调参数嵌入，实现位置不确定性的事后校准。

Result: 基于实际人类移动数据的数值结果表明，所提方法能将RMSE退化限制在约0.25-0.29 dB，而基线方法的性能损失超过1 dB。

Conclusion: 该方法能有效处理位置信息中的突发性误差，在存在定位误差的情况下仍能保持较高的无线电地图构建精度。

Abstract: This paper proposes a high-accuracy radio map construction method tailored
for environments where location information is affected by bursty errors. Radio
maps are an effective tool for visualizing wireless environments. Although
extensive research has been conducted on accurate radio map construction, most
existing approaches assume noise-free location information during sensing. In
practice, however, positioning errors ranging from a few to several tens of
meters can arise due to device-based positioning systems (e.g., GNSS). Ignoring
such errors during inference can lead to significant degradation in radio map
accuracy. This study highlights that these errors often tend to be biased when
using mobile devices as sensors. We introduce a novel framework that models
these errors together with spatial correlation in radio propagation by
embedding them as tunable parameters in the marginal log-likelihood function.
This enables ex-post calibration of location uncertainty during radio map
construction. Numerical results based on practical human mobility data
demonstrate that the proposed method can limit RMSE degradation to
approximately 0.25-0.29 dB, compared with Gaussian process regression using
noise-free location data, whereas baseline methods suffer performance losses
exceeding 1 dB.

</details>


### [46] [Reciprocal Beyond-Diagonal Reconfigurable Intelligent Surface (BD-RIS): Scattering Matrix Design via Manifold Optimization](https://arxiv.org/abs/2509.20246)
*Marko Fidanovski,Iván Alexander Morales Sandoval,Hyeon Seok Rou,Giuseppe Thadeu Freitas de Abreu,Emil Björnson*

Main category: eess.SP

TL;DR: 本文研究了超对角可重构智能表面（BD-RIS）在无线通信中的对称散射矩阵设计问题，通过流形优化框架实现和率最大化，并确保物理实现的可行性。


<details>
  <summary>Details</summary>
Motivation: BD-RIS技术因其低成本和高信号处理能力，能够在恶劣城市环境中提升无线系统的性能和QoS。现有方法在物理实现复杂度方面存在挑战，需要设计可行的对称散射矩阵。

Method: 采用流形优化框架，在目标函数中添加惩罚项来保证对称约束，并通过投影到可行散射矩阵集合来进一步确保互易性。

Result: 仿真结果表明，所提方法在和率最大化方面优于当前最先进的方法。

Conclusion: 通过对称散射矩阵设计和流形优化，BD-RIS能够有效提升无线系统的和率性能，同时保证低复杂度的物理实现可行性。

Abstract: Beyond-diagonal reconfigurable intelligent surfaces (BD-RISs) are emerging as
a transformative technology in wireless communications, enabling enhanced
performance and quality of service (QoS) of wireless systems in harsh urban
environments due to their relatively low cost and advanced signal processing
capabilities. Generally, BD-RIS systems are employed to improve robustness,
increase achievable rates, and enhance energy efficiency of wireless systems in
both direct and indirect ways. The direct way is to produce a favorable
propagation environment via the design of optimized scattering matrices, while
the indirect way is to reap additional improvements via the design of
multiple-input multiple-output (MIMO) beamformers that further exploit the
latter "engineered" medium. In this article, the problem of sum-rate
maximization via BD-RIS is examined, with a focus on feasibility, namely
low-complexity physical implementation, by enforcing reciprocity in the BD-RIS
design. We begin by outlining the system model and formulating an optimization
problem that aims to enhance the system's sum-rate by designing a symmetric
scattering matrix. In particular, the approach leverages a manifold
optimization framework, where a penalty term is added to the objective function
to ensure that the symmetry constraint is upheld, with reciprocity further
enforced by projecting the obtained solution onto a set of feasible scattering
matrices. Simulation results demonstrate the effectiveness of the proposed
method in outperforming current state-of-the-art (SotA) approaches in terms of
sum-rate maximization.

</details>


### [47] [Geometric Port Selection in CUMA Systems](https://arxiv.org/abs/2509.20299)
*Chenguang Rao,Kai-Kit Wong,Mohd Hamza Naim Shaikh,Hanjiang Hong,Hyundong Shin,Yangyang Zhang*

Main category: eess.SP

TL;DR: 本文提出了两种自适应单射频端口选择方案（EOHS和PCA），用于改进紧凑型超大规模天线阵列（CUMA）技术，在保持低复杂度的同时显著提升性能。


<details>
  <summary>Details</summary>
Motivation: CUMA技术虽然通过简单的端口选择机制实现了大规模连接，但其随机的端口选择策略仍有很大优化空间，需要开发更智能的自适应方案来提升性能。

Method: 提出了两种自适应端口选择方案：1）精确最优半空间（EOHS）方案，动态选择最大化瞬时信号累积的投影方向；2）基于主成分分析（PCA）的方案，将端口分区与每端口信道向量的主要统计方向对齐。

Result: 仿真结果表明，EOHS和PCA方案在各种用户密度、端口数量和FAS孔径尺寸下均优于传统CUMA。PCA方案以较低的计算成本实现了接近EOHS的性能。

Conclusion: 所提出的方案能有效扩展到大规模用户场景，为下一代多址接入系统提供了有吸引力的复杂度-性能权衡。

Abstract: Compact ultra-massive antenna-array (CUMA) is a novel multiple access
technology built on the fluid antenna system (FAS) concept, offering an
improved scheme over fluid antenna multiple access (FAMA) that can support
massive connectivity on the same physical channel without the need of precoding
and interference cancellation. By employing a simple port-selection mechanism
that leverages random channel superposition, CUMA can suppress inter-user
interference while keeping hardware costs low. Nevertheless, its ad-hoc
port-selection strategy leaves considerable room for optimization. In this
work, we revisit CUMA and propose two adaptive single-RF port-selection schemes
that retain its simplicity while significantly enhancing performance. The first
one, referred to as exact optimal half-space (EOHS), dynamically selects the
projection direction that maximizes the instantaneous signal build-up across
active ports. To reduce complexity while preserving most of the gains, we
furthermore introduce a principal component analysis (PCA)-based scheme, which
aligns port partitioning with the dominant statistical direction of per-port
channel vectors. This method yields a closed-form low-complexity solution,
complemented by a tractable analytical framework that provides a closed-form
expression for the signal-to-interference ratio (SIR) probability density
function (PDF). Simulation results corroborate the analysis, demonstrating that
both EOHS and PCA consistently outperform conventional CUMA across diverse user
densities, port counts, and FAS aperture sizes. Notably, PCA achieves
performance close to EOHS at a fraction of the computational cost. The proposed
schemes scale effectively to large-user regimes, offering a compelling
complexity-performance trade-off for next-generation multiple access systems.

</details>
