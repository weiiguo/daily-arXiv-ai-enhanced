<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 12]
- [cs.IT](#cs.IT) [Total: 9]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [Distributed Detection and Bandwidth Allocation with Hybrid Quantized and Full-Precision Observations over Multiplicative Fading Channels](https://arxiv.org/abs/2510.06429)
*Linlin Mao,Zeping Sui,Michail Matthaiou,Hongbin Li*

Main category: eess.SP

TL;DR: 提出了一种融合量化和全精度观测的混合检测器，用于加性和乘性高斯噪声下的弱信号检测，并优化了量化阈值和带宽分配策略。


<details>
  <summary>Details</summary>
Motivation: 在加性和乘性高斯噪声环境下，需要开发有效的弱信号检测方法，同时考虑传输带宽约束和易出错信道条件。

Method: 基于复合观测的概率分布推导局部最优检验混合检测器，分析其渐近检测性能，优化传感器量化阈值，并提出混合整数线性规划方法解决带宽分配问题。

Result: 仿真结果表明所提出的混合检测器和带宽分配策略具有优越性，特别是在具有挑战性的易出错信道条件下表现突出。

Conclusion: 该混合检测器结合了量化和全精度观测的优势，通过优化的量化阈值和带宽分配策略，在弱信号检测和资源受限场景中实现了良好的性能。

Abstract: A hybrid detector that fuses both quantized and full-precision observations
is proposed for weak signal detection under additive and multiplicative
Gaussian noise. We first derive a locally most powerful test (LMPT)--based
hybrid detector from the composite probability distribution of the compound
observations received by the fusion center, and then analyze its asymptotic
detection performance. Subsequently, we optimize the sensor-wise quantization
thresholds to achieve near-optimal asymptotic performance at the local sensor
level. Moreover, we propose a mixed-integer linear programming approach to
solve the optimization problem of transmission bandwidth allocation accounting
for bandwidth constraints and error-prone channels. Finally, simulation results
demonstrate the superiority of the proposed hybrid detector and the bandwidth
allocation strategy, especially in challenging error-prone channel conditions.

</details>


### [2] [Optimized SVR Framework for Electric Load Forecasting](https://arxiv.org/abs/2510.06476)
*Nishant Gadde,Yoshua Alexander,Sarvesh Parthasarthy,Arman Allidina*

Main category: eess.SP

TL;DR: 提出了一种基于支持向量回归(SVR)的电力负荷预测框架，相比行业标准方法在各项评估指标上表现更优，特别是在均方误差方面减少了54.2%。


<details>
  <summary>Details</summary>
Motivation: 由于电力系统日益复杂、极端天气增多以及用户用电需求变化，传统负荷预测方法有时会失效，需要更准确的预测工具来支持电网运营。

Method: 采用支持向量回归(SVR)框架进行电力负荷预测，这是一种机器学习方法。

Result: SVR模型在所有重要评估指标上都表现出更好的准确性：均方误差从69.63降低到31.91（减少54.2%），平均绝对误差改善33.5%，其他指标也有性能提升。

Conclusion: 该方法为电力系统规划和资源分配提供了额外的准确性检查工具，与电力预测工具集成后显示出显著效益。

Abstract: Load forecasting has always been a challenge for grid operators due to the
growing complexity of power systems. The increase in extreme weather and the
need for energy from customers has led to load forecasting sometimes failing.
This research presents a Support Vector Regression (SVR) framework for electric
load forecasting that outperforms the industry standard. The SVR model
demonstrates better accuracy across all evaluation metrics that are important
for power system operations. The model has a 54.2\% reduction in Mean Squared
Error (31.91 vs. 69.63), a 33.5\% improvement in Mean Absolute Error, and
performance benefits across other metrics. These improvements show significant
benefits when integrated with power forecasting tools and show that the
approach provides an additional tool for accuracy checking for system planning
and resource allocation in times of need for resource allocation in electric
power systems.

</details>


### [3] [Cooperative Multi-Static ISAC Networks: A Unified Design Framework for Active and Passive Sensing](https://arxiv.org/abs/2510.06654)
*Yan Yang,Zhendong Li,Jianwei Zhao,Qingqing Wu,Zhiqing Wei,Wen Chen,Weimin Jia*

Main category: eess.SP

TL;DR: 提出了一种联合主动和被动感知(JAPS)的统一设计框架，用于多静态ISAC系统，通过交替优化算法联合优化波束成形、接收滤波器和功率分配，在保证感知要求的同时最大化下行和上行传输的和速率。


<details>
  <summary>Details</summary>
Motivation: 多静态协作感知是推进集成感知与通信(ISAC)的有前景技术，能够提高感知精度和范围。本文旨在解决下行和上行通信共存场景下的联合优化问题。

Method: 采用交替优化(AO)算法框架，将问题分解为波束成形子问题和接收滤波器与上行功率分配子问题。前者使用SCA和基于惩罚的算法，后者使用基于分数规划(FP)的算法。

Result: 大量数值结果验证了所提JAPS方案的性能提升，证明了所提算法的有效性。

Conclusion: 提出的JAPS框架和算法能够有效解决多静态ISAC系统中的联合优化问题，在保证感知要求的同时显著提升通信性能。

Abstract: Multi-static cooperative sensing emerges as a promising technology for
advancing integrated sensing and communication (ISAC), enhancing sensing
accuracy and range. In this paper, we develop a unified design framework for
joint active and passive sensing (JAPS). In particular, we consider a JAPSbased
cooperative multi-static ISAC system for coexisting downlink (DL) and uplink
(UL) communications. An optimization problem is formulated for maximizing the
sum rate of both the DL and UL transmissions via jointly optimizing
beamforming, receive filters and power allocation, while guaranteeing the
sensing requirements and transmission power constraints. However, the
formulated problem is a non-convex optimization problem that is challenging to
solve directly due to the tight coupling among optimization variables. To
tackle this complicated issue, we employ an efficient algorithm architecture
leveraging alternating optimization (AO). Specifically, with the given receive
filters and transmission power for UL communication, the transmit beamforming
subproblem is addressed by successive convex approximation (SCA)-based and
penalty-based algorithms. A fractional programming (FP)-based algorithm is
developed to tackle the receive filters and transmission power for UL
communication optimization subproblem. Extensive numerical results validate the
performance improvement of our proposed JAPS scheme and demonstrate the
effectiveness of our proposed algorithms.

</details>


### [4] [Personalized Federated Learning-Driven Beamforming Optimization for Integrated Sensing and Communication Systems](https://arxiv.org/abs/2510.06709)
*Zhou Ni,Sravan Reddy Chintareddy,Peiyuan Guan,Morteza Hashemi*

Main category: eess.SP

TL;DR: 提出基于期望最大化算法的个性化联邦学习框架，用于集成感知与通信系统中的多目标优化，通过自适应权重聚合提升性能。


<details>
  <summary>Details</summary>
Motivation: 标准联邦学习方法对所有客户端统一处理，无法适应集成感知与通信系统中通信与感知目标的竞争关系，需要个性化方法来处理应用特定的权衡。

Method: 使用期望最大化算法，每个基站计算后验概率来量化全局模型与局部模型的相对适用性，基于模型在各自数据集上的损失进行自适应权重聚合。

Result: 在目标同质和异质条件下进行仿真，结果显示该方法优于FedPer和pFedMe等现有PFL基线，收敛更快且多目标性能更好。

Conclusion: 所提出的EM个性化联邦学习框架能有效处理集成感知与通信系统中的多目标优化问题，使基站能够动态适应应用特定的权衡关系。

Abstract: In this paper, we propose an Expectation-Maximization-based (EM) Personalized
Federated Learning (PFL) framework for multi-objective optimization (MOO) in
Integrated Sensing and Communication (ISAC) systems. In contrast to standard
federated learning (FL) methods that handle all clients uniformly, the proposed
approach enables each base station (BS) to adaptively determine its aggregation
weight with the EM algorithm. Specifically, an EM posterior is computed at each
BS to quantify the relative suitability between the global and each local
model, based on the losses of models on their respective datasets. The proposed
method is especially valuable in scenarios with competing communication and
sensing objectives, as it enables BSs to dynamically adapt to
application-specific trade-offs. To assess the effectiveness of the proposed
approach, we conduct simulation studies under both objective-wise homogeneous
and heterogeneous conditions. The results demonstrate that our approach
outperforms existing PFL baselines, such as FedPer and pFedMe, achieving faster
convergence and better multi-objective performance.

</details>


### [5] [Low Complexity Weight Flexible Decoding Schemes of Linear Block Code for 6G xURLLC](https://arxiv.org/abs/2510.06768)
*Di Zhang,Yinglei Yang,Zhilong Liu,Shaobo Jia,Kyungchun Lee,Zhirong Zhang*

Main category: eess.SP

TL;DR: 提出了一种基于对偶码字特性的线性分组码解码方案，利用灵活权重的对偶码字提供错误位置和幅度的解码信息，实现更高可靠性。


<details>
  <summary>Details</summary>
Motivation: 为6G时代的超可靠低延迟通信提供低复杂度纠错码解决方案，满足下一代通信系统对可靠性和延迟的要求。

Method: 利用对偶码字的灵活权重特性，提出了两种解码方案：一种是直接利用内在信息进行迭代解码，另一种是将先验信道信息与内在信息结合进行解码。两种方案都采用向量乘法和实数比较实现，便于硬件实现。

Result: 仿真结果验证了所提方案的有效性，能够提供更高的可靠性性能。

Conclusion: 所提出的基于对偶码字的解码方案为6G xURLLC应用提供了一种低复杂度、高可靠性的纠错码解决方案，具有良好的硬件实现可行性。

Abstract: Low complexity error correction code is a key enabler for next generation
ultra-reliable low-latency communications (xURLLC) in six generation (6G).
Against this background, this paper proposes a decoding scheme for linear block
code by leveraging certain interesting properties of dual codewords. It is
found that dual codewords with flexible weights can provide useful decoding
information for the locations and magnitudes of error bits, which yielding
higher reliability performance. In addition, two decoding schemes are proposed,
in which one directly utilizes intrinsic information for iterative decoding,
and the other combines prior channel information with intrinsic information for
decoding. Both schemes are implemented using vector multiplication and
real-number comparisons, making them easy to implement in hardware. Simulation
results demonstrate the validness of our study.

</details>


### [6] [Mobility-Aware Localization in mmWave Channel: Adaptive Hybrid Filtering Approach](https://arxiv.org/abs/2510.06861)
*Abidemi Orimogunje,Kyeong-Ju Cha,Hyunwoo Park,Abdulahi A. Badrudeen,Sunwoo Kim,Dejan Vukobratovic*

Main category: eess.SP

TL;DR: 提出了一种混合移动感知自适应定位框架，通过毫米波信号实现联合感知与通信，根据用户速度自适应选择扩展卡尔曼滤波或无迹卡尔曼滤波，显著提升了定位精度。


<details>
  <summary>Details</summary>
Motivation: 下一代无线网络中需要精确的用户定位和追踪来支持能效高、超可靠低延迟的应用。传统卡尔曼滤波定位技术存在计算复杂度高、数据关联问题，且随着用户移动速度增加，估计误差会增大。

Method: 利用毫米波信号进行联合感知与通信，无需额外传感器。提出混合移动感知自适应框架：在行人速度下使用扩展卡尔曼滤波，在车辆速度下使用无迹卡尔曼滤波。通过自适应噪声缩放、卡方门控、Rauch-Tung-Striebel平滑等技术缓解数据关联问题和估计误差。

Result: 使用绝对轨迹误差、相对位姿误差、归一化估计误差平方和均方根误差等指标评估，在各自应用场景下相比现有方法提升了约30-60%的性能。

Conclusion: 该方法在定位精度上明显优于现有针对室内或静态场景的方法，证明了自适应滤波策略在动态移动环境中的有效性。

Abstract: Precise user localization and tracking enhances energy-efficient and
ultra-reliable low latency applications in the next generation wireless
networks. In addition to computational complexity and data association
challenges with Kalman-filter localization techniques, estimation errors tend
to grow as the user's trajectory speed increases. By exploiting mmWave signals
for joint sensing and communication, our approach dispenses with additional
sensors adopted in most techniques while retaining high resolution spatial
cues. We present a hybrid mobility-aware adaptive framework that selects the
Extended Kalman filter at pedestrian speed and the Unscented Kalman filter at
vehicular speed. The scheme mitigates data-association problem and estimation
errors through adaptive noise scaling, chi-square gating, Rauch-Tung-Striebel
smoothing. Evaluations using Absolute Trajectory Error, Relative Pose Error,
Normalized Estimated Error Squared and Root Mean Square Error metrics
demonstrate roughly 30-60% improvement in their respective regimes indicating a
clear advantage over existing approaches tailored to either indoor or static
settings.

</details>


### [7] [Memory-Augmented Generative AI for Real-time Wireless Prediction in Dynamic Industrial Environments](https://arxiv.org/abs/2510.06884)
*Rahul Gulia,Amlan Ganguly,Michael E. Kuhl,Ehsan Rashedi,Clark Hochgraf*

Main category: eess.SP

TL;DR: Evo-WISVA是一种用于智能仓库无线信道预测的深度学习架构，结合了记忆增强变分自编码器和卷积LSTM网络，在动态工业环境中显著提升了SINR预测精度和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 传统物理或统计模型难以应对智能仓库中移动障碍物和瞬时干扰带来的时空复杂性，无法满足URLLC对无线信道条件实时准确预测的需求。

Method: 提出Evo-WISVA架构，集成记忆增强VAE（含注意力驱动的潜在记忆模块）用于空间特征提取，以及ConvLSTM网络用于时间序列预测，通过端到端联合损失函数优化。

Result: 在高保真工业仓库数据集上，Evo-WISVA显著超越现有方法，平均重建误差降低47.6%，在复杂动态环境中（最多10个同时移动障碍物）表现出优异的泛化能力，同时保持实时部署的计算效率。

Conclusion: Evo-WISVA为主动无线资源管理奠定了基础技术，推动了工业通信网络中预测性数字孪生的实现。

Abstract: Accurate and real-time prediction of wireless channel conditions,
particularly the Signal-to-Interference-plus-Noise Ratio (SINR), is a
foundational requirement for enabling Ultra-Reliable Low-Latency Communication
(URLLC) in highly dynamic Industry 4.0 environments. Traditional physics-based
or statistical models fail to cope with the spatio-temporal complexities
introduced by mobile obstacles and transient interference inherent to smart
warehouses. To address this, we introduce Evo-WISVA (Evolutionary Wireless
Infrastructure for Smart Warehouse using VAE), a novel synergistic deep
learning architecture that functions as a lightweight 2D predictive digital
twin of the radio environment. Evo-WISVA integrates a memory-augmented
Variational Autoencoder (VAE) featuring an Attention-driven Latent Memory
Module (LMM) for robust, context-aware spatial feature extraction, with a
Convolutional Long Short-Term Memory (ConvLSTM) network for precise temporal
forecasting and sequential refinement. The entire pipeline is optimized
end-to-end via a joint loss function, ensuring optimal feature alignment
between the generative and predictive components. Rigorous experimental
evaluation conducted on a high-fidelity ns-3-generated industrial warehouse
dataset demonstrates that Evo-WISVA significantly surpasses state-of-the-art
baselines, achieving up to a 47.6\% reduction in average reconstruction error.
Crucially, the model exhibits exceptional generalization capacity to unseen
environments with vastly increased dynamic complexity (up to ten simultaneously
moving obstacles) while maintaining amortized computational efficiency
essential for real-time deployment. Evo-WISVA establishes a foundational
technology for proactive wireless resource management, enabling autonomous
optimization and advancing the realization of predictive digital twins in
industrial communication networks.

</details>


### [8] [Sensing Management for Pilot-Free Predictive Beamforming in Cell-Free Massive MIMO Systems](https://arxiv.org/abs/2510.06936)
*Eren Berk Kama,Murat Babek Salman,Isaac Skog,Emil Björnson*

Main category: eess.SP

TL;DR: 提出了一种用于无蜂窝大规模MIMO系统中集成感知与通信的感知管理方法，通过状态跟踪和预测波束成形减少信道估计开销


<details>
  <summary>Details</summary>
Motivation: 传统通信系统的信道估计过程在数据传输期间产生显著开销，消耗了本可用于数据的资源

Method: 采用基于状态的方法，利用感知能力在没有通信请求时跟踪用户位置，在收到通信请求时基于跟踪位置进行预测波束成形，使用扩展卡尔曼滤波跟踪算法和自适应感知管理

Result: 仿真结果表明，所提出的感知管理方法通过实现无开销的预测波束成形，提供了比现有方法更高的均匀下行通信速率

Conclusion: 该方法有效减少了信道估计开销，提高了系统性能

Abstract: This paper introduces a sensing management method for integrated sensing and
communications (ISAC) in cell-free massive multiple-input multiple-output
(MIMO) systems. Conventional communication systems employ channel estimation
procedures that impose significant overhead during data transmission, consuming
resources that could otherwise be utilized for data. To address this challenge,
we propose a state-based approach that leverages sensing capabilities to track
the user when there is no communication request. Upon receiving a communication
request, predictive beamforming is employed based on the tracked user position,
thereby reducing the need for channel estimation. Our framework incorporates an
extended Kalman filter (EKF) based tracking algorithm with adaptive sensing
management to perform sensing operations only when necessary to maintain high
tracking accuracy. The simulation results demonstrate that our proposed sensing
management approach provides uniform downlink communication rates that are
higher than with existing methods by achieving overhead-free predictive
beamforming.

</details>


### [9] [Optimal Real-time Communication in 6G Ultra-Massive V2X Mobile Networks](https://arxiv.org/abs/2510.06937)
*He Huang,Zilong Liu,Zeping Sui,Wei Huang,Md. Noor-A-Rahim,Haishi Wang,Zhiheng Hu*

Main category: eess.SP

TL;DR: 提出了一种用于6G超大规模V2X网络的协作车辆通信算法，通过集成空天地通信系统解决快速移动车辆间的实时信息交换问题，证明了给定中继数量下信道容量的上界，并提出低复杂度中继选择启发式算法。


<details>
  <summary>Details</summary>
Motivation: 解决未来6G网络中快速移动车辆间实时信息交换的挑战，利用集成空天地通信系统提升车辆通信性能。

Method: 证明了给定中继数量下信道容量的上界，并提出了一种低复杂度的中继选择启发式算法。

Result: 仿真结果表明，所提算法相比现有协作车辆通信方法实现了更优的信道容量。

Conclusion: 该算法为6G超大规模V2X网络提供了一种有效的协作通信解决方案，在保证实时性的同时提升了信道容量性能。

Abstract: This paper introduces a novel cooperative vehicular communication algorithm
tailored for future 6G ultra-massive vehicle-to-everything (V2X) networks
leveraging integrated space-air-ground communication systems. Specifically, we
address the challenge of real-time information exchange among rapidly moving
vehicles. We demonstrate the existence of an upper bound on channel capacity
given a fixed number of relays, and propose a low-complexity relay selection
heuristic algorithm. Simulation results verify that our proposed algorithm
achieves superior channel capacities compared to existing cooperative vehicular
communication approaches.

</details>


### [10] [Maritime Communication in Evaporation Duct Environment with Ship Trajectory Optimization](https://arxiv.org/abs/2510.06946)
*Ruifeng Gao,Hao Zhang,Jue Wang,Ye Li,Yingdong Hu,Qiuming Zhu,Shu Sun,Meixia Tao*

Main category: eess.SP

TL;DR: 提出了一种利用蒸发管道效应信道增益图先验信息的新型框架，通过优化船舶轨迹来最小化数据传输时间和航行时间，采用动态种群PSO集成NSGA-II算法求解多目标优化问题。


<details>
  <summary>Details</summary>
Motivation: 在海上无线网络中，蒸发管道效应被认为是远距离传输的有利条件，但如何有效利用该效应进行高效通信设计仍有待研究。

Method: 提出利用蒸发管道效应下信道增益图先验信息的框架，通过优化船舶轨迹最小化传输时间和航行时间，采用动态种群PSO集成NSGA-II算法求解多目标优化问题。

Result: 仿真结果表明，与忽略蒸发管道效应有用信息的基准方案相比，所提方案能有效减少数据传输时间和航行时间。

Conclusion: 利用蒸发管道效应的信道增益图先验信息可以有效优化船舶轨迹，实现更高效的海上数据传输。

Abstract: In maritime wireless networks, the evaporation duct effect has been known as
a preferable condition for long-range transmissions. However, how to
effectively utilize the duct effect for efficient communication design is still
open for investigation. In this paper, we consider a typical scenario of
ship-to-shore data transmission, where a ship collects data from multiple
oceanographic buoys, sails from one to another, and transmits the collected
data back to a terrestrial base station during its voyage. A novel framework,
which exploits priori information of the channel gain map in the presence of
evaporation duct, is proposed to minimize the data transmission time and the
sailing time by optimizing the ship's trajectory. To this end, a
multi-objective optimization problem is formulated and is further solved by a
dynamic population PSO-integrated NSGA-II algorithm. Through simulations, it is
demonstrated that, compared to the benchmark scheme which ignores useful
information of the evaporation duct, the proposed scheme can effectively reduce
both the data transmission time and the sailing time.

</details>


### [11] [Towards Reliable Emergency Wireless Communications over SAGINs: A Composite Fading and QoS-Centric Perspective](https://arxiv.org/abs/2510.07120)
*Yinong Chen,Wenchi Cheng,Jingqing Wang,Xiao Zheng,Jiangzhou Wang*

Main category: eess.SP

TL;DR: 该论文提出了一个基于Fisher-Snedecor F复合衰落模型的卫星-空中-地面综合网络性能建模框架，用于分析紧急无线通信场景下的服务质量约束性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究大多忽略了复杂地形变化导致的信道特性，或在没有服务质量约束的情况下分析性能，导致理论分析与实际性能不匹配。

Method: 采用F复合衰落模型准确描述恶劣地面环境中的多径衰落和阴影效应，开发了端到端信噪比统计的精确分布，分析了固定增益放大转发和解码转发中继协议的级联信道。

Result: 推导了具有服务质量保障的有效容量、中断概率和ε中断容量的闭式解和渐近表达式，并通过现场测量和蒙特卡洛仿真验证了有效性。

Conclusion: 所提出的建模框架能够准确表征SAGIN在紧急通信场景下的性能，理论预测与高信噪比区域的实际表现高度一致。

Abstract: In emergency wireless communications (EWC) scenarios, ensuring reliable,
flexible, and high-rate transmission while simultaneously maintaining seamless
coverage and rapid response capabilities presents a critical technical
challenge. To this end, satellite-aerial-ground integrated network (SAGIN) has
emerged as a promising solution due to its comprehensive three-dimensional
coverage and capability to meet stringent, multi-faceted quality-of-service
(QoS) requirements. Nevertheless, most existing studies either neglected the
inherent characteristics of the complex channel conditions due to the terrain
changes or analyzed the performance in the absence of QoS constraints,
resulting in a mismatch between theoretical analysis and practical performance.
To remedy such deficiencies, in this paper we establish a performance modeling
framework for SAGIN employing the Fisher-Snedecor $\mathcal{F}$ composite
fading model to characterize the air-ground link. In specific, the proposed
$\mathcal{F}$ composite fading channel is adopted to accurately describe both
multipath fading and shadowing in harsh ground environments. The exact
distribution of end-to-end signal-to-noise (SNR) statistics for space-air and
air-ground links is developed, enabling theoretical analysis of cascaded
channels with fixed-gain amplify-and-forward (AF) and decode-and-forward (DF)
relaying protocols, respectively. Furthermore, asymptotic expressions of the
derived results are provided to offer concise representations and demonstrate
close alignment with theoretical predictions in the high-SNR regime. Finally,
the insightful closed-form and asymptotic expressions of effective capacity
with QoS provisioning, outage probability, and $\epsilon$-outage capacity are
investigated, respectively, followed by both field measurements and Monte Carlo
simulations to verify the effectiveness.

</details>


### [12] [Moments Matter: Posterior Recovery in Poisson Denoising via Log-Networks](https://arxiv.org/abs/2510.07199)
*Shirin Shoushtari,Edward P. Chandler,Ulugbek S. Kamilov*

Main category: eess.SP

TL;DR: 提出了一种基于对数网络的泊松去噪新方法，能够恢复后验分布的高阶矩，而不仅仅是后验均值。


<details>
  <summary>Details</summary>
Motivation: 传统基于MSE损失的方法只能估计后验均值，无法捕捉泊松去噪中的后验不确定性，限制了其在光子受限成像应用中的实用性。

Method: 训练对数网络来学习条件期望E[log x|y]，利用对数作为泊松分布的便捷参数化，从而恢复后验分布的高阶矩。

Result: 在模拟数据上的实验表明，该方法在去噪性能上与标准MMSE模型相当，同时能够提供后验分布信息。

Conclusion: 对数网络方法在保持去噪性能的同时，实现了对泊松去噪后验分布的近似，为光子受限成像应用提供了更完整的不确定性量化。

Abstract: Poisson denoising plays a central role in photon-limited imaging applications
such as microscopy, astronomy, and medical imaging. It is common to train deep
learning models for denoising using the mean-squared error (MSE) loss, which
corresponds to computing the posterior mean $\mathbb{E}[x \mid y]$. When the
noise is Gaussian, Tweedie's formula enables approximation of the posterior
distribution through its higher-order moments. However, this connection no
longer holds for Poisson denoising: while $ \mathbb{E}[x \mid y] $ still
minimizes MSE, it fails to capture posterior uncertainty. We propose a new
strategy for Poisson denoising based on training a log-network. Instead of
predicting the posterior mean $ \mathbb{E}[x \mid y] $, the log-network is
trained to learn $\mathbb{E}[\log x \mid y]$, leveraging the logarithm as a
convenient parameterization for the Poisson distribution. We provide a
theoretical proof that the proposed log-network enables recovery of
higher-order posterior moments and thus supports posterior approximation.
Experiments on simulated data show that our method matches the denoising
performance of standard MMSE models while providing access to the posterior.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [13] [A doubly composite Chernoff-Stein lemma and its applications](https://arxiv.org/abs/2510.06342)
*Ludovico Lami*

Main category: cs.IT

TL;DR: 本文提出了一个适用于复合假设和真实相关性的广义Chernoff-Stein引理，扩展了传统结果，并开发了符号级模糊技术来证明该定理。


<details>
  <summary>Details</summary>
Motivation: 传统Chernoff-Stein引理仅适用于简单i.i.d.假设，对于复合假设和真实相关性的情况缺乏一般性结果。本文旨在填补这一空白。

Method: 使用符号级模糊技术，这是对广义量子Stein引理中模糊技术的改进，使其在缺乏置换对称性的情况下也能适用。

Result: 建立了适用于复合假设和真实相关性的广义Chernoff-Stein引理，该结果严格包含了大多数先前工作。

Conclusion: 所提出的广义Chernoff-Stein引理为复合假设和相关性情况下的假设检验提供了理论基础，并在量子假设检验中有相关应用。

Abstract: Given a sequence of random variables $X^n=X_1,\ldots, X_n$, discriminating
between two hypotheses on the underlying probability distribution is a key task
in statistics and information theory. Of interest here is the Stein exponent,
i.e. the largest rate of decay (in $n$) of the type II error probability for a
vanishingly small type I error probability. When the hypotheses are simple and
i.i.d., the Chernoff-Stein lemma states that this is given by the relative
entropy between the single-copy probability distributions. Generalisations of
this result exist in the case of composite hypotheses, but mostly to settings
where the probability distribution of $X^n$ is not genuinely correlated, but
rather, e.g., a convex combination of product distributions with components
taken from a base set. Here, we establish a general Chernoff-Stein lemma that
applies to the setting where both hypotheses are composite and genuinely
correlated, satisfying only generic assumptions such as convexity (on both
hypotheses) and some weak form of permutational symmetry (on either
hypothesis). Our result, which strictly subsumes most prior work, is proved
using a refinement of the blurring technique developed in the context of the
generalised quantum Stein's lemma [Lami, IEEE Trans. Inf. Theory 2025]. In this
refined form, blurring is applied symbol by symbol, which makes it both
stronger and applicable also in the absence of permutational symmetry. The
second part of the work is devoted to applications: we provide a single-letter
formula for the Stein exponent characterising the discrimination of broad
families of null hypotheses vs a composite i.i.d. or an arbitrarily varying
alternative hypothesis, and establish a 'constrained de Finetti reduction'
statement that covers a wide family of convex constraints. Applications to
quantum hypothesis testing are explored in a related paper [Lami, arXiv:today].

</details>


### [14] [$α$-leakage Interpretation of Rényi Capacity](https://arxiv.org/abs/2510.06622)
*Ni Ding,Farhad Farokhi,Tao Guo,Yinfei Xu,Xiang Zhang*

Main category: cs.IT

TL;DR: 本文揭示了Sibson互信息是α-泄漏在信道输出Y的基本事件以及信道输入X和输出Y的联合事件上对攻击者的f-均值相对信息增益的平均值，并提出了Y-基本α-泄漏概念，将点态最大泄漏扩展到Rényi阶数范围α∈[0,∞)。


<details>
  <summary>Details</summary>
Motivation: 研究α-泄漏的统计解释，扩展点态最大泄漏概念，并为实现δ-近似的ε-上界α-泄漏提供充分条件。

Method: 提出Y-基本α-泄漏概念，最大化该泄漏得到Rényi散度，将Rényi容量解释为在攻击者恶意推理决策和信道输入X上的最大f-均值信息泄漏。

Result: 建立了Sibson互信息与α-泄漏之间的统计关系，提出了交替最大-最大实现方法来计算广义Blahut-Arimoto方法。

Conclusion: 本文为α-泄漏提供了新的统计解释，扩展了点态泄漏概念，并为信息泄漏分析提供了新的实现方法。

Abstract: For $\tilde{f}(t) = \exp(\frac{\alpha-1}{\alpha}t)$, this paper shows that
the Sibson mutual information is an $\alpha$-leakage averaged over the
adversary's $\tilde{f}$-mean relative information gain (on the secret) at
elementary event of channel output $Y$ as well as the joint occurrence of
elementary channel input $X$ and output $Y$. This interpretation is used to
derive a sufficient condition that achieves a $\delta$-approximation of
$\epsilon$-upper bounded $\alpha$-leakage. A $Y$-elementary $\alpha$-leakage is
proposed, extending the existing pointwise maximal leakage to the overall
R\'{e}nyi order range $\alpha \in [0,\infty)$. Maximizing this $Y$-elementary
leakage over all attributes $U$ of channel input $X$ gives the R\'{e}nyi
divergence. Further, the R\'{e}nyi capacity is interpreted as the maximal
$\tilde{f}$-mean information leakage over both the adversary's malicious
inference decision and the channel input $X$ (represents the adversary's prior
belief). This suggests an alternating max-max implementation of the existing
generalized Blahut-Arimoto method.

</details>


### [15] [Optimizing Fronthaul Quantization for Flexible User Load in Cell-Free Massive MIMO](https://arxiv.org/abs/2510.06734)
*Fabian Göttsch,Max Franke,Arash Pourdamghani,Giuseppe Caire,Stefan Schmid*

Main category: cs.IT

TL;DR: 研究了可扩展用户中心化无小区大规模MIMO系统的物理层频谱效率和前传网络负载，通过优化量化率和前传路由来平衡系统性能与网络负载。


<details>
  <summary>Details</summary>
Motivation: 解决用户中心化无小区大规模MIMO系统中，由于前传链路容量有限，需要在保证物理层性能的同时控制前传网络负载的问题。

Method: 使用混合整数线性规划联合优化集群处理器放置和前传流量路由，并基于率失真理论计算量化率参数。

Result: 优化量化率后，前传负载在广泛用户负载范围内保持稳定，且物理层性能损失很小。

Conclusion: 无小区大规模MIMO系统和前传网络对变化的用户密度具有弹性，可通过优化量化率实现性能与负载的良好平衡。

Abstract: We investigate the physical layer (PHY) spectral efficiency and fronthaul
network load of a scalable user-centric cell-free massive MIMO system. Each
user-centric cluster processor responsible for cluster-level signal processing
is located at one of multiple decentralized units (DUs). Thus, the radio units
in the cluster must exchange data with the corresponding DU over the fronthaul.
Because the fronthaul links have limited capacity, this data must be quantized
before it is sent over the fronthaul. We consider a routed fronthaul network,
where the cluster processor placement and fronthaul traffic routing are jointly
optimized with a mixed-integer linear program. For different numbers of users
in the network, we investigate the effect of fronthaul quantization rates, a
system parameter computed based on rate-distortion theory. Our results show
that with optimized quantization rates, the fronthaul load is quite stable for
a wide range of user loads without significant PHY performance loss. This
demonstrates that the cell-free massive MIMO PHY and fronthaul network are
resilient to varying user densities.

</details>


### [16] [Multi-hop Deep Joint Source-Channel Coding with Deep Hash Distillation for Semantically Aligned Image Retrieval](https://arxiv.org/abs/2510.06868)
*Didrik Bergström,Deniz Gündüz,Onur Günlü*

Main category: cs.IT

TL;DR: 该论文提出了一种结合深度哈希蒸馏的DeepJSCC方法，通过语义聚类提升多跳AWGN信道中图像传输的语义一致性和感知重建质量。


<details>
  <summary>Details</summary>
Motivation: 传统DeepJSCC在多跳传输中可能面临噪声累积问题，需要增强语义一致性以支持安全应用并改善感知重建质量。

Method: 训练DeepJSCC编码器-解码器对，结合预训练的深度哈希蒸馏模块，同时最小化MSE和源图像与重建图像DHD哈希的余弦距离。

Result: 在不同多跳设置下，语义对齐显著改善了感知质量，通过LPIPS指标验证了性能提升。

Conclusion: 结合深度哈希蒸馏的DeepJSCC方法有效解决了多跳传输中的噪声累积问题，提升了语义一致性和感知重建质量。

Abstract: We consider image transmission via deep joint source-channel coding
(DeepJSCC) over multi-hop additive white Gaussian noise (AWGN) channels by
training a DeepJSCC encoder-decoder pair with a pre-trained deep hash
distillation (DHD) module to semantically cluster images, facilitating
security-oriented applications through enhanced semantic consistency and
improving the perceptual reconstruction quality. We train the DeepJSCC module
to both reduce mean square error (MSE) and minimize cosine distance between DHD
hashes of source and reconstructed images. Significantly improved perceptual
quality as a result of semantic alignment is illustrated for different
multi-hop settings, for which classical DeepJSCC may suffer from noise
accumulation, measured by the learned perceptual image patch similarity (LPIPS)
metric.

</details>


### [17] [A Stochastic Geometric Analysis on Multi-cell Pinching-antenna Systems under Blockage Effect](https://arxiv.org/abs/2510.06972)
*Yanshi Sun,Zhiguo Ding,George K. Karagiannidis*

Main category: cs.IT

TL;DR: 本文提出了一个多细胞夹持天线系统的分析框架，考虑了连接到不同基站的分布式波导，使用随机几何工具进行建模，获得了中断概率表达式，并验证了夹持天线系统相比固定天线系统的优越性能。


<details>
  <summary>Details</summary>
Motivation: 现有关于夹持天线技术的研究大多关注单细胞场景，忽略了来自连接到空间分布式基站的干扰夹持天线对波导的影响，本文旨在填补这一知识空白。

Method: 应用随机几何工具进行系统建模，考虑连接到不同基站的分布式波导，推导出中断概率的解析表达式。

Result: 仿真结果验证了分析的准确性，并证明了夹持天线系统相比固定天线系统具有更优越的性能。

Conclusion: 本文成功建立了多细胞夹持天线系统的分析框架，为性能评估提供了理论基础，并展示了该技术的优势。

Abstract: Recently, the study on pinching-antenna technique has attracted significant
attention. However, most relevant literature focuses on a single-cell scenario,
where the effect from the interfering pinching-antennas on waveguides connected
to spatially distributed base stations (BSs) was ignored. To fulfill this
knowledge gap, this letter aims to provide an analytical framework on
performance evaluation for multi-cell pinching-antenna systems where spatially
distributed waveguides which are connected to different BSs are considered. In
particular, tools from stochastic geometry is applied for system modeling. The
expression for the outage probability is obtained. Simulation results are
provided to verify the accuracy of the analysis and demonstrate the superior
performance of pinching-antenna system compared to fixed-antenna systems.

</details>


### [18] [Lossless Compression of Time Series Data: A Comparative Study](https://arxiv.org/abs/2510.07015)
*Jonas G. Matt,Pengcheng Huang,Balz Maag*

Main category: cs.IT

TL;DR: 本研究对时间序列数据的无损压缩方法进行了大规模比较分析，提出了包含数据转换和熵编码的两阶段统一框架，通过消融实验评估了不同算法在各种数据集上的性能表现。


<details>
  <summary>Details</summary>
Motivation: 数字时代产生了前所未有的海量数据，需要高效管理、传输和存储。数据压缩是实现资源节约和可扩展性的关键技术，但目前缺乏对时间序列数据压缩方法的系统性比较研究。

Method: 采用两阶段压缩框架：数据转换和熵编码。在合成和真实数据集上评估各种压缩算法，通过消融实验分析各组件对整体压缩性能的影响。

Result: 研究揭示了不同算法在面对多样化时间序列特性时的优缺点，强调了完整压缩流程的重要性，而不仅仅是单个组件或算法。

Conclusion: 研究为针对特定数据集选择和组合最合适的压缩算法提供了全面指导，证明了良好配置的完整压缩流程对性能的关键影响。

Abstract: Our increasingly digital and connected world has led to the generation of
unprecedented amounts of data. This data must be efficiently managed,
transmitted, and stored to preserve resources and allow scalability. Data
compression has therein been a key technology for a long time, resulting in a
vast landscape of available techniques. This largest-to-date study analyzes and
compares various lossless data compression methods for time series data. We
present a unified framework encompassing two stages: data transformation and
entropy encoding. We evaluate compression algorithms across both synthetic and
real-world datasets with varying characteristics. Through ablation studies at
each compression stage, we isolate the impact of individual components on
overall compression performance -- revealing the strengths and weaknesses of
different algorithms when facing diverse time series properties. Our study
underscores the importance of well-configured and complete compression
pipelines beyond individual components or algorithms; it offers a comprehensive
guide for selecting and composing the most appropriate compression algorithms
tailored to specific datasets.

</details>


### [19] [Robustness of Covariance Estimators with Application in Activity Detection](https://arxiv.org/abs/2510.07044)
*Hendrik Bernd Zarucha,Peter Jung,Giuseppe Caire*

Main category: cs.IT

TL;DR: 该论文提出了一类通用的协方差估计器，通过实值函数g和模型协方差矩阵集H构建。证明了这类估计器在扰动足够小时具有鲁棒性，并将其应用于多接收天线随机接入中的活动检测问题。


<details>
  <summary>Details</summary>
Motivation: 研究协方差估计的鲁棒性，并将其应用于无线通信中的活动检测问题，解决大规模衰落系数的稀疏恢复问题。

Method: 使用实值函数g和模型协方差矩阵集H构建协方差估计器，将其应用于活动检测中的结构化协方差估计问题，提出了基于符号核条件的码本设计。

Result: 证明了在适当条件下，松弛最大似然估计器属于所考虑的通用协方差估计器类。当接收天线数量足够多且活跃用户数S≤⌈1/2M²⌉-1时，两种估计器都能恢复大规模衰落系数。

Conclusion: 所提出的通用协方差估计器类具有良好的鲁棒性，在活动检测应用中能够有效恢复大规模衰落系数，为无线通信系统设计提供了理论支持。

Abstract: The first part of this work considers a general class of covariance
estimators. Each estimator of that class is generated by a real-valued function
$g$ and a set of model covariance matrices $H$. If $\bf{W}$ is a potentially
perturbed observation of a searched covariance matrix, then the estimator is
the minimizer of the sum of $g$ applied to each eigenvalue of
$\bf{W}^\frac{1}{2}\bf{Z}^{-1}\bf{W}^\frac{1}{2}$ under the constraint that
$\bf{Z}$ is from $H$. It is shown that under mild conditions on $g$ and $H$
such estimators are robust, meaning the estimation error can be made
arbitrarily small if the perturbation of $\bf{W}$ gets small enough. \par In
the second part of this work the previous results are applied to activity
detection in random access with multiple receive antennas. In activity
detection recovering the large scale fading coefficients is a sparse recovery
problem which can be reduced to a structured covariance estimation problem. The
recovery can be done with a non-negative least squares estimator or with a
relaxed maximum likelihood estimator. It is shown that under suitable
assumptions on the distributions of the noise and the channel coefficients, the
relaxed maximum likelihood estimator is from the general class of covariance
estimators considered in the first part of this work. Then, codebooks based
upon a signed kernel condition are proposed. It is shown that with the proposed
codebooks both estimators can recover the large-scale fading coefficients if
the number of receive antennas is high enough and
$S\leq\left\lceil\frac{1}{2}M^2\right\rceil-1$ where $S$ is the number of
active users and $M$ is number of pilot symbols per user.

</details>


### [20] [A Theoretically-Grounded Codebook for Digital Semantic Communications](https://arxiv.org/abs/2510.07108)
*Lingyi Wang,Rashed Shelim,Walid Saad,Naren Ramakrishnan*

Main category: cs.IT

TL;DR: 提出了一种基于信息理论的语义通信码本设计方法，通过优化量化效率、传输效率和鲁棒性能，在图像重建任务中相比现有方法显著提升了性能指标。


<details>
  <summary>Details</summary>
Motivation: 现有语义通信系统需要将高维语义特征映射到离散符号表示，但缺乏理论指导的码本设计方法，无法同时优化量化效率、传输效率和鲁棒性能。

Method: 建立语义信息理论中一对多同义映射与码本Voronoi分区多对一量化映射的等价关系；推导语义特征与量化索引间的互信息；提出基于经验估计的熵正则化量化损失进行端到端码本训练；分析物理信道引起的语义失真并确定最优码本大小；提出信道感知的语义失真损失来减轻信道噪声影响。

Result: 在图像重建任务中，当信噪比为10dB时，所提出的理论指导码本设计相比现有方法在峰值信噪比(PSNR)上提升了24.1%，在学习感知图像块相似度(LPIPS)上提升了46.5%。

Conclusion: 该研究为数字语义通信提供了一种理论指导的码本设计框架，能够有效平衡量化效率、传输效率和鲁棒性能，显著提升了语义通信系统的性能。

Abstract: The use of a learnable codebook provides an efficient way for semantic
communications to map vector-based high-dimensional semantic features onto
discrete symbol representations required in digital communication systems. In
this paper, the problem of codebook-enabled quantization mapping for digital
semantic communications is studied from the perspective of information theory.
Particularly, a novel theoretically-grounded codebook design is proposed for
jointly optimizing quantization efficiency, transmission efficiency, and robust
performance. First, a formal equivalence is established between the one-to-many
synonymous mapping defined in semantic information theory and the many-to-one
quantization mapping based on the codebook's Voronoi partitions. Then, the
mutual information between semantic features and their quantized indices is
derived in order to maximize semantic information carried by discrete indices.
To realize the semantic maximum in practice, an entropy-regularized
quantization loss based on empirical estimation is introduced for end-to-end
codebook training. Next, the physical channel-induced semantic distortion and
the optimal codebook size for semantic communications are characterized under
bit-flip errors and semantic distortion. To mitigate the semantic distortion
caused by physical channel noise, a novel channel-aware semantic distortion
loss is proposed. Simulation results on image reconstruction tasks demonstrate
the superior performance of the proposed theoretically-grounded codebook that
achieves a 24.1% improvement in peak signal-to-noise ratio (PSNR) and a 46.5%
improvement in learned perceptual image patch similarity (LPIPS) compared to
the existing codebook designs when the signal-to-noise ratio (SNR) is 10 dB.

</details>


### [21] [Spectral Graph Clustering under Differential Privacy: Balancing Privacy, Accuracy, and Efficiency](https://arxiv.org/abs/2510.07136)
*Mohamed Seif,Antti Koskela,H. Vincent Poor,Andrea J. Goldsmith*

Main category: cs.IT

TL;DR: 提出了三种在边差分隐私下进行谱图聚类的机制：边翻转与邻接矩阵重排、低维空间投影加高斯噪声、以及带噪声的幂迭代方法，实现了严格的隐私保证和误差率分析。


<details>
  <summary>Details</summary>
Motivation: 研究在边差分隐私约束下进行谱图聚类的问题，需要在保护图边隐私的同时保持图的关键谱特性。

Method: 开发了三种机制：(1) 边翻转与邻接矩阵重排组合；(2) 低维空间投影加高斯噪声；(3) 带噪声的幂迭代方法，在迭代中分布高斯噪声。

Result: 提供了严格的隐私保证和误分类误差率的精确表征，在合成和真实网络上的实验验证了理论分析。

Conclusion: 所提出的机制在边差分隐私下实现了有效的谱图聚类，展示了实际的隐私-效用权衡。

Abstract: We study the problem of spectral graph clustering under edge differential
privacy (DP). Specifically, we develop three mechanisms: (i) graph perturbation
via randomized edge flipping combined with adjacency matrix shuffling, which
enforces edge privacy while preserving key spectral properties of the graph.
Importantly, shuffling considerably amplifies the guarantees: whereas flipping
edges with a fixed probability alone provides only a constant epsilon edge DP
guarantee as the number of nodes grows, the shuffled mechanism achieves
(epsilon, delta) edge DP with parameters that tend to zero as the number of
nodes increase; (ii) private graph projection with additive Gaussian noise in a
lower-dimensional space to reduce dimensionality and computational complexity;
and (iii) a noisy power iteration method that distributes Gaussian noise across
iterations to ensure edge DP while maintaining convergence. Our analysis
provides rigorous privacy guarantees and a precise characterization of the
misclassification error rate. Experiments on synthetic and real-world networks
validate our theoretical analysis and illustrate the practical privacy-utility
trade-offs.

</details>
