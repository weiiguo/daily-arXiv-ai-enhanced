<div id=toc></div>

# Table of Contents

- [cs.IT](#cs.IT) [Total: 15]
- [eess.SP](#eess.SP) [Total: 9]


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [1] [Efficient Synthesis for Two-Dimensional Strand Arrays with Row Constraints](https://arxiv.org/abs/2601.07968)
*Boaz Moav,Ryan Gabrys,Eitan Yaakobi*

Main category: cs.IT

TL;DR: 研究DNA合成中的空间约束问题，分析在行约束模型下两条DNA链的期望合成时间，提出不同策略的性能界限和优化算法。


<details>
  <summary>Details</summary>
Motivation: 受大规模DNA合成技术的驱动，研究在空间约束下的DNA链合成理论问题。DNA链在阵列中排列，按照固定的全局合成序列合成，但每行每周期最多只能合成一条链。

Method: 将合成过程分解为马尔可夫链进行分析，推导期望合成时间的上下界。研究不同策略：简单的滞后优先策略、带单符号前瞻的策略，并提出动态规划算法计算最优离线调度。

Result: 滞后优先策略的渐近期望完成时间为(q+3)L/2（q为字母表大小），且无前瞻的在线策略无法超越此界限。二进制情况下，单符号前瞻可将时间改进为7L/3。动态规划算法可计算任意固定序列对的最优离线调度。

Conclusion: 首次为空间约束下的DNA合成提供了分析界限，为未来研究此类设置中的最优合成策略奠定了基础。

Abstract: We study the theoretical problem of synthesizing multiple DNA strands under spatial constraints, motivated by large-scale DNA synthesis technologies. In this setting, strands are arranged in an array and synthesized according to a fixed global synthesis sequence, with the restriction that at most one strand per row may be synthesized in any synthesis cycle. We focus on the basic case of two strands in a single row and analyze the expected completion time under this row-constrained model. By decomposing the process into a Markov chain, we derive analytical upper and lower bounds on the expected synthesis time. We show that a simple laggard-first policy achieves an asymptotic expected completion time of (q+3)L/2 for any alphabet of size q, and that no online policy without look-ahead can asymptotically outperform this bound. For the binary case, we show that allowing a single-symbol look-ahead strictly improves performance, yielding an asymptotic expected completion time of 7L/3. Finally, we present a dynamic programming algorithm that computes the optimal offline schedule for any fixed pair of sequences. Together, these results provide the first analytical bounds for synthesis under spatial constraints and lay the groundwork for future studies of optimal synthesis policies in such settings.

</details>


### [2] [Distributed Detection under Stringent Resource Constraints](https://arxiv.org/abs/2601.07989)
*Abdelaziz Bounhar,Mireille Sarkiss,Michèle Wigger*

Main category: cs.IT

TL;DR: 本文研究了分布式检测中的Stein指数，分析了三种严格通信约束下离散无记忆信道的性能，发现部分连接和全连接信道存在性能差异。


<details>
  <summary>Details</summary>
Motivation: 研究在严格通信约束下分布式检测的性能极限，特别是当传感器通过离散无记忆信道向决策中心传输信息时，在不同约束条件下的Stein指数表现。

Method: 分析三种通信约束场景：1)信道使用次数随观测数n亚线性增长；2)信道使用次数为n但施加几乎必然的块输入成本约束；3)仅对期望施加块输入约束。通过调整Han的零速率编码策略适应部分连接DMCs，并为全连接DMCs提出新的编码策略和反证证明。

Result: 发现部分连接DMCs的Stein指数与Han和Kobayashi以及Shalaby和Papamarcou在零速率无噪声链路下的指数相同；全连接DMCs在前两种场景下性能退化为本地测试，传感器变得无用；第三种场景下传感器仍有帮助但性能下降，且零假设下约束的指数大于双边假设约束。

Conclusion: DMC的连接结构对分布式检测的Stein指数有决定性影响，部分连接信道能保持零速率无噪声链路的性能，而全连接信道在严格约束下性能严重退化，仅期望约束下传感器仍有一定作用。

Abstract: This paper identifies the Stein-exponent of distributed detection when the sensor communicates to the decision center over a discrete memoryless channel (DMC) subject to one of three stringent communication constraints: 1) The number of channel uses of the DMC grows sublinearly in the number of source observations n; 2) The number of channel uses is n but a block-input cost constraint is imposed almost surely, which grows sublinearly in n; 3) The block-input constraint is imposed only on expectation. We identify a dichotomy in the Stein-exponent of all these setups depending on the structure of the DMC's transition law. Under any of these three constraints, when the DMC is partially-connected (i.e., some outputs cannot be induced by certain inputs) the Stein-exponent matches the exponent identified by Han and Kobayashi and by Shalaby and Papamarcou for the scenario where communication is of zero-rate but over a noiseless link. We prove our result by adapting Han's zero-rate coding strategy to partially-connected DMCs.
  In contrast, for fully-connected DMCs, in our scenarios 1) and 2) the Stein-exponent collapses to that of a local test at the decision center, rendering the remote sensor and communication useless. %To prove this result, we propose new converse proofs relying on change of measure arguments.
  In scenario 3), the sensor remains beneficial even for fully-connected DMCs, however also collapses compared to the case of a partially-connected DMC. Moreover, the Stein-exponent is larger when the expectation constraint is imposed only under the null hypothesis compared to when it is imposed under both hypotheses. To prove these results, we propose both new coding strategies and new converse proofs.

</details>


### [3] [The many faces of multivariate information](https://arxiv.org/abs/2601.08030)
*Thomas F. Varley*

Main category: cs.IT

TL;DR: 提出一个通用函数Δ^k，将三种高阶信息度量统一起来，揭示高阶冗余和协同交互的层次结构


<details>
  <summary>Details</summary>
Motivation: 从多元数据中提取高阶结构对理解复杂系统至关重要，但现有信息论度量众多且分散，需要统一框架

Method: 提出参数化函数Δ^k，通过不同k值恢复现有度量，并利用熵共轭框架推导其共轭Γ^k

Result: Δ^0对应S信息，Δ^1对应对偶总相关，Δ^2对应负O信息，形成高阶协同层次；Γ^k形成高阶冗余层次

Conclusion: 统一了现有高阶信息度量，为理解复杂系统中的高阶冗余和协同交互提供了更一致的理论框架

Abstract: Extracting higher-order structures from multivariate data has become an area of intensive study in complex systems science, as these multipartite interactions can reveal insights into fundamental features of complex systems like emergent phenomena. Information theory provides a natural language for exploring these interactions, as it elegantly formalizes the problem of comparing ``wholes" and ``parts" using joint, conditional, and marginal entropies. A large number of distinct statistics have been developed over the years, all aiming to capture different aspects of ``higher-order" information sharing. Here, we show that three of them (the dual total correlation, S-information, and O-information) are special cases of a more general function, $Δ^{k}$ which is parameterized by a free parameter $k$. For different values of $k$, we recover different measures: $Δ^{0}$ is equal to the S-information, $Δ^{1}$ is equal to the dual total correlation, and $Δ^{2}$ is equal to the negative O-information. Generally, the $Δ^{k}$ function is arranged into a hierarchy of increasingly high-order synergies; for a given value of $k$, if $Δ^{k}>0$, then the system is dominated by interactions with order greater than $k$, while if $Δ^{k}<0$, then the system is dominated by interactions with order lower than $k$. $Δ^{k}=0$ if the system is composed entirely of synergies of order-k. Using the entropic conjugation framework, we also find that the conjugate of $Δ^{k}$, which we term $Γ^{k}$ is arranged into a similar hierarchy of increasingly high-order redundancies. These results provide new insights into the nature of both higher-order redundant and synergistic interactions, and helps unify the existing zoo of measures into a more coherent structure.

</details>


### [4] [Cardinality-consistent flag codes with longer type vectors](https://arxiv.org/abs/2601.08144)
*Junfeng Jia,Yanxun Chang*

Main category: cs.IT

TL;DR: 本文提出了一种统一的构造方法，生成两类旗码：一类具有最优距离和最长的类型向量，另一类具有更长的类型向量，两者都达到相同的码本大小。


<details>
  <summary>Details</summary>
Motivation: 旗码将常维码推广到具有规定维数的嵌套子空间序列作为码字。需要一种统一的构造方法来生成具有特定性质的旗码。

Method: 提出了一种综合构造方法，统一了循环轨道旗码，生成了两类旗码：一类具有最优距离和最长的类型向量，另一类具有更长的类型向量。

Result: 构造了两类旗码：1) 最优距离旗码，类型向量为(1,2,...,k,n-k,...,n-1)；2) 更长类型向量的旗码，类型向量为(1,2,...,k+h,2k+h,...,(s-2)k+h,n-k,...,n-1)。两类旗码都达到相同的码本大小∑_{i=1}^{s-1}q^{ik+h}+1。

Conclusion: 该统一构造方法成功生成了两类具有特定性质的旗码，为旗码设计提供了新的有效途径。

Abstract: Flag codes generalize constant dimension codes by considering sequences of nested subspaces with prescribed dimensions as codewords. A comprehensive construction, which unites cyclic orbit flag codes, yields two families of flag codes on $\mathbb{F}^n_q$ (where $n=sk+h$ with $s\geq 2$ and $0\leq h < k$): optimum distance flag codes of the longest possible type vector $(1, 2, \ldots, k, n-k, \ldots, n-1)$ and flag codes with longer type vectors $(1, 2, \ldots, k+h, 2k+h, \ldots, (s-2)k+h, n-k, \ldots, n-1)$. These flag codes achieve the same cardinality $\sum^{s-1}_{i=1}q^{ik+h}+1$.

</details>


### [5] [From Antenna Abundance to Antenna Intelligence in 6G Gigantic MIMO Systems](https://arxiv.org/abs/2601.08326)
*Emil Björnson,Amna Irshad,Özlem Tugfe Demir,Giuseppe Thadeu Freitas de Abreu,Alva Kosasih,Vitaly Petrov*

Main category: cs.IT

TL;DR: 论文提出通过智能非均匀稀疏阵列设计减少天线数量，实现更高效的巨型MIMO系统，用天线智能替代天线数量


<details>
  <summary>Details</summary>
Motivation: 当前大规模MIMO系统依赖大量天线实现高谱效，但未来系统需要数百天线，带来硬件复杂度、成本和功耗问题。需要更智能的阵列设计来减少天线需求。

Method: 重新审视经典均匀阵列设计，利用非均匀稀疏阵列和站点特定的天线布局（基于预优化的不规则阵列或实时可移动天线），借鉴无线定位技术原理，适应通信需求。

Result: 通过数值模拟证明，这些概念能够以更少天线实现优越的多用户MIMO性能，提高平均和速率等指标。

Conclusion: 提出未来天线阵列设计的范式转变：用天线智能替代天线数量，为高效、适应性强、可持续的巨型MIMO系统开辟新机遇。

Abstract: Current cellular systems achieve high spectral efficiency through Massive MIMO, which leverages an abundance of antennas to create favorable propagation conditions for multiuser spatial multiplexing. Looking towards future networks, the extrapolation of this paradigm leads to systems with many hundreds of antennas per base station, raising concerns regarding hardware complexity, cost, and power consumption. This article suggests more intelligent array designs that reduce the need for excessive antenna numbers. We revisit classical uniform array design principles and explain how their uniform spatial sampling leads to unnecessary redundancies in practical deployment scenarios. By exploiting non-uniform sparse arrays with site-specific antenna placements -- based on either pre-optimized irregular arrays or real-time movable antennas -- we demonstrate how superior multiuser MIMO performance can be achieved with far fewer antennas. These principles are inspired by previous works on wireless localization. We explain and demonstrate numerically how these concepts can be adapted for communications to improve the average sum rate and similar metrics. The results suggest a paradigm shift for future antenna array design, where antenna intelligence replaces sheer antenna count. This opens new opportunities for efficient, adaptable, and sustainable Gigantic MIMO systems.

</details>


### [6] [Movable Antenna for Integrating Near-field Channel Estimation and Localization](https://arxiv.org/abs/2601.08357)
*Chongjia Sun,Ziwei Wan,Lipeng Zhu,Zhenyu Xiao,Zhen Gao,Rui Zhang*

Main category: cs.IT

TL;DR: 提出多阶段设计框架，利用可移动天线在近场区域增强集成感知与通信性能，通过子区域划分、高精度角度估计、散射体定位和信道估计优化实现性能提升。


<details>
  <summary>Details</summary>
Motivation: 可移动天线为未来无线通信系统引入新的自由度，其大范围移动使无线信道传输进入近场区域，这为集成感知与通信带来新的性能增强机会。然而，需要有效的框架来利用这一优势。

Method: 提出多阶段设计框架：1) 将MA移动区域划分为多个子区域；2) 在每个子区域使用牛顿化正交匹配追踪算法进行高精度角度估计；3) 提出近场定位通过子区域射线聚类方法识别散射体位置；4) 基于估计的散射体位置细化近场信道估计以提升通信性能。

Result: 仿真结果表明，所提方案能显著提升MA感知精度和信道估计性能，为MA辅助的近场ISAC提供高效解决方案。

Conclusion: 该多阶段设计框架有效利用了可移动天线在近场区域的优势，通过系统化的角度估计、散射体定位和信道估计优化，显著提升了集成感知与通信系统的性能。

Abstract: Movable antenna (MA) introduces a new degree of freedom for future wireless communication systems by enabling the adaptive adjustment of antenna positions. Its large-range movement renders wireless channels transmission into the near-field region, which brings new performance enhancement for integrated sensing and communication (ISAC). This paper proposes a novel multi-stage design framework for broadband near-field ISAC assisted by MA. The framework first divides the MA movement area into multiple subregions, and employs the Newtonized orthogonal matching pursuit algorithm (NOMP) to achieve high-precision angle estimation in each subregion. Subsequently, a method called near-field localization via subregion ray clustering (LSRC) is proposed for identifying the positions of scatterers. This method finds the coordinates of each scatterer by jointly processing the angle estimates across all subregions. Finally, according to the estimated locations of the scatterers, the near-field channel estimation (CE) is refined for improving communication performance. Simulation results demonstrate that the proposed scheme can significantly enhance MA sensing accuracy and CE, providing an efficient solution for MA-aided near-field ISAC.

</details>


### [7] [On the Generalization Error of Differentially Private Algorithms Via Typicality](https://arxiv.org/abs/2601.08386)
*Yanxiao Liu,Chun Hei Michael Shiu,Lele Wang,Deniz Gündüz*

Main category: cs.IT

TL;DR: 本文从信息论角度研究随机学习算法的泛化误差，特别关注差分隐私算法的更紧致边界，改进了现有互信息和最大泄漏的边界。


<details>
  <summary>Details</summary>
Motivation: 现有研究已表明随机学习算法的泛化误差可以用互信息和最大泄漏来界定，但现有边界不够紧致，特别是对于差分隐私算法。本文旨在通过典型性论证和利用隐私算法的稳定性，推导出更紧致、易于计算的边界。

Method: 采用信息论框架，使用典型性论证方法，并利用差分隐私算法的稳定性特性。第一部分严格改进了Rodríguez-Gálvez等人（2021）的互信息边界；第二部分推导了学习算法最大泄漏的新上界。

Result: 获得了互信息和最大泄漏的显式、易于计算的边界公式，这些信息度量边界可直接转化为泛化误差保证，为差分隐私算法提供了更紧致的泛化误差边界。

Conclusion: 本文通过信息论方法显著改进了随机学习算法泛化误差的边界，特别是为差分隐私算法提供了更紧致的理论保证，将信息度量边界直接转化为泛化性能保证。

Abstract: We study the generalization error of stochastic learning algorithms from an information-theoretic perspective, with a particular emphasis on deriving sharper bounds for differentially private algorithms. It is well known that the generalization error of stochastic learning algorithms can be bounded in terms of mutual information and maximal leakage, yielding in-expectation and high-probability guarantees, respectively. In this work, we further upper bound mutual information and maximal leakage by explicit, easily computable formulas, using typicality-based arguments and exploiting the stability properties of private algorithms. In the first part of the paper, we strictly improve the mutual-information bounds by Rodríguez-Gálvez et al. (IEEE Trans. Inf. Theory, 2021). In the second part, we derive new upper bounds on the maximal leakage of learning algorithms. In both cases, the resulting bounds on information measures translate directly into generalization error guarantees.

</details>


### [8] [An Efficient Algorithm to Sample Quantum Low-Density Parity-Check Codes](https://arxiv.org/abs/2601.08387)
*Paolo Santini*

Main category: cs.IT

TL;DR: 提出一种高效的随机稀疏矩阵采样算法，用于生成量子LDPC码的校验矩阵，该算法基于信息集解码(ISD)技术，具有纯组合特性而非代数约束。


<details>
  <summary>Details</summary>
Motivation: 现有量子LDPC码构造方法多为代数方法，需要施加特定约束（如准循环性），限制了随机性和灵活性。需要一种更通用、更随机的稀疏自正交矩阵采样方法。

Method: 使用信息集解码(ISD)技术逐行采样稀疏矩阵H的行向量，确保H满足自正交条件HH^T=0。算法为纯组合方法，不依赖代数结构，可推广到非二进制有限域和更一般的量子稳定子LDPC码。

Result: 理论上分析了算法的参数范围和计算复杂度，数值模拟验证了方法的可行性和高效性。能够生成尽可能随机的稀疏自正交矩阵。

Conclusion: 提出了一种简单而有效的组合算法，用于采样随机稀疏自正交矩阵，为量子LDPC码构造提供了更灵活、更通用的工具，克服了现有代数方法的局限性。

Abstract: In this paper, we present an efficient algorithm to sample random sparse matrices to be used as check matrices for quantum Low-Density Parity-Check (LDPC) codes. To ease the treatment, we mainly describe our algorithm as a technique to sample a dual-containing binary LDPC code, hence, a sparse matrix $\mathbf H\in\mathbb F_2^{r\times n}$ such that $\mathbf H\mathbf H^\top = \mathbf 0$. However, as we show, the algorithm can be easily generalized to sample dual-containing LDPC codes over non binary finite fields as well as more general quantum stabilizer LDPC codes.
  While several constructions already exist, all of them are somewhat algebraic as they impose some specific property (e.g., the matrix being quasi-cyclic). Instead, our algorithm is purely combinatorial as we do not require anything apart from the rows of $\mathbf H$ being sparse enough. In this sense, we can think of our algorithm as a way to sample sparse, self-orthogonal matrices that are as random as possible.
  Our algorithm is conceptually very simple and, as a key ingredient, uses Information Set Decoding (ISD) to sample the rows of $\mathbf H$, one at a time. The use of ISD is fundamental as, without it, efficient sampling would not be feasible. We give a theoretical characterization of our algorithm, determining which ranges of parameters can be sampled as well as the expected computational complexity. Numerical simulations and benchmarks confirm the feasibility and efficiency of our approach.

</details>


### [9] [LWM-Spectro: A Foundation Model for Wireless Baseband Signal Spectrograms](https://arxiv.org/abs/2601.08780)
*Namhyun Kim,Sadjad Alikhani,Ahmed Alkhateeb*

Main category: cs.IT

TL;DR: 提出LWM-Spectro，一个基于Transformer的基础模型，通过自监督掩码建模和对比学习从大规模I/Q时频谱图学习通用无线表示，在调制分类等下游任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 无线通信中的I/Q基带信号包含物理层和信道特征，但直接从原始信号学习鲁棒且可迁移的表示面临挑战，包括异构通信系统、多样化传播环境和有限标注数据。

Method: 使用Transformer架构，将I/Q数据表示为时频谱图，通过自监督掩码建模和对比学习进行预训练，采用专家混合(MoE)架构学习通用无线表示。

Result: LWM-Spectro在调制分类和联合SNR/移动性识别等下游任务中，在少样本和数据丰富场景下均优于现有深度学习基线，提供统一的无线学习基础。

Conclusion: LWM-Spectro通过大规模预训练学习通用无线表示，能有效迁移到各种下游任务，为无线学习提供了统一的基础模型框架。

Abstract: The received in-phase and quadrature (I/Q) baseband signals inherently encode physical-layer and channel characteristics of wireless links. Learning robust and transferable representations directly from such raw signals, however, remains challenging due to heterogeneous communication systems, diverse propagation environments, and limited labeled data. To address this, we present LWM-Spectro, a transformer-based foundation model pretrained on large-scale I/Q data represented as time-frequency spectrograms. The model leverages self-supervised masked modeling, contrastive learning, and a mixture-of-experts (MoE) architecture to learn general-purpose wireless representations. These representations transfer effectively to downstream tasks such as modulation classification and joint SNR/mobility recognition, even with minimal supervision. Across tasks, LWM-Spectro consistently outperforms state-of-the-art deep learning baselines in both few-shot and data-rich regimes, providing a unified foundation for wireless learning.

</details>


### [10] [Distribution Estimation with Side Information](https://arxiv.org/abs/2601.08535)
*Haricharan Balasundaram,Andrew Thangaraj*

Main category: cs.IT

TL;DR: 该论文研究在具有额外侧信息的情况下进行离散分布估计的问题，特别关注文本数据中通过词向量嵌入获得的语义相似性信息，提出了局部模型和偏序模型两种侧信息模型，并理论分析了侧信息对平方误差风险的改进。


<details>
  <summary>Details</summary>
Motivation: 在大型字母表数据集（如文本语料库）中，通过词向量嵌入可以自然地获得关于词义/相似性的侧信息，这些信息可以改善离散分布估计的性能。论文旨在探索如何利用这种语义侧信息来提升传统分布估计方法的准确性。

Method: 提出了两种侧信息模型：1）局部模型，假设未知分布位于已知分布的邻域内；2）偏序模型，将字母表划分为已知的高概率和低概率集合。对这两种模型进行了理论分析，使用i.i.d.样本进行离散分布估计，并在自然语言和合成数据上进行仿真验证。

Result: 理论分析表明，在两种侧信息模型下，平方误差风险都有显著改善。仿真实验在自然语言数据和合成数据上验证了这些理论增益，证明了利用语义侧信息可以有效地提升分布估计的准确性。

Conclusion: 该研究表明，在离散分布估计中利用额外的侧信息（特别是从词向量嵌入中获得的语义信息）可以显著改善估计性能。提出的局部模型和偏序模型为利用这类侧信息提供了理论框架，并在实际应用中展示了实际价值。

Abstract: We consider the classical problem of discrete distribution estimation using i.i.d. samples in a novel scenario where additional side information is available on the distribution. In large alphabet datasets such as text corpora, such side information arises naturally through word semantics/similarities that can be inferred by closeness of vector word embeddings, for instance. We consider two specific models for side information--a local model where the unknown distribution is in the neighborhood of a known distribution, and a partial ordering model where the alphabet is partitioned into known higher and lower probability sets. In both models, we theoretically characterize the improvement in a suitable squared-error risk because of the available side information. Simulations over natural language and synthetic data illustrate these gains.

</details>


### [11] [On the Optimality of Decode and Forward for Some Cooperative Broadcast Channels](https://arxiv.org/abs/2601.08592)
*Nicolas Le Gouic,Yossef Steinberg,Michèle Wigger*

Main category: cs.IT

TL;DR: 该论文针对具有从强接收器到弱接收器单向协作的"更有能力"广播信道，提出了新的容量区域边界点，并通过简单的编码方案实现。


<details>
  <summary>Details</summary>
Motivation: 研究具有接收器间协作的广播信道容量区域，特别是针对"更有能力"广播信道（即强接收器信道条件优于弱接收器），探索通过单向协作提升系统性能的可能性。

Method: 采用简单的编码方案：在发射端使用叠加编码，在强接收器端使用解码转发策略。强接收器解码后将其信息转发给弱接收器，实现协作通信。

Result: 为特定类别的广播信道确定了新的容量区域边界点。将一般结果应用于高斯广播信道和混合信道（强接收器为二进制擦除信道，弱接收器为二进制对称信道），验证了理论结果的有效性。

Conclusion: 对于具有单向协作的"更有能力"广播信道，提出的简单编码方案能够实现新的容量区域边界点，为这类协作广播系统的设计提供了理论指导和实用方案。

Abstract: This article characterizes new boundary points on the capacity region of certain classes of more capable broadcast channels (BC) with uni-directional cooperation from the stronger to the weaker receiver. The new boundary points are achieved by a simple coding scheme that employs superposition coding at the transmitter with decode and forward at the stronger receiver. We evaluate our general result for Gaussian BCs and for a BC consisting of a binary erasure channel (BEC) to the stronger receiver and a binary symmetric channel (BSC) to the weaker receiver.

</details>


### [12] [Quantum CSS LDPC Codes based on Dyadic Matrices for Belief Propagation-based Decoding](https://arxiv.org/abs/2601.08636)
*Alessio Baldelli,Massimo Battaglioni,Jonathan Mandelbaum,Sisi Miao,Laurent Schmalen*

Main category: cs.IT

TL;DR: 提出基于二元矩阵的代数构造方法，设计具有围长6的经典和量子LDPC码，并满足CAMEL-ensemble四进制BP解码器的兼容性条件


<details>
  <summary>Details</summary>
Motivation: 量子LDPC码在量子纠错中需要在纠错能力和实现复杂度之间取得平衡，需要设计更实用的构造方法

Method: 使用二元矩阵代数构造方法，首先生成具有围长6的经典二进制准二元LDPC码，然后在CSS框架下扩展，构建满足CAMEL-ensemble四进制BP解码器兼容性条件的两个分量奇偶校验矩阵

Result: 该方法能够设计出满足兼容性条件的量子LDPC码，确保所有不可避免的长度为4的循环集中在一个变量节点，从而通过对该变量节点进行抽选来减轻其有害影响

Conclusion: 提出的二元矩阵代数构造方法为设计实用的量子LDPC码提供了一种有效途径，特别适用于CAMEL-ensemble四进制BP解码器框架

Abstract: Quantum low-density parity-check (QLDPC) codes provide a practical balance between error-correction capability and implementation complexity in quantum error correction (QEC). In this paper, we propose an algebraic construction based on dyadic matrices for designing both classical and quantum LDPC codes. The method first generates classical binary quasi-dyadic LDPC codes whose Tanner graphs have girth 6. It is then extended to the Calderbank-Shor-Steane (CSS) framework, where the two component parity-check matrices are built to satisfy the compatibility condition required by the recently introduced CAMEL-ensemble quaternary belief propagation decoder. This compatibility condition ensures that all unavoidable cycles of length 4 are assembled in a single variable node, allowing the mitigation of their detrimental effects by decimating that variable node.

</details>


### [13] [Multivariate Polynomial Codes for Efficient Matrix Chain Multiplication in Distributed Systems](https://arxiv.org/abs/2601.08708)
*Jesús Gómez-Vilardebò*

Main category: cs.IT

TL;DR: 本文提出两种多元多项式编码方案，专门针对分布式环境中的矩阵链乘法问题，在计算复杂度和存储开销之间实现权衡，相比单变量编码显著降低存储开销。


<details>
  <summary>Details</summary>
Motivation: 分布式计算集群中的矩阵链乘法存在straggler问题（最慢工作者主导整体延迟）。现有编码计算策略主要针对两个矩阵相乘的简单情况，虽然缓解了straggler效应，但增加了计算复杂度和存储需求。实际应用中常涉及长矩阵链乘法，单变量多项式编码会显著放大计算和存储开销，限制可扩展性。

Method: 提出两种专门为分布式环境设计的多元多项式编码方案，用于矩阵链乘法。这些方案利用多元多项式特性，在计算和存储之间进行权衡优化。

Result: 多元多项式编码虽然增加了工作者的计算成本，但相比单变量扩展方案能显著降低存储开销。这揭示了计算效率和存储效率之间的基本权衡，展示了多元编码作为大规模分布式线性代数任务实用解决方案的潜力。

Conclusion: 多元多项式编码为分布式矩阵链乘法提供了有前景的解决方案，通过接受一定的计算成本来换取存储开销的大幅降低，为解决大规模分布式线性代数任务中的straggler问题提供了实用途径。

Abstract: We study the problem of computing matrix chain multiplications in a distributed computing cluster. In such systems, performance is often limited by the straggler problem, where the slowest worker dominates the overall computation latency. To resolve this issue, several coded computing strategies have been proposed, primarily focusing on the simplest case: the multiplication of two matrices. These approaches successfully alleviate the straggler effect, but they do so at the expense of higher computational complexity and increased storage needs at the workers. However, in many real-world applications, computations naturally involve long chains of matrix multiplications rather than just a single two-matrix product. Extending univariate polynomial coding to this setting has been shown to amplify the costs -- both computation and storage overheads grow significantly, limiting scalability. In this work, we propose two novel multivariate polynomial coding schemes specifically designed for matrix chain multiplication in distributed environments. Our results show that while multivariate codes introduce additional computational cost at the workers, they can dramatically reduce storage overhead compared to univariate extensions. This reveals a fundamental trade-off between computation and storage efficiency, and highlights the potential of multivariate codes as a practical solution for large-scale distributed linear algebra tasks.

</details>


### [14] [On the Algebraic Structure Underlying the Support Enumerators of Linear Codes](https://arxiv.org/abs/2601.08744)
*Nitin Kenjale,Anuradha S. Garge*

Main category: cs.IT

TL;DR: 论文引入了支撑分布和支撑枚举器作为经典重量分布和重量枚举器的细化，用于捕捉线性分组码的坐标级活动，建立了支撑分布的计数公式和MacWilliams型恒等式，并推导了自对偶码的判定条件。


<details>
  <summary>Details</summary>
Motivation: 经典重量分布和重量枚举器虽然提供了码字的整体重量信息，但无法捕捉到坐标级别的活动模式。为了更详细地理解码的结构，需要引入能够反映每个坐标非零情况的细化工具。

Method: 引入支撑分布和支撑枚举器概念，建立计算第i个坐标非零的码字数量的公式，推导支撑分布与对偶码支撑分布之间的MacWilliams型恒等式，并基于此恒等式推导自对偶码的判定条件。

Result: 1. 建立了支撑分布的精确计数公式；2. 推导了线性码与其对偶码支撑枚举器之间的MacWilliams型恒等式；3. 基于支撑分布相等性得到了自对偶码的判定条件。

Conclusion: 支撑分布和支撑枚举器提供了比经典重量分布更详细的码结构信息，补充了基于重量的对偶理论，为理解线性码的坐标级特性提供了新的理论框架。

Abstract: In this paper, we have introduced the concepts of support distribution and the support enumerator as refinements of the classical weight distribution and weight enumerator respectively, capturing coordinate level activity in linear block codes. More precisely, we have established formula for counting codewords in the linear code C whose i-th coordinate is nonzero. Moreover, we derived a MacWilliam's type identity, relating the normalized support enumerators of a linear code and its dual, explaining how coordinate information transforms under duality. Using this identity we deduce a condition for self duality based on the equality of support distributions. These results provide a more detailed understanding of code structure and complement classical weight based duality theory.

</details>


### [15] [Majority-Logic Decoding of Binary Locally Recoverable Codes: A Probabilistic Analysis](https://arxiv.org/abs/2601.08765)
*Hoang Ly,Emina Soljanin,Philip Whiting*

Main category: cs.IT

TL;DR: 研究二进制线性局部可修复码在多数逻辑解码下的纠错性能，推导了在BEC和BSC信道上的解码失败概率上界，展示了典型性能与最坏情况保证之间的显著差距。


<details>
  <summary>Details</summary>
Motivation: 局部可修复码在分布式存储系统中用于高效恢复擦除，但其结构特性已得到广泛研究，而在随机擦除和错误下的性能尚未充分探索。本文旨在研究LRC在多数逻辑解码下的纠错性能。

Method: 采用多数逻辑解码方法，针对具有固定局部性和可变可用性的二进制线性LRC，推导了在BEC和BSC信道上的解码失败概率的显式上界，分析了比特错误率和块错误率与局部性和可用性参数的关系。

Result: 在可用性满足温和增长条件下，块解码失败概率渐近消失，多数逻辑解码能够成功纠正几乎所有与块长度成线性关系的错误和擦除模式。结果揭示了最坏情况保证与随机信道模型下典型性能之间的显著差距。

Conclusion: 局部可修复码在多数逻辑解码下表现出优异的纠错性能，特别是在可用性适度增长时能够实现渐近可靠的解码，这为LRC的实际应用提供了重要的性能保证。

Abstract: Locally repairable codes (LRCs) were originally introduced to enable efficient recovery from erasures in distributed storage systems by accessing only a small number of other symbols. While their structural properties-such as bounds and constructions-have been extensively studied, the performance of LRCs under random erasures and errors has remained largely unexplored. In this work, we study the error- and erasure-correction performance of binary linear LRCs under majority-logic decoding (MLD). Focusing on LRCs with fixed locality and varying availability, we derive explicit upper bounds on the probability of decoding failure over the memoryless Binary Erasure Channel (BEC) and Binary Symmetric Channel (BSC). Our analysis characterizes the behavior of the bit-error rate (BER) and block-error rate (BLER) as functions of the locality and availability parameters. We show that, under mild growth conditions on the availability, the block decoding failure probability vanishes asymptotically, and that majority-logic decoding can successfully correct virtually all of error and erasure patterns of weight linear in the blocklength. The results reveal a substantial gap between worst-case guarantees and typical performance under stochastic channel models.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [16] [Modal Parameter Extraction via Propeller-Driven Vibration Testing](https://arxiv.org/abs/2601.08123)
*Gabriele Dessena,Alessandro Pontillo*

Main category: eess.SP

TL;DR: 螺旋桨驱动振动测试(PVT)作为传统地面振动测试(GVT)的替代方案，通过螺旋桨激励识别飞机结构模态参数，验证了其在低频模态提取方面的可行性。


<details>
  <summary>Details</summary>
Motivation: 传统地面振动测试(GVT)成本高、耗时长，需要寻找更高效的替代方法。螺旋桨驱动振动测试(PVT)作为一种输出模态分析方法，旨在验证其作为GVT补充方案的可行性。

Method: 使用7075-T6铝合金悬臂翼梁，安装7个加速度计，通过外置电机和螺旋桨激励。进行7次测试：无激励基线、5个恒定油门工况、1个手动上下油门扫频。采用自然激励技术与Loewner框架(NExT-LF)识别模态参数。

Result: 螺旋桨激励下主要共振峰仍可观测，低油门工况会产生窄带谐波可能掩盖结构峰值，扫频可减少持续重叠。前两阶模态匹配度高(MAC>0.99)，第三阶模态重复性较差(MAC=0.827)且频率偏移较大，这与螺旋桨引起的弯扭耦合和非理想扫频控制有关。

Conclusion: PVT可作为GVT的可行补充方案，用于提取低频模态信息。未来研究方向包括自动油门调度和考虑耦合效应的测试规划。

Abstract: Ground Vibration Testing (GVT) supports aircraft certification but often requires lengthy and costly campaigns. Propeller-driven Vibration Testing (PVT) is assessed here as an output-only alternative, in line with Operational Modal Analysis approaches such as Taxi Vibration Testing and Flight Vibration Testing. A cantilever Aluminium 7075-T6 wing spar is instrumented with seven accelerometers and excited by an outboard electric motor and propeller. Seven runs are carried out: a motor-off baseline, five constant-throttle cases, and a manual up-down throttle sweep. The acquired spectra indicate that the dominant resonances remain observable under propeller excitation, while low-throttle conditions introduce narrowband harmonics that may mask structural peaks; the sweep reduces persistent overlap. Modal parameters are identified for the baseline and sweep cases using the Natural Excitation Technique with the Loewner Framework (NExT-LF). The first two modes remain closely matched (Modal Assurance Criterion (MAC) > 0.99), whereas the third mode shows reduced repeatability (MAC = 0.827) and a larger frequency shift, consistent with propeller-induced bending--torsion coupling and non-ideal sweep control. Overall, PVT provides a viable complement to GVT for extracting low-frequency modal information and motivates pursuing future work on automated throttle scheduling and coupling-aware test planning.

</details>


### [17] [Variable-Length Wideband CSI Feedback via Loewner Interpolation and Deep Learning](https://arxiv.org/abs/2601.08300)
*Meilin Li,Wei Xu,Zhixiang Hu,An Liu*

Main category: eess.SP

TL;DR: 提出用于U6G频段FDD大规模MIMO系统的变长宽带CSI反馈方案，采用Loewner插值框架和神经网络压缩，支持变长反馈并提升恢复精度


<details>
  <summary>Details</summary>
Motivation: 现有基于压缩感知和深度学习的CSI反馈方案在角延迟域截断信道，但DFT基的能量泄漏效应在U6G等宽带信道中更严重，导致恢复精度瓶颈

Method: 引入Loewner插值框架生成基于当前CSI矩阵的动态基，在频域高效压缩；通过神经网络在空域进一步压缩；设计无速率自编码器，支持变长反馈；开发自适应量化策略增强鲁棒性

Result: 仿真结果表明，所提方案能以更少或相等的反馈开销实现更高的CSI反馈精度，并相比基线方案提升频谱效率

Conclusion: 提出的Loewner插值框架结合神经网络压缩和变长反馈机制，有效解决了宽带信道中的能量泄漏问题，为U6G频段FDD大规模MIMO系统提供了高效的CSI反馈方案

Abstract: In this paper, we propose a variable-length wideband channel state information (CSI) feedback scheme for Frequency Division Duplex (FDD) massive multiple-input multipleoutput (MIMO) systems in U6G band (6425MHz-7125MHz). Existing compressive sensing (CS)-based and deep learning (DL)- based schemes preprocess the channel by truncating it in the angular-delay domain. However, the energy leakage effect caused by the Discrete Fourier Transform (DFT) basis will be more serious and leads to a bottleneck in recovery accuracy when applied to wideband channels such as those in U6G. To solve this problem, we introduce the Loewner Interpolation (LI) framework which generates a set of dynamic bases based on the current CSI matrix, enabling highly efficient compression in the frequency domain. Then, the LI basis is further compressed in the spatial domain through a neural network. To achieve a flexible trade-off between feedback overhead and recovery accuracy, we design a rateless auto-encoder trained with tail dropout and a multi-objective learning schedule, supporting variable-length feedback with a singular model. Meanwhile, the codewords are ranked by importance, ensuring that the base station (BS) can still maintain acceptable reconstruction performance under limited feedback with tail erasures. Furthermore, an adaptive quantization strategy is developed for the feedback framework to enhance robustness. Simulation results demonstrate that the proposed scheme could achieve higher CSI feedback accuracy with less or equal feedback overhead, and improve spectral efficiency compared with baseline schemes.

</details>


### [18] [Meta-Backscatter: Long-Distance Battery-Free Metamaterial-Backscatter Sensing and Communication](https://arxiv.org/abs/2601.08307)
*Taorui Liu,Xu Liu,Zhiquan Xu,Houfeng Chen,Hongliang Zhang,Lingyang Song*

Main category: eess.SP

TL;DR: 该论文提出了基于超材料的元反向散射系统，通过超材料标签集中反射信号功率，显著扩展了无电池物联网的通信距离，突破了传统反向散射标签仅几米范围的限制。


<details>
  <summary>Details</summary>
Motivation: 传统无电池物联网（BF-IoT）虽然具有低成本、超低功耗和鲁棒性等优势，但受限于反向散射标签的通信范围（通常仅几米），这严重制约了其实际部署。需要突破这一关键通信距离障碍。

Method: 提出元反向散射系统，利用超材料标签替代传统全向天线标签。超材料标签通过密集铺设的亚波长单元集中反射信号功率，显著扩展通信范围。论文建立了统一的设计框架，包括超材料标签设计方法、兼容收发器设计，并实现了原型系统进行实验验证。

Result: 元反向散射系统原型实验结果表明，超材料标签能够显著扩展无电池物联网的通信距离，突破了传统反向散射标签的几米限制，同时保持了BF-IoT的低成本、低功耗等固有优势。

Conclusion: 元反向散射系统为无电池物联网提供了突破通信距离限制的可行解决方案。论文建立了统一设计框架和研究路线图，指出了未来研究的关键挑战和潜在方向，包括进一步优化超材料设计、系统集成和应用扩展等。

Abstract: Battery-free Internet of Things (BF-IoT) enabled by backscatter communication is a rapidly evolving technology offering advantages of low cost, ultra-low power consumption, and robustness. However, the practical deployment of BF-IoT is significantly constrained by the limited communication range of common backscatter tags, which typically operate with a range of merely a few meters due to inherent round-trip path loss. Meta-backscatter systems that utilize metamaterial tags present a promising solution, retaining the inherent advantages of BF-IoT while breaking the critical communication range barrier. By leveraging densely paved sub-wavelength units to concentrate the reflected signal power, metamaterial tags enable a significant communication range extension over existing BF-IoT tags that employ omni-directional antennas. In this paper, we synthesize the principles and paradigms of metamaterial sensing to establish a unified design framework and a forward-looking research roadmap. Specifically, we first provide an overview of backscatter communication, encompassing its development history, working principles, and tag classification. We then introduce the design methodology for both metamaterial tags and their compatible transceivers. Moreover, we present the implementation of a meta-backscatter system prototype and report the experimental results based on it. Finally, we conclude by highlighting key challenges and outlining potential avenues for future research.

</details>


### [19] [Bio-RV: Low-Power Resource-Efficient RISC-V Processor for Biomedical Applications](https://arxiv.org/abs/2601.08428)
*Vijay Pratap Sharma,Annu Kumar,Mohd Faisal Khan,Mukul Lokhande,Santosh Kumar Vishvakarma*

Main category: eess.SP

TL;DR: Bio-RV是一款紧凑型RISC-V处理器，专为生物医学控制应用设计，具有低功耗、确定性执行和硬件复杂度低的特点，适用于起搏器等植入式医疗设备。


<details>
  <summary>Details</summary>
Motivation: 针对生物医学控制应用（如加速器基生物医学SoC和植入式起搏器系统）需要超低功耗、安全关键且资源高效的处理器，现有方案可能过于复杂或功耗过高。

Method: 设计了一个多周期RV32I核心，提供显式执行控制和外部指令加载功能，支持受控固件部署、ASIC启动和硅后测试。作为轻量级主机控制器，协调加速器配置和数据传输，并处理与起搏、传感、心电、遥测和电池管理模块的接口。

Result: 在FPGA原型上仅需708个LUT和235个触发器，采用180nm CMOS技术实现，工作频率50MHz，硬件占用小。布局后结果表明架构决策符合最小能耗要求。

Conclusion: Bio-RV优先考虑确定性执行、最小硬件复杂度和集成灵活性，而非峰值计算速度，满足超低功耗、安全关键生物医学系统的需求。

Abstract: This work presents Bio-RV, a compact and resource-efficient RISC-V processor intended for biomedical control applications, such as accelerator-based biomedical SoCs and implantable pacemaker systems. The proposed Bio-RV is a multi-cycle RV32I core that provides explicit execution control and external instruction loading with capabilities that enable controlled firmware deployment, ASIC bring-up, and post-silicon testing. In addition to coordinating accelerator configuration and data transmission in heterogeneous systems, Bio-RV is designed to function as a lightweight host controller, handling interfaces with pacing, sensing, electrogram (EGM), telemetry, and battery management modules. With 708 LUTs and 235 flip-flops on FPGA prototypes, Bio-RV, implemented in a 180 nm CMOS technology, operate at 50 MHz and feature a compact hardware footprint. According to post-layout results, the proposed architectural decisions align with minimal energy use. Ultimately, Bio-RV prioritises deterministic execution, minimal hardware complexity, and integration flexibility over peak computing speed to meet the demands of ultra-low-power, safety-critical biomedical systems.

</details>


### [20] [Effective outdoor pathloss prediction: A multi-layer segmentation approach with weighting map](https://arxiv.org/abs/2601.08436)
*Yuan Gao,Tao Wen,Wenjing Xie,Jianbo Du,Yong Zeng,Dusit Niyato,Shugong Xu*

Main category: eess.SP

TL;DR: 提出基于ResNet的路径损耗预测模型，通过生成Tx/Rx深度图、距离图和权重图来捕捉环境特征，在计算效率和预测精度上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统射线追踪和模型方法计算复杂度高且与实际环境存在差异，深度学习为路径损耗预测提供了更准确且计算效率更高的替代方案。

Method: 使用ResNet架构，从地理数据生成发射端深度图、接收端深度图和距离图，并创建权重图来强调Tx-Rx直接路径相邻区域的影响。

Result: 在ITU挑战赛2024和ICASSP 2023数据集上，模型性能比PPNet、RPNet和Vision Transformer提升1.2-3.0 dB，浮点运算量减少60%。消融研究证实权重图显著提升预测性能。

Conclusion: 提出的ResNet模型通过创新的特征提取和权重图设计，在路径损耗预测任务中实现了更高的精度和更低的计算复杂度。

Abstract: Predicting pathloss by considering the physical environment is crucial for effective wireless network planning. Traditional methods, such as ray tracing and model-based approaches, often face challenges due to high computational complexity and discrepancies between models and real-world environments. In contrast, deep learning has emerged as a promising alternative, offering accurate path loss predictions with reduced computational complexity. In our research, we introduce a ResNet-based model designed to enhance path loss prediction. We employ innovative techniques to capture key features of the environment by generating transmission (Tx) and reception (Rx) depth maps, as well as a distance map from the geographic data. Recognizing the significant attenuation caused by signal reflection and diffraction, particularly at high frequencies, we have developed a weighting map that emphasizes the areas adjacent to the direct path between Tx and Rx for path loss prediction. {Extensive simulations demonstrate that our model outperforms PPNet, RPNet, and Vision Transformer (ViT) by 1.2-3.0 dB using dataset of ITU challenge 2024 and ICASSP 2023. In addition, the floating point operations (FLOPs) of the proposed model is 60\% less than those of benchmarks.} Additionally, ablation studies confirm that the inclusion of the weighting map significantly enhances prediction performance.

</details>


### [21] [SDP: A Unified Protocol and Benchmarking Framework for Reproducible Wireless Sensing](https://arxiv.org/abs/2601.08463)
*Di Zhang,Jiawei Huang,Yuanhao Cui,Xiaowen Cao,Tony Xiao Han,Xiaojun Jing,Christos Masouros*

Main category: eess.SP

TL;DR: SDP（Sensing Data Protocol）是一个协议级抽象和统一基准，用于标准化无线感知研究，解决硬件异构性和实验可复现性问题。


<details>
  <summary>Details</summary>
Motivation: 无线感知领域缺乏统一的实验基础，硬件相关的信道测量、预处理流程和评估协议在不同设备和数据集间差异很大，阻碍了公平比较和可复现性。

Method: SDP作为标准化层，通过确定性物理层净化、规范张量构建、标准化训练和评估流程，将学习任务与硬件异构性解耦。

Result: SDP在保持竞争力的准确率的同时，显著提高了稳定性，在复杂活动识别任务中将种子间性能方差降低了几个数量级。真实世界实验展示了跨异构硬件的互操作性。

Conclusion: SDP为无线感知研究提供了统一的协议和基准，支持从临时实验向可靠工程实践的转变，实现了可复现和可比较的研究。

Abstract: Learning-based wireless sensing has made rapid progress, yet the field still lacks a unified and reproducible experimental foundation. Unlike computer vision, wireless sensing relies on hardware-dependent channel measurements whose representations, preprocessing pipelines, and evaluation protocols vary significantly across devices and datasets, hindering fair comparison and reproducibility.
  This paper proposes the Sensing Data Protocol (SDP), a protocol-level abstraction and unified benchmark for scalable wireless sensing. SDP acts as a standardization layer that decouples learning tasks from hardware heterogeneity. To this end, SDP enforces deterministic physical-layer sanitization, canonical tensor construction, and standardized training and evaluation procedures, decoupling learning performance from hardware-specific artifacts. Rather than introducing task-specific models, SDP establishes a principled protocol foundation for fair evaluation across diverse sensing tasks and platforms. Extensive experiments demonstrate that SDP achieves competitive accuracy while substantially improving stability, reducing inter-seed performance variance by orders of magnitude on complex activity recognition tasks. A real-world experiment using commercial off-the-shelf Wi-Fi hardware further illustrating the protocol's interoperability across heterogeneous hardware. By providing a unified protocol and benchmark, SDP enables reproducible and comparable wireless sensing research and supports the transition from ad hoc experimentation toward reliable engineering practice.

</details>


### [22] [Drone Surveillance via Coordinated Beam Sweeping in MIMO-ISAC Networks](https://arxiv.org/abs/2601.08483)
*Palatip Jopanya,Diana P. M. Osorio,Erik G. Larsson*

Main category: eess.SP

TL;DR: 提出一种与5G SSB同步信号块协同的无人机监控方案，通过多基站协作在波束扫描中同时实现通信和感知，采用预编码器设计保证感知与通信信号正交性


<details>
  <summary>Details</summary>
Motivation: 需要同时实现5G通信和低空无人机监控，解决通信信号与感知信号之间的干扰问题，提高无人机检测性能

Method: 采用多基站协作配置，AP协同照射监控区域体素网格，与5G SSB突发信号同时发送感知波束，设计预编码器保证感知波束与SSB正交性，最大化感知SINR同时确保用户SINR要求

Result: 提出的预编码器性能优于非协同预编码器，对无人机高度变化影响小，能有效分离通信和感知信号

Conclusion: 该方案成功实现了5G通信与无人机监控的协同工作，通过预编码器设计解决了信号干扰问题，为低空无人机检测提供了有效解决方案

Abstract: This paper introduces a scheme for drone surveillance coordinated with the fifth generation (5G) synchronization signal block (SSB) cell-search procedure to simultaneously detect low-altitude drones within a volumetric surveillance grid. Herein, we consider a multistatic configuration where multiple access points (APs) collaboratively illuminate the volume while independently transmitting SSB broadcast signals. Both tasks are performed through a beam sweeping. In the proposed scheme, coordinated APs send sensing beams toward a grid of voxels within the volumetric surveillance region simultaneously with the 5G SSB burst. To prevent interference between communication and sensing signals, we propose a precoder design that guarantees orthogonality of the sensing beam and the SSB in order to maximize the sensing signal-to-interference-plus-noise ratio (SINR) while ensuring a specified SINR for users, as well as minimizing the impact of the direct link. The results demonstrate that the proposed precoder outperforms the non-coordinated precoder and is minimally affected by variations in drone altitude.

</details>


### [23] [Airborne Particle Communication Through Time-varying Diffusion-Advection Channels](https://arxiv.org/abs/2601.08534)
*Fatih Merdan,Ozgur B. Akan*

Main category: eess.SP

TL;DR: 该论文研究了时变对流条件下的空气粒子通信，将其建模为线性时变信道，推导了信道冲激响应，提出了信道色散时间作为信道记忆的物理度量，并通过仿真验证了波形设计对性能的重要性。


<details>
  <summary>Details</summary>
Motivation: 现有粒子通信研究大多假设恒定流动条件，而实际宏观环境（如大气风）具有时变特性。需要建立时变对流条件下粒子通信的数学模型，为复杂流动环境中的粒子通信提供理论基础。

Method: 将时变对流条件下的空气粒子通信建模为线性时变信道，使用移动坐标系方法推导了时间相关的闭式信道冲激响应。基于此公式，通过功率延迟分布表征信道特性，定义了信道色散时间作为信道记忆的物理度量和符号持续时间选择的指导原则。

Result: 在定向时变风条件下的系统级仿真表明，波形设计对性能至关重要。当色散得到充分控制时，可以使用单一粒子类型实现多符号调制。时变扩散对流信道可以通过通信理论工具进行系统建模和工程设计。

Conclusion: 时变扩散对流信道可以通过通信理论工具进行系统建模和工程设计，为复杂流动环境中的粒子通信提供了现实基础。信道色散时间作为信道记忆的物理度量，为符号持续时间选择提供了指导。

Abstract: Particle based communication using diffusion and advection has emerged as an alternative signaling paradigm recently. While most existing studies assume constant flow conditions, real macro scale environments such as atmospheric winds exhibit time varying behavior. In this work, airborne particle communication under time varying advection is modeled as a linear time varying (LTV) channel, and a closed form, time dependent channel impulse response is derived using the method of moving frames. Based on this formulation, the channel is characterized through its power delay profile, leading to the definition of channel dispersion time as a physically meaningful measure of channel memory and a guideline for symbol duration selection. System level simulations under directed, time varying wind conditions show that waveform design is critical for performance, enabling multi symbol modulation using a single particle type when dispersion is sufficiently controlled. The results demonstrate that time varying diffusion advection channels can be systematically modeled and engineered using communication theoretic tools, providing a realistic foundation for particle based communication in complex flow environments.

</details>


### [24] [Stable Filtering for Efficient Dimensionality Reduction of Streaming Manifold Data](https://arxiv.org/abs/2601.08685)
*Nicholas P. Bertrand,Eva Yezerets,Han Lun Yap,Adam S. Charles,Christopher J. Rozell*

Main category: eess.SP

TL;DR: 本文提出随机滤波(RF)方法，利用随机降维技术保持数据非线性流形结构，无需训练且计算高效，适用于大规模数据处理。


<details>
  <summary>Details</summary>
Motivation: 科学和工程领域面临海量数据处理的挑战，现有方法需要昂贵训练且难以保持数据底层几何结构。数据通常演化在低维吸引子流形上，但该流形结构可能未知。

Method: 提出随机滤波(RF)方法，基于随机降维理论，通过特定实例化在嵌入空间中可证明地保持非线性流形结构，同时保持数据无关性和计算效率。

Result: 开发了实用的RF方法，包括新颖方法、分析和实验验证，在多个模拟和真实数据应用中展示了RF的实际效益。

Conclusion: RF提供了一种无需训练、计算高效且能保持数据几何结构的降维工具，解决了大规模数据处理中的关键挑战。

Abstract: Many areas in science and engineering now have access to technologies that enable the rapid collection of overwhelming data volumes. While these datasets are vital for understanding phenomena from physical to biological and social systems, the sheer magnitude of the data makes even simple storage, transmission, and basic processing highly challenging. To enable efficient and accurate execution of these data processing tasks, we require new dimensionality reduction tools that 1) do not need expensive, time-consuming training, and 2) preserve the underlying geometry of the data that has the information required to understand the measured system. Specifically, the geometry to be preserved is that induced by the fact that in many applications, streaming high-dimensional data evolves on a low-dimensional attractor manifold. Importantly, we may not know the exact structure of this manifold a priori. To solve these challenges, we present randomized filtering (RF), which leverages a specific instantiation of randomized dimensionality reduction to provably preserve non-linear manifold structure in the embedded space while remaining data-independent and computationally efficient. In this work we build on the rich theoretical promise of randomized dimensionality reduction to develop RF as a real, practical approach. We introduce novel methods, analysis, and experimental verification to illuminate the practicality of RF in diverse scientific applications, including several simulated and real-data examples that showcase the tangible benefits of RF.

</details>
