<div id=toc></div>

# Table of Contents

- [cs.IT](#cs.IT) [Total: 12]
- [eess.SP](#eess.SP) [Total: 19]


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [1] [Resource Allocation for Mutualistic Symbiotic Radio with Hybrid Active-Passive Communications](https://arxiv.org/abs/2509.14567)
*Hong Guo,Yinghui Ye,Haijian Sun,Liqin Shi,Rose Qingyang Hu*

Main category: cs.IT

TL;DR: 提出了一种新型互惠频谱反向散射通信系统，通过混合主动-被动通信(HAPC)探索反向散射与主动通信之间的权衡，采用SCA和BCD算法分别优化固定和动态SIC排序下的总速率最大化问题


<details>
  <summary>Details</summary>
Motivation: 传统互惠频谱反向散射通信中，次级用户调制速率低导致传输速率极差，需要提升次级用户传输速率

Method: 提出混合主动-被动通信(HAPC)框架，次级用户交替使用被动反向散射和主动通信；分别针对固定和动态SIC排序设计优化问题，采用SCA和BCD迭代算法求解

Result: 所提系统在相同约束下优于传统设计；当主用户最小速率增益高时，动态SIC排序的总速率大于固定排序，当增益低时两者接近

Conclusion: 混合主动-被动通信策略能有效提升互惠频谱反向散射系统的性能，动态SIC排序在高主用户速率要求下更具优势

Abstract: Mutualistic SR is a communication paradigm that offers high spectrum
efficiency and low power consumption, where the SU transmits information by
modulating and backscattering the PT's signal, enabling shared use of spectrum
and power with PT. In return, the PT's performance can be enhanced by SU's
backscattered signal, forming a mutualistic relationship. However, the low
modulation rate causes extremely inferior transmission rates for SUs. To
improve the SU transmission rate, this paper proposes a new mutualistic SR with
HAPC to explore the tradeoff between BC and AC in terms of power consumption
and transmission rate, enabling each SU to transmit signal via passive BC and
AC alternatively. We propose two problems to maximize the total rate of all SUs
under the fixed and dynamic SIC ordering, respectively. The fixed SIC
ordering-based problem is to jointly optimize the SUs' reflection coefficients,
the transmit power of each SU during AC, and the time allocation for each SU
during BC and AC, subject to the energy causality constraint and the PT's
transmission rate gain constraint. In addition to pondering the constraints
involved in the fixed SIC ordering-based problem, the dynamic SIC
ordering-based problem, which is a mixed integer programming one, further
considers the SIC ordering constraint. The above two problems are solved by our
proposed SCA-based and BCD-based iterative algorithms, respectively. Simulation
results demonstrate that: 1) the proposed mutualistic SR system outperforms
traditional designs in terms of the rates achieved by SUs under the same
constraints; 2) the total rate of all SUs under the dynamic SIC ordering is
larger than that of the fixed one when the PT's minimum rate gain is high, and
becomes nearly identical when the PT's minimum rate gain is low.

</details>


### [2] [Joint Scheduling and Multiflow Maximization in Wireless Networks](https://arxiv.org/abs/2509.14582)
*Yanxiao Liu,Shenghao Yang,Cheuk Ting Li*

Main category: cs.IT

TL;DR: 本文针对6G网络中大规模网络的最大多流问题，提出了无需计算完整调度速率区域的高效算法，能够直接输出最优解，解决了传统方法计算复杂度高的问题。


<details>
  <summary>Details</summary>
Motivation: 随着6G移动网络发展，需要集成大量多维度平台设备，理解大规模网络的理论极限至关重要。传统方法计算调度速率区域的NP-hard特性使得在大规模网络中求解最大多流问题计算上不可行。

Method: 提出了联合计算调度速率区域和求解最大多流问题的高效算法，采用图形化框架，能够在有限迭代次数内输出最优解，适用于多源多汇网络的组播场景。

Result: 理论证明算法总是能在有限迭代次数内输出最优解，仿真结果显示相比传统方法具有显著优势，并可扩展到传播延迟大的场景（如水下网络）。

Conclusion: 该框架为大规模网络中的最大多流问题提供了高效精确的解决方案，突破了传统方法的计算瓶颈，具有广泛的应用前景。

Abstract: Towards the development of 6G mobile networks, it is promising to integrate a
large number of devices from multi-dimensional platforms, and it is crucial to
have a solid understanding of the theoretical limits of large-scale networks.
We revisit a fundamental problem at the heart of network communication theory:
the maximum multiflow (MMF) problem in multi-hop networks, with network coding
performed at intermediate nodes. To derive the exact-optimal solution to the
MMF problem (as opposed to approximations), conventional methods usually
involve two steps: first calculate the scheduling rate region, and then find
the maximum multiflow that can be supported by the achievable link rates.
However, the NP-hardness of the scheduling part makes solving the MMF problem
in large networks computationally prohibitive. In this paper, while still
focusing on the exact-optimal solution, we provide efficient algorithms that
can jointly calculate the scheduling rate region and solve the MMF problem,
thereby outputting optimal values without requiring the entire scheduling rate
region. We theoretically prove that our algorithms always output optimal
solutions in a finite number of iterations, and we use various simulation
results to demonstrate our advantages over conventional approaches. Our
framework is applicable to the most general scenario in multi-source multi-sink
networks: the multiple multicast problem with network coding. Moreover, by
employing a graphical framework, we show that our algorithm can be extended to
scenarios where propagation delays are large (e.g., underwater networks), in
which recent studies have shown that the scheduling rate region can be
significantly improved by utilizing such delays.

</details>


### [3] [Inference of unknown syndrome values in the implementation of the Berlekamp-Massey-Sakata algorithm](https://arxiv.org/abs/2509.14835)
*J. J. Bernal,J. J. Simón*

Main category: cs.IT

TL;DR: 研究如何找到实现Berlekamp-Massey-Sakata算法所需的缺失校验子值，用于代数几何码的Feng-Rao多数投票，并将结果应用于解决阿贝尔码中的校验子校正问题


<details>
  <summary>Details</summary>
Motivation: 在代数几何码的实现中，需要找到缺失的校验子值来支持Berlekamp-Massey-Sakata算法和Feng-Rao多数投票方法的应用

Method: 研究并开发方法来识别和获取实现算法所需的缺失校验子值

Result: 成功找到了支持算法实现所需的校验子值，并将该方法应用于阿贝尔码的校验子校正

Conclusion: 该方法有效解决了代数几何码中校验子缺失的问题，为阿贝尔码的校验子校正提供了可行的解决方案

Abstract: We study the problem of finding those missing syndrome values that are needed
to implment the Berlekamp-Massey-Sakata algorithm as the Feng-Rao Majority
Voting for algebraic geometric codes. We apply our results to solve syndrome
correction in abelian codes.

</details>


### [4] [Beam Squint Assisted Joint Angle-Distance Localization for Near-Field Communications](https://arxiv.org/abs/2509.14850)
*Aibiao Zhang,Weizheng Zhang,Chiya Zhang*

Main category: cs.IT

TL;DR: 本文针对宽带近场场景中基于移相器的波束成形引起的显著近场波束斜视问题，提出了一种波束斜视辅助的联合角度-距离定位方案，通过TTD单元和PS合成可控的联合角度-距离轨迹，实现单次扫描获取目标角度和距离。


<details>
  <summary>Details</summary>
Motivation: 随着超大规模MIMO、毫米波/太赫兹频段和超宽带传输的发展，未来6G系统需要实现厘米甚至毫米级的实时定位精度，但宽带近场场景中的波束斜视问题严重影响了定位性能。

Method: 采用TTD单元与PS相结合的方式合成可控的联合角度-距离轨迹；设计粗到精两阶段估计器：基于子载波功率峰值的低复杂度粗估计阶段进行用户分离和候选区域选择，然后通过空间平滑和近场MUSIC算法进行局部高分辨率细化，并通过几何平均融合频谱来抑制虚假峰值。

Result: 仿真结果表明，该方法在单用户和多用户场景下都能实现很高的精度和鲁棒性，显著优于传统的两步方法，有望用于实际的6G感知和定位部署。

Conclusion: 提出的波束斜视辅助联合角度-距离定位方案有效解决了宽带近场波束斜视问题，通过理论证明和仿真验证了方法的正确性和优越性，为6G系统的精确定位提供了有前景的解决方案。

Abstract: With the advent of extremely large-scale MIMO (XL-MIMO), mmWave/THz bands and
ultra-wideband transmission, future 6G systems demand real-time positioning
with centimeter or even millimeter level accuracy. This paper addresses the
pronounced near-field beam squint problem caused by phase shifter based
beamforming in wideband near-field scenarios and proposes a beam squint
assisted joint angle-distance localization scheme. The key idea is to employ
true-time-delay (TTD) units together with phase shifters (PS) to synthesize a
controllable joint angle-distance (JAD) trajectory that establishes a unique
mapping between subcarriers and spatial locations, enabling single scan
acquisition of target angle and range. To implement this paradigm efficiently,
we design a coarse to fine two stage estimator: a low complexity coarse stage
based on subcarrier power peaks for user separation and candidate region
selection, followed by a local high resolution refinement stage that applies
spatial smoothing and near-field multiple signal classification (MUSIC) over
multiple subcarriers and fuses the resulting spectra by geometric averaging to
suppress spurious peaks. We theoretically prove the correctness and uniqueness
of the MUSIC spatial spectrum peak under the proposed near-field steering
model, and derive the Cram\'er-Rao lower bound (CRLB) for joint angle-distance
estimation. Simulation results in single and multi-user scenarios validate that
the proposed method achieves very high accuracy and robustness, significantly
outperforming conventional two-step approaches, and is promising for practical
6G sensing and localization deployments.

</details>


### [5] [On Finite-Blocklength Noisy Classical-Quantum Channel Coding With Amplitude Damping Errors](https://arxiv.org/abs/2509.14852)
*Tamás Havas,Hsuan-Yin Lin,Eirik Rosnes,Ching-Yi Lai*

Main category: cs.IT

TL;DR: 在有限块长下，朴素的无编码方法无法在量子振幅阻尼通道上获得量子性能优势，需要结合经典纠错码和量子输入状态的复杂编码策略


<details>
  <summary>Details</summary>
Motivation: 研究有限块长下的经典-量子信道编码，探索在量子振幅阻尼通道上传输经典信息的实际性能，特别关注是否能在有限块长下实现量子性能增益

Method: 通过分析量子振幅阻尼通道的特性，比较朴素无编码方法和结合经典纠错码与量子输入状态的复杂编码策略的性能差异

Result: 研究发现对于任何有限块长，朴素的无编码方法都无法在ADC上提供任何优势，只有复杂的编码策略才能实现有限块长下的量子性能增益

Conclusion: 在量子振幅阻尼通道上进行经典信息传输时，必须采用结合经典纠错码和量子输入状态的复杂编码策略，而不能依赖简单的无编码方法

Abstract: We investigate practical finite-blocklength classical-quantum channel coding
over the quantum amplitude damping channel (ADC), aiming to transmit classical
information reliably through quantum outputs. Our findings indicate that for
any finite blocklength, a naive (uncoded) approach fails to offer any advantage
over the ADC. Instead, sophisticated encoding strategies that leverage both
classical error-correcting codes and quantum input states are crucial for
realizing quantum performance gains at finite blocklengths.

</details>


### [6] [Four classes of LCD codes from (*)-(L,P)-twisted generalized Reed-Solomon codes](https://arxiv.org/abs/2509.14878)
*Zhonghao Liang,Qunying Liao*

Main category: cs.IT

TL;DR: 本文统一了LCD MDS码的现有构造方法，定义了(*)-(L,P)-TGRS码，给出了其奇偶校验矩阵，并构造了四类LCD码


<details>
  <summary>Details</summary>
Motivation: 统一Yue等人和Wu等人的LCD MDS码构造方法，提供更通用的框架

Method: 定义(*)-(L,P)-TGRS码，推导其奇偶校验矩阵，基于此构造四类LCD码

Result: 成功统一了现有构造方法，提出了更通用的(*)-(L,P)-TGRS码框架，并构造了四类新的LCD码

Conclusion: 所提出的(*)-(L,P)-TGRS码框架有效统一了LCD MDS码的构造方法，扩展了LCD码的设计空间

Abstract: It's well-known that maximum distance separable codes (in short, MDS) and
linear complementary dual (in short, LCD) codes are very important in coding
theory and practice. In 2023, Yue et al. [25] constructed three classes of LCD
MDS codes via (*)-TGRS codes. Recently, Wu et al. [27] generalized the results
given by Yue et al. and constructed several classes of LCD MDS codes. In this
paper, we unify their constructions by defining the (*)-(L,P)-twisted
generalized Reed-Solomon (in short, (*)-(L,P)-TGRS) code, give the parity-check
matrix of (*)-(L,P)-TGRS codes, and then construct four classes of LCD codes.
Finally, some corresponding examples are given.

</details>


### [7] [Movable-Antenna Trajectory Optimization for Wireless Sensing: CRB Scaling Laws over Time and Space](https://arxiv.org/abs/2509.14905)
*Wenyan Ma,Lipeng Zhu,Rui Zhang*

Main category: cs.IT

TL;DR: 提出了一种基于可移动天线(MA)的新型无线传感系统，通过天线连续移动接收信号来提升角度估计性能，相比传统固定位置天线(FPA)传感有显著改进


<details>
  <summary>Details</summary>
Motivation: 传统固定位置天线传感系统在角度估计性能上存在局限，希望通过天线移动来增强传感能力，提高角度到达(AoA)估计精度

Method: 推导了角度估计的Cramér-Rao下界(CRB)与天线轨迹的关系，针对1D情况推导了全局最优轨迹闭式解，针对2D情况设计了交替优化算法获得局部最优轨迹

Result: 数值结果显示，提出的1D/2D MA传感方案相比传统FPA传感和基准MA轨迹，显著降低了CRB和实际AoA估计MSE，且设计的轨迹在角域具有低相关性，提高了角分辨率

Conclusion: 可移动天线传感系统通过优化轨迹设计，能够实现比传统固定天线系统更优越的角度估计性能，为无线传感提供了新的技术途径

Abstract: In this paper, we present a new wireless sensing system utilizing a movable
antenna (MA) that continuously moves and receives sensing signals to enhance
sensing performance over the conventional fixed-position antenna (FPA) sensing.
We show that the angle estimation performance is fundamentally determined by
the MA trajectory, and derive the Cramer-Rao bound (CRB) of the mean square
error (MSE) for angle-of-arrival (AoA) estimation as a function of the
trajectory for both one-dimensional (1D) and two-dimensional (2D) antenna
movement. For the 1D case, a globally optimal trajectory that minimizes the CRB
is derived in closed form. Notably, the resulting CRB decreases cubically with
sensing time in the time-constrained regime, whereas it decreases linearly with
sensing time and quadratically with the movement line segment's length in the
space-constrained regime. For the 2D case, we aim to achieve the minimum of
maximum (min-max) CRBs of estimation MSE for the two AoAs with respect to the
horizontal and vertical axes. To this end, we design an efficient alternating
optimization algorithm that iteratively updates the MA's horizontal or vertical
coordinates with the other being fixed, yielding a locally optimal trajectory.
Numerical results show that the proposed 1D/2D MA-based sensing schemes
significantly reduce both the CRB and actual AoA estimation MSE compared to
conventional FPA-based sensing with uniform linear/planar arrays (ULAs/UPAs) as
well as various benchmark MA trajectories. Moreover, it is revealed that the
steering vectors of our designed 1D/2D MA trajectories have low correlation in
the angular domain, thereby effectively increasing the angular resolution for
achieving higher AoA estimation accuracy.

</details>


### [8] [Indoor Fluid Antenna Systems Enabled by Layout-Specific Modeling and Group Relative Policy Optimization](https://arxiv.org/abs/2509.15006)
*Tong Zhang,Qianren Li,Shuai Wang,Wanli Ni,Jiliang Zhang,Rui Wang,Kai-Kit Wong,Chan-Byoung Chae*

Main category: cs.IT

TL;DR: 流动天线系统(FAS)通过动态优化天线位置改善室内通信性能，本文提出了布局特定通道模型和GRPO算法，在计算效率和系统性能方面取得显著改善


<details>
  <summary>Details</summary>
Motivation: 室内环境中信号传播受到结构障碍和复杂多径反射的严重影响，流动天线系统可以通过动态优化天线位置来缓解这些问题，提升通信质量

Method: 提出布局特定通道模型和新的组相对策略优化(GRPO)算法，进行天线定位、放大器设计和功率分配的联合优化

Result: 与Sionna模型相比，计算时间减少83.3%，RMSE提升3dB；GRPO算法在总速率上超过PPO等基准方法，仅需PPO计算资源的49.2%

Conclusion: 流动天线系统在室内环境中具有重要价值，提出的布局特定模型和GRPO算法能够在保持高性能的同时显著提升计算效率，为室内通信系统优化提供了有效解决方案

Abstract: The fluid antenna system (FAS) revolutionizes wireless communications by
employing position-flexible antennas that dynamically optimize channel
conditions and mitigate multipath fading. This innovation is particularly
valuable in indoor environments, where signal propagation is severely degraded
due to structural obstructions and complex multipath reflections. In this
paper, we study the channel modeling and joint optimization of antenna
positioning, beamforming, and power allocation for indoor FAS. In particular,
we propose, for the first time, a layout-specific channel model and a novel
group relative policy optimization (GRPO) algorithm for indoor FAS. Compared to
the state-of-the-art Sionna model, our approach achieves an $83.3\%$ reduction
in computation time with an approximately $3$ dB increase in root-mean-square
error (RMSE). When simplified to a two-ray model, our channel model enables a
closed-form solution for the optimal antenna position, achieving near-optimal
performance. {For the joint optimization problem, the proposed GRPO algorithm
outperforms proximal policy optimization (PPO) and other baselines in sum-rate,
while requiring only 49.2\% computational resources of PPO, due to its
group-based advantage estimation.} Simulation results reveal that increasing
either the group size or trajectory length in GRPO does not yield significant
improvements in sum-rate, suggesting that these parameters can be selected
conservatively without sacrificing performance.

</details>


### [9] [Improved Constructions and Lower Bounds for Maximally Recoverable Grid Codes](https://arxiv.org/abs/2509.15013)
*Joshua Brakensiek,Manik Dhar,Sivakanth Gopi*

Main category: cs.IT

TL;DR: 本文研究最大可恢复网格码，针对m×n网格拓扑结构，在m和h为常数、n增长的情况下，提出了多项式域大小的显式构造，并给出了新的域大小下界。


<details>
  <summary>Details</summary>
Motivation: 先前的研究主要关注m=n的情况，此时显式构造需要指数级域大小。本文受实际应用驱动，研究m和h为常数、n增长时的更实用场景。

Method: 研究m×n网格拓扑的编码，每行每列有一个奇偶校验，加上h≥1个全局奇偶校验。在m和h为常数、n增长的情况下，提供新的显式构造方法。

Result: 提出了多个域大小为n的多项式的显式构造，显著降低了所需域大小。同时给出了新的域大小下界结果。

Conclusion: 在实用场景下，本文成功降低了最大可恢复网格码的域大小要求，从指数级降至多项式级，为实际应用提供了更可行的编码方案。

Abstract: In this paper, we continue the study of Maximally Recoverable (MR) Grid Codes
initiated by Gopalan et al. [SODA 2017]. More precisely, we study codes over an
$m \times n$ grid topology with one parity check per row and column of the grid
along with $h \ge 1$ global parity checks. Previous works have largely focused
on the setting in which $m = n$, where explicit constructions require field
size which is exponential in $n$. Motivated by practical applications, we
consider the regime in which $m,h$ are constants and $n$ is growing. In this
setting, we provide a number of new explicit constructions whose field size is
polynomial in $n$. We further complement these results with new field size
lower bounds.

</details>


### [10] [Integrated Sensing and Communication for Vehicular Networks: A Rate-Distortion Fundamental Limits of State Estimator](https://arxiv.org/abs/2509.15025)
*Lugaoze Feng,Guocheng Lv,Xunan Li,Ye Jin*

Main category: cs.IT

TL;DR: 本文建立了状态依赖无记忆信道中感知性能的率失真函数，提出了改进的Blahut-Arimoto算法求解，并首次统一了通信和感知的信息理论结果。


<details>
  <summary>Details</summary>
Motivation: 现有工作中往往忽视感知性能，需要为集成感知与通信系统建立统一的信息理论框架。

Method: 使用状态依赖无记忆信道建模，建立率失真函数，提出改进的Blahut-Arimoto算法进行求解。

Result: 成功定义了容量-率-失真权衡区域，数值评估显示在某些信道中编码能提高估计速率。

Conclusion: 该研究首次在单一优化框架内统一了通信和感知的信息理论结果，为集成感知与通信系统提供了理论基础。

Abstract: The state-dependent memoryless channel (SDMC) is employed to model the
integrated sensing and communication (ISAC) system for connected vehicular
networks, where the transmitter conveys messages to the receiver while
simultaneously estimating the state parameter of interest via the received echo
signals. However, the performance of sensing has often been neglected in
existing works. To address this gap, we establish the rate-distortion function
for sensing performance in the SDMC model, which is defined based on standard
information-theoretic principles to ensure clear operational meaning. In
addition, we propose a modified Blahut-Arimoto type algorithm for solving the
rate-distortion function and provide convergence proofs for the algorithm. We
further define the capacity-rate-distortion tradeoff region, which, for the
first time, unifies information-theoretic results for communication and sensing
within a single optimization framework. Finally, we numerically evaluate the
capacity-rate-distortion region and demonstrate the benefit of coding in terms
of estimation rate for certain channels.

</details>


### [11] [Distributed Batch Matrix Multiplication: Trade-Offs in Download Rate, Randomness, and Privacy](https://arxiv.org/abs/2509.15047)
*Amirhosein Morteza,Remi A. Chou*

Main category: cs.IT

TL;DR: 本文研究了分布式批量矩阵乘法中通信速率与隐私保护的权衡，重点关注矩阵A的隐私保护要求，以及本地随机性与隐私之间的关系。


<details>
  <summary>Details</summary>
Motivation: 随着分布式计算的发展，如何在保证计算效率的同时保护敏感数据隐私成为重要问题。特别是在矩阵乘法这种基础运算中，需要平衡通信开销和数据保密性。

Method: 研究两个独立矩阵序列A和B的分布式乘法，其中B公开而A必须保持私有。用户从k个最快服务器获取响应来计算AB乘积。通过参数α控制隐私约束，确保任何ℓ个合谋服务器最多只能学习A的α比例信息。

Result: 建立了矩阵为方阵时的最优权衡关系，发现了信息泄漏与通信速率之间的线性关系。确定了本地随机性需求与隐私保护之间的定量关系。

Conclusion: 该研究为分布式矩阵计算提供了隐私-通信权衡的理论框架，揭示了信息泄漏与通信效率之间的内在联系，对设计隐私保护的分布式系统具有指导意义。

Abstract: We study the trade-off between communication rate and privacy for distributed
batch matrix multiplication of two independent sequences of matrices $\bold{A}$
and $\bold{B}$ with uniformly distributed entries. In our setting, $\bold{B}$
is publicly accessible by all the servers while $\bold{A}$ must remain private.
A user is interested in evaluating the product $\bold{AB}$ with the responses
from the $k$ fastest servers. For a given parameter $\alpha \in [0, 1]$, our
privacy constraint must ensure that any set of $\ell$ colluding servers cannot
learn more than a fraction $\alpha$ of $\bold{A}$. Additionally, we study the
trade-off between the amount of local randomness needed at the encoder and
privacy. Finally, we establish the optimal trade-offs when the matrices are
square and identify a linear relationship between information leakage and
communication rate.

</details>


### [12] [Version Age of Information with Contact Mobility in Gossip Networks](https://arxiv.org/abs/2509.15184)
*Irtiza Hasan,Ahmed Arafa*

Main category: cs.IT

TL;DR: 该论文研究了接触移动性对gossip网络中信息新鲜度的影响，使用版本年龄信息(VAoI)作为度量指标，通过随机混合系统框架分析不同拓扑结构下的性能表现，并优化移动成本与信息新鲜度的权衡。


<details>
  <summary>Details</summary>
Motivation: 研究移动节点之间的接触移动性如何影响gossip网络中的信息传播效率，特别是在网络连接性两端（完全断开和完全连接）的情况下，探索移动性对信息新鲜度的改善效果。

Method: 采用随机混合系统(SHS)框架分析不同网络拓扑和移动性缩放下的信息传播，使用版本年龄信息(VAoI)作为新鲜度度量，通过数学分析和仿真验证理论结果，并构建优化问题来平衡移动成本和信息新鲜度。

Result: 研究表明接触移动性显著改善了网络两端（断开和完全连接）的信息新鲜度，通过优化的移动成本策略可以进一步提升网络平均版本年龄性能，理论分析结果得到仿真验证。

Conclusion: 接触移动性是提升gossip网络信息新鲜度的有效机制，即使考虑移动成本，通过优化设计仍能显著改善网络性能，这为移动网络中的信息传播策略提供了重要见解。

Abstract: A gossip network is considered in which a source node updates its status
while other nodes in the network aim at keeping track of it as it varies over
time. Information gets disseminated by the source sending status updates to the
nodes, and the nodes gossiping with each other. In addition, the nodes in the
network are mobile, and can move to other nodes to get information, which we
term contact mobility. The goal for the nodes is to remain as fresh as
possible, i.e., to have the same information as the source's. To evaluate the
freshness of information, we use the Version Age-of-Information (VAoI) metric,
defined as the difference between the version of information available at a
given node and that at the source. We analyze the effect of contact mobility on
information dissemination in the gossip network using a Stochastic Hybrid
System (SHS) framework for different topologies and mobility scalings with
increasing number of nodes. It is shown that with the presence of contact
mobility the freshness of the network improves in both ends of the network
connectivity spectrum: disconnected and fully connected gossip networks. We
mathematically analyze the average version age scalings and validate our
theoretical results via simulations. Finally, we incorporate the cost of
mobility for the network by formulating and solving an optimization problem
that minimizes a weighted sum of version age and mobility cost. Our results
show that contact mobility, with optimized mobility cost, improves the average
version age in the network.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [13] [In Planta Tattoo and Kirigami Sensors for Self-Powered Monitoring of Vapor Pressure Deficit and Growth Dynamics](https://arxiv.org/abs/2509.14240)
*Nafize Ishtiaque Hossain,Kundan Saha,Atul Sharma,Sameer Sonkusale*

Main category: eess.SP

TL;DR: 开发了一种可扩展的自供电植物传感器平台，用于连续监测植物水分和生长，包括叶片纹身传感器测量温湿度并收集能量，以及茎杆应变传感器跟踪生长。


<details>
  <summary>Details</summary>
Motivation: 需要开发能够连续监测植物水分状况和生长情况的传感器系统，以改善农业管理和应对非生物胁迫，同时实现能源自给自足和大规模部署。

Method: 集成两种传感器：1）叶片安装的纹身传感器，使用五氧化二钒纳米片膜同时测量叶下温湿度和从环境水分收集能量；2）受剪纸启发的应变传感器，包裹在茎杆上跟踪径向生长。采用无洁净室、卷对卷兼容的制造方法。

Result: 纹身传感器功率密度达0.1114 μW/cm²，可准确估计蒸汽压差超过10天；应变传感器规格因子1.5，对无关机械干扰免疫，可连续跟踪生长超过20天。系统实现能源自主运行。

Conclusion: 该自供电传感器平台具有大规模农业部署潜力，能够有效监测植物非生物胁迫并改善作物管理，制造方法简单且可扩展。

Abstract: We report a scalable, self-powered in planta sensor platform for continuous
monitoring of plant hydration and growth. The system integrates two components
a leaf mounted tattoo sensor for estimating vapor pressure deficit and a
kirigami inspired strain sensor for tracking radial stem growth. Uniquely, the
tattoo sensor serves a dual function measuring temperature and humidity beneath
the leaf surface while simultaneously harvesting power from ambient moisture
via a vanadium pentoxide nanosheet membrane. This moist-electric generator
configuration enables energy-autonomous operation, delivering a power density
of 0.1114 miroW per square cm. The V2O5 based sensor exhibits high sensitivity
to humidity and temperature, enabling accurate VPD estimation for over 10 days
until leaf senescence. The eutectogel based kirigami strain sensor, wrapped
around the stem, offers a gauge factor of 1.5 and immunity to unrelated
mechanical disturbances, allowing continuous growth tracking for more than 20
days. Both sensors are fabricated via cleanroom-free, roll to roll compatible
methods, underscoring their potential for large-scale agricultural deployment
to monitor abiotic stress and improve crop management.

</details>


### [14] [Artificial Intelligence-derived Cardiotocography Age as a Digital Biomarker for Predicting Future Adverse Pregnancy Outcomes](https://arxiv.org/abs/2509.14242)
*Jinshuai Gu,Zenghui Lin,Jingying Ma,Jingyu Wang,Linyan Zhang,Rui Bai,Zelin Tu,Youyou Jiang,Donglin Xie,Yuxi Zhou,Guoli Liu,Shenda Hong*

Main category: eess.SP

TL;DR: 基于胎心监护(CTG)时间序列开发AI模型预测胎儿生物年龄(CTGage)，通过计算与实际年龄的差距(CTGage-gap)作为预测不良妊娠结局的新型数字生物标志物。


<details>
  <summary>Details</summary>
Motivation: CTG目前主要用于评估胎儿当前状态，但其预测未来不良妊娠结局的潜力尚未充分挖掘，需要开发新的预测方法。

Method: 使用61,140条记录训练1D卷积神经网络，采用分布对齐增强回归技术，将CTGage-gap分为5组并定义高风险组，比较各组不良结局发生率。

Result: 模型平均绝对误差10.91天。高估组早产率5.33% vs 正常组1.42%，妊娠糖尿病31.93% vs 20.86%；低估组低出生体重0.17% vs 0.15%，贫血37.51% vs 34.74%。

Conclusion: AI衍生的CTGage能预测未来不良妊娠结局风险，有望成为新型无创易获取的数字生物标志物。

Abstract: Cardiotocography (CTG) is a low-cost, non-invasive fetal health assessment
technique used globally, especially in underdeveloped countries. However, it is
currently mainly used to identify the fetus's current status (e.g., fetal
acidosis or hypoxia), and the potential of CTG in predicting future adverse
pregnancy outcomes has not been fully explored. We aim to develop an AI-based
model that predicts biological age from CTG time series (named CTGage), then
calculate the age gap between CTGage and actual age (named CTGage-gap), and use
this gap as a new digital biomarker for future adverse pregnancy outcomes. The
CTGage model is developed using 61,140 records from 11,385 pregnant women,
collected at Peking University People's Hospital between 2018 and 2022. For
model training, a structurally designed 1D convolutional neural network is
used, incorporating distribution-aligned augmented regression technology. The
CTGage-gap is categorized into five groups: < -21 days (underestimation group),
-21 to -7 days, -7 to 7 days (normal group), 7 to 21 days, and > 21 days
(overestimation group). We further defined the underestimation group and
overestimation group together as the high-risk group. We then compare the
incidence of adverse outcomes and maternal diseases across these groups. The
average absolute error of the CTGage model is 10.91 days. When comparing the
overestimation group with the normal group, premature infants incidence is
5.33% vs. 1.42% (p < 0.05) and gestational diabetes mellitus (GDM) incidence is
31.93% vs. 20.86% (p < 0.05). When comparing the underestimation group with the
normal group, low birth weight incidence is 0.17% vs. 0.15% (p < 0.05) and
anaemia incidence is 37.51% vs. 34.74% (p < 0.05). Artificial
intelligence-derived CTGage can predict the future risk of adverse pregnancy
outcomes and hold potential as a novel, non-invasive, and easily accessible
digital biomarker.

</details>


### [15] [InWaveSR: Topography-Aware Super-Resolution Network for Internal Solitary Waves](https://arxiv.org/abs/2509.14243)
*Xinjie Wang,Zhongrui Li,Peng Han,Chunxin Yuan,Jiexin Xu,Zhiqiang Wei,Jie Nie*

Main category: eess.SP

TL;DR: 提出InWaveSR模型，基于深度学习框架和物理约束，用于从低分辨率观测数据生成高分辨率内孤立波数据，在PSNR指标上达到36.2，优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 观测数据分辨率不足限制了其有效利用，特别是在内孤立波(ISW)等复杂物理现象的研究中。

Method: 基于深度学习框架，使用原始Navier-Stokes方程作为物理约束确保结果物理一致性；结合注意力机制和快速傅里叶变换的HF-ResBlock组件捕捉高频特征；采用边缘采样和数值预处理方法增强对复杂地形的适应性。

Result: 在实地观测ISW数据评估中，PSNR达到36.2，优于传统插值方法和先前神经网络方法。

Conclusion: InWaveSR模型在内孤立波高分辨率重建方面表现出卓越性能和可靠性，显著优于传统方法。

Abstract: The effective utilization of observational data is frequently hindered by
insufficient resolution. To address this problem, we present a new
spatio-temporal super-resolution (STSR) model, called InWaveSR. It is built on
a deep learning framework with physical restrictions and can efficiently
generate high-resolution data from low-resolution input, especially for data
featuring internal solitary waves (ISWs). To increase generality and
interpretation, the model InWaveSR uses the primitive Navier-Stokes equations
as the constraint, ensuring that the output results are physically consistent.
In addition, the proposed model incorporates an HF-ResBlock component that
combines the attention mechanism and the Fast Fourier Transform (FFT) method to
improve the performance of the model in capturing high-frequency
characteristics. Simultaneously, in order to enhance the adaptability of the
model to complicated bottom topography, an edge sampling and numerical
pre-processing method are carried out to optimize the training process. On
evaluations using the in-situ observational ISW data, the proposed InWaveSR
achieved a peak signal-to-noise ratio (PSNR) score of 36.2, higher than those
of the traditional interpolation method and the previous neural network. This
highlights its significant superiority over traditional methods, demonstrating
its excellent performance and reliability in high-resolution ISW
reconstruction.

</details>


### [16] [Conditional Nearest Level Modulation for Improved Switching Dynamics in Asymmetric Multilevel Converters](https://arxiv.org/abs/2509.14402)
*Jinshui Zhang,Angel V Peterchev,Stefan M Goetz*

Main category: eess.SP

TL;DR: 提出条件最近电平调制(cNLM)方法，通过数学惩罚模型调节开关动态，解决非对称多电平电路中传统NLM方法导致的过度开关和输出电压尖峰问题


<details>
  <summary>Details</summary>
Motivation: 模块化多电平变换器在清洁能源等领域应用广泛，但需要大量模块实现精细输出。非对称多电平电路通过模块电压差异使输出电平数指数增长，传统最近电平调制(NLM)方法在大数量电平时会导致某些模块过度开关和输出电压尖峰

Method: 提出条件最近电平调制(cNLM)，通过引入数学惩罚模型来调节开关动态，还提出了针对特定功能(如强制最小开关间隔)的cNLM变体

Result: 在非对称多电平原型上的实验验证显示，cNLM将总输出失真从66.3%降低到15.1%，同时将开关速率降至原始NLM的仅8%

Conclusion: cNLM方法显著改善了输出质量并降低了开关速率，为非对称多电平电路提供了一种有效的调制解决方案

Abstract: Modular multilevel converters have promising applications in clean energy,
electric vehicles, and biomedical instrumentation, but need many modules to
achieve fine output granularity, particularly of the voltage. Asymmetric
multilevel circuits introduce differences in module voltages so that the
quantity of output levels grows exponentially with the number of modules.
Nearest-level modulation (NLM) is preferred over carrier-based methods in
asymmetric circuits for its simplicity. However, the large number of output
levels can overwhelm NLM and cause excessive transistor switching on some
modules and output voltage spikes. We propose a conditional nearest-level
modulation (cNLM) by incorporating mathematical penalty models to regulate
switching dynamics. This approach improves output quality and reduces switching
rates. Additionally, we present cNLM variations tailored for specific
functions, such as enforcing a minimum switching interval. Experimental
validation on an asymmetric multilevel prototype demonstrates that cNLM reduces
the total output distortion from 66.3% to 15.1% while cutting the switching
rate to just 8% of the original NLM.

</details>


### [17] [Indoor Airflow Imaging Using Physics-Informed Background-Oriented Schlieren Tomography](https://arxiv.org/abs/2509.14442)
*Arjun Teh,Wael H. Ali,Joshua Rapp,Hassan Mansour*

Main category: eess.SP

TL;DR: 提出基于单视角背景纹影法的室内三维气流估计框架，结合物理信息神经网络实现非侵入式重建


<details>
  <summary>Details</summary>
Motivation: 解决单视角BOS层析成像的严重病态问题，实现从单一观测点对室内气流的非侵入式三维重建

Method: 使用光投影仪投射图案到背景墙，相机观测光图案的微小畸变；改进光线追踪、物理渲染和损失函数，并采用PINN进行物理正则化

Result: 开发了一个完整的框架，能够从单视角BOS测量中重建符合浮力驱动流控制方程的三维气流场

Conclusion: 该框架成功解决了单视角BOS层析成像的病态性问题，为室内气流监测提供了有效的非侵入式解决方案

Abstract: We develop a framework for non-invasive volumetric indoor airflow estimation
from a single viewpoint using background-oriented schlieren (BOS) measurements
and physics-informed reconstruction. Our framework utilizes a light projector
that projects a pattern onto a target back-wall and a camera that observes
small distortions in the light pattern. While the single-view BOS tomography
problem is severely ill-posed, our proposed framework addresses this using: (1)
improved ray tracing, (2) a physics-based light rendering approach and loss
formulation, and (3) a physics-based regularization using a physics-informed
neural network (PINN) to ensure that the reconstructed airflow is consistent
with the governing equations for buoyancy-driven flows.

</details>


### [18] [Biologically Plausible Online Hebbian Meta-Learning: Two-Timescale Local Rules for Spiking Neural Brain Interfaces](https://arxiv.org/abs/2509.14447)
*Sriram V. C. Nallani,Gautham Ramachandran,Sahil S. Shah*

Main category: eess.SP

TL;DR: 提出了一种用于脑机接口的在线脉冲神经网络解码器，使用局部三因子学习规则和双时间尺度资格迹，避免通过时间的反向传播，在保持竞争力的同时显著减少内存需求。


<details>
  <summary>Details</summary>
Motivation: 脑机接口面临神经信号不稳定性和实时植入应用的内存限制挑战，需要开发内存高效且能持续自适应的神经解码方法。

Method: 采用误差调制的Hebbian更新、快/慢迹线整合和自适应学习率控制，结合局部三因子学习规则和双时间尺度资格迹，仅需O(1)内存。

Result: 在两个灵长类数据集上达到可比解码精度（Pearson R≥0.63和R≥0.81），内存减少28-35%，收敛速度比BPTT方法更快，闭环仿真显示能适应神经干扰并从零开始学习。

Conclusion: 该方法实现了内存高效、持续自适应的神经解码，适用于资源受限的植入式脑机接口系统。

Abstract: Brain-Computer Interfaces face challenges from neural signal instability and
memory constraints for real-time implantable applications. We introduce an
online SNN decoder using local three-factor learning rules with dual-timescale
eligibility traces that avoid backpropagation through time while maintaining
competitive performance. Our approach combines error-modulated Hebbian updates,
fast/slow trace consolidation, and adaptive learning rate control, requiring
only O(1) memory versus O(T) for BPTT methods. Evaluations on two primate
datasets achieve comparable decoding accuracy (Pearson $R \geq 0.63$ Zenodo, $R
\geq 0.81$ MC Maze) with 28-35% memory reduction and faster convergence than
BPTT-trained SNNs. Closed-loop simulations with synthetic neural populations
demonstrate adaptation to neural disruptions and learning from scratch without
offline calibration. This work enables memory-efficient, continuously adaptive
neural decoding suitable for resource-constrained implantable BCI systems.

</details>


### [19] [Secure Blind Graph Signal Recovery and Adversary Detection Using Smoothness Maximization](https://arxiv.org/abs/2509.14449)
*Mahdi Shamsi,Hadi Zayyani,Hasan Abu Hilal,Mohammad Salman*

Main category: eess.SP

TL;DR: 提出了一种安全的盲图信号恢复算法，能够检测对抗节点并恢复受虚假数据注入攻击的图信号


<details>
  <summary>Details</summary>
Motivation: 解决图信号处理中未知对抗节点注入虚假数据的问题，这些对抗节点的数量和位置未知，需要在测量噪声和虚假数据注入攻击下恢复图信号

Method: 基于差分平滑度的统计测量进行对抗检测，使用平滑度最大化变体进行图信号恢复，通过Dinkelbach算法高效求解分数优化问题

Result: 仿真结果显示该方法在信号恢复方面相比中位数GSR算法和其他竞争方法有显著改进

Conclusion: 该方法是一种有效的安全图信号恢复算法，具有低复杂度和良好的对抗检测性能

Abstract: In this letter, we propose a secure blind Graph Signal Recovery (GSR)
algorithm that can detect adversary nodes. Some unknown adversaries are assumed
to be injecting false data at their respective nodes in the graph. The number
and location of adversaries are not known in advance and the goal is to recover
the graph signal in the presence of measurement noise and False Data Injection
(FDI) caused by the adversaries. Consequently, the proposed algorithm would be
a perfect candidate to solve this challenging problem. Moreover, due to the
presence of malicious nodes, the proposed method serves as a secure GSR
algorithm. For adversary detection, a statistical measure based on differential
smoothness is used. Specifically, the difference between the current observed
smoothness and the average smoothness excluding the corresponding node. This
genuine statistical approach leads to an effective and low-complexity adversary
detector. In addition, following malicious node detection, the GSR is performed
using a variant of smoothness maximization, which is solved efficiently as a
fractional optimization problem using a Dinkelbach's algorithm. Analysis of the
detector, which determines the optimum threshold of the detector is also
presented. Simulation results show a significant improvement of the proposed
method in signal recovery compared to the median GSR algorithm and other
competing methods.

</details>


### [20] [Age of Information Aided Intelligent Grant-Free Massive Access for Heterogeneous mMTC Traffic](https://arxiv.org/abs/2509.14503)
*Zhongwen Sun,Wei Chen,Yuxuan Sun,Bo Ai*

Main category: eess.SP

TL;DR: 本文针对6G物联网中不同类型流量共存的问题，提出了一种基于信息年龄的免授权随机接入方案，通过优化接入参数和设计A-PIAAE神经网络，同时实现了监控设备的高信息时效性和报警设备的高检测成功率。


<details>
  <summary>Details</summary>
Motivation: 现有免授权随机接入研究主要关注用户检测和数据恢复的准确性，但忽略了流量的异构性。在6G物联网场景中，事件触发流量和状态更新流量具有不同的服务质量需求，需要同时满足报警设备的高检测成功率和监控设备的高信息时效性。

Method: 1) 分析基于年龄的随机接入方案并优化接入参数以最小化监控设备的平均信息年龄(AoI)；2) 设计年龄先验信息辅助自编码器(A-PIAAE)联合检测活跃设备；3) 在解码器中提出基于年龄的迭代收缩阈值算法(LISTA-AGE)，利用监控设备的AoI作为先验信息增强活跃用户检测。

Result: 理论分析表明A-PIAAE具有更好的收敛性能。实验证明所提方法在降低监控设备平均AoI和提高报警设备检测成功率方面具有优势。

Conclusion: 该研究为异构物联网流量提供了一种有效的免授权随机接入解决方案，通过结合信息年龄优化和深度学习技术，成功平衡了不同类型设备的不同服务质量需求。

Abstract: With the arrival of 6G, the Internet of Things (IoT) traffic is becoming more
and more complex and diverse. To meet the diverse service requirements of IoT
devices, massive machine-type communications (mMTC) becomes a typical scenario,
and more recently, grant-free random access (GF-RA) presents a promising
direction due to its low signaling overhead. However, existing GF-RA research
primarily focuses on improving the accuracy of user detection and data
recovery, without considering the heterogeneity of traffic. In this paper, we
investigate a non-orthogonal GF-RA scenario where two distinct types of traffic
coexist: event-triggered traffic with alarm devices (ADs), and status update
traffic with monitor devices (MDs). The goal is to simultaneously achieve high
detection success rates for ADs and high information timeliness for MDs. First,
we analyze the age-based random access scheme and optimize the access
parameters to minimize the average age of information (AoI) of MDs. Then, we
design an age-based prior information aided autoencoder (A-PIAAE) to jointly
detect active devices, together with learned pilots used in GF-RA to reduce
interference between non-orthogonal pilots. In the decoder, an Age-based
Learned Iterative Shrinkage Thresholding Algorithm (LISTA-AGE) utilizing the
AoI of MDs as the prior information is proposed to enhance active user
detection. Theoretical analysis is provided to demonstrate the proposed A-PIAAE
has better convergence performance. Experiments demonstrate the advantage of
the proposed method in reducing the average AoI of MDs and improving the
successful detection rate of ADs.

</details>


### [21] [Radiolunadiff: Estimation of wireless network signal strength in lunar terrain](https://arxiv.org/abs/2509.14559)
*Paolo Torrado,Anders Pearson,Jason Klein,Alexander Moscibroda,Joshua Smith*

Main category: eess.SP

TL;DR: 提出了一种基于物理信息的深度学习架构，用于预测月球地形上的无线电地图，结合物理地形生成器和射线追踪引擎创建高保真数据集，采用triplet-UNet架构在各项指标上优于现有方法


<details>
  <summary>Details</summary>
Motivation: 为了解决月球地形上无线电传播预测的挑战，需要结合物理模型和深度学习方法来准确建模复杂的传播效应

Method: 集成基于物理的月球地形生成器（使用NASA数据）和射线追踪引擎创建数据集，采用triplet-UNet架构（两个标准UNet和一个扩散网络）

Result: 实验结果表明该方法在月球地形数据集上的各项指标均优于现有的深度学习方法

Conclusion: 提出的物理信息深度学习架构能够有效预测月球地形上的无线电地图，为月球通信和导航提供重要技术支持

Abstract: In this paper, we propose a novel physics-informed deep learning architecture
for predicting radio maps over lunar terrain. Our approach integrates a
physics-based lunar terrain generator, which produces realistic topography
informed by publicly available NASA data, with a ray-tracing engine to create a
high-fidelity dataset of radio propagation scenarios. Building on this dataset,
we introduce a triplet-UNet architecture, consisting of two standard UNets and
a diffusion network, to model complex propagation effects. Experimental results
demonstrate that our method outperforms existing deep learning approaches on
our terrain dataset across various metrics.

</details>


### [22] [Task-Oriented Learning for Automatic EEG Denoising](https://arxiv.org/abs/2509.14665)
*Tian-Yu Xiang,Zheng Lei,Xiao-Hu Zhou,Xiao-Liang Xie,Shi-Qi Liu,Mei-Jiang Gui,Hong-Yun Ou,Xin-Zheng Huang,Xin-Yi Fu,Zeng-Guang Hou*

Main category: eess.SP

TL;DR: 提出了一种基于任务导向学习的自动EEG去噪框架，无需干净参考信号，仅使用任务标签即可实现有效去噪


<details>
  <summary>Details</summary>
Motivation: 传统EEG去噪方法依赖人工干预或干净参考信号，限制了实际应用。需要开发无需干净参考的自动去噪方法

Method: 使用盲源分离技术分解EEG信号，学习型选择器为每个分量分配保留概率，通过概率加权组合重建去噪信号，下游代理任务模型评估重建信号并通过任务损失监督选择器

Result: 在三个数据集上的实验显示，任务性能提升2.56%，信噪比提升0.82dB，框架对算法具有通用性

Conclusion: 该任务导向学习框架是实用的EEG去噪解决方案，对神经科学研究和基于EEG的交互系统具有潜在影响

Abstract: Electroencephalography (EEG) denoising methods typically depend on manual
intervention or clean reference signals. This work introduces a task-oriented
learning framework for automatic EEG denoising that uses only task labels
without clean reference signals. EEG recordings are first decomposed into
components based on blind source separation (BSS) techniques. Then, a
learning-based selector assigns a retention probability to each component, and
the denoised signal is reconstructed as a probability-weighted combination. A
downstream proxy-task model evaluates the reconstructed signal, with its task
loss supervising the selector in a collaborative optimization scheme that
relies solely on task labels, eliminating the need for clean EEG references.
Experiments on three datasets spanning two paradigms and multiple noise
conditions show consistent gains in both task performance (accuracy:
$2.56\%\uparrow$) and standard signal-quality metrics (signal-to-noise-ratio:
$0.82$\,dB\,$\uparrow$). Further analyses demonstrate that the task-oriented
learning framework is algorithm-agnostic, as it accommodates diverse
decomposition techniques and network backbones for both the selector and the
proxy model. These promising results indicate that the proposed task-oriented
learning framework is a practical EEG denoising solution with potential
implications for neuroscience research and EEG-based interaction systems.

</details>


### [23] [Mitigating the Impact of Location Uncertainty on Radio Map-Based Predictive Rate Selection via Noisy-Input Gaussian Process](https://arxiv.org/abs/2509.14710)
*Koya Sato*

Main category: eess.SP

TL;DR: 提出基于高斯过程的抗位置不确定性预测速率选择框架，通过噪声输入GP处理定位误差，提高6G网络传输可靠性


<details>
  <summary>Details</summary>
Motivation: 现有无线电地图方法假设完美位置信息，但实际定位系统存在误差，这种位置不确定性会降低无线系统可靠性

Method: 引入噪声输入高斯过程(NIGP)，通过泰勒近似将位置噪声视为额外输出噪声来处理定位误差

Result: 数值结果表明NIGP设计比纯GP实现更可靠的传输速率选择，比基于路径损耗的方法获得更高吞吐量

Conclusion: 所提出的NIGP框架能有效处理位置不确定性，提高无线电地图在6G网络中的实际应用价值

Abstract: This paper proposes a predictive rate-selection framework based on Gaussian
process (GP)-based radio map construction that is robust to location
uncertainty. Radio maps are a promising tool for improving communication
efficiency in 6G networks. Although they enable the design of location-based
maximum transmission rates by exploiting statistical channel information,
existing discussions often assume perfect (i.e., noiseless) location
information during channel sensing. Since such information must be obtained
from positioning systems such as global navigation satellite systems, it
inevitably involves positioning errors; this location uncertainty can degrade
the reliability of radio map-based wireless systems. To mitigate this issue, we
introduce the noisy-input GP (NIGP), which treats location noise as additional
output noise by applying a Taylor approximation of the function of interest.
Numerical results demonstrate that the proposed NIGP-based design achieves more
reliable transmission-rate selection than pure GP and yields higher throughput
than path loss-based rate selection.

</details>


### [24] [LLM4MG: Adapting Large Language Model for Multipath Generation via Synesthesia of Machines](https://arxiv.org/abs/2509.14711)
*Ziwei Huang,Shiliang Lu,Lu Bai,Xuesong Cai,Xiang Cheng*

Main category: eess.SP

TL;DR: 基于机器联觉(SoM)首次将大语言模型(LLM)适配用于多径生成(LLM4MG)，在6G车联网场景下构建多模态感知-通信数据集SynthSoM-V2I，利用LLaMA 3.2通过多模态感知数据生成多径信息，在多个指标上优于传统深度学习方法。


<details>
  <summary>Details</summary>
Motivation: 为了解决6G车联网场景中高精度多径生成的需求，利用大语言模型的强大能力来处理多模态感知数据并生成准确的多径信息，以提升通信系统性能。

Method: 构建SynthSoM-V2I多模态数据集；使用LLaMA 3.2模型；通过特征提取和融合网络对齐多模态特征空间与语义空间；采用LoRA参数高效微调和传播感知提示工程实现知识迁移。

Result: LoS/NLoS分类准确率达到92.76%；多径功率/时延生成的归一化均方误差分别为0.099/0.032；在跨车辆密度、跨频段和跨场景泛化方面表现优异；通过实际场景验证了实用性。

Conclusion: LLM4MG方法在6G车联网多径生成任务中显著优于传统深度学习方法，证明了高精度多径生成对系统设计的重要性，为大语言模型在通信领域的应用提供了新思路。

Abstract: Based on Synesthesia of Machines (SoM), a large language model (LLM) is
adapted for multipath generation (LLM4MG) for the first time. Considering a
typical sixth-generation (6G) vehicle-to-infrastructure (V2I) scenario, a new
multi-modal sensing-communication dataset is constructed, named SynthSoM-V2I,
including channel multipath information, millimeter wave (mmWave) radar sensory
data, RGB-D images, and light detection and ranging (LiDAR) point clouds. Based
on the SynthSoM-V2I dataset, the proposed LLM4MG leverages Large Language Model
Meta AI (LLaMA) 3.2 for multipath generation via multi-modal sensory data. The
proposed LLM4MG aligns the multi-modal feature space with the LLaMA semantic
space through feature extraction and fusion networks. To further achieve
general knowledge transfer from the pre-trained LLaMA for multipath generation
via multi-modal sensory data, the low-rank adaptation (LoRA)
parameter-efficient fine-tuning and propagation-aware prompt engineering are
exploited. Simulation results demonstrate that the proposed LLM4MG outperforms
conventional deep learning-based methods in terms of line-of-sight
(LoS)/non-LoS (NLoS) classification with accuracy of 92.76%, multipath
power/delay generation precision with normalized mean square error (NMSE) of
0.099/0.032, and cross-vehicular traffic density (VTD), cross-band, and
cross-scenario generalization. The utility of the proposed LLM4MG is validated
by real-world generalization. The necessity of high-precision multipath
generation for system design is also demonstrated by channel capacity
comparison.

</details>


### [25] [Efficient Solutions for Mitigating Initialization Bias in Unsupervised Self-Adaptive Auditory Attention Decoding](https://arxiv.org/abs/2509.14764)
*Yuanyuan Yao,Simon Geirnaert,Tinne Tuytelaars,Alexander Bertrand*

Main category: eess.SP

TL;DR: 本文提出了三种计算效率高的无监督听觉注意解码方法，用于多说话人环境中的脑电信号分析，显著降低了计算复杂度并保持可比性能。


<details>
  <summary>Details</summary>
Motivation: 当前的无监督听觉注意解码方法存在初始化偏差问题，而无偏变体虽然解决了偏差但计算复杂度随数据量增加而显著上升，需要开发计算效率更高的替代方案。

Method: 提出了三种计算效率高的无监督AAD算法，这些算法通过优化计算过程来降低复杂度，同时保持与现有无偏方法相当的解码性能。

Result: 所提出的三种算法在性能上与现有无偏方法相当，但计算成本显著降低且保持恒定，不随数据量增加而上升。

Conclusion: 本文开发的计算高效无监督AAD方法为神经引导听力设备的实际应用提供了可行的解决方案，消除了对标记数据的依赖并解决了计算复杂度问题。

Abstract: Decoding the attended speaker in a multi-speaker environment from
electroencephalography (EEG) has attracted growing interest in recent years,
with neuro-steered hearing devices as a driver application. Current approaches
typically rely on ground-truth labels of the attended speaker during training,
necessitating calibration sessions for each user and each EEG set-up to achieve
optimal performance. While unsupervised self-adaptive auditory attention
decoding (AAD) for stimulus reconstruction has been developed to eliminate the
need for labeled data, it suffers from an initialization bias that can
compromise performance. Although an unbiased variant has been proposed to
address this limitation, it introduces substantial computational complexity
that scales with data size. This paper presents three computationally efficient
alternatives that achieve comparable performance, but with a significantly
lower and constant computational cost. The code for the proposed algorithms is
available at https://github.com/YYao-42/Unsupervised_AAD.

</details>


### [26] [Comparative Performance Analysis of Different Hybrid NOMA Schemes](https://arxiv.org/abs/2509.14809)
*Ning Wang,Chenyu Zhang,Yanshi Sun,Minghui Min,Shiyin Li*

Main category: eess.SP

TL;DR: 本文分析了三种混合非正交多址接入(H-NOMA)方案在随机信道增益排序下的性能，包括固定顺序SIC、混合SIC无功率适配和混合SIC功率适配方案，推导了闭式表达式并验证了理论分析。


<details>
  <summary>Details</summary>
Motivation: 现有H-NOMA分析通常假设固定信道增益顺序，但实际信道系数是随机分布的，其大小关系具有随机性和时变性，需要研究随机信道排序下的性能。

Method: 理论分析推导了三种H-NOMA方案相对于传统OMA性能较差的概率闭式表达式，并在高信噪比区域开发了渐近结果，通过仿真验证分析。

Result: 仿真结果验证了理论分析的正确性，展示了不同信噪比场景下H-NOMA方案的性能表现。

Conclusion: 研究为下一代无线系统中H-NOMA的部署提供了理论基础，证明了在随机信道条件下不同SIC方案的性能特征。

Abstract: Hybrid non-orthogonal multiple access (H-NOMA), which combines the advantages
of pure NOMA and conventional OMA organically, has emerged as a highly
promising multiple access technology for future wireless networks. Recent
studies have proposed various H-NOMA systems by employing different successive
interference cancellation (SIC) methods for the NOMA transmission phase.
However, existing analyses typically assume a fixed channel gain order between
paired users, despite the fact that channel coefficients follow random
distribution, leading to their magnitude relationships inherently stochastic
and time varying. This paper analyzes the performance of three H-NOMA schemes
under stochastic channel gain ordering: a) fixed order SIC (FSIC) aided H-NOMA
scheme; b) hybrid SIC with non-power adaptation (HSIC-NPA) aided H-NOMA scheme;
c) hybrid SIC with power adaptation (HSIC-PA) aided H-NOMA scheme. Theoretical
analysis derives closed-form expressions for the probability that H-NOMA
schemes underperform conventional OMA. Asymptotic results in the high
signal-to-noise ratio (SNR) regime are also developed. Simulation results
validate our analysis and demonstrate the performance of H-NOMA schemes across
different SNR scenarios, providing a theoretical foundation for the deployment
of H-NOMA in next-generation wireless systems.

</details>


### [27] [Sampling Method for Generalized Graph Signals with Pre-selected Vertices via DC Optimization](https://arxiv.org/abs/2509.14836)
*Keitaro Yamashita,Kazuki Naganuma,Shunsuke Ono*

Main category: eess.SP

TL;DR: 提出一种基于广义采样理论的图信号顶点灵活采样方法，通过优化设计采样算子实现最佳恢复性能，支持控制活跃顶点数量和先验知识整合


<details>
  <summary>Details</summary>
Motivation: 现有顶点灵活采样方法无法整合先验知识（如必须包含或排除的顶点），限制了在实际应用中的灵活性

Method: 将采样算子设计转化为带约束的优化问题，使用核范数和DC惩罚处理顶点选择，开发基于双近端梯度DC算法的收敛求解器

Result: 在各种图信号模型和真实数据上的实验表明，该方法在恢复精度上优于现有方法

Conclusion: 所提出的方法能够有效整合先验知识并控制采样顶点数量，在保持灵活性的同时显著提升图信号恢复性能

Abstract: This paper proposes a method for vertex-wise flexible sampling of a broad
class of graph signals, designed to attain the best possible recovery based on
the generalized sampling theory. This is achieved by designing a sampling
operator by an optimization problem, which is inherently non-convex, as the
best possible recovery imposes a rank constraint. An existing method for
vertex-wise flexible sampling is able to control the number of active vertices
but cannot incorporate prior knowledge of mandatory or forbidden vertices. To
address these challenges, we formulate the operator design as a problem that
handles a constraint of the number of active vertices and prior knowledge on
specific vertices for sampling, mandatory inclusion or exclusion. We
transformed this constrained problem into a difference-of-convex (DC)
optimization problem by using the nuclear norm and a DC penalty for vertex
selection. To solve this, we develop a convergent solver based on the general
double-proximal gradient DC algorithm. The effectiveness of our method is
demonstrated through experiments on various graph signal models, including
real-world data, showing superior performance in the recovery accuracy by
comparing to existing methods.

</details>


### [28] [Hybrid Table-Assisted and RL-Based Dynamic Routing for NGSO Satellite Networks](https://arxiv.org/abs/2509.14909)
*Flor Ortiz,Eva Lagunas*

Main category: eess.SP

TL;DR: 提出了一种结合预计算路由表和深度Q学习备用机制的混合路由策略，用于下一代卫星轨道星座的动态路由，在保持性能的同时降低复杂度


<details>
  <summary>Details</summary>
Motivation: 完全基于强化学习的路由方案虽然能适应拓扑动态变化，但存在复杂度高、收敛时间长、重负载下性能不稳定等问题，需要更高效可靠的解决方案

Method: 混合策略：正常情况下使用确定性表查找路由，仅在链路不可用或拥塞时选择性激活深度Q学习代理作为备用机制

Result: 在大规模NGSO网络仿真中，混合方法相比纯RL基线实现了更高的包交付率、更低的端到端延迟、更短的平均跳数和更高的吞吐量

Conclusion: 混合路由是面向延迟敏感卫星宽带服务的可扩展且具有弹性的有效解决方案

Abstract: This letter investigates dynamic routing in Next-Generation Satellite Orbit
(NGSO) constellations and proposes a hybrid strategy that combines precomputed
routing tables with a Deep Q-Learning (DQL) fallback mechanism. While fully
RL-based schemes offer adaptability to topology dynamics, they often suffer
from high complexity, long convergence times, and unstable performance under
heavy traffic. In contrast, the proposed framework exploits deterministic table
lookups under nominal conditions and selectively activates the DQL agent only
when links become unavailable or congested. Simulation results in large-scale
NGSO networks show that the hybrid approach consistently achieves higher packet
delivery ratio, lower end-to-end delay, shorter average hop count, and improved
throughput compared to a pure RL baseline. These findings highlight the
effectiveness of hybrid routing as a scalable and resilient solution for
delay-sensitive satellite broadband services

</details>


### [29] [Efficient Computation of Time-Index Powered Weighted Sums Using Cascaded Accumulators](https://arxiv.org/abs/2509.15069)
*Deijany Rodriguez Linares,Oksana Moryakova,Håkan Johansson*

Main category: eess.SP

TL;DR: 提出了一种基于级联累加器的高效计算时间索引加权和的新方法，将计算复杂度从K×N次通用乘法降低到K+1次常数乘法，无需存储整个数据块。


<details>
  <summary>Details</summary>
Motivation: 传统直接计算方法需要K×N次通用乘法，对于大N值计算成本过高；而基于查找表或信号反转的替代策略需要存储整个数据块，不适用于实时系统。

Method: 利用级联累加器的特性，通过巧妙的数学变换将时间索引加权和的计算转化为仅需K+1次常数乘法的形式，避免了数据存储需求。

Result: 该方法显著降低了计算复杂度，从O(KN)降低到O(K)，同时消除了对数据块存储的需求，适合实时样本处理系统。

Conclusion: 提出的级联累加器方法为高效计算时间索引加权和提供了一种实用的解决方案，特别适用于需要逐样本处理的实时系统应用。

Abstract: This letter presents a novel approach for \mbox{efficiently} computing
time-index powered weighted sums of the form $\sum_{n=0}^{N-1} n^{K} v[n]$
using cascaded accumulators. Traditional direct computation requires
$K{\times}N$ general multiplications, which become prohibitive for large $N$,
while alternative strategies based on lookup tables or signal reversal require
storing entire data blocks. By exploiting accumulator properties, the proposed
method eliminates the need for such storage and reduces the multiplicative cost
to only $K{+}1$ constant multiplications, enabling efficient real-time
implementation. The approach is particularly useful when such sums need to be
efficiently computed in sample-by-sample processing systems.

</details>


### [30] [Doppler Radiance Field-Guided Antenna Selection for Improved Generalization in Multi-Antenna Wi-Fi-based Human Activity Recognition](https://arxiv.org/abs/2509.15129)
*Navid Hasanzadeh,Shahrokh Valaee*

Main category: eess.SP

TL;DR: 提出基于多普勒辐射场(DoRF)的Wi-Fi感知新框架，通过多天线AP噪声抑制和最优天线选择，显著提升小规模手势识别的泛化能力


<details>
  <summary>Details</summary>
Motivation: Wi-Fi CSI信号受AP时钟异步和环境硬件噪声影响，现有预处理技术仍无法完全消除噪声和异常值，限制了基于Wi-Fi的人类活动识别性能

Method: 为多天线AP设计新框架，基于DoRF拟合误差抑制噪声并识别最具信息量的天线，利用多普勒速度投影的不一致性来指导优化

Result: 在具有挑战性的小规模手势识别数据集上实验表明，该方法显著提高了泛化能力

Conclusion: 该方法为鲁棒的实时Wi-Fi感知部署铺平了道路，解决了CSI信号噪声问题并提升了识别性能

Abstract: With the IEEE 802.11bf Task Group introducing amendments to the WLAN standard
for advanced sensing, interest in using Wi-Fi Channel State Information (CSI)
for remote sensing has surged. Recent findings indicate that learning a unified
three-dimensional motion representation through Doppler Radiance Fields (DoRFs)
derived from CSI significantly improves the generalization capabilities of
Wi-Fi-based human activity recognition (HAR). Despite this progress, CSI
signals remain affected by asynchronous access point (AP) clocks and additive
noise from environmental and hardware sources. Consequently, even with existing
preprocessing techniques, both the CSI data and Doppler velocity projections
used in DoRFs are still susceptible to noise and outliers, limiting HAR
performance. To address this challenge, we propose a novel framework for
multi-antenna APs to suppress noise and identify the most informative antennas
based on DoRF fitting errors, which capture inconsistencies among Doppler
velocity projections. Experimental results on a challenging small-scale hand
gesture recognition dataset demonstrate that the proposed DoRF-guided
Wi-Fi-based HAR approach significantly improves generalization capability,
paving the way for robust real-world sensing deployments.

</details>


### [31] [A Unified Distributed Algorithm for Hybrid Near-Far Field Activity Detection in Cell-Free Massive MIMO](https://arxiv.org/abs/2509.15162)
*Jingreng Lei,Yang Li,Ziyue Wang,Qingfeng Lin,Ya-Feng Liu,Yik-Chung Wu*

Main category: eess.SP

TL;DR: 本文提出了一种基于协方差的分布式算法，用于细胞自由MIMO系统中的混合近远场活动检测，理论证明近场信道比例增加能提升检测性能，算法具有收敛保证且统一处理单细胞/细胞自由系统的近远场设备。


<details>
  <summary>Details</summary>
Motivation: 随着接入点天线数量增加，瑞利距离扩大使得传统的远场传播假设不切实际，需要处理混合近远场信道的活动检测问题。

Method: 建立基于协方差的混合近远场信道统计特性建模，提出分布式算法让每个接入点进行本地活动检测，仅向中央处理单元交换检测结果。

Result: 理论分析表明增加近场信道比例能提升检测性能，仿真结果验证了理论分析并显示所提方法优于现有方法。

Conclusion: 所提算法能有效处理混合近远场场景，显著降低计算复杂度和通信开销，具有收敛保证且适用于单细胞和细胞自由系统。

Abstract: A great amount of endeavor has recently been devoted to activity detection
for massive machine-type communications in cell-free multiple-input
multiple-output (MIMO) systems. However, as the number of antennas at the
access points (APs) increases, the Rayleigh distance that separates the
near-field and far-field regions also expands, rendering the conventional
assumption of far-field propagation alone impractical. To address this
challenge, this paper establishes a covariance-based formulation that can
effectively capture the statistical property of hybrid near-far field channels.
Based on this formulation, we theoretically reveal that increasing the
proportion of near-field channels enhances the detection performance.
Furthermore, we propose a distributed algorithm, where each AP performs local
activity detection and only exchanges the detection results to the central
processing unit, thus significantly reducing the computational complexity and
the communication overhead. Not only with convergence guarantee, the proposed
algorithm is unified in the sense that it can handle single-cell or cell-free
systems with either near-field or far-field devices as special cases.
Simulation results validate the theoretical analyses and demonstrate the
superior performance of the proposed approach compared with existing methods.

</details>
