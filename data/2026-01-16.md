<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 10]
- [cs.IT](#cs.IT) [Total: 41]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [Distributed Hypothesis Testing Under A Covertness Constraint](https://arxiv.org/abs/2601.09837)
*Ismaila Salihou Adamou,Michèle Wigger*

Main category: eess.SP

TL;DR: 该论文研究了分布式假设检验中的隐蔽性约束问题，在非警觉情况下，传感器与决策中心之间的通信需要对外部监控者保持隐蔽。论文分析了部分连接和全连接离散无记忆信道下的Stein指数性能。


<details>
  <summary>Details</summary>
Motivation: 在分布式假设检验中，传感器与决策中心之间的通信可能被外部监控者检测到。传统隐蔽通信通常需要共享密钥，且隐蔽约束随观测长度缓慢衰减。本文旨在研究无需共享密钥、隐蔽约束能快速衰减的隐蔽假设检验方案。

Method: 针对部分连接离散无记忆信道，推导了Stein指数的可达性特征；针对全连接信道，提出了改进的Stein指数可达方案。所有编码方案都不需要传感器与决策中心共享密钥，且隐蔽约束随观测长度呈指数级快速衰减。

Result: 对于部分连接DMC，Stein指数不依赖于具体的信道转移概率，等于Shalaby和Papamarcou的无监控者指数，但传感器可以发送k个无噪声比特（k是观测长度n的次线性函数）。对于全连接DMC，提出的Stein指数可以改进决策中心的局部指数。

Conclusion: 本文展示了在分布式假设检验中，无需共享密钥即可实现隐蔽通信，且隐蔽约束能快速衰减。这为隐蔽假设检验提供了新的理论框架，与传统隐蔽通信的典型行为形成鲜明对比。

Abstract: We study distributed hypothesis testing under a covertness constraint in the non-alert situation, which requires that under the null-hypothesis an external warden be unable to detect whether communication between the sensor and the decision center is taking place. We characterize the achievable Stein exponent of this setup when the channel from the sensor to the decision center is a partially-connected discrete memoryless channel (DMC), i.e., when certain output symbols can only be induced by some of the inputs. The Stein-exponent in this case, does not depend on the specific transition law of the DMC and equals Shalaby and Papamarcou's exponent without a warden but where the sensor can send $k$ noise-free bits to the decision center, for $k$ a function that is sublinear in the observation length $n$. For fully-connected DMCs, we propose an achievable Stein-exponent and show that it can improve over the local exponent at the decision center. All our coding schemes do not require that the sensor and decision center share a common secret key, as commonly assumed in covert communication. Moreover, in our schemes the divergence covertness constraint vanishes (almost) exponentially fast in the obervation length $n$, again, an atypical behaviour for covert communication.

</details>


### [2] [Towards Native Intelligence: 6G-LLM Trained with Reinforcement Learning from NDT Feedback](https://arxiv.org/abs/2601.09992)
*Zhuoran Xiao,Tao Tao,Chenhui Ye,Yunbo Hu,Yijia Feng,Tianyu Jiao,Liyu Cai*

Main category: eess.SP

TL;DR: 本文提出了一种名为RLDTF（基于数字孪生反馈的强化学习）的新训练范式，用于6G-LLM，通过数字孪生生成奖励信号，结合强化学习动态优化网络编排决策，显著提升了编排准确性和解决方案最优性。


<details>
  <summary>Details</summary>
Motivation: 当前构建6G-LLM的方法依赖于大规模人工标注语料库，这在现实场景中难以获取。此外，纯离线训练的模型缺乏持续自我改进能力，难以适应无线通信环境的高度动态需求。

Method: 提出RLDTF训练范式：1）利用网络数字孪生根据编排结果生成奖励信号；2）采用强化学习动态引导模型进行最优决策；3）引入加权令牌机制提高输出准确性。

Result: 综合实验结果表明，所提出的框架在编排准确性和解决方案最优性方面显著优于现有最先进的基线方法。

Conclusion: RLDTF框架通过结合数字孪生和强化学习，克服了当前6G-LLM训练的限制，实现了网络编排的动态优化和持续改进，为6G网络原生智能提供了有效解决方案。

Abstract: Owing to its comprehensive understanding of upper-layer application requirements and the capabilities of practical communication systems, the 6G-LLM (6G domain large language model) offers a promising pathway toward realizing network native intelligence. Serving as the system orchestrator, the 6G-LLM drives a paradigm shift that fundamentally departs from existing rule-based approaches, which primarily rely on modular, experience-driven optimization. By contrast, the 6G-LLM substantially enhances network flexibility and adaptability. Nevertheless, current efforts to construct 6G-LLMs are constrained by their reliance on large-scale, meticulously curated, human-authored corpora, which are impractical to obtain in real-world scenarios. Moreover, purely offline-trained models lack the capacity for continual self-improvement, limiting their ability to adapt to the highly dynamic requirements of wireless communication environments. To overcome these limitations, we propose a novel training paradigm termed RLDTF (Reinforcement Learning from Digital Twin Feedback) for 6G-LLMs. This framework leverages network digital twins to generate reward signals based on orchestration outcomes, while employing reinforcement learning to guide the model toward optimal decision-making dynamically. Furthermore, we introduce a weighted token mechanism to improve output accuracy. Comprehensive experimental results demonstrate that our proposed framework significantly outperforms state-of-the-art baselines in orchestration accuracy and solution optimality.

</details>


### [3] [Clustering-Based User Selection in Federated Learning: Metadata Exploitation for 3GPP Networks](https://arxiv.org/abs/2601.10013)
*Ce Zheng,Shiyao Ma,Ke Zhang,Chen Sun,Wenqi Zhang*

Main category: eess.SP

TL;DR: 提出基于元数据的联邦学习框架，包含HPPP数据划分模型和聚类用户选择策略，提升非IID场景下的性能、稳定性和收敛性


<details>
  <summary>Details</summary>
Motivation: 传统联邦学习模拟常依赖不现实的数据划分，且现有用户选择方法忽略用户间数据相关性，需要更贴近实际部署的解决方案

Method: 1) 基于齐次泊松点过程(HPPP)的数据划分模型，捕捉数据量异质性和用户数据集自然重叠；2) 基于元数据(如用户位置)的聚类用户选择策略，减少数据相关性并增强标签多样性

Result: 在FMNIST和CIFAR-10数据集上，该框架在非IID场景下显著提升模型性能、稳定性和收敛速度，在IID设置下保持相当性能，尤其在每轮选择用户数较少时优势更明显

Conclusion: 该元数据驱动的联邦学习框架能有效提升实际部署中的性能，为未来标准化提供指导，特别适用于资源受限的真实场景

Abstract: Federated learning (FL) enables collaborative model training without sharing raw user data, but conventional simulations often rely on unrealistic data partitioning and current user selection methods ignore data correlation among users. To address these challenges, this paper proposes a metadatadriven FL framework. We first introduce a novel data partition model based on a homogeneous Poisson point process (HPPP), capturing both heterogeneity in data quantity and natural overlap among user datasets. Building on this model, we develop a clustering-based user selection strategy that leverages metadata, such as user location, to reduce data correlation and enhance label diversity across training rounds. Extensive experiments on FMNIST and CIFAR-10 demonstrate that the proposed framework improves model performance, stability, and convergence in non-IID scenarios, while maintaining comparable performance under IID settings. Furthermore, the method shows pronounced advantages when the number of selected users per round is small. These findings highlight the framework's potential for enhancing FL performance in realistic deployments and guiding future standardization.

</details>


### [4] [Microwave Linear Analog Computer (MiLAC)-aided Multiuser MISO: Fundamental Limits and Beamforming Design](https://arxiv.org/abs/2601.10060)
*Zheyu Wu,Matteo Nerini,Bruno Clerckx*

Main category: eess.SP

TL;DR: 微波线性模拟计算机（MiLAC）作为实现全模拟波束成形的有前景技术，在巨型MIMO系统中能提供接近数字波束成形的性能，同时降低硬件和计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 随着无线通信系统向6G演进，超大规模/巨型MIMO成为关键技术。传统数字波束成形面临可扩展性挑战，而MiLAC技术有望在模拟域实现波束成形，解决巨型MIMO系统的可扩展性问题。

Method: 首先严格表征MiLAC可实现的波束成形矩阵集合，证明其灵活性介于数字波束成形和传统相移器模拟波束成形之间。提出混合数字-MiLAC架构，在RF链数量等于数据流数量时实现数字波束成形灵活性。将MiLAC辅助的和速率最大化问题重新表述为凸线性矩阵不等式，并建立低维子空间特性以降低问题维度，提出基于WMMSE的求解算法。

Result: 仿真结果表明，MiLAC辅助波束成形在巨型MIMO系统中能实现接近数字波束成形的性能。与混合波束成形相比，通过避免符号级数字处理和启用低分辨率DAC，能以更低的硬件和计算复杂度实现相当或更优的性能。

Conclusion: MiLAC技术为6G时代的巨型MIMO系统提供了一种有前景的波束成形解决方案，在性能、灵活性和硬件复杂度之间取得了良好平衡，有望成为未来大规模天线系统的关键技术。

Abstract: As wireless communication systems evolve toward the 6G era, ultra-massive/gigantic MIMO is envisioned as a key enabling technology. Recently, microwave linear analog computer (MiLAC) has emerged as a promising approach to realize beamforming entirely in the analog domain, thereby alleviating the scalability challenges associated with gigantic MIMO. In this paper, we investigate the fundamental beamforming flexibility and design of lossless and reciprocal MiLAC-aided beamforming for MU-MISO systems. We first provide a rigorous characterization of the set of beamforming matrices achievable by MiLAC. Based on this characterization, we prove that MiLAC-aided beamforming does not generally achieve the full flexibility of digital beamforming, while offering greater flexibility than conventional phase-shifter-based analog beamforming. Furthermore, we propose a hybrid digital-MiLAC architecture and show that it achieves digital beamforming flexibility when the number of radio frequency (RF) chains equals the number of data streams, halving that required by conventional hybrid beamforming. We then formulate the MiLAC-aided sum-rate maximization problem for MU-MISO systems. To solve the problem efficiently, we reformulate the MiLAC-related constraints as a convex linear matrix inequality and establish a low-dimensional subspace property that significantly reduces the problem dimension. Leveraging these results, we propose WMMSE-based algorithms for solving the resulting problem. Simulation results demonstrate that MiLAC-aided beamforming achieves performance close to that of digital beamforming in gigantic MIMO systems. Compared with hybrid beamforming, it achieves comparable or superior performance with lower hardware and computational complexity by avoiding symbol-level digital processing and enabling low-resolution digital-to-analog converters (DACs).

</details>


### [5] [P-norm based Fractional-Order Robust Subband Adaptive Filtering Algorithm for Impulsive Noise and Noisy Input](https://arxiv.org/abs/2601.10074)
*Jianhong Ye,Haiquan Zhao,Yi Peng*

Main category: eess.SP

TL;DR: 提出分数阶NSPN算法，结合分数阶随机梯度下降，提升在α稳定噪声环境（0<α≤1）中的鲁棒性


<details>
  <summary>Details</summary>
Motivation: 现有NSPN算法在α稳定噪声环境（1<α≤2）中表现良好，但在0<α≤1的噪声环境下性能显著下降，需要改进算法以应对更广泛的噪声类型

Method: 提出分数阶NSPN算法，将分数阶随机梯度下降方法融入MPE框架，分析步长收敛范围、分数阶β的理论值域，建立稳态均方偏差理论模型

Result: 在多种脉冲噪声环境下的仿真实验证实，FoNSPN算法优于现有最先进算法

Conclusion: FoNSPN算法通过分数阶优化有效扩展了NSPN算法的适用范围，在更广泛的α稳定噪声环境中表现出优越的鲁棒性能

Abstract: Building upon the mean p-power error (MPE) criterion, the normalized subband p-norm (NSPN) algorithm demonstrates superior robustness in $α$-stable noise environments ($1 < α\leq 2$) through effective utilization of low-order moment hidden in robust loss functions. Nevertheless, its performance degrades significantly when processing noise input or additive noise characterized by $α$-stable processes ($0 < α\leq 1$). To overcome these limitations, we propose a novel fractional-order NSPN (FoNSPN) algorithm that incorporates the fractional-order stochastic gradient descent (FoSGD) method into the MPE framework. Additionally, this paper also analyzes the convergence range of its step-size, the theoretical domain of values for the fractional-order $β$, and establishes the theoretical steady-state mean square deviation (MSD) model. Simulations conducted in diverse impulsive noise environments confirm the superiority of the proposed FoNSPN algorithm against existing state-of-the-art algorithms.

</details>


### [6] [Service Provisioning and Path Planning with Obstacle Avoidance for Low-Altitude Wireless Networks](https://arxiv.org/abs/2601.10179)
*Senning Wan,Bin Li,Hongbin Chen,Lei Liu*

Main category: eess.SP

TL;DR: 本文研究异构通信网络中无人机作为空中基站的3D部署问题，考虑地面障碍物约束和用户个性化需求，通过联合优化无人机轨迹、波束赋形和关联指示器来最大化用户满意度。


<details>
  <summary>Details</summary>
Motivation: 在异构通信网络中部署无人机作为空中基站面临多重挑战：地面障碍物影响信号传输，用户设备具有多样化数据需求，无人机可能因电池耗尽而失效。需要开发一种能够适应动态环境、提供个性化服务并最大化用户满意度的解决方案。

Method: 采用块坐标下降法将问题分解为两个子问题：1) 波束赋形子问题使用基于二分法的注水算法高效求解；2) 轨迹和关联子问题设计基于近端策略优化的深度强化学习算法来学习自适应控制策略。

Result: 仿真结果表明，所提方案在收敛速度和整体系统性能方面优于基准方案，能够实现高效的关联和准确的障碍物规避。

Conclusion: 该研究成功解决了异构网络中无人机3D部署的复杂优化问题，提出的联合优化框架能够有效处理障碍物约束、用户个性化需求和系统动态性，为未来无人机辅助通信网络提供了实用解决方案。

Abstract: This paper investigates the three-dimensional (3D) deployment of uncrewed aerial vehicles (UAVs) as aerial base stations in heterogeneous communication networks under constraints imposed by diverse ground obstacles. Given the diverse data demands of user equipments (UEs), a user satisfaction model is developed to provide personalized services. In particular, when a UE is located within a ground obstacle, the UAV must approach the obstacle boundary to ensure reliable service quality. Considering constraints such as UAV failures due to battery depletion, heterogeneous UEs, and obstacles, we aim to maximize overall user satisfaction by jointly optimizing the 3D trajectories of UAVs, transmit beamforming vectors, and binary association indicators between UAVs and UEs. To address the complexity and dynamics of the problem, a block coordinate descent method is adopted to decompose it into two subproblems. The beamforming subproblem is efficiently addressed via a bisection-based water-filling algorithm. For the trajectory and association subproblem, we design a deep reinforcement learning algorithm based on proximal policy optimization to learn an adaptive control policy. Simulation results demonstrate that the proposed scheme outperforms baseline schemes in terms of convergence speed and overall system performance. Moreover, it achieves efficient association and accurate obstacle avoidance.

</details>


### [7] [BeamCKMDiff: Beam-Aware Channel Knowledge Map Construction via Diffusion Transformer](https://arxiv.org/abs/2601.10207)
*Le Zhao,Yining Wang,Xinyi Wang,Zesong Fei,Yong Zeng*

Main category: eess.SP

TL;DR: 提出BeamCKMDiff生成框架，通过扩散变换器结合自适应层归一化机制，无需站点特定采样即可构建高保真信道知识图，支持任意连续波束赋形向量。


<details>
  <summary>Details</summary>
Motivation: 现有CKM构建方法依赖稀疏采样测量，仅限于全向地图或离散码本，限制了波束赋形增益的利用。需要一种能够处理任意连续波束向量且无需站点特定采样的高保真CKM构建方法。

Method: 提出BeamCKMDiff生成框架，在扩散变换器的噪声预测网络中引入自适应层归一化机制，将连续波束嵌入作为全局控制参数注入，引导生成过程捕捉波束模式与环境几何的复杂耦合关系。

Result: 仿真结果表明BeamCKMDiff显著优于现有基线方法，在主瓣和旁瓣的重建精度方面表现出优越性能。

Conclusion: BeamCKMDiff为6G网络提供了一种无需站点特定采样即可构建高保真CKM的创新解决方案，能够有效支持任意连续波束赋形向量，为环境感知网络提供重要使能技术。

Abstract: Channel knowledge map (CKM) is emerging as a critical enabler for environment-aware 6G networks, offering a site-specific database to significantly reduce pilot overhead. However, existing CKM construction methods typically rely on sparse sampling measurements and are restricted to either omnidirectional maps or discrete codebooks, hindering the exploitation of beamforming gain. To address these limitations, we propose BeamCKMDiff, a generative framework for constructing high-fidelity CKMs conditioned on arbitrary continuous beamforming vectors without site-specific sampling. Specifically, we incorporate a novel adaptive layer normalization (adaLN) mechanism into the noise prediction network of the Diffusion Transformer (DiT). This mechanism injects continuous beam embeddings as {global control parameters}, effectively steering the generative process to capture the complex coupling between beam patterns and environmental geometries. Simulation results demonstrate that BeamCKMDiff significantly outperforms state-of-the-art baselines, achieving superior reconstruction accuracy in capturing main lobes and side lobes.

</details>


### [8] [Sim2Real Deep Transfer for Per-Device CFO Calibration](https://arxiv.org/abs/2601.10264)
*Jingze Zheng,Zhiguo Shi,Shibo He,Chaojie Gu*

Main category: eess.SP

TL;DR: 提出Sim2Real迁移学习框架，通过仿真预训练和轻量级接收器适配，实现异构SDR平台的CFO校准，相比传统方法BER降低30倍。


<details>
  <summary>Details</summary>
Motivation: OFDM系统中CFO估计在异构SDR平台上因硬件损伤未校准而性能严重下降，现有DNN方法缺乏设备级适配，限制了实际部署。

Method: 提出Sim2Real迁移学习框架：1）在包含参数化硬件损伤的合成OFDM信号上预训练骨干DNN；2）仅对回归层使用每个目标设备1000个真实帧进行微调，保留硬件无关知识同时适配设备特定损伤。

Result: 在三个SDR平台（USRP B210、USRP N210、HackRF One）上实验，相比传统CP方法在室内多径条件下实现30倍BER降低。

Conclusion: 该框架弥合了仿真与现实的差距，为异构无线系统中的CFO估计提供了鲁棒且成本效益高的部署方案。

Abstract: Carrier Frequency Offset (CFO) estimation in Orthogonal Frequency Division Multiplexing (OFDM) systems faces significant performance degradation across heterogeneous software-defined radio (SDR) platforms due to uncalibrated hardware impairments. Existing deep neural network (DNN)-based approaches lack device-level adaptation, limiting their practical deployment. This paper proposes a Sim2Real transfer learning framework for per-device CFO calibration, combining simulation-driven pretraining with lightweight receiver adaptation. A backbone DNN is pre-trained on synthetic OFDM signals incorporating parametric hardware distortions (e.g., phase noise, IQ imbalance), enabling generalized feature learning without costly cross-device data collection. Subsequently, only the regression layers are fine-tuned using $1,000$ real frames per target device, preserving hardware-agnostic knowledge while adapting to device-specific impairments. Experiments across three SDR families (USRP B210, USRP N210, HackRF One) achieve $30\times$ BER reduction compared to conventional CP-based methods under indoor multipath conditions. The framework bridges the simulation-to-reality gap for robust CFO estimation, enabling cost-effective deployment in heterogeneous wireless systems.

</details>


### [9] [Low-Complexity Blind Estimator of SNR and MSE for mmWave Multi-Antenna Communications](https://arxiv.org/abs/2601.10331)
*Hanyoung Park,Ji-Woong Choi*

Main category: eess.SP

TL;DR: 提出一种用于毫米波通信的盲估计器，无需导频信号即可估计噪声功率、信号功率、SNR和MSE，计算复杂度低


<details>
  <summary>Details</summary>
Motivation: 毫米波信道快速变化导致传统基于导频的估计方法精度下降，现有盲估计算法计算复杂度高，难以满足实时服务需求

Method: 利用毫米波信道在波束空间域的固有稀疏性，使信号和噪声功率分量更易区分，设计无需真实信号先验知识且计算复杂度低的盲估计算法

Result: 提出的盲估计器能够有效估计平均噪声功率、信号功率、SNR和MSE，无需导频信号且计算复杂度低

Conclusion: 该方法解决了毫米波通信中信道估计的挑战，为实时服务提供了可行的解决方案，增强了系统对动态环境变化的适应能力

Abstract: To enhance the robustness and resilience of wireless communication and meet performance requirements, various environment-reflecting metrics, such as the signal-to-noise ratio (SNR), are utilized as the system parameter. To obtain these metrics, training signals such as pilot sequences are generally employed. However, the rapid fluctuations of the millimeter-wave (mmWave) propagation channel often degrade the accuracy of such estimations. To address this challenge, various blind estimators that operate without pilot have been considered as potential solutions. However, these algorithms often involve a training phase for machine learning or a large number of iterations, which implies prohibitive computational complexity, making them difficult to employ for real-time services and the system less resilient to dynamic environment variation. In this paper, we propose blind estimators for average noise power, signal power, SNR, and mean-square error (MSE) that do not require knowledge of the ground-truth signal or involve high computational complexity. The proposed algorithm leverages the inherent sparsity of mmWave channel in beamspace domain, which makes the signal and noise power components more distinguishable.

</details>


### [10] [Achievable Degrees of Freedom Analysis and Optimization in Massive MIMO via Characteristic Mode Analysis](https://arxiv.org/abs/2601.10576)
*Shaohua Yue,Siyu Miao,Shuhao Zeng,Fenghan Lin,Boya Di*

Main category: eess.SP

TL;DR: 本文提出使用特征模分析(CMA)来分析MIMO系统的可达自由度(DoF)，不仅考虑无线信道，还包含天线激励和辐射特性，并通过可重构全息表面(RHS)天线优化来提升DoF。


<details>
  <summary>Details</summary>
Motivation: 大规模MIMO是6G通信的关键技术，但现有研究主要关注无线信道的自由度，忽略了天线激励和辐射特性对MIMO系统独立数据流数量的影响。需要更全面的DoF分析框架。

Method: 引入特征模分析(CMA)来建模天线激励和辐射特性，建立CMA-based DoF分析框架，推导可达DoF。针对可重构全息表面(RHS)天线，提出CMA-based遗传算法优化特征模，改变电场和表面电流分布以最大化DoF。

Result: 建立了包含天线特性的DoF分析框架，通过优化RHS天线的特征模分布，成功提升了系统的可达自由度。全波仿真验证了理论分析，显示基于所提算法的RHS重构能够改善DoF性能。

Conclusion: 特征模分析为MIMO系统DoF分析提供了更全面的框架，考虑了天线激励和辐射特性。通过优化天线特征模，特别是可重构全息表面天线，可以有效提升MIMO系统的可达自由度，对6G通信系统设计具有重要意义。

Abstract: Massive multiple-input multiple-output (MIMO) is esteemed as a critical technology in 6G communications, providing large degrees of freedom (DoF) to improve multiplexing gain. This paper introduces characteristic mode analysis (CMA) to derive the achievable DoF. Unlike existing works primarily focusing on the DoF of the wireless channel,the excitation and radiation properties of antennas are also involved in our DoF analysis, which influences the number of independent data streams for communication of a MIMO system. Specifically, we model the excitation and radiation properties of transceiver antennas using CMA to analyze the excitation and radiation properties of antennas. The CMA-based DoF analysis framework is established and the achievable DoF is derived. A characteristic mode optimization problem of antennas is then formulated to maximize the achievable DoF. A case study where the reconfigurable holographic surface (RHS) antennas are deployed at the transceiver is investigated, and a CMA-based genetic algorithm is later proposed to solve the above problem. By changing the characteristic modes electric field and surface current distribution of RHS, the achievable DoF is enhanced. Full-wave simulation verifies the theoretical analysis on the the achievable DoF and shows that, via the reconfiguration of RHS based on the proposed algorithm, the achievable DoF is improved.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [11] [High signal-to-noise ratio asymptotics of entropy-constrained Gaussian channel capacity](https://arxiv.org/abs/2601.09864)
*Adway Girish,Shlomo Shamai,Emre Telatar*

Main category: cs.IT

TL;DR: 在高信噪比渐近条件下，高斯信道在输入熵约束下的容量达到分布是支撑在缩放整数格上的离散高斯分布，输入熵与容量的差距随信噪比指数衰减。


<details>
  <summary>Details</summary>
Motivation: 研究高斯信道在输入熵约束下的容量问题，特别是在高信噪比渐近条件下的行为，这对于理解实际通信系统中有限精度输入的性能极限具有重要意义。

Method: 采用渐近分析方法，在高信噪比条件下分析输入熵约束高斯信道的容量问题，推导容量达到分布的形式和性能差距的衰减特性。

Result: 证明当信噪比趋于无穷时，容量达到分布是支撑在缩放整数格上的离散高斯分布，输入熵与容量的差距随信噪比指数衰减，并刻画了该指数。

Conclusion: 在高信噪比渐近条件下，离散高斯分布是输入熵约束高斯信道的最优输入分布，且输入熵与容量之间的差距呈指数衰减，为实际通信系统设计提供了理论指导。

Abstract: We study the input-entropy-constrained Gaussian channel capacity problem in the asymptotic high signal-to-noise ratio (SNR) regime. We show that the capacity-achieving distribution as SNR goes to infinity is given by a discrete Gaussian distribution supported on a scaled integer lattice. Further, we show that the gap between the input entropy and the capacity decreases to zero exponentially in SNR, and characterize this exponent.

</details>


### [12] [One-Cold Poisson Channel: A Simple Continuous-Time Channel with Zero Dispersion](https://arxiv.org/abs/2601.09894)
*Cheuk Ting Li*

Main category: cs.IT

TL;DR: 本文介绍了一种新型通信信道——单冷泊松信道（OCPC），其中发射机选择衰减一个频带。完美OCPC具有容量1、零信道色散和简并信息谱，是唯一已知具有闭式最优非渐近误码率公式的非平凡无记忆信道。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索一种极其简单的连续时间无记忆信道模型，该模型具有闭式最优非渐近误码率公式，可作为信息的基本计量单位（替代比特），并应用于带可调谐带阻滤波器的光通信。

Method: 引入单冷泊松信道（OCPC）模型，其中发射机选择衰减一个频带。研究完美OCPC（无限频带数）的特性和一般OCPC的非渐近编码与信道仿真结果。

Result: 完美OCPC具有容量1、零信道色散、信息谱为在1处的简并分布。它是唯一已知具有闭式最优非渐近误码率公式的非平凡无记忆信道。OCPC可作为无限可分的信息基本单位，其带完美反馈的版本推广了前缀码。

Conclusion: OCPC是一种极其简单的连续时间无记忆信道模型，具有独特的数学性质，可作为信息的基本计量单位，并有望应用于光通信等领域。

Abstract: We introduce the one-cold Poisson channel (OCPC), where the transmitter chooses one of several frequency bands to attenuate at a time. In particular, the perfect OCPC, where the number of bands is unlimited, is an extremely simple continuous-time memoryless channel. It has a capacity 1, zero channel dispersion, and an information spectrum being the degenerate distribution at 1. It is the only known nontrivial (discrete or continuous-time) memoryless channel with a closed-form formula for its optimal non-asymptotic error probability, making it the simplest channel in this sense. A potential application is optical communication with a tunable band rejection filter. Due to its simplicity, we may use it as a basic currency of information that is infinitely divisible, as an alternative to bits which are not infinitely divisible. OCPC with perfect feedback gives a generalization of prefix codes. We also study non-asymptotic coding and channel simulation results for the general OCPC.

</details>


### [13] [Learning-Augmented Perfectly Secure Collaborative Matrix Multiplication](https://arxiv.org/abs/2601.09916)
*Zixuan He,Mohammad Reza Deylam Salehi,Derya Malak,Photios A. Stavrou*

Main category: cs.IT

TL;DR: 提出了一种用于多方计算中矩阵乘法的完美安全协议，保证信息论隐私和正确性，并引入了学习增强扩展以提高计算效率。


<details>
  <summary>Details</summary>
Motivation: 在多方计算中实现矩阵乘法时，需要在保证完美安全性的同时提高计算效率。现有方案在安全性和效率之间存在权衡，特别是在大规模矩阵运算中。

Method: 使用稀疏掩码多项式编码子矩阵，结合系数对齐和Beaver式随机性确保完美保密。学习增强扩展集成了基于张量分解的本地块乘法，兼容经典和学习的低秩方法。

Result: 协议在阈值限制下保证信息论隐私，任何低于安全阈值的合谋方只能观察到均匀随机份额。恢复阈值达到最优，匹配现有信息论极限。学习增强版本在保持隐私和恢复保证的同时，随着矩阵维度增长可提供高达80%的计算效率提升。

Conclusion: 该工作提出了一个完美安全的矩阵乘法协议框架，在保证信息论隐私的同时实现了最优恢复阈值，并通过学习增强扩展显著提高了大规模矩阵运算的计算效率。

Abstract: This paper presents a perfectly secure matrix multiplication (PSMM) protocol for multiparty computation (MPC) of $\mathrm{A}^{\top}\mathrm{B}$ over finite fields. The proposed scheme guarantees correctness and information-theoretic privacy against threshold-bounded, semi-honest colluding agents, under explicit local storage constraints. Our scheme encodes submatrices as evaluations of sparse masking polynomials and combines coefficient alignment with Beaver-style randomness to ensure perfect secrecy. We demonstrate that any colluding set of parties below the security threshold observes uniformly random shares, and that the recovery threshold is optimal, matching existing information-theoretic limits. Building on this framework, we introduce a learning-augmented extension that integrates tensor-decomposition-based local block multiplication, capturing both classical and learned low-rank methods. We demonstrate that the proposed learning-based PSMM preserves privacy and recovery guarantees for MPC, while providing scalable computational efficiency gains (up to $80\%$) as the matrix dimensions grow.

</details>


### [14] [Reconstructing Reed-Solomon Codes from Multiple Noisy Channel Outputs](https://arxiv.org/abs/2601.09947)
*Shubhransh Singhvi,Han Mao Kiah,Eitan Yaakobi*

Main category: cs.IT

TL;DR: 研究序列重构问题，针对RS码在q元DMS替换信道下的高效重构算法，推导出依赖于(p,K)的显式速率阈值


<details>
  <summary>Details</summary>
Motivation: Levenshtein在2001年提出的序列重构问题考虑发送方传输码字，接收方观察到K个独立噪声版本。本研究旨在解决当每个输出被q元离散无记忆对称替换信道（替换概率p）干扰时的高效重构问题

Method: 针对Reed-Solomon码，将Koetter-Vardy软判决译码算法适配为高效重构算法。对于足够大的分组长度和字母表大小，推导出显式速率阈值

Result: 当码率R低于该阈值时，传输的码字可以以任意小的错误概率被重构。阈值仅依赖于(p,K)参数

Conclusion: 成功将软判决译码算法应用于序列重构问题，为RS码在DMS替换信道下的高效重构提供了理论保证和实用算法

Abstract: The sequence reconstruction problem, introduced by Levenshtein in 2001, considers a communication setting in which a sender transmits a codeword and the receiver observes K independent noisy versions of this codeword. In this work, we study the problem of efficient reconstruction when each of the $K$ outputs is corrupted by a $q$-ary discrete memoryless symmetric (DMS) substitution channel with substitution probability $p$. Focusing on Reed-Solomon (RS) codes, we adapt the Koetter-Vardy soft-decision decoding algorithm to obtain an efficient reconstruction algorithm. For sufficiently large blocklength and alphabet size, we derive an explicit rate threshold, depending only on $(p, K)$, such that the transmitted codeword can be reconstructed with arbitrarily small probability of error whenever the code rate $R$ lies below this threshold.

</details>


### [15] [Private Information Retrieval for Graph-based Replication with Minimal Subpacketization](https://arxiv.org/abs/2601.09957)
*Vayur Shanbhag,Prasad Krishnan*

Main category: cs.IT

TL;DR: 提出了两种基于图复制数据库的最小子包化私有信息检索方案：针对星图的方案和针对一般图的方案，两者都具有单位子包化（最小化），其中星图方案比现有方案有更高速率。


<details>
  <summary>Details</summary>
Motivation: 在图复制数据库中设计私有信息检索方案时，需要在高速率（文件大小与总下载成本之比）和低子包化（协议执行时文件大小的约束）之间取得平衡。现有方案在子包化方面存在限制，需要设计具有最小子包化的高效方案。

Method: 提出了两种新方案：1）针对星图的单位子包化方案，具有比现有方案更好的速率；2）针对一般图的方案，通过独立集分解图结构，虽然对完全图的速率低于先前方案，但对某些特定图类能达到更高速率。还扩展到多图情况，对完全多图实现了更高速率。

Result: 成功设计了两种具有单位子包化（最小化）的私有信息检索方案。星图方案在一般星图上比现有低子包化方案有更好的速率。一般图方案虽然对完全图速率较低，但对特定图类能实现更高速率。多图扩展方案对完全多图实现了比先前方案更高的速率。

Conclusion: 通过图分解和独立集方法，成功设计了具有最小子包化的私有信息检索方案，在保持隐私性的同时优化了速率性能，为图复制数据库系统提供了更实用的解决方案。

Abstract: We design new minimal-subpacketization schemes for information-theoretic private information retrieval on graph-based replicated databases. In graph-based replication, the system consists of $K$ files replicated across $N$ servers according to a graph with $N$ vertices and $K$ edges. The client wants to retrieve one desired file, while keeping the index of the desired file private from each server via a query-response protocol. We seek PIR protocols that have (a) high rate, which is the ratio of the file-size to the total download cost, and (b) low subpacketization, which acts as a constraint on the size of the files for executing the protocol. We report two new schemes which have unit-subpacketization (which is minimal): (i) for a special class of graphs known as star graphs, and (ii) for general graphs. Our star-graph scheme has a better rate than previously known schemes with low subpacketization for general star graphs. Our scheme for general graphs uses a decomposition of the graph via independent sets. This scheme achieves a rate lower than prior schemes for the complete graph, however it can achieve higher rates than known for some specific graph classes. An extension of our scheme to the case of multigraphs achieves a higher rate than previous schemes for the complete multi-graph.

</details>


### [16] [On the Leaky Private Information Retrieval with Side Information](https://arxiv.org/abs/2601.09960)
*Yingying Huangfu,Tian Bai*

Main category: cs.IT

TL;DR: 论文研究带侧信息的泄露隐私私有信息检索(L-PIR-SI)，通过放宽完美隐私要求来提高通信效率，提出统一概率框架量化隐私泄露，并建立了泄露、侧信息和检索效率之间的权衡关系。


<details>
  <summary>Details</summary>
Motivation: 在私有信息检索(PIR)中，完美隐私要求会导致较高的通信开销。虽然带侧信息的PIR-SI的容量问题已有部分研究，但控制信息泄露在这些设置中的影响尚未解决。作者希望探索在存在侧信息的情况下，通过允许可控隐私泄露来改善通信效率。

Method: 提出统一的概率框架来构建L-PIR-SI方案，使用参数ε量化隐私泄露（符合差分隐私标准）。该框架能够处理W-隐私和(W,S)-隐私两种设置，并推导了可实现的下载成本。

Result: 当ε→0时，结果恢复PIR-SI的容量；当侧信息不存在时，结果简化为已知的泄露-PIR边界。这是首次系统地研究泄露、侧信息和检索效率之间的权衡关系。

Conclusion: 该工作为带侧信息的泄露隐私私有信息检索提供了首个理论框架，展示了通过可控隐私泄露可以显著提高通信效率，同时保持可量化的隐私保护水平。

Abstract: This paper investigates the problem of leaky-private Private Information Retrieval with Side Information (L-PIR-SI), which relaxes the requirement of perfect privacy to achieve improved communication efficiency in the presence of side information. While the capacities of PIR-SI under both $W$-privacy and $(W,S)$-privacy have been partially explored, the impact of controlled information leakage in these settings remains unaddressed. We propose a unified probabilistic framework to construct L-PIR-SI schemes where the privacy leakage is quantified by a parameter $\varepsilon$, consistent with differential privacy standards. We characterize the achievable download costs and show that our results generalize several landmark results in the PIR literature: they recover the capacity of PIR-SI when $\varepsilon \to 0$, and reduce to the known bounds for leaky-PIR when side information is absent. This work provides the first look at the trade-offs between leakage, side information, and retrieval efficiency.

</details>


### [17] [Fundamental Limits of Coded Polynomial Aggregation](https://arxiv.org/abs/2601.10028)
*Xi Zhong,Jörg Kliewer,Mingyue Ji*

Main category: cs.IT

TL;DR: 将编码多项式聚合(CPA)扩展到含掉队者的分布式计算系统，建立掉队者感知CPA框架，通过分析非掉队者集合的交集结构，给出精确恢复的充要条件与阈值。


<details>
  <summary>Details</summary>
Motivation: 传统基于多项式编码的计算需要单独解码每个项，而CPA可以直接恢复多项式评估的加权聚合，减少所需工作节点响应数量。本文旨在将CPA扩展到存在掉队者的分布式计算系统，建立掉队者感知的CPA框架。

Method: 提出掉队者感知CPA框架，预设非掉队者模式，仅需对给定的可接受非掉队者集合实现精确恢复。通过分析非掉队者模式的交集结构，建立精确恢复的充要条件，识别交集大小阈值，并提供可行的CPA方案构造方法。

Result: 证明精确恢复所需的工作节点响应数量少于基于单独解码的多项式编码计算；建立了精确恢复的充要条件，识别了保证精确恢复的交集大小阈值；当可接受非掉队者集合数量足够大时，该阈值成为充要条件；提供了可行的CPA方案构造。

Conclusion: 掉队者感知CPA能有效减少分布式计算中的工作节点响应需求，精确恢复的可行性由非掉队者模式的交集结构决定。仿真显示在预测阈值处存在急剧的可行性转变，证明边界在实践中是紧致的。

Abstract: Coded polynomial aggregation (CPA) enables the master to directly recover a weighted aggregation of polynomial evaluations without individually decoding each term, thereby reducing the number of required worker responses. In this paper, we extend CPA to straggler-aware distributed computing systems and introduce a straggler-aware CPA framework with pre-specified non-straggler patterns, where exact recovery is required only for a given collection of admissible non-straggler sets. Our main result shows that exact recovery of the desired aggregation is achievable with fewer worker responses than required by polynomial coded computing based on individual decoding, and that feasibility is fundamentally characterized by the intersection structure of the non-straggler patterns. In particular, we establish necessary and sufficient conditions for exact recovery in straggler-aware CPA and identify an intersection-size threshold that is sufficient to guarantee exact recovery. We further prove that this threshold becomes both necessary and sufficient when the number of admissible non-straggler sets is sufficiently large. We also provide an explicit construction of feasible CPA schemes whenever the intersection size exceeds the derived threshold. Finally, simulations reveal a sharp feasibility transition at the predicted threshold, providing empirical evidence that the bound is tight in practice.

</details>


### [18] [Optimal Proximity Gap for Folded Reed--Solomon Codes via Subspace Designs](https://arxiv.org/abs/2601.10047)
*Fernando Granha Jeronimo,Lenny Liu,Pranav Rajpal*

Main category: cs.IT

TL;DR: Folded Reed-Solomon (FRS) 码在最优容量范围内具有 (δ,ε)-邻近间隙性质


<details>
  <summary>Details</summary>
Motivation: Ben-Sasson 等人证明了仿射子空间对于 Reed-Solomon 码在 Johnson 界范围内具有邻近间隙性质。Folded Reed-Solomon 码能达到最优列表解码半径（容量），因此自然要问 FRS 码是否在最优容量范围内也具有类似的邻近间隙性质。

Method: 将 Ben-Sasson 等人的框架扩展到适合的子空间设计码，特别是 Folded Reed-Solomon 码。该框架依赖于 FRS 码的列表解码算法，这些算法在容量范围内有效。

Result: 证明了 FRS 码在最优容量范围内确实具有 (δ,ε)-邻近间隙性质。该框架也适用于其他合适的子空间设计码。

Conclusion: Folded Reed-Solomon 码在最优列表解码容量范围内具有邻近间隙性质，这扩展了之前关于 Reed-Solomon 码的结果，并为理解 FRS 码与随机线性码的相似性提供了新视角。

Abstract: A collection of sets satisfies a $(δ,\varepsilon)$-proximity gap with respect to some property if for every set in the collection, either (i) all members of the set are $δ$-close to the property in (relative) Hamming distance, or (ii) only a small $\varepsilon$-fraction of members are $δ$-close to the property.
  In a seminal work, Ben-Sasson \textit{et al.}\ showed that the collection of affine subspaces exhibits a $(δ,\varepsilon)$-proximity gap with respect to the property of being Reed--Solomon (RS) codewords with $δ$ up to the so-called Johnson bound for list decoding. Their technique relies on the Guruswami--Sudan list decoding algorithm for RS codes, which is guaranteed to work in the Johnson bound regime.
  Folded Reed--Solomon (FRS) codes are known to achieve the optimal list decoding radius $δ$, a regime known as capacity. Moreover, a rich line of list decoding algorithms was developed for FRS codes. It is then natural to ask if FRS codes can be shown to exhibit an analogous $(δ,\varepsilon)$-proximity gap, but up to the so-called optimal capacity regime. We answer this question in the affirmative (and the framework naturally applies more generally to suitable subspace-design codes).
  An additional motivation to understand proximity gaps for FRS codes is the recent results [BCDZ'25] showing that they exhibit properties similar to random linear codes, which were previously shown to be related to properties of RS codes with random evaluation points in [LMS'25], as well as codes over constant-size alphabet based on AEL [JS'25].

</details>


### [19] [Codebook Design for Limited Feedback in Near-Field XL-MIMO Systems](https://arxiv.org/abs/2601.10391)
*Liujia Yao,Changsheng You,Zixuan Huang,Chao Zhou,Zhaohui Yang,Xiaoyang Li*

Main category: cs.IT

TL;DR: 提出针对XL-MIMO FDD系统的用户分布自适应码本设计，通过联合优化角度-距离采样和比特分配提升反馈效率


<details>
  <summary>Details</summary>
Motivation: 现有XL-MIMO码本设计（如极域码本）未充分考虑实际用户分布，导致反馈开销过大

Method: 基于Voronoi划分证明均匀角度采样最优；针对距离采样提出几何采样作为高质量次优解；扩展至非均匀用户分布；理论分析比特分配趋势

Result: 数值结果表明所提码本在各种系统设置下具有优越的速率性能和鲁棒性，相比基准方案（包括广泛使用的极域码本）获得显著增益

Conclusion: 提出的用户分布自适应码本设计能有效降低XL-MIMO FDD系统的反馈开销，随着阵列规模增大，比特分配应更倾向于距离采样而非角度采样

Abstract: In this paper, we study efficient codebook design for limited feedback in extremely large-scale multiple-input-multiple-output (XL-MIMO) frequency division duplexing (FDD) systems. It is worth noting that existing codebook designs for XL-MIMO, such as polar-domain codebook, have not well taken into account user (location) distribution in practice, thereby incurring excessive feedback overhead. To address this issue, we propose in this paper a novel and efficient feedback codebook tailored to user distribution. To this end, we first consider a typical scenario where users are uniformly distributed within a specific polar-region, based on which a sum-rate maximization problem is formulated to jointly optimize angle-range samples and bit allocation among angle/range feedback. This problem is challenging to solve due to the lack of a closed-form expression for the received power in terms of angle and range samples. By leveraging a Voronoi partitioning approach, we show that uniform angle sampling is optimal for received power maximization. For more challenging range sampling design, we obtain a tight lower-bound on the received power and show that geometric sampling, where the ratio between adjacent samples is constant, can maximize the lower bound and thus serves as a high-quality suboptimal solution. We then extend the proposed framework to accommodate more general non-uniform user distribution via an alternating sampling method. Furthermore, theoretical analysis reveals that as the array size increases, the optimal allocation of feedback bits increasingly favors range samples at the expense of angle samples. Finally, numerical results validate the superior rate performance and robustness of the proposed codebook design under various system setups, achieving significant gains over benchmark schemes, including the widely used polar-domain codebook.

</details>


### [20] [Function Correcting Codes for Maximally-Unbalanced Boolean Functions](https://arxiv.org/abs/2601.10135)
*Rajlaxmi Pandey,Shiven Bajpai,Anjana A Mahesh,B. Sundar Rajan*

Main category: cs.IT

TL;DR: 研究针对最大不平衡布尔函数的最优单错误校正函数校正码，分析其距离矩阵结构对AWGN信道性能的影响


<details>
  <summary>Details</summary>
Motivation: 函数校正码允许在噪声信道上可靠计算函数而无需完全恢复消息，但现有研究对最优单错误校正FCC的结构及其对性能影响的理解有限

Method: 通过关联码字距离矩阵分析最优SEFCC结构，识别不同FCC类别，在AWGN信道上评估软判决和硬判决解码的性能差异

Result: 不同距离矩阵结构的FCC在数据BER和函数错误行为上表现显著差异，代码结构的影响强烈依赖于解码策略

Conclusion: FCC的结构特性对性能有重要影响，解码策略选择应基于具体应用需求和信道条件，为FCC设计提供了重要指导

Abstract: Function-Correcting Codes (FCCs) enable reliable computation of a function of a $k$-bit message over noisy channels without requiring full message recovery. In this work, we study optimal single-error correcting FCCs (SEFCCs) for maximally-unbalanced Boolean functions, where $k$ denotes the message length and $t$ denotes the error-correction capability. We analyze the structure of optimal SEFCC constructions through their associated codeword distance matrices and identify distinct FCC classes based on this structure. We then examine the impact of these structural differences on error performance by evaluating representative FCCs over the additive white Gaussian noise (AWGN) channel using both soft-decision and hard-decision decoding. The results show that FCCs with different distance-matrix structures can exhibit markedly different Data BER and function error behavior, and that the influence of code structure depends strongly on the decoding strategy.

</details>


### [21] [Breaking the Storage-Bandwidth Tradeoff in Distributed Storage with Quantum Entanglement](https://arxiv.org/abs/2601.10676)
*Lei Hu,Mohamed Nomeir,Alptug Aytekin,Sennur Ulukus*

Main category: cs.IT

TL;DR: 量子分布式存储系统利用量子通信和纠缠显著改善了存储-修复带宽权衡，在某些条件下甚至能同时最小化存储和修复带宽，突破了经典系统的限制。


<details>
  <summary>Details</summary>
Motivation: 研究量子资源在分布式存储系统中的应用，探索量子通信如何改善经典分布式存储系统中存储容量和修复带宽之间的权衡关系。

Method: 在(n,k,d)分布式存储系统中，当节点故障时，允许d个辅助节点通过量子信道向新节点传输经典信息，新节点通过对接收的量子态进行测量来生成存储。利用幸存节点间的量子纠缠增强系统性能。

Result: 完全刻画了量子分布式存储系统中存储和修复带宽的基本权衡关系。相比经典系统，量子纠缠显著改善了最优存储-带宽权衡，特别是在最小存储再生点。当d≥2k-2时，存在一个操作点能同时最小化存储和修复带宽。

Conclusion: 量子通信和纠缠为分布式存储系统带来了根本性的改进，突破了经典系统中的权衡限制，揭示了量子通信实现的新机制。

Abstract: This work investigates the use of quantum resources in distributed storage systems. Consider an $(n,k,d)$ distributed storage system in which a file is stored across $n$ nodes such that any $k$ nodes suffice to reconstruct the file. When a node fails, any $d$ helper nodes transmit information to a newcomer to rebuild the system. In contrast to the classical repair, where helper nodes transmit classical bits, we allow them to send classical information over quantum channels to the newcomer. The newcomer then generates its storage by performing appropriate measurements on the received quantum states. In this setting, we fully characterize the fundamental tradeoff between storage and repair bandwidth (total communication cost). Compared to classical systems, the optimal storage--bandwidth tradeoff can be significantly improved with the enhancement of quantum entanglement shared only among the surviving nodes, particularly at the minimum-storage regenerating point. Remarkably, we show that when $d \geq 2k-2$, there exists an operating point at which \textit{both storage and repair bandwidth are simultaneously minimized}. This phenomenon breaks the tradeoff in the classical setting and reveals a fundamentally new regime enabled by quantum communication.

</details>


### [22] [On Existence of Girth-8 QC-LDPC Code with Large Column Weight: Combining Mirror-sequence with Classification Modulo Ten](https://arxiv.org/abs/2601.10170)
*Guohua Zhang,Xiangya Liu,Jianhua Zhang,Yi Fang*

Main category: cs.IT

TL;DR: 本文提出了一种基于GCD框架的代数方法，构造了列重为7和8、围长为8、长度极短的QC-LDPC码，通过镜像序列和行重组技术将连续循环子阵大小的下界提高了约20%。


<details>
  <summary>Details</summary>
Motivation: QC-LDPC码在大围长情况下在信道编码、压缩感知和分布式存储系统中具有重要应用。主要挑战是如何用代数方法而非搜索方法构造出长度最短（循环子阵尺寸最小）的此类码。

Method: 在先前提出的GCD框架基础上，引入镜像序列概念并采用新的行重组方案，以代数方式构造列重为7和8、任意行重、围长为8的QC-LDPC码。

Result: 对于列重7和8的情况，连续循环子阵大小的下界相比现有基准均提高了约20%。新构造方法提供的循环子阵尺寸比现有下界小约25%。

Conclusion: 通过镜像序列和行重组等创新代数方法，成功构造了列重更高（7和8）、长度极短、围长为8的QC-LDPC码，显著改进了现有构造的性能界限。

Abstract: Quasi-cyclic (QC) LDPC codes with large girths play a crucial role in several research and application fields, including channel coding, compressed sensing and distributed storage systems. A major challenge in respect of the code construction is how to obtain such codes with the shortest possible length (or equivalently, the smallest possible circulant size) using algebraic methods instead of search methods. The greatest-common-divisor (GCD) framework we previously proposed has algebraically constructed QC-LDPC codes with column weights of 5 and 6, very short lengths, and a girth of 8. By introducing the concept of a mirror sequence and adopting a new row-regrouping scheme, QC-LDPC codes with column weights of 7 and 8, very short lengths, and a girth of 8 are proposed for arbitrary row weights in this article via an algebraic manner under the GCD framework. Thanks to these novel algebraic methods, the lower bounds (for column weights 7 and 8) on consecutive circulant sizes are both improved by asymptotically about 20%, compared with the existing benchmarks. Furthermore, these new constructions can also offer circulant sizes asymptotically about 25% smaller than the novel bounds.

</details>


### [23] [A Low-Complexity Architecture for Multi-access Coded Caching Systems with Arbitrary User-cache Access Topology](https://arxiv.org/abs/2601.10175)
*Ting Yang,Minquan Cheng,Xinping Yi,Robert Caiming Qiu,Giuseppe Caire*

Main category: cs.IT

TL;DR: 该论文提出了一种基于图神经网络的通用学习框架，用于解决任意用户-缓存访问拓扑下的多接入编码缓存问题，显著降低了计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 现有MACC模型依赖高度结构化的连接设计，无法处理任意访问拓扑。传统DSatur算法虽然性能接近理论下界，但计算复杂度随图规模增长而急剧增加，限制了实际应用。

Method: 1) 建立基于冲突图的通用建模框架，将传输设计转化为图着色问题；2) 提出基于图神经网络的学习框架，高效构建近最优编码多播传输；3) 将索引编码下界扩展到任意访问拓扑，并提出低复杂度贪心近似。

Result: 学习方案实现了接近DSatur算法和理论下界的传输负载，同时显著减少了计算时间。数值结果表明该方法在不同访问拓扑和用户数量下具有良好的泛化能力。

Conclusion: 该论文提出的学习框架为任意拓扑MACC问题提供了高效解决方案，在保持接近最优性能的同时大幅降低计算复杂度，具有实际应用价值。

Abstract: This paper studies the multi-access coded caching (MACC) problem under arbitrary user-cache access topologies, extending existing models that rely on highly structured and combinatorially designed connectivity. We consider a MACC system consisting of a single server, multiple cache nodes, and multiple user nodes. Each user can access an arbitrary subset of cache nodes to retrieve cached content. The objective is to design a general and low-complexity delivery scheme under fixed cache placement for arbitrary access topologies. We propose a universal graph-based framework for modeling the MACC delivery problem, where decoding conflicts among requested packets are captured by a conflict graph and the delivery design is reduced to a graph coloring problem. In this formulation, a lower transmission load corresponds to using fewer colors. The classical greedy coloring algorithm DSatur achieves a transmission load close to the index-coding converse bound, providing a tight benchmark, but its computational complexity becomes prohibitive for large-scale graphs. To overcome this limitation, we develop a learning-based framework using graph neural networks that efficiently constructs near-optimal coded multicast transmissions and generalizes across diverse access topologies and varying numbers of users. In addition, we extend the index-coding converse bound for uncoded cache placement to arbitrary access topologies and propose a low-complexity greedy approximation. Numerical results demonstrate that the proposed learning-based scheme achieves transmission loads close to those of DSatur and the converse bound while significantly reducing computational time.

</details>


### [24] [Error-Correcting Codes for the Sum Channel](https://arxiv.org/abs/2601.10256)
*Lyan Abboud,Eitan Yaakobi*

Main category: cs.IT

TL;DR: 提出了一种新的信道模型——和信道，用于分布式存储和DNA数据存储应用，构建了纠双删除码和纠单替换码，并证明了其冗余度的近似最优性。


<details>
  <summary>Details</summary>
Motivation: 该论文的动机源于分布式存储和DNA数据存储的实际应用需求。在这些应用中，数据通常以矩阵形式存储，需要设计能够有效纠正删除和替换错误的编码方案，以提高数据存储的可靠性和容错能力。

Method: 引入了一种新的信道模型——和信道，该模型将输入视为ℓ行二进制矩阵，输出为(ℓ+1)行矩阵，其中前ℓ行等于输入，最后一行是前ℓ行的奇偶校验行（和行）。基于此模型，构建了两种编码方案：1）纠双删除码，冗余度为2⌈log₂log₂n⌉ + O(ℓ²)；2）纠单替换码，冗余度为⌈log₂(ℓ+1)⌉。

Result: 当ℓ=2时，证明了纠双删除码的冗余度上界为⌈log₂log₂n⌉ + O(1)，表明所提方案的冗余度在因子2范围内是最优的。对于纠单替换码，证明了其冗余度与最优解相差不超过1比特。

Conclusion: 和信道模型为分布式存储和DNA数据存储提供了一种有效的编码框架。所提出的纠双删除码和纠单替换码在冗余度方面具有近似最优的性能，为实际存储系统提供了实用的错误纠正解决方案。

Abstract: We introduce the sum channel, a new channel model motivated by applications in distributed storage and DNA data storage. In the error-free case, it takes as input an $\ell$-row binary matrix and outputs an $(\ell+1)$-row matrix whose first $\ell$ rows equal the input and whose last row is their parity (sum) row. We construct a two-deletion-correcting code with redundancy $2\lceil\log_2\log_2 n\rceil + O(\ell^2)$ for $\ell$-row inputs. When $\ell=2$, we establish an upper bound of $\lceil\log_2\log_2 n\rceil + O(1)$, implying that our redundancy is optimal up to a factor of 2. We also present a code correcting a single substitution with $\lceil \log_2(\ell+1)\rceil$ redundant bits and prove that it is within one bit of optimality.

</details>


### [25] [Transmission Mask Analysis for Range-Doppler Sensing in Half-Duplex ISAC](https://arxiv.org/abs/2601.10259)
*Dikai Liu,Yifeng Xiong,Marco Lops,Fan Liu,Jianhua Zhang*

Main category: cs.IT

TL;DR: 分析半双工ISAC中MASM的周期性传输掩码，推导其闭式期望距离-多普勒响应，证明距离旁瓣的多普勒不变性，并揭示不同动态场景下的最优掩码设计


<details>
  <summary>Details</summary>
Motivation: 在半双工集成感知与通信（ISAC）系统中，需要分析掩码调制（MASM）的周期性传输掩码性能，以优化距离-多普勒响应，特别是距离旁瓣和多普勒旁瓣特性

Method: 推导周期性掩码的闭式期望距离-多普勒响应数学表达式，分析距离主瓣和旁瓣特性，研究循环差集（特别是Singer CDS）在不同动态场景下的最优性

Result: 距离旁瓣具有多普勒不变性，将距离旁瓣最优性扩展到二维设置；对于距离主瓣，周期性掩码产生稀疏多普勒旁瓣：在中等动态场景下CDS是最小最大最优的，在高度动态场景下多普勒旁瓣能量是掩码自相关的凹函数

Conclusion: 周期性掩码设计在不同动态场景下有不同的最优策略，揭示了主瓣波动与多普勒旁瓣性能之间不可避免的权衡关系

Abstract: In this paper, we analyze the periodic transmission masks for MASked Modulation (MASM) in half-duplex integrated sensing and communication (ISAC), and derive their closed-form expected range-Doppler response $\mathbb{E}\{r(k,l,ν)\}$. We show that range sidelobes ($k\neq l$) are Doppler-invariant, extending the range-sidelobe optimality to the 2-D setting. For the range mainlobe ($k=l$), periodic masking yields sparse Doppler sidelobes: Cyclic difference sets (CDSs) (in particular Singer CDSs) are minimax-optimal in a moderately dynamic regime, while in a highly dynamic regime the Doppler-sidelobe energy is a concave function of the mask autocorrelation, revealing an inevitable tradeoff with mainlobe fluctuation.

</details>


### [26] [Algebraic Properties of PAC Codes](https://arxiv.org/abs/2601.10262)
*Vlad-Florin Dragoi,Mohammad Rowshan*

Main category: cs.IT

TL;DR: 本文分析了极化调整卷积码，定义了广义多项式极化码，推导了其结构性质如对偶性、最小距离，并得出了最小重量码字数等结构限制。


<details>
  <summary>Details</summary>
Motivation: 研究极化码和Reed-Muller码的代数表示，扩展PAC码和反向PAC码的理论框架，建立更广泛的广义多项式极化码类。

Method: 使用极化码和Reed-Muller码的代数表示方法，定义广义多项式极化码，分析其结构性质，推导对偶性、最小距离等数学特性。

Result: 成功定义了包含PAC码和反向PAC码的广义多项式极化码类，推导了其对偶性、最小距离等结构性质，并得出了最小重量码字数和单项式子码维数等结构限制。

Conclusion: 广义多项式极化码为极化调整卷积码提供了统一的理论框架，其结构性质分析有助于理解这类码的性能特征和设计原则。

Abstract: We analyze polarization-adjusted convolutional codes using the algebraic representation of polar and Reed-Muller codes. We define a large class of codes, called generalized polynomial polar codes which include PAC codes and Reverse PAC codes. We derive structural properties of generalized polynomial polar codes, such as duality, minimum distance. We also deduce some structural limits in terms of number of minimum weight codewords, and dimension of monomial sub-code.

</details>


### [27] [On the Capacity of Noisy Frequency-based Channels](https://arxiv.org/abs/2601.10329)
*Yuval Gerzon,Ilan Shomorony,Nir Weinberger*

Main category: cs.IT

TL;DR: 该论文研究了基于频率的信道在噪声下的容量，针对DNA数据存储中的短分子机制，其中信息通过项目类型的频率而非顺序编码。信道输出是通过随机采样项目形成的直方图，随后进行有噪声的项目识别。


<details>
  <summary>Details</summary>
Motivation: 研究动机源于DNA数据存储中的短分子机制，其中信息通过项目类型的频率而非顺序编码。虽然无噪声频率信道的容量已有研究，但识别噪声的影响尚未完全表征，需要建立噪声频率信道的容量界限。

Method: 方法包括：1）通过随机退化和数据处理不等式推导信道容量的逆界；2）基于多项式采样过程的泊松化建立可达界，分析由此产生的具有符号间干扰的向量泊松信道；3）改进用于Feinstein界的信息密度集中不等式，并显式表征识别噪声导致的互信息加性损失。

Result: 建立了噪声频率信道的容量界限：逆界通过随机退化和数据处理不等式获得，可达界通过泊松化方法和向量泊松信道分析获得。显式表征了识别噪声导致的互信息加性损失，并将结果应用于DNA存储信道，量化了可靠存储比特总数缩放中的损失。

Conclusion: 该研究为噪声频率信道提供了容量界限分析框架，特别适用于DNA数据存储的短分子机制。通过显式表征识别噪声对容量的影响，为优化DNA存储系统设计提供了理论依据，并量化了噪声导致的存储容量损失。

Abstract: We investigate the capacity of noisy frequency-based channels, motivated by DNA data storage in the short-molecule regime, where information is encoded in the frequency of items types rather than their order. The channel output is a histogram formed by random sampling of items, followed by noisy item identification. While the capacity of the noiseless frequency-based channel has been previously addressed, the effect of identification noise has not been fully characterized. We present a converse bound on the channel capacity that follows from stochastic degradation and the data processing inequality. We then establish an achievable bound, which is based on a Poissonization of the multinomial sampling process, and an analysis of the resulting vector Poisson channel with inter-symbol interference. This analysis refines concentration inequalities for the information density used in Feinstein bound, and explicitly characterizes an additive loss in the mutual information due to identification noise. We apply our results to a DNA storage channel in the short-molecule regime, and quantify the resulting loss in the scaling of the total number of reliably stored bits.

</details>


### [28] [Convertible Codes for Data and Device Heterogeneity](https://arxiv.org/abs/2601.10341)
*Anina Gruica,Benjamin Jany,Stanislav Kruglik*

Main category: cs.IT

TL;DR: 本文研究分布式存储系统中的可转换编码，通过Reed-Muller码同时处理数据异构性和设备异构性，推导了线性码转换的读写成本下界，并构建了首个结合两种异构性的显式转换方案。


<details>
  <summary>Details</summary>
Motivation: 分布式存储系统面临两大挑战：数据异构性（由非均匀访问需求引起）和设备异构性（由节点可靠性随时间变化引起）。现有研究通常分别处理这两个问题，缺乏同时解决两种异构性的方案。

Method: 研究可转换编码，在合并机制下以最小成本实现编码转换。首先推导线性码转换的读写成本一般下界，然后专注于Reed-Muller码，构建显式的转换过程，首次将两种异构性结合。

Result: 获得了适用于任意线性码的读写成本下界，并针对Reed-Muller码构建了具体的转换方案，首次实现了同时处理数据异构性和设备异构性的分布式数据存储方案。

Conclusion: 可转换编码为解决分布式存储中的异构性问题提供了有效框架，Reed-Muller码的转换方案首次将数据异构性和设备异构性结合，为实际系统设计提供了理论基础。

Abstract: Distributed storage systems must handle both data heterogeneity, arising from non-uniform access demands, and device heterogeneity, caused by time-varying node reliability. In this paper, we study convertible codes, which enable the transformation of one code into another with minimum cost in the merge regime, addressing the latter. We derive general lower bounds on the read and write costs of linear code conversion, applicable to arbitrary linear codes. We then focus on Reed-Muller codes, which efficiently handle data heterogeneity, addressing the former issue, and construct explicit conversion procedures that, for the first time, combine both forms of heterogeneity for distributed data storage.

</details>


### [29] [A New Construction Structure on MISO Coded Caching with Linear Subpacketization: Half-Sum Disjoint Packing](https://arxiv.org/abs/2601.10353)
*Bowen Zheng,Minquan Cheng,Kai Wan,Giuseppe Caire*

Main category: cs.IT

TL;DR: 提出基于L-half-sum disjoint packing (HSDP)的MISO编码缓存方案，实现线性子分组(F=K)，显著降低子分组复杂度，仅轻微牺牲和自由度性能。


<details>
  <summary>Details</summary>
Motivation: 现有MISO编码缓存方案在实现最大和自由度时，子分组数随用户数指数增长，导致实际实现困难。需要设计低子分组复杂度的方案。

Method: 基于拉丁方框架，将F=K的MAPDA设计转化为L-HSDP组合结构构造。L-HSDP是NHSDP的推广，用于生成共享链路编码缓存方案。

Result: 通过构造L-HSDP获得新方案，理论数值分析表明：相比指数子分组方案显著降低复杂度，仅轻微牺牲和自由度；相比线性子分组方案同时获得更高和自由度和更低子分组。

Conclusion: 提出的L-HSDP方案在子分组复杂度和和自由度之间取得良好平衡，为MISO编码缓存系统提供了实用的低复杂度解决方案。

Abstract: In the $(L,K,M,N)$ cache-aided multiple-input single-output (MISO) broadcast channel (BC) system, the server is equipped with $L$ antennas and communicates with $K$ single-antenna users through a wireless broadcast channel where the server has a library containing $N$ files, and each user is equipped with a cache of size $M$ files. Under the constraints of uncoded placement and one-shot linear delivery strategies, many schemes achieve the maximum sum Degree-of-Freedom (sum-DoF). However, for general parameters $L$, $M$, and $N$, their subpacketizations increase exponentially with the number of users. We aim to design a MISO coded caching scheme that achieves a large sum-DoF with low subpacketization $F$. An interesting combinatorial structure, called the multiple-antenna placement delivery array (MAPDA), can be used to generate MISO coded caching schemes under these two strategies; moreover, all existing schemes with these strategies can be represented by the corresponding MAPDAs. In this paper, we study the case with $F=K$ (i.e., $F$ grows linearly with $K$) by investigating MAPDAs. Specifically, based on the framework of Latin squares, we transform the design of MAPDA with $F=K$ into the construction of a combinatorial structure called the $L$-half-sum disjoint packing (HSDP). It is worth noting that a $1$-HSDP is exactly the concept of NHSDP, which is used to generate the shared-link coded caching scheme with $F=K$. By constructing $L$-HSDPs, we obtain a class of new schemes with $F=K$. Finally, theoretical and numerical analyses show that our $L$-HSDP schemes significantly reduce subpacketization compared to existing schemes with exponential subpacketization, while only slightly sacrificing sum-DoF, and achieve both a higher sum-DoF and lower subpacketization than the existing schemes with linear subpacketization.

</details>


### [30] [Generalized Weight Structure of Polar Codes: Selected Template Polynomials](https://arxiv.org/abs/2601.10362)
*Mohammad Rowshan,Vlad-Florin Dragoi*

Main category: cs.IT

TL;DR: 本文提出了一种计算极化码汉明权重的通用框架，通过将极化码视为递减单项式码，利用LTA群作用，推导出权重谱的闭式表达式和多重性公式。


<details>
  <summary>Details</summary>
Motivation: 极化码可以被视为递减单项式码，具有由下三角仿射(LTA)群支配的丰富代数结构。然而，需要一种系统的方法来计算由单项式和生成的码字的汉明权重，并理解其权重谱的结构。

Method: 开发了一个通用框架来计算由单项式和生成的码字的汉明权重，将这些权重表示为规范的二元形式，并推导出生成低和中权重谱的关键结构模板（不相交和、嵌套块、互补翻转）的闭式表达式。结合LTA群作用，得到明确的多重性公式。

Result: 获得了统一的代数方法来表征和枚举码字，能够计算极化码的权重谱，特别是低和中权重部分，并提供了明确的闭式表达式。

Conclusion: 该方法为分析极化码的权重结构提供了强大的代数工具，通过LTA群作用和结构模板的组合，实现了对码字权重的系统计算和枚举，为极化码的理论分析开辟了新途径。

Abstract: Polar codes can be viewed as decreasing monomial codes, revealing a rich algebraic structure governed by the lower-triangular affine (LTA) group. We develop a general framework to compute the Hamming weight of codewords generated by sums of monomials, express these weights in a canonical dyadic form, and derive closed expressions for key structural templates (disjoint sums, nested blocks, complementary flips) that generate the low and intermediate weight spectrum. Combining these templates with the LTA group action, we obtain explicit multiplicity formulas, yielding a unified algebraic method to characterize and enumerate codewords.

</details>


### [31] [A Hybrid Reliability--Weight Framework for Construction of Polar Codes](https://arxiv.org/abs/2601.10376)
*Mohammad Rowshan,Vlad-Florin Dragoi*

Main category: cs.IT

TL;DR: 提出一种混合（可靠性-权重）比特信道排序方法，结合可靠性排序和最小权重码字贡献，优化短/中等长度极化码的权重谱


<details>
  <summary>Details</summary>
Motivation: 传统极化码构造基于可靠性排序，能保证容量可达但短/中等长度下权重谱较差。需要结合代数结果中比特信道对最小/近最小权重码字贡献的闭式表达，改进构造方法

Method: 定义混合比特信道排序，每个比特的成本函数包含基于最小权重码字轨道枚举的距离项和Bhattacharyya型因子。证明该构造在递减单项式码类中最小化截断SC/ML联合界代理

Result: 混合设计作为可靠性构造的局部扰动，其渐近影响随码长趋于无穷而消失。数值结果显示在BPSK-AWGN信道上，混合构造在最小距离、重数和联合界近似方面优于纯可靠性构造

Conclusion: 混合可靠性-权重比特信道排序能有效平衡极化码的可靠性和权重谱特性，在短/中等长度下提供更好的性能折衷，同时保持渐近容量可达性

Abstract: Polar codes are usually constructed by ranking synthetic bit-channels according to reliability, which guarantees capacity-achieving behavior but can yield poor low-weight spectra at short and moderate lengths. Recent algebraic results express the contribution of individual bit-channels to the multiplicities of minimum and near-minimum weight codewords in closed form. In this work we combine these insights into a mixed (reliability--weight) bit-channel ordering. We define a per-bit cost whose distance term is derived from orbit enumeration of minimum-weight codewords and scaled by a Bhattacharyya-type factor, and show that the resulting mixed construction minimises a truncated SC/ML union-bound surrogate within a class of decreasing monomial codes. We relate the mixed metric to error events in SCL decoding via a pruning/ML decomposition, and prove that mixed designs act as local perturbations of reliability-based constructions whose asymptotic impact vanishes as code-length approaches infinity. Numerical results for short and moderate lengths on BPSK-AWGN, implemented via Gaussian approximation and closed-form weight contributions, illustrate the trade-off between pure reliability-based and mixed constructions in terms of minimum distance, multiplicity, and union-bound approximations. All proofs are deferred to the appendices.

</details>


### [32] [Multiaccess Coded Caching with Heterogeneous Retrieval Costs](https://arxiv.org/abs/2601.10394)
*Wenbo Huang,Minquan Cheng,Kai Wan,Xiaojun Li,Robert Caiming Qiu,Giuseppe Caire*

Main category: cs.IT

TL;DR: 提出了一种基于叠加编码的成本感知多接入编码缓存框架，通过优化缓存放置来最小化包含缓存访问成本和广播成本的总系统成本。


<details>
  <summary>Details</summary>
Motivation: 现有MACC系统假设用户从连接的缓存节点检索内容没有通信成本，但实际中不同缓存节点的访问成本不同，服务器传输内容也有成本，需要设计成本感知的系统来最小化总成本。

Method: 提出基于叠加编码的新型编码缓存框架，将Cheng等人的MACC方案分层；推导成本感知优化问题来优化缓存放置；利用最优解的稀疏特性设计复杂度降低的结构感知算法。

Result: 仿真结果表明，在异构检索成本场景下，提出的方案始终优于Cheng等人的方案。

Conclusion: 提出的成本感知MACC框架能有效降低包含缓存访问和广播成本的总系统成本，特别是在异构成本环境中表现优异。

Abstract: The multiaccess coded caching (MACC) system, as formulated by Hachem {\it et al.}, consists of a central server with a library of $N$ files, connected to $K$ cache-less users via an error-free shared link, and $K$ cache nodes, each equipped with cache memory of size $M$ files. Each user can access $L$ neighboring cache nodes under a cyclic wrap-around topology. Most existing studies operate under the strong assumption that users can retrieve content from their connected cache nodes at no communication cost. In practice, each user retrieves content from its $L$ different connected cache nodes at varying costs. Additionally, the server also incurs certain costs to transmit the content to the users. In this paper, we focus on a cost-aware MACC system and aim to minimize the total system cost, which includes cache-access costs and broadcast costs. Firstly, we propose a novel coded caching framework based on superposition coding, where the MACC schemes of Cheng \textit{et al.} are layered. Then, a cost-aware optimization problem is derived that optimizes cache placement and minimizes system cost. By identifying a sparsity property of the optimal solution, we propose a structure-aware algorithm with reduced complexity. Simulation results demonstrate that our proposed scheme consistently outperforms the scheme of Cheng {\it et al.} in scenarios with heterogeneous retrieval costs.

</details>


### [33] [Placement Delivery Array for Cache-Aided MIMO Systems](https://arxiv.org/abs/2601.10422)
*Yifei Huang,Kai Wan,Minquan Cheng,Jinyan Wang,Giuseppe Caire*

Main category: cs.IT

TL;DR: 提出MIMO-PDA统一结构，在缓存辅助MIMO网络中同时实现最大和自由度与低子分组化，构造两种方案分别实现线性与指数级子分组化


<details>
  <summary>Details</summary>
Motivation: 在缓存辅助MIMO网络中，现有方案难以同时实现最大和自由度与低子分组化，需要设计能平衡这两个关键性能指标的编码缓存方案

Method: 引入MIMO-PDA统一组合结构描述无编码放置和单次迫零传输，分析其组合性质推导和自由度上界，构造两种MIMO-PDA方案：第一种在严格参数约束下实现线性子分组化，第二种在更宽松约束下实现有序指数级子分组化

Result: 推导出和自由度上界min{KG, Gt+G⌈L/G⌉}，与现有最优结果一致；第二种构造相比现有方案指数级降低子分组化同时保持最大和自由度

Conclusion: MIMO-PDA框架有效平衡了和自由度与子分组化的权衡，提出的两种构造方案在不同参数约束下均能实现最优性能，特别是第二种方案显著降低了子分组化复杂度

Abstract: We consider a $(G,L,K,M,N)$ cache-aided multiple-input multiple-output (MIMO) network, where a server equipped with $L$ antennas and a library of $N$ equal-size files communicates with $K$ users, each equipped with $G$ antennas and a cache of size $M$ files, over a wireless interference channel. Each user requests an arbitrary file from the library. The goal is to design coded caching schemes that simultaneously achieve the maximum sum degrees of freedom (sum-DoF) and low subpacketization. In this paper, we first introduce a unified combinatorial structure, termed the MIMO placement delivery array (MIMO-PDA), which characterizes uncoded placement and one-shot zero-forcing delivery. By analyzing the combinatorial properties of MIMO-PDAs, we derive a sum-DoF upper bound of $\min\{KG, Gt+G\lceil L/G \rceil\}$, where $t=KM/N$, which coincides with the optimal DoF characterization in prior work by Tehrani \emph{et al.}. Based on this upper bound, we present two novel constructions of MIMO-PDAs that achieve the maximum sum-DoF. The first construction achieves linear subpacketization under stringent parameter constraints, while the second achieves ordered exponential subpacketization under substantially milder constraints. Theoretical analysis and numerical comparisons demonstrate that the second construction exponentially reduces subpacketization compared to existing schemes while preserving the maximum sum-DoF.

</details>


### [34] [Energy-Efficient Probabilistic Semantic Communication Over Visible Light Networks With Rate Splitting](https://arxiv.org/abs/2601.10452)
*Zhouxiang Zhao,Zhaohui Yang,Mingzhe Chen,Chen Zhu,Xin Tong,Zhaoyang Zhang*

Main category: cs.IT

TL;DR: 该论文研究了资源受限的可见光通信概率语义通信系统中的能效最大化问题，通过联合优化波束成形、直流偏置、公共速率分配和语义压缩比，提出了一种基于SCA和Dinkelbach方法的交替优化算法。


<details>
  <summary>Details</summary>
Motivation: 可见光通信作为未来无线通信的关键技术，与传统射频系统相比具有独特的物理层优势，但其与语义通信等高层技术的结合仍待探索。在资源受限的VLC概率语义通信系统中，需要解决能效最大化问题。

Method: 采用概率图表示知识库，使用速率分割多址接入同时传输知识和信息数据。提出基于连续凸近似和Dinkelbach方法的交替优化算法，联合优化发射波束成形、直流偏置、公共速率分配和语义压缩比。

Result: 仿真结果表明所提方法的有效性，能够显著提升VLC概率语义通信系统的能效。

Conclusion: 该研究为VLC与语义通信的融合提供了有效的能效优化方案，通过联合优化通信和计算资源，解决了资源受限环境下的能效最大化问题。

Abstract: Visible light communication (VLC) is emerging as a key technology for future wireless communication systems due to its unique physical-layer advantages over traditional radio-frequency (RF)-based systems. However, its integration with higher-layer techniques, such as semantic communication, remains underexplored. This paper investigates the energy efficiency maximization problem in a resource-constrained VLC-based probabilistic semantic communication (PSCom) system. In the considered model, light-emitting diode (LED) transmitters perform semantic compression to reduce data size, which incurs additional computation overhead. The compressed semantic information is transmitted to the users for semantic inference using a shared knowledge base that requires periodic updates to ensure synchronization. In the PSCom system, the knowledge base is represented by probabilistic graphs. To enable simultaneous transmission of both knowledge and information data, rate splitting multiple access (RSMA) is employed. The optimization problem focuses on maximizing energy efficiency by jointly optimizing transmit beamforming, direct current (DC) bias, common rate allocation, and semantic compression ratio, while accounting for both communication and computation costs. To solve this problem, an alternating optimization algorithm based on successive convex approximation (SCA) and Dinkelbach method is developed. Simulation results demonstrate the effectiveness of the proposed approach.

</details>


### [35] [Joint Source-Channel Coding for ISAC: Distortion Tradeoffs and Separation Theorems](https://arxiv.org/abs/2601.10470)
*Gefei Peng,Youlong Wu*

Main category: cs.IT

TL;DR: 本文研究了集成感知与通信（ISAC）系统中联合信源信道编码（JSCC）框架的性能权衡，证明了分离信源信道编码在该场景下可以达到联合最优性。


<details>
  <summary>Details</summary>
Motivation: ISAC系统能够同时实现高效通信和环境感知，但需要量化感知与通信之间的性能权衡关系。本文旨在从信息论角度建立这种权衡关系。

Method: 采用联合信源信道编码（JSCC）框架，包含带信道状态估计器的发射机、联合信源信道编码器、状态相关无记忆信道，以及带联合信源信道解码器的接收机。

Result: 从信息论角度建立了信道容量、通信和感知过程中的失真以及估计成本之间的权衡关系，证明了分离信源信道编码在该设置下可以达到联合最优性，并通过二进制设置的示例验证了理论结果。

Conclusion: 在ISAC系统的JSCC框架中，分离信源信道编码能够达到联合最优性，为ISAC系统的性能权衡提供了理论依据。

Abstract: Integrated Sensing and Communication (ISAC) systems have garnered significant attention due to their capability to simultaneously achieve efficient communication and environmental sensing. A core objective in this field is characterizing the performance tradeoff between sensing and communication. In this paper, we consider a joint source-channel coding (JSCC) framework for the ISAC system that consists of a transmitter with a channel state estimator and a joint source-channel encoder, a state-dependent memoryless channel, and a receiver with a joint source-channel decoder. From an information-theoretic perspective, we establish the tradeoff relationships among channel capacity, distortions in both communication and sensing processes, and the estimation cost. We prove that the separate source and channel coding can achieve joint optimality in this setting. An illustrative example of a binary setting is also provided to validate our theoretical results.

</details>


### [36] [A Construction Framework of Coded Caching Scheme for Multi-Access MIMO Systems via Knapsack Problem](https://arxiv.org/abs/2601.10484)
*Siying Luo,Youlong Wu,Mingming Zhang,Minquan Cheng,Dianhua Wu*

Main category: cs.IT

TL;DR: 本文研究具有组合拓扑的多接入多输入单输出网络中的编码缓存问题，提出基于0-1背包问题的多天线放置交付阵列设计方法，在提高和自由度同时降低子分组复杂度。


<details>
  <summary>Details</summary>
Motivation: 现有的编码缓存方案在组合拓扑的多接入MISO网络中难以同时实现高和自由度与低子分组复杂度，需要一种能平衡这两个关键性能指标的新方案。

Method: 将多天线放置交付阵列设计建模为0-1背包问题来最大化可实现的自由度，将复杂的组合缓存结构转化为可处理的优化框架，从而得到高效的缓存放置和灵活的交付策略。

Result: 在组合拓扑网络中，所提方案比现有方案获得更高的和自由度；在相同缓存大小约束下，子分组水平与现有线性子分组方案相当；在特定系统条件下，达到理论最大和自由度min{L+KM/N, K}并进一步降低子分组复杂度。

Conclusion: 提出的基于优化框架的编码缓存方案能有效平衡和自由度与子分组复杂度，在组合拓扑多接入MISO网络中优于现有方案，并为特定组合结构提供进一步优化的构造方法。

Abstract: This paper investigates the coded caching problem in a multi-access multiple-input single-output (MAMISO) network with the combinatorial topology. The considered system consists of a server containing $N$ files, $Λ$ cache nodes, and $K$ cache-less users, where each user can access a unique subset of $r$ cache nodes. The server is equipped with $L$ transmit antennas. Our objective is to design a caching scheme that simultaneously achieves a high sum Degree of Freedom (sum-DoF) and low subpacketization complexity. To address this challenge, we formulate the design of multi-antenna placement delivery arrays (MAPDA) as a $0$--$1$ knapsack problem to maximize the achievable DoF, thereby transforming the complex combinatorial caching structure into a tractable optimization framework that yields efficient cache placement and flexible delivery strategies. Theoretical and numerical analyses demonstrate that: for networks with combinatorial topologies, the proposed scheme achieves a higher sum-DoF than existing schemes. Under identical cache size constraints, the subpacketization level remains comparable to existing linear subpacketization schemes. Moreover, under specific system conditions, the proposed scheme attains the theoretical maximum sum-DoF of $\min\{L+KM/N, K\}$ while achieving further reductions subpacketization. For particular combinatorial structures, we further derive optimized constructions that achieve even higher sum-DoF with lower subpacketization. ```

</details>


### [37] [Coded Caching for Combinatorial Multi-Access Hotplug Networks from $t$-Designs](https://arxiv.org/abs/2601.10503)
*Dhruv Pratap Singh,Anjana A. Mahesh,B. Sundar Rajan*

Main category: cs.IT

TL;DR: 提出了一种基于t设计的组合多接入热插拔编码缓存方案，在特定内存区间优于现有方案


<details>
  <summary>Details</summary>
Motivation: 现有热插拔编码缓存模型只允许用户访问单个缓存，而实际网络中用户可能访问多个缓存，且交付阶段只有部分缓存在线，需要更通用的模型

Method: 将热插拔放置交付阵列框架推广到组合多接入场景，提出基于t设计的编码缓存方案，通过适当参数选择消除冗余组播传输

Result: 方案实现了灵活子分组化下的速率-内存权衡族，数值比较显示在特定内存区间优于现有热插拔编码缓存方案

Conclusion: 提出的t设计方案为组合多接入热插拔网络提供了有效的编码缓存解决方案，在性能和灵活性方面具有优势

Abstract: We study hotplug coded caching in combinatorial multi-access networks, which generalizes existing hotplug coded caching models by allowing users to access multiple caches, while only a subset of caches is online during the delivery phase. We first generalize the Hotplug Placement Delivery Array (HpPDA) framework to the combinatorial multi-access setting. Based on this generalized framework, we propose a t-design-based coded caching scheme for combinatorial multi-access networks. We characterize a class of design parameters under which every active user has access to a sufficient number of coded subfiles to decode its requested file, and show that appropriate parameter choices allow for the elimination of redundant multicast transmissions. As a result, the proposed scheme achieves a family of rate memory trade offs with flexible subpacketization. We present numerical comparisons illustrating that the proposed t-scheme outperforms existing hotplug coded caching schemes in certain memory regimes.

</details>


### [38] [A New Construction Structure on Coded Caching with Linear Subpacketization: Non-Half-Sum Latin Rectangle](https://arxiv.org/abs/2601.10505)
*Yongcheng Yang,Minquan Cheng,Kai Wan,Giuseppe Caire*

Main category: cs.IT

TL;DR: 本文提出了一种新的组合结构NHSLR，将线性编码缓存的子分组化从F=K扩展到F=O(K)，实现了线性可扩展的子分组化，同时进一步降低了传输负载。


<details>
  <summary>Details</summary>
Motivation: 编码缓存是缓解网络拥塞的有效方法，但现有方案要么需要指数级或多项式级的子分组化，要么线性子分组化方案导致传输负载过高。Cheng等人提出的NHSDP框架虽然实现了F=K的线性子分组化，但仍需进一步降低传输负载。

Method: 提出了一种新的组合结构——非半和拉丁矩形(NHSLR)，扩展了线性编码缓存方案的框架，从F=K扩展到更广泛的F=O(K)场景。通过构造NHSLR，获得了一类新的编码缓存方案。

Result: 新方案实现了线性可扩展的子分组化，同时进一步降低了传输负载。理论分析和数值分析表明，该方案不仅比现有线性子分组化方案传输负载更低，而且接近某些指数子分组化方案的性能。

Conclusion: NHSLR结构为编码缓存方案设计提供了新思路，在保持线性子分组化的同时显著降低了传输负载，平衡了子分组化和传输负载这两个关键设计挑战。

Abstract: Coded caching is recognized as an effective method for alleviating network congestion during peak periods by leveraging local caching and coded multicasting gains. The key challenge in designing coded caching schemes lies in simultaneously achieving low subpacketization and low transmission load. Most existing schemes require exponential or polynomial subpacketization levels, while some linear subpacketization schemes often result in excessive transmission load. Recently, Cheng et al. proposed a construction framework for linear coded caching schemes called Non-Half-Sum Disjoint Packing (NHSDP), where the subpacketization equals the number of users $K$. This paper introduces a novel combinatorial structure, termed the Non-Half-Sum Latin Rectangle (NHSLR), which extends the framework of linear coded caching schemes from $F=K$ (i.e., the construction via NHSDP) to a broader scenario with $F=\mathcal{O}(K)$. By constructing NHSLR, we have obtained a new class of coded caching schemes that achieves linearly scalable subpacketization, while further reducing the transmission load compared with the NHSDP scheme. Theoretical and numerical analyses demonstrate that the proposed schemes not only achieves lower transmission load than existing linear subpacketization schemes but also approaches the performance of certain exponential subpacketization schemes.

</details>


### [39] [A New Construction Structure on Multi-access Coded Caching with Linear Subpacketization: Cyclic Multi-Access Non-Half-Sum Disjoint Packing](https://arxiv.org/abs/2601.10510)
*Mengyuan Li,Minquan Cheng,Kai Wan,Giuseppe Caire*

Main category: cs.IT

TL;DR: 提出一种基于CMA-NHSDP结构的多接入编码缓存方案，在保持线性子分组化(F=K)的同时实现较低的传输负载


<details>
  <summary>Details</summary>
Motivation: 现有多接入编码缓存方案存在矛盾：指数级子分组化方案传输性能好但复杂度高，线性/多项式子分组化方案复杂度低但传输负载高。需要设计在保持线性子分组化的同时降低传输负载的方案。

Method: 将NHSDP（非半和不相交包装）结构扩展到多接入系统，提出CMA-NHSDP（循环多接入非半和不相交包装）组合结构，基于此构造新的多接入编码缓存方案。

Result: 理论分析和数值比较表明，新方案在线性子分组化下比现有线性方案传输负载更低，在某些情况下甚至比指数子分组化方案的传输负载还低。

Conclusion: CMA-NHSDP结构成功解决了多接入编码缓存中线性子分组化与低传输负载之间的矛盾，为实际系统部署提供了有前景的解决方案。

Abstract: We consider the $(K,L,M,N)$ multi-access coded caching system introduced by Hachem et al., which consists of a central server with $N$ files and $K$ cache nodes, each of memory size $M$, where each user can access $L$ cache nodes in a cyclic wrap-around fashion. At present, several existing schemes achieve competitive transmission performance, but their subpacketization levels grow exponentially with the number of users. In contrast, schemes with linear or polynomial subpacketization always incur higher transmission loads. We aim to design a multi-access coded caching scheme with linear subpacketization $F$ while maintaining low transmission load. Recently, Cheng et al. proposed a construction framework for coded caching schemes with linear subpacketization (i.e., $F=K$) called non-half-sum disjoint packing (NHSDP). Inspired by this structure, we introduce a novel combinatorial structure named cyclic multi-access non-half-sum disjoint packing (CMA-NHSDP) by extending NHSDP to MACC system. By constructing CMA-NHSDP, we obtain a new class of multi-access coded caching schemes. Theoretical and numerical analyses show that our scheme achieves lower transmission loads than some existing schemes with linear subpacketization. Moreover, the proposed schemes achieves lower transmission load compared to existing schemes with exponential subpacketization in some case.

</details>


### [40] [On the suboptimality of linear codes for binary distributed hypothesis testing](https://arxiv.org/abs/2601.10526)
*Adway Girish,Robinson D. H. Cung,Emre Telatar*

Main category: cs.IT

TL;DR: 研究二进制分布式假设检验问题，两个代理观察相关二进制向量并以相同速率向中央决策者发送压缩信息。分析线性压缩方案，发现截断在某些情况下是最佳线性方案。


<details>
  <summary>Details</summary>
Motivation: 研究分布式假设检验中的信息压缩问题，特别是在两个代理观察相关数据并以有限速率通信给中央决策者的场景下，探索线性压缩方案的性能极限。

Method: 研究线性压缩方案，特别关注截断方法。分析两种具体场景：1) 测试相同幅度但符号相反的相关性；2) 测试独立性或反对独立性。通过理论分析和数值证据支持结论。

Result: 发现截断在两种情况下是最佳线性方案：测试相同幅度但符号相反的相关性，以及测试独立性或反对独立性。数值证据支持截断对于测试任何符号相反的相关性都是最佳线性编码的猜想。对于测试反对独立性，经典随机编码指数显示截断（以及任何线性编码）严格次优。

Conclusion: 线性压缩方案在特定假设检验场景中具有优势，截断在某些情况下是最佳线性方案。然而，对于测试反对独立性，线性编码存在性能限制，随机编码方案更优。

Abstract: We study a binary distributed hypothesis testing problem where two agents observe correlated binary vectors and communicate compressed information at the same rate to a central decision maker. In particular, we study linear compression schemes and show that simple truncation is the best linear scheme in two cases: (1) testing opposite signs of the same magnitude of correlation, and (2) testing for or against independence. We conjecture, supported by numerical evidence, that truncation is the best linear code for testing any correlations of opposite signs. Further, for testing against independence, we also compute classical random coding exponents and show that truncation, and consequently any linear code, is strictly suboptimal.

</details>


### [41] [Network Integrated Sensing and Communication](https://arxiv.org/abs/2601.10538)
*Edward Andrews,Lawrence Ong,Duy T. Ngo,Yao Liu,Min Li*

Main category: cs.IT

TL;DR: 该论文研究了网络级ISAC（集成感知与通信）系统，分析了感知覆盖与通信路由之间的基本权衡关系，为6G异构网络设计提供关键见解。


<details>
  <summary>Details</summary>
Motivation: 现有ISAC研究主要集中在链路级设计，但大规模部署需要理解网络级性能。本文旨在研究网络级ISAC模型中感知覆盖与通信路由之间的基本权衡关系。

Method: 提出一个新颖的优化框架，捕捉多节点路由和感知覆盖之间的相互作用。针对一维路径网络提供完整的感知-吞吐量区域解析表征，并扩展到一般网络拓扑，建立感知-吞吐量帕累托边界的分段线性特性。

Result: 对于一维路径网络，提供了完整的感知-吞吐量区域解析表征。对于一般网络拓扑，证明了感知-吞吐量帕累托边界是分段线性的，并为每个分段提供了物理解释。

Conclusion: 研究揭示了感知覆盖与通信路由之间的基本权衡关系，为未来6G异构网络设计提供了关键见解，支持网络级ISAC系统的优化部署。

Abstract: Integrated sensing and communication (ISAC) is a cornerstone technology for 6G networks, offering unified support for high-rate communication and high-accuracy sensing. While existing literature extensively covers link-level designs, the transition toward large-scale deployment necessitates a fundamental understanding of network-level performance. This paper investigates a network ISAC model where a source node communicates with a destination via a relay network, while intermediate nodes concurrently perform cooperative sensing over specific spatial regions. We formulate a novel optimization framework that captures the interplay between multi-node routing and sensing coverage. For a one-dimensional path network, we provide an analytical characterization of the complete sensing-throughput region. Extending this to general network topologies, we establish that the sensing-throughput Pareto boundary is piecewise linear and provide physical interpretations for each segment. Our results reveal the fundamental trade-offs between sensing coverage and communication routing, offering key insights for the design of future 6G heterogeneous networks.

</details>


### [42] [Error-Correcting Codes for Two Bursts of t1-Deletion-t2-Insertion with Low Computational Complexity](https://arxiv.org/abs/2601.10540)
*Yajuan Liu,Tolga M. Duman*

Main category: cs.IT

TL;DR: 该论文研究了能纠正多个突发(t₁,t₂)-DI错误的纠错码，建立了不同错误类型的等价关系，推导了码大小的上下界，并提出了低复杂度构造方法。


<details>
  <summary>Details</summary>
Motivation: 在DNA数据存储和文档同步等实际场景中，经常出现同时包含插入、删除和替换的突发错误，这促使需要开发能够纠正此类错误的信道编码。

Method: 1) 建立三种错误类型的等价关系；2) 推导两个突发(t₁,t₂)-DI错误码的码大小上下界；3) 提出两个突发(t₁,t₂)-DI错误码的构造方法。

Result: 证明了三种错误类型的等价性，获得了码大小的理论界限，提出的构造方法相比传统综合征压缩技术显著降低了计算复杂度。

Conclusion: 该研究为处理多个突发(t₁,t₂)-DI错误提供了理论基础和实用构造方法，在DNA数据存储和文档同步等应用中具有重要价值。

Abstract: Burst errors involving simultaneous insertions, deletions, and substitutions occur in practical scenarios, including DNA data storage and document synchronization, motivating developments of channel codes that can correct such errors. In this paper, we address the problem of constructing error-correcting codes (ECCs) capable of handling multiple bursts of $t_1$-deletion-$t_2$-insertion ($(t_1,t_2)$-DI) errors, where each burst consists of $t_1$ deletions followed by $t_2$ insertions in a binary sequence. We make three key contributions: Firstly, we establish the fundamental equivalence of (1) two bursts of $(t_1,t_2)$-DI ECCs, (2) two bursts of $(t_2,t_1)$-DI ECCs, and (3) one burst each of $(t_1,t_2)$-DI and $(t_2,t_1)$-DI ECCs. Then, we derive lower and upper bounds on the code size of two bursts of $(t_1,t_2)$-DI ECCs, which can naturally be extended to the case of multiple bursts. Finally, we present constructions of two bursts of $(t_1,t_2)$-DI ECCs. Compared to the codes obtained by the syndrome compression technique, the resulting codes achieve significantly lower computational complexity.

</details>


### [43] [Sparse Signal Recovery from Random Measurements](https://arxiv.org/abs/2601.10569)
*Siu-Wing Cheng,Man Ting Wong*

Main category: cs.IT

TL;DR: 提出一种无需优化或解线性系统的简单方法，仅需Θ(log n)个随机测量矩阵即可从压缩感知测量中恢复稀疏信号


<details>
  <summary>Details</summary>
Motivation: 传统压缩感知方法需要解决优化问题或线性系统，计算复杂度高。本文旨在开发一种更简单、更高效的方法来恢复稀疏信号，避免复杂的优化过程。

Method: 使用Θ(log n)个随机测量矩阵进行压缩感知测量，通过简单的算法而非优化问题来恢复信号。方法时间复杂度为O(kn log n)，其中k = Θ(s log n)，s是信号的非零坐标数。还扩展了该方法用于确定信号的支持集。

Result: 方法在二进制信号上进行了实验验证，并与基于优化的方法进行了比较。结果显示该方法能够有效恢复稀疏信号，且计算效率更高。

Conclusion: 提出了一种简单高效的压缩感知信号恢复方法，避免了传统优化问题的复杂性，适用于稀疏信号恢复，并在二进制信号上展示了良好的性能。

Abstract: Given the compressed sensing measurements of an unknown vector $z \in \mathbb{R}^n$ using random matrices, we present a simple method to determine $z$ without solving any optimization problem or linear system. Our method uses $Θ(\log n)$ random sensing matrices in $\mathbb{R}^{k \times n}$ and runs in $O(kn\log n)$ time, where $k = Θ(s\log n)$ and $s$ is the number of nonzero coordinates in $z$. We adapt our method to determine the support set of $z$ and experimentally compare with some optimization-based methods on binary signals.

</details>


### [44] [Fundamental Limits of Multi-User Distributed Computing of Linearly Separable Functions](https://arxiv.org/abs/2601.10603)
*K. K. Krishnan Namboodiri,Elizabath Peter,Derya Malak,Petros Elia*

Main category: cs.IT

TL;DR: 本文研究了多用户分布式计算中线性可分函数的基本极限，提出了联合任务分配和传输设计的方案，并在实域和有限域中证明了其最优性。


<details>
  <summary>Details</summary>
Motivation: 分布式计算中通信与计算之间存在根本权衡：服务器计算能力有限（最多计算M个子函数），通信能力也有限（最多向Δ个用户发送线性组合）。目标是设计能降低通信成本（服务器到用户的总数据量）的分布式计算方案。

Method: 针对给定的K（基础子函数数）、L（用户数）、M（服务器计算能力）、Δ（服务器通信能力），提出了一种联合设计任务分配和传输的分布式计算方案。使用新颖的反向证明方法在实域中证明方案的最优性，并使用基于计数论证的另一种反向证明在有限域中表征方案性能。

Result: 提出的分布式计算方案在各种条件下实现了实域中的最优性能。在有限域中，方案性能也得到了完整表征。该方案有效降低了服务器到用户的通信成本。

Conclusion: 本文建立了多用户分布式计算线性可分函数的基本极限，提出的联合设计方案在实域中达到最优，在有限域中性能得到完整表征，为分布式计算中的通信-计算权衡问题提供了理论框架。

Abstract: This work establishes the fundamental limits of the classical problem of multi-user distributed computing of linearly separable functions. In particular, we consider a distributed computing setting involving $L$ users, each requesting a linearly separable function over $K$ basis subfunctions from a master node, who is assisted by $N$ distributed servers. At the core of this problem lies a fundamental tradeoff between communication and computation: each server can compute up to $M$ subfunctions, and each server can communicate linear combinations of their locally computed subfunctions outputs to at most $Δ$ users. The objective is to design a distributed computing scheme that reduces the communication cost (total amount of data from servers to users), and towards this, for any given $K$, $L$, $M$, and $Δ$, we propose a distributed computing scheme that jointly designs the task assignment and transmissions, and shows that the scheme achieves optimal performance in the real field under various conditions using a novel converse. We also characterize the performance of the scheme in the finite field using another converse based on counting arguments.

</details>


### [45] [Basis-Spline Assisted Coded Computing: Strategies and Error Bounds](https://arxiv.org/abs/2601.10616)
*Rimpi Borah,J. Harshan,V. Lalitha*

Main category: cs.IT

TL;DR: 提出基于三次B样条插值的编码计算框架，用于处理非多项式函数的分布式计算，相比现有Berrut方法在存在大量掉队者时提供更好的精度和稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有的Berrut近似编码计算方法在处理非多项式函数时，由于Berrut插值具有全局支撑特性，当掉队者数量较多时精度会显著下降，需要更稳定的解决方案。

Method: 提出基于三次B样条插值的编码计算框架，利用B样条的局部支撑和平滑特性，在master节点重建服务器端函数评估，增强稳定性和精度。

Result: 提供了将B样条插值集成到编码计算中的系统方法，推导了近似误差的理论界限，并通过比较分析证明该方法在各种非多项式函数上显著优于Berrut方法。

Conclusion: 基于B样条的编码计算框架能够有效解决现有方法在处理大量掉队者时的精度问题，为分布式非多项式函数计算提供了更稳定可靠的解决方案。

Abstract: Coded computing has become a key framework for reliable distributed computation over decentralized networks, effectively mitigating the impact of stragglers. Although there exists a wide range of coded computing methods to handle both polynomial and non-polynomial functions, computing methods for the latter class have received traction due its inherent challenges in reconstructing non-polynomial functions using a finite number of evaluations. Among them, the state-of-the-art method is Berrut Approximated coded computing, wherein Berrut interpolants, are used for approximating the non-polynomial function. However, since Berrut interpolants have global support characteristics, such methods are known to offer degraded accuracy when the number of stragglers is large. To address this challenge, we propose a coded computing framework based on cubic B-spline interpolation. In our approach, server-side function evaluations are reconstructed at the master node using B-splines, exploiting their local support and smoothness properties to enhance stability and accuracy. We provide a systematic methodology for integrating B-spline interpolation into coded computing and derive theoretical bounds on approximation error in terms of the number of servers and stragglers. Comparative analysis demonstrates that our framework significantly outperforms Berrut-based methods for various non-polynomial functions.

</details>


### [46] [Converse Bounds for Sun-Jafar-type Weak Private Information Retrieval](https://arxiv.org/abs/2601.10643)
*Chandan Anand,Jayesh Seshadri,Prasad Krishnan,Gowtham R. Kurri*

Main category: cs.IT

TL;DR: 本文证明了Chandan等人提出的Sun-Jafar型弱私有信息检索方案在无合谋复制存储场景下的速率-隐私权衡是最优的，并证明了Banawan-Ulukus型MDS-WPIR和Sun-Jafar型T-合谋WPIR方案在系统参数满足阈值约束下的类最优性。


<details>
  <summary>Details</summary>
Motivation: Chandan等人提出了新的弱私有信息检索(WPIR)方案，并给出了速率-隐私权衡的表达式，但这些权衡是否在各自类别中是最优的尚不清楚。本文旨在研究这些方案的类最优性问题。

Method: 通过理论分析，证明了Sun-Jafar型方案在无合谋复制存储场景下的最优性，以及在阈值约束下Banawan-Ulukus型MDS-WPIR和Sun-Jafar型T-合谋WPIR方案的类最优性。当阈值约束不满足时，通过构造反例展示可以获得比之前报道更高的速率。

Result: 证明了Chandan等人提出的Sun-Jafar型方案在无合谋复制存储场景下的速率-隐私权衡是最优的；证明了在阈值约束下，Banawan-Ulukus型MDS-WPIR和Sun-Jafar型T-合谋WPIR方案具有类最优性；当阈值约束不满足时，构造了反例表明可以获得更高的速率。

Conclusion: 本文解决了Chandan等人提出的WPIR方案的类最优性问题，明确了这些方案在特定条件下的最优性边界，并指出了当系统参数不满足阈值约束时存在改进空间。

Abstract: Building on the well-established capacity-achieving schemes of Sun-Jafar (for replicated storage) and the closely related scheme of Banawan-Ulukus (for MDS-coded setting), a recent work by Chandan et al. proposed new classes of weak private information retrieval (WPIR) schemes for the collusion-free (replication and MDS-coded) setting, as well as for the $T$-colluding scenario. In their work, Chandan et al. characterized the expressions for the rate-privacy trade-offs for these classes of WPIR schemes, under the mutual information leakage and maximal leakage metrics. Explicit achievable trade-offs for the same were also presented, which were shown to be competitive or better than prior WPIR schemes. However, the class-wise optimality of the reported trade-offs were unknown. In this work, we show that the explicit rate-privacy trade-offs reported for the Sun-Jafar-type schemes by Chandan et al. are optimal for the non-colluding and replicated setting. Furthermore, we prove the class-wise optimality for Banawan-Ulukus-type MDS-WPIR and Sun-Jafar-type $T$-colluding WPIR schemes, under threshold-constraints on the system parameters. When these threshold-constraints do not hold, we present counter-examples which show that even higher rates than those reported before can be achieved.

</details>


### [47] [One-Shot Broadcast Joint Source-Channel Coding with Codebook Diversity](https://arxiv.org/abs/2601.10648)
*Joseph Rowan,Buu Phan,Ashish Khisti*

Main category: cs.IT

TL;DR: 研究单次联合信源信道编码，广播到K个解码器，至少一个解码器在最大失真约束下恢复信源即可成功。发现使用不相交码本可获得码本分集增益，不同于共享码本时的信道分集增益。


<details>
  <summary>Details</summary>
Motivation: 研究广播场景下，多个解码器通过独立信道接收编码信源时，如何设计编码方案使得至少一个解码器能成功恢复信源。探索码本设计（共享vs不相交）对系统性能的影响。

Method: 提出利用不相交码本获得码本分集增益的编码方案，推导一阶和二阶可达界（基于泊松匹配引理扩展）。进一步提出混合编码方案，将解码器分组以平衡码本分集和信道分集。

Result: 在二进制对称信道上的数值结果表明，混合方法（部分共享码本）优于完全共享或完全不相交码本的策略，能更好地平衡码本分集和信道分集。

Conclusion: 在单次联合信源信道编码的广播场景中，码本设计对系统性能有重要影响。不相交码本提供码本分集增益，而混合方案通过分组优化平衡码本分集和信道分集，获得最佳性能。

Abstract: We study a one-shot joint source-channel coding setting where the source is encoded once and broadcast to $K$ decoders through independent channels. Success is predicated on at least one decoder recovering the source within a maximum distortion constraint. We find that in the one-shot regime, utilizing disjoint codebooks at each decoder yields a codebook diversity gain, distinct from the channel diversity gain that may be expected when several decoders observe independent realizations of the channel's output but share the same codebook. Coding schemes are introduced that leverage this phenomenon, where first- and second-order achievability bounds are derived via an adaptation of the Poisson matching lemma (Li and Anantharam, 2021) which allows for multiple decoders using disjoint codebooks. We further propose a hybrid coding scheme that partitions decoders into groups to optimally balance codebook and channel diversity. Numerical results on the binary symmetric channel demonstrate that the hybrid approach outperforms strategies where the decoders' codebooks are either fully shared or disjoint.

</details>


### [48] [Synchronizing Probabilities in Model-Driven Lossless Compression](https://arxiv.org/abs/2601.10678)
*Aviv Adler,Jennifer Tang*

Main category: cs.IT

TL;DR: 提出PMATIC算法解决模型驱动压缩中的预测不匹配问题，通过容忍有界预测差异实现鲁棒压缩


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在概率预测方面表现出色，可用于改进压缩算法，但模型在压缩器和解压器之间的微小非确定性差异会导致解码失败，需要解决预测不匹配问题

Method: 提出概率匹配区间编码（PMATIC），这是一种模型无关算法，能够容忍有界预测不匹配且开销低，可作为算术编码的替代方案直接集成到模型驱动压缩工具中

Result: 理论证明了PMATIC的正确性和性能界限，在文本数据上验证了结果，当与先进预测模型配合使用时，PMATIC对预测不匹配具有鲁棒性，且压缩率优于标准现代压缩工具

Conclusion: PMATIC为解决模型驱动压缩中的预测不匹配问题提供了有效方案，实现了鲁棒的高效压缩

Abstract: It is well-known in the field of lossless data compression that probabilistic next-symbol prediction can be used to compress sequences of symbols. Deep neural networks are able to capture rich dependencies in data, offering a powerful means of estimating these probabilities and hence an avenue towards more effective compression algorithms. However, both compressor and decompressor must have exactly matching predictions; even small non-deterministic differences (which often happen with learned models due to hardware, software, or computation order) can lead to cascading decoding failures. In this paper, we formalize the problem of prediction mismatch in model-driven compression, and introduce Probability Matching Interval Coding (PMATIC), a model-agnostic algorithm that tolerates bounded prediction mismatch with low overhead. PMATIC works with the predicted probabilities, making it compatible as a drop-in replacement for the arithmetic encoder in model-driven compression tools. We show theoretical correctness and performance bounds for PMATIC, and validate these results on text data. These results confirm that, when paired an advanced prediction model, PMATIC is robust to prediction mismatch while achieving compression rates that out-perform standard modern compression tools.

</details>


### [49] [Implementation of Oblivious Transfer over Binary-Input AWGN Channels by Polar Codes](https://arxiv.org/abs/2601.10682)
*Pin-Hsun Lin,Hadi Aghaee,Christian Deppe,Eduard A. Jorswieck,Holger Boche*

Main category: cs.IT

TL;DR: 基于极化码在二进制输入加性高斯白噪声信道上的二选一不经意传输协议，通过极化变换自同构实现完美接收者隐私，渐近发送者隐私，并优化有限码长性能


<details>
  <summary>Details</summary>
Motivation: 在二进制输入加性高斯白噪声信道上实现安全的不经意传输协议，解决传统方案在有限码长下的隐私保护问题，特别是接收者隐私的完美保障

Method: 使用极化码，通过极化变换的自同构连接两个解码器视图，公开从对应的自同构群中随机选择编码器；在选定的坏比特信道上故意注入随机性；利用比特级置换结构优化有限码长性能

Result: 在任何有限码长下实现完美接收者隐私（公开编码器分布独立于接收者选择比特）；通过信道极化结合隐私放大获得渐近发送者隐私；推导了松弛的可靠性准则并评估了有限码长性能；优化了可实现的有限码长不经意传输速率

Conclusion: 成功开发了基于极化码的二选一不经意传输协议，在二进制输入加性高斯白噪声信道上实现了完美的接收者隐私和渐近的发送者隐私，通过自同构结构和优化方法提升了有限码长下的性能表现

Abstract: We develop a one-out-of-two-oblivious transfer protocol over the binary-input additive white Gaussian noise channel using polar codes. The scheme uses two decoder views linked by automorphisms of the polar transform and publicly draws the encoder at random from the corresponding automorphism group. This yields perfect receiver privacy at any finite blocklength, since the public encoder distribution is independent of the receiver's choice bit. Sender privacy is obtained asymptotically via channel polarization combined with privacy amplification. Because the construction deliberately injects randomness on selected bad bit-channels, we derive a relaxed reliability criterion and evaluate finite-blocklength performance. Finally, we characterize the polar-transform automorphisms as bit-level permutations of bit-channel indices, and exploit this structure to derive and optimize an achievable finite-blocklength OT rate.

</details>


### [50] [Improved Constructions of Reed-Solomon Codes with Optimal Repair Bandwidth](https://arxiv.org/abs/2601.10685)
*Jing Qiu,Weijun Fang,Shu-Tao Xia,Fang-Wei Fu*

Main category: cs.IT

TL;DR: 改进的RS-MSR码构造，消除了素数模s同余1的条件，显著降低了子分组化程度并扩展了参数范围


<details>
  <summary>Details</summary>
Motivation: 现有RS-MSR码构造要求素数p_i ≡ 1 (mod s)，限制了参数选择和增加了子分组化程度，需要更灵活的构造方法

Method: 提出改进的RS-MSR码构造，消除了p_i ≡ 1 (mod s)的约束条件，使用更一般的素数选择

Result: 子分组化程度降低了φ(s)^n倍，显著扩展了RS-MSR码的可行参数范围

Conclusion: 新构造提供了更灵活、更高效的RS-MSR码设计，为分布式存储系统提供了更好的修复带宽优化方案

Abstract: Maximum-distance-separable (MDS) codes are widely used in distributed storage, yet naive repair of a single erasure in an $[n,k]$ MDS code downloads the entire contents of $k$ nodes. Minimum Storage Regenerating (MSR) codes (Dimakis et al., 2010) minimize repair bandwidth by contacting $d>k$ helpers and downloading only a fraction of data from each. Guruswami and Wootters first proposed a linear repair scheme for Reed-Solomon (RS) codes, showing that they can be repaired with lower bandwidth than the naive approach. The existence of RS codes achieving the MSR point (RS-MSR codes) nevertheless remained open until the breakthrough construction of Tamo, Barg, and Ye, which yields RS-MSR codes with subpacketization $\ell = s \prod_{i=1}^n p_i$, where $p_i$ are distinct primes satisfying $p_i \equiv 1 \pmod{s}$ and $s=d+1-k$.
  In this paper, we present an improved construction of RS-MSR codes by eliminating the congruence condition $p_i \equiv 1 \pmod{s}$. Consequently, our construction reduces the subpacketization by a multiplicative factor of $φ(s)^n$ ( $φ(\cdot)$ is Euler's totient function) and broadens the range of feasible parameters for RS-MSR codes.

</details>


### [51] [Perfect Secret Key Generation for a class of Hypergraphical Sources](https://arxiv.org/abs/2601.10697)
*Manuj Mukherjee,Sagnik Chatterjee,Alhad Sethi*

Main category: cs.IT

TL;DR: 该论文扩展了PIN模型到超图，提出了两种完美密钥生成方案：1）基于星超图打包的完整t-均匀超图容量可达方案；2）针对3-均匀超图的2比特完美密钥方案


<details>
  <summary>Details</summary>
Motivation: Nitinawarat和Narayan提出的PIN模型完美密钥生成方案基于图的生成树打包率。本研究旨在将这一框架推广到超图，利用超图的组合性质设计类似的完美密钥生成方案。

Method: 1）对完整t-均匀超图，使用星超图打包方法，每个星图生成binom(m-2,t-2)比特完美密钥；2）对3-均匀超图，首先设计投影为环的3-均匀星超图的2比特方案，然后扩展到一般3-均匀超图，结合星图打包和图哈密顿打包技术。

Result: 提出了两种完美密钥生成方案：第一种对完整t-均匀超图达到容量；第二种对3-均匀超图有效，且对某些超图类别达到容量可达。

Conclusion: 成功将PIN模型扩展到超图领域，利用超图的组合性质设计了有效的完美密钥生成方案，为某些超图类别提供了容量可达的解决方案。

Abstract: Nitinawarat and Narayan proposed a perfect secret key generation scheme for the so-called \emph{pairwise independent network (PIN) model} by exploiting the combinatorial properties of the underlying graph, namely the spanning tree packing rate. This work considers a generalization of the PIN model where the underlying graph is replaced with a hypergraph, and makes progress towards designing similar perfect secret key generation schemes by exploiting the combinatorial properties of the hypergraph.
  Our contributions are two-fold. We first provide a capacity achieving scheme for a complete $t$-uniform hypergraph on $m$ vertices by leveraging a packing of the complete $t$-uniform hypergraphs by what we refer to as star hypergraphs, and designing a scheme that gives $\binom{m-2}{t-2}$ bits of perfect secret key per star graph. Our second contribution is a 2-bit perfect secret key generation scheme for 3-uniform star hypergraphs whose projections are cycles. This scheme is then extended to a perfect secret key generation scheme for generic 3-uniform hypergraphs by exploiting star graph packing of 3-uniform hypergraphs and Hamiltonian packings of graphs. The scheme is then shown to be capacity achieving for certain classes of hypergraphs.

</details>
