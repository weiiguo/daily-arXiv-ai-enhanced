<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 22]
- [cs.IT](#cs.IT) [Total: 50]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [Dual radar-guided glide path error correction based on the Izhikevich neuron model](https://arxiv.org/abs/2601.06068)
*Yuan Gao,Xinyu Wang,Yifan Ren,Yuning Zhou,Ziwei Wang*

Main category: eess.SP

TL;DR: 提出基于Izhikevich神经模型的双雷达航迹误差校正方法，通过脉冲神经网络动态补偿雷达测量误差


<details>
  <summary>Details</summary>
Motivation: 针对双雷达跟踪中目标反射特性和系统噪声导致的测距测角误差问题，需要有效的误差校正方法

Method: 使用Izhikevich神经模型的动态微分方程模拟生物神经元放电特性，输入层集成双雷达坐标测量数据，输出层通过脉冲发射频率表示误差补偿量，采用STDP规则动态调整神经元连接权重

Result: 能够有效抑制系统噪声和雷达测距测角误差引起的轨迹失真

Conclusion: 基于Izhikevich神经模型的脉冲神经网络方法可以有效校正双雷达航迹误差，提高跟踪精度

Abstract: Aiming at the ranging and angle measurement errors caused by target reflection characteristics and system noise in dual radar tracking, this paper proposes a dual radar track error correction method based on the Izhikevich neural model. The network uses the dynamic differential equation of the Izhikevich model to simulate the discharge characteristics of biological neurons. Its input layer integrates the coordinate measurement data of the dual radar, and the output layer represents the error compensation amount through the pulse emission frequency. The spike-timing-dependent plasticity (STDP) is used to adjust the neuron connection weights dynamically, and the trajectory distortion caused by system noise and radar ranging and angle measurement errors can be effectively suppressed.

</details>


### [2] [Optimizing the 4G--5G Migration: A Simulation-Driven Roadmap for Emerging Markets](https://arxiv.org/abs/2601.06076)
*Desire Guel,Justin Pegd-Windé Kouraogo,Kouka Kouakou Nakoulma*

Main category: eess.SP

TL;DR: 本文通过MATLAB仿真分析了5G网络在新兴市场部署中的关键技术选择，包括MIMO、载波聚合、频谱重耕、毫米波传播和网络架构等，量化了它们对容量、覆盖、时延和干扰鲁棒性的影响，并提出了从NSA到SA的演进路线图。


<details>
  <summary>Details</summary>
Motivation: 在新兴市场部署5G网络面临预算、频谱和基础设施限制，需要在性能目标和实际约束之间取得平衡。研究旨在量化各种无线电和架构杠杆对网络性能的影响，为实际部署提供指导。

Method: 使用MATLAB仿真来量化分析多种技术：MIMO（波束赋形、分集、空间复用）、载波聚合、频谱重耕到新空口、毫米波传播（考虑遮挡/雨衰）、NSA与SA核心网架构，以及D2D和M2M作为广域接入的补充。

Result: 波束赋形可提升小区边缘SNR约3-6 dB；空间复用在中等/高SNR下通过多流增益占主导；载波聚合显著提升吞吐量（1到5个20MHz载波使峰值速率从200 Mb/s提升至1 Gb/s）；中频段重耕到NR可提升城市中位数吞吐量60-90%；28GHz毫米波受雨衰和人体遮挡影响严重（额外损耗8-30 dB）；NSA相比SA提供更广的初始覆盖。

Conclusion: 提出实用路线图：从NSA开始部署NR，优先采用以载波聚合为中心的频谱策略并聚焦频谱重耕，在需求热点区域选择性密集化，随着回传和设备生态成熟逐步迁移到SA架构。

Abstract: Deploying fifth-generation (5G) networks in emerging markets demands a balance between performance targets and constraints in budget, spectrum, and infrastructure. We use MATLAB simulations to quantify how radio and architectural levers - MIMO (beamforming, diversity, spatial multiplexing), carrier aggregation (CA), targeted spectrum refarming to New Radio (NR), mmWave propagation with blockage/rain, and Non-Standalone (NSA) versus Standalone (SA) cores - affect capacity, coverage, latency, and interference robustness, with D2D and M2M as complements to wide-area access. Beamforming improves cell-edge SNR by about 3-6 dB, while spatial multiplexing dominates at moderate/high SNR via multi-stream gains. Throughput scales strongly with CA: increasing from 1 to 5x20-MHz carriers raises peak rate from about 200 Mb/s to about 1 Gb/s at 30 dB SNR; water-filling adds 5-12% over equal power at mid-SNR. Targeted mid-band refarming to NR increases median throughput by 60-90% in urban and 40-70% in rural scenarios when sub-1-GHz layers preserve coverage. At 28 GHz, rain and human blockage add about 8-30 dB excess loss, so viable mmWave deployment concentrates in LOS hot zones with narrow-beam arrays and short inter-site distances. NSA delivers broader initial coverage than SA by reusing LTE/EPC, while SA becomes attractive as transport improves (e.g., >= 10 Gb/s and < 5 ms RTT) and site density grows. We synthesize these results into a practical roadmap: start NR on NSA, prioritize CA-centric spectrum strategies with focused refarming, densify selectively in demand hotspots, and migrate to SA as backhaul and device ecosystems mature.

</details>


### [3] [Timing Fragility Aware Selective Hardening of RISCV Soft Processors on SRAM Based FPGAs](https://arxiv.org/abs/2601.06308)
*Mostafa Darvishi*

Main category: eess.SP

TL;DR: 提出一种基于时序脆弱性感知的选择性加固方法，用于SRAM FPGA上的RISC-V软处理器，通过量化流水线组件的时序敏感性来指导加固决策，在保持可靠性的同时显著减少开销。


<details>
  <summary>Details</summary>
Motivation: 现有选择性加固方法主要依赖架构关键性或功能故障分析，忽略了路由相关的时序敏感性对处理器鲁棒性的影响。需要一种考虑时序脆弱性的方法来优化FPGA软处理器的可靠性设计。

Method: 基于原位时序可观测性的最新进展，量化流水线组件在受控路由扰动下的统计时序敏感性，利用这些信息指导加固决策。通过分析时序脆弱性与路由诱导延迟效应之间的相关性来制定选择性加固策略。

Result: 实验结果显示，具有较高时序脆弱性的组件对路由诱导延迟效应表现出更高的脆弱性。提出的选择性加固策略实现了与完全加固相当的鲁棒性，同时显著减少了面积和时序开销。

Conclusion: 时序脆弱性为FPGA处理器架构的可靠性感知设计优化提供了一个实用有效的度量指标，能够在不显著增加开销的情况下提高系统可靠性。

Abstract: Selective hardening is widely employed to improve the reliability of FPGA based soft processors while limiting the overhead of full redundancy. However, existing approaches primarily rely on architectural criticality or functional fault analysis, overlooking the impact of routing dependent timing sensitivity on processor robustness. This paper introduces a timing fragility aware selective hardening methodology for RISCV soft processors implemented on SRAM based FPGAs. Building on recent advances in in situ timing observability, the proposed approach quantifies the statistical timing sensitivity of pipeline components under controlled routing perturbations and uses this information to guide hardening decisions. Experimental results on a RISCV processor implemented on a commercial FPGA platform show that components exhibiting higher timing fragility also demonstrate increased vulnerability to routing induced delay effects. Leveraging this correlation, the proposed selective hardening strategy achieves robustness comparable to full hardening while significantly reducing area and timing overhead. These results demonstrate that timing fragility provides a practical and effective metric for reliability aware design optimization in FPGA based processor architectures.

</details>


### [4] [Building Envelope Inversion by Data-driven Interpretation of Ground Penetrating Radar](https://arxiv.org/abs/2601.06333)
*Ahmed Nirjhar Alam,Wesley Reinhart,Rebecca Napolitano*

Main category: eess.SP

TL;DR: 开发基于GPR的墙体诊断框架，将墙体诊断分解为垂直（立柱存在）和横向（墙体类型）变化的分类任务，使用稀疏神经网络实现高精度且可解释的特征提取。


<details>
  <summary>Details</summary>
Motivation: 探地雷达（GPR）具有深度分辨率高、非破坏性操作和材料敏感性广等优点，但在建筑围护结构诊断中应用有限。墙体组件的紧凑几何结构使得来自紧密排列的立柱、护板和覆层的反射信号严重重叠，导致系统反演困难。数据驱动解释的最新进展为重新审视这一挑战提供了机会，评估机器学习是否能从复杂信号中可靠提取结构信息。

Method: 开发GPR反演框架，将墙体诊断分解为处理垂直（立柱存在）和横向（墙体类型）变化的分类任务。实施多种特征最小化策略，包括递归消除、凝聚聚类和基于L0的稀疏性，以提高保真度和可解释性。特别采用基于L0的稀疏神经网络（SparseNN），该网络仅依赖一小部分输入特征，每个特征都与可识别的介电界面相关联。

Result: 基于L0的稀疏神经网络（SparseNN）表现出色：在仅使用一小部分输入特征的情况下，其准确率超过了随机森林。每个特征都与可识别的介电界面相关联。SHAP分析进一步证实，SparseNN学习的反射模式与物理层边界一致。

Conclusion: 该框架为使用GPR雷达图进行物理可解释且数据高效的墙体组件反演奠定了基础。虽然未涉及缺陷检测，但重建完整围护结构并隔离与关键元素相关特征的能力，为未来的反演和异常分析任务提供了必要的基线。

Abstract: Ground-penetrating radar (GPR) combines depth resolution, non-destructive operation, and broad material sensitivity, yet it has seen limited use in diagnosing building envelopes. The compact geometry of wall assemblies, where reflections from closely spaced studs, sheathing, and cladding strongly overlap, has made systematic inversion difficult. Recent advances in data-driven interpretation provide an opportunity to revisit this challenge and assess whether machine learning can reliably extract structural information from such complex signals. Here, we develop a GPR-based inversion framework that decomposes wall diagnostics into classification tasks addressing vertical (stud presence) and lateral (wall-type) variations. Alongside model development, we implement multiple feature minimization strategies - including recursive elimination, agglomerative clustering, and L0-based sparsity - to promote fidelity and interpretability. Among these approaches, the L0-based sparse neural network (SparseNN) emerges as particularly effective: it exceeds Random Forest accuracy while relying on only a fraction of the input features, each linked to identifiable dielectric interfaces. SHAP analysis further confirms that the SparseNN learns reflection patterns consistent with physical layer boundaries. In summary, this framework establishes a foundation for physically interpretable and data-efficient inversion of wall assemblies using GPR radargrams. Although defect detection is not addressed here, the ability to reconstruct intact envelope structure and isolate features tied to key elements provides a necessary baseline for future inversion and anomaly-analysis tasks.

</details>


### [5] [Performance Analysis for Wireless Localization with Random Sensor Network](https://arxiv.org/abs/2601.06396)
*Mengqi Ma,Aihua Xia*

Main category: eess.SP

TL;DR: 该论文研究了在随机传感器网络中，基于RSS和AOA测量的融合定位估计器的性能，建立了在噪声较大时非泊松部署与泊松点过程之间的近似等价性，并推导了MSE和CMSE的解析上界。


<details>
  <summary>Details</summary>
Motivation: 准确的无线定位对于自动驾驶系统和智能基础设施等应用至关重要。研究需要理解在实际随机传感器网络中，基于接收信号强度(RSS)和到达角(AOA)测量的融合定位估计器的性能，特别是如何将部署和传感参数转化为可实现的精度目标。

Method: 首先建立了近似定理：当测量噪声足够大时，广泛类别的平稳各向同性部署下RSS和AOA观测的联合分布与齐次泊松点过程(PPP)诱导的分布在分布上无法区分。然后利用这种等价性，研究基于齐次PPP的传感器网络，提出融合估计器，其中中央处理器聚合来自空间分布传感器的RSS和AOA测量来推断目标位置。对于有限观测区域内的PPP部署，推导了MSE和CMSE的可处理解析上界。

Result: 建立了传感器密度、观测半径和噪声方差与定位精度之间的显式标度律。近似定理证明这些基于PPP的界限在噪声较大时可以作为非泊松部署的合理代理。结果为部署和传感参数如何影响定位精度提供了量化分析。

Conclusion: 研究结果为下一代位置感知无线网络的设计提供了稳健、成本感知的指导，将部署和传感参数转化为可实现的精度目标，为实际系统设计提供了理论依据。

Abstract: Accurate wireless localization underpins applications from autonomous systems to smart infrastructure. We study the mean-squared error (MSE) and conditional MSE (CMSE) of a practical fusion-based estimator in d-dimensional, stationary isotropic (translation- and rotation-invariant) random sensor networks, where a central processor combines received-signal-strength (RSS) and angle-of-arrival (AOA) measurements to infer a target's position. Our contributions are twofold. First, we establish an approximation theorem: when measurement noise is sufficiently large, the joint law of RSS and AOA observations under a broad class of stationary isotropic deployments is, in distribution, indistinguishable from that induced by a homogeneous Poisson point process (PPP). Second, leveraging this equivalence, we investigate a homogeneous PPP-based sensor network. We propose a fusion-based estimator in which a central processor aggregates RSS and AOA measurements from a set of spatially distributed sensors to infer the target position. For this PPP deployment within a finite observation region, we derive tractable analytical upper bounds for both the MSE and CMSE, establishing explicit scaling laws with respect to sensor density, observation radius, and noise variance. The approximation theorem then certifies these PPP-based bounds as reasonable proxies for non-Poisson deployments in noisy regimes. Overall, the results translate deployment and sensing parameters into achievable accuracy targets and provide robust, cost-aware guidance for the design of next-generation location-aware wireless networks.

</details>


### [6] [Neuro-Wideband WiFi Sensing via Self-Conditioned CSI Extrapolation](https://arxiv.org/abs/2601.06467)
*Sijie Ji,Weiying Hou,Chenshu Wu*

Main category: eess.SP

TL;DR: NWB提出一种新范式，无需专用硬件或额外信道测量即可实现宽带WiFi感知，通过将CSI转换为扩展CSI(eCSI)来近似更宽带宽的测量


<details>
  <summary>Details</summary>
Motivation: 传统WiFi感知受限于为通信设计的有限带宽，导致多径分辨率和多用户感知存在根本限制，而商用WiFi上获取大带宽在实际中不可行

Method: 提出Neuro-Wideband(NWB)范式，通过WUKONG框架将CSI转换为扩展CSI(eCSI)。WUKONG采用Transformer和Diffusion模型，作为自条件学习问题，利用现有CSI数据作为自标记样本进行训练

Result: 在多种WiFi信号、协议和带宽下的真实世界实验显示NWB具有良好效果，通过定位和多人员呼吸监测案例进一步验证了eCSI的有效性

Conclusion: NWB为在商用硬件上实现宽带WiFi感知提供了实用途径，扩展了无线感知系统的设计空间

Abstract: WiFi sensing has suffered from the limited bandwidths designated for its original communication purpose, leading to fundamental limits in multipath resolution and thus multi-user sensing. Unfortunately, it is practically prohibitive to obtain large bandwidths on commercial WiFi, considering the conflict between the limited spectrum and the crowded networks. In this paper, we present Neuro-Wideband (NWB), a completely different paradigm that enables wideband WiFi sensing without specialized hardware or extra channel measurements. Our key insight is that any physical measurement of channel state information (CSI) inherently encapsulates multipath parameters, which, while unsolvable in isolation, can be transformed into an expanded form of CSI (eCSI) approximating measurements over a broader bandwidth. To ground this insight, we propose WUKONG to address NWB as a unique self-conditioned learning problem that can be trained by using any existing CSI data as self-labeled samples. WUKONG introduces a novel deep learning framework by integrating Transformer and Diffusion models, which captures sample-specific multipath parameters and transfers this sample-level knowledge to the outcome eCSI. We conduct real-world experiments to evaluate WUKONG on diverse WiFi signals across protocols and bandwidths. The results show the promising effectiveness of NWB, which is further demonstrated through case studies on localization and multi-person breathing monitoring using eCSI. Overall, the proposed NWB promises a practical pathway toward realizing wideband WiFi sensing on commodity hardware, expanding the design space of wireless sensing systems.

</details>


### [7] [Joint Impact of ADC and Fronthaul Quantization in Cell-Free Massive MIMO-OFDM Uplink](https://arxiv.org/abs/2601.06483)
*Özlem Tuğfe Demir,Emil Björnson*

Main category: eess.SP

TL;DR: 论文研究了宽带OFDM无蜂窝大规模MIMO系统中，ADC量化与fronthaul量化的联合影响，提出了一种在fronthaul传输前处理接收信号以减少量化失真的策略。


<details>
  <summary>Details</summary>
Motivation: 在无蜂窝大规模MIMO系统的上行链路中，量化影响性能的两个关键领域：AP端有限分辨率ADC引入的时域失真，以及发送到CPU的fronthaul信号量化。虽然窄带系统中这两种量化效应已被广泛研究，但在实际宽带OFDM无蜂窝大规模MIMO中的联合影响仍未被充分探索。

Method: 建模联合失真并提出fronthaul策略，其中每个AP在传输前处理接收信号以减少量化伪影。开发了一种有效的估计算法，在fronthaul传输前重建未量化的时域信号。

Result: 提出的设计为在宽带无蜂窝架构中实现高效、量化感知的上行传输提供了新的见解。

Conclusion: 该研究填补了宽带OFDM无蜂窝大规模MIMO系统中ADC和fronthaul量化联合影响的空白，提出的信号处理策略能有效减少量化失真，为实际系统实现提供了重要指导。

Abstract: In the uplink of a cell-free massive MIMO system, quantization affects performance in two key domains: the time-domain distortion introduced by finite-resolution analog-to-digital converters (ADCs) at the access points (APs), and the fronthaul quantization of signals sent to the central processing unit (CPU). Although quantizing twice may seem redundant, the ADC quantization in orthogonal frequency-division duplex (OFDM) systems appears in the time domain, and one must then convert to the frequency domain, where quantization can be applied only to the signals at active subcarriers. This reduces fronthaul load and avoids unnecessary distortion, since the ADC output spans all OFDM samples while only a subset of subcarriers carries useful information.
  While both quantization effects have been extensively studied in narrowband systems, their joint impact in practical wideband OFDM-based cell-free massive MIMO remains largely unexplored. This paper addresses the gap by modeling the joint distortion and proposing a fronthaul strategy in which each AP processes the received signal to reduce quantization artifacts before transmission. We develop an efficient estimation algorithm that reconstructs the unquantized time-domain signal prior to fronthaul transmission and evaluate its effectiveness. The proposed design offers new insights for implementing efficient, quantization-aware uplink transmission in wideband cell-free architectures.

</details>


### [8] [Cell-Free Massive MIMO with Hardware-Impaired Wireless Fronthaul](https://arxiv.org/abs/2601.06486)
*Özlem Tuğfe Demir,Emil Björnson*

Main category: eess.SP

TL;DR: 提出一种针对cell-free大规模MIMO的新型无线前传方案，联合建模AP和前传收发器的硬件损伤，设计损伤感知线性组合器以提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注接入侧的硬件损伤，而无线前传链路的硬件损伤影响尚未充分探索。cell-free大规模MIMO中AP成本低且密集部署，射频链路的非理想硬件损伤不可避免，需要系统性的建模和缓解方案。

Method: 提出基于放大转发(AF)的无线前传方案，开发分析框架联合建模AP和前传收发器的硬件损伤，推导端到端失真信号表达式，量化各损伤对频谱效率的贡献，并设计损伤感知线性组合器来优化缓解这些影响。

Result: 数值结果表明，损伤感知处理带来显著的性能增益，验证了所提出的AF前传方案作为未来cell-free架构成本效益使能器的潜力。

Conclusion: 该工作填补了cell-free大规模MIMO中无线前传链路硬件损伤建模的重要空白，提出的联合损伤建模框架和损伤感知处理方案为实际部署提供了有效的解决方案。

Abstract: Cell-free massive MIMO (multiple-input multiple-output) enhances spectral and energy efficiency compared to conventional cellular networks by enabling joint transmission and reception across a large number of distributed access points (APs). Since these APs are envisioned to be low-cost and densely deployed, hardware impairments, stemming from non-ideal radio-frequency (RF) chains, are unavoidable. While existing studies primarily address hardware impairments on the access side, the impact of hardware impairments on the wireless fronthaul link has remained largely unexplored. In this work, we fill this important gap by introducing a novel amplify-and-forward (AF) based wireless fronthauling scheme tailored for cell-free massive MIMO. Focusing on the uplink, we develop an analytical framework that jointly models the hardware impairments at both the APs and the fronthaul transceivers, derives the resulting end-to-end distorted signal expression, and quantifies the individual contribution of each impairment to the spectral efficiency. Furthermore, we design distortion-aware linear combiners that optimally mitigate these effects. Numerical results demonstrate significant performance gains from distortion-aware processing and illustrate the potential of the proposed AF fronthauling scheme as a cost-effective enabler for future cell-free architectures.

</details>


### [9] [A Multimodal Deep Learning Framework for Predicting ICU Deterioration: Integrating ECG Waveforms with Clinical Data and Clinician Benchmarking](https://arxiv.org/abs/2601.06645)
*Juan Miguel López Alcaraz,Xicoténcatl López Moran,Erick Dávila Zaragoza,Claas Händel,Richard Koebe,Wilhelm Haverkamp,Nils Strodthoff*

Main category: eess.SP

TL;DR: MDS ICU是一个多模态机器学习框架，融合ICU常规数据（人口统计、生命体征、实验室值、ECG波形等），联合预测33种临床结局，在MIMIC-IV数据上表现优异，能增强而非替代临床决策。


<details>
  <summary>Details</summary>
Motivation: 现有ICU风险预测模型通常关注单一结局或有限数据类型，而临床医生需要整合纵向历史、实时生理学和异质临床信息。需要开发能融合多源数据的统一框架来支持ICU临床决策。

Method: 开发MDS ICU多模态框架，融合人口统计、生物特征、生命体征、实验室值、ECG波形、手术过程和医疗设备使用等常规数据。使用MIMIC-IV的63001个样本（27062名患者），结合结构化状态空间S4编码器处理ECG波形，多层感知机RealMLP编码器处理表格数据，联合预测33种临床相关结局。

Result: 模型表现出强区分能力：24小时死亡率AUROC 0.90，镇静剂给药0.92，有创机械通气0.97，凝血功能障碍0.93。校准分析显示预测风险与实际风险高度一致，ECG波形集成带来持续增益。模型预测优于临床医生和大型语言模型，提供模型输出作为决策支持能进一步提升临床医生表现。

Conclusion: 多模态AI能在多种ICU结局中提供有临床意义的风险分层，增强而非替代临床专业知识，为精准重症监护决策支持建立了可扩展的基础。

Abstract: Artificial intelligence holds strong potential to support clinical decision making in intensive care units where timely and accurate risk assessment is critical. However, many existing models focus on isolated outcomes or limited data types, while clinicians integrate longitudinal history, real time physiology, and heterogeneous clinical information. To address this gap, we developed MDS ICU, a unified multimodal machine learning framework that fuses routinely collected data including demographics, biometrics, vital signs, laboratory values, ECG waveforms, surgical procedures, and medical device usage to provide continuous predictive support during ICU stays. Using 63001 samples from 27062 patients in MIMIC IV, we trained a deep learning architecture that combines structured state space S4 encoders for ECG waveforms with multilayer perceptron RealMLP encoders for tabular data to jointly predict 33 clinically relevant outcomes spanning mortality, organ dysfunction, medication needs, and acute deterioration. The model achieved strong discrimination with AUROCs of 0.90 for 24 hour mortality, 0.92 for sedative administration, 0.97 for invasive mechanical ventilation, and 0.93 for coagulation dysfunction. Calibration analysis showed close agreement between predicted and observed risks, with consistent gains from ECG waveform integration. Comparisons with clinicians and large language models showed that model predictions alone outperformed both, and that providing model outputs as decision support further improved their performance. These results demonstrate that multimodal AI can deliver clinically meaningful risk stratification across diverse ICU outcomes while augmenting rather than replacing clinical expertise, establishing a scalable foundation for precision critical care decision support.

</details>


### [10] [Artificial Intelligence Driven Channel Coding and Resource Optimization for Wireless Networks](https://arxiv.org/abs/2601.06796)
*Yasir Ali,Tayyab Manzoor,Huan Yang,Chenhang Yan,Yuanqing Xia*

Main category: eess.SP

TL;DR: 本文探讨了AI在5G/5G+网络中的关键作用，特别是在编码理论方面的创新，通过深度学习、强化学习等方法提升错误纠正、资源分配和网络性能。


<details>
  <summary>Details</summary>
Motivation: 5G/5G+网络对超高速度、超低延迟和弹性连接的需求日益增长，以支持物联网、自动驾驶和智慧城市等关键应用。传统技术面临干扰缓解、动态资源分配和网络无缝运行等挑战，需要AI提供更先进的解决方案。

Method: 研究采用AI驱动的编码理论创新，包括深度学习、强化学习和神经网络方法，结合大规模MIMO、智能反射面等新兴技术，开发自适应传输策略和隐私增强机制。

Result: AI方法在错误纠正性能、解码效率和自适应传输策略方面取得显著进展，为下一代无线网络提供了可扩展、自适应且更高效的网络架构基础。

Conclusion: AI在5G/5G+网络中具有变革性影响，通过编码理论创新和技术整合，能够推动无线通信向更智能、更高效的方向发展，为未来网络架构奠定基础。

Abstract: The ongoing evolution of 5G and its enhanced version, 5G+, has significantly transformed the telecommunications landscape, driving an unprecedented demand for ultra-high-speed data transmission, ultra-low latency, and resilient connectivity. These capabilities are essential for enabling mission-critical applications such as the Internet of Things, autonomous vehicles, and smart city infrastructures. This paper investigates the important role of Artificial Intelligence (AI) in addressing the key challenges faced by 5G/5G+ networks, including interference mitigation, dynamic resource allocation, and maintaining seamless network operation. The study particularly focuses on AI-driven innovations in coding theory, which offer advanced solutions to the limitations of conventional error correction and modulation techniques. By employing deep learning, reinforcement learning, and neural network-based approaches, this research demonstrates significant advancements in error correction performance, decoding efficiency, and adaptive transmission strategies. Additionally, the integration of AI with emerging technologies, such as massive multiple-input and multiple-output, intelligent reflecting surfaces, and privacy-enhancing mechanisms, is discussed, highlighting their potential to propel the next generation of wireless networks. This paper also provides insights into the transformative impact of AI on modern wireless communication, establishing a foundation for scalable, adaptive, and more efficient network architectures.

</details>


### [11] [RIS-aided ISAC with $K$-Rydberg Atomic Receivers](https://arxiv.org/abs/2601.06809)
*Hong-Bae Jeon,Chan-Byoung Chae*

Main category: eess.SP

TL;DR: 该论文提出了一种基于可重构智能表面辅助的集成感知与通信框架，采用多用户Rydberg原子接收器，通过联合优化算法平衡通信性能和感知精度。


<details>
  <summary>Details</summary>
Motivation: 研究动机是开发6G网络中集成感知与通信系统，利用Rydberg原子接收器的参考辅助接收机制，解决传统方法在通信性能与感知精度之间的平衡问题。

Method: 提出RIS辅助的ISAC框架，建立统一信号模型，采用Cramer-Rao边界约束的效用最大化问题，结合分数规划、主化-最小化和交替方向乘子法进行联合优化。

Result: 仿真结果表明，所提框架在各种系统环境下均优于传统方法，有效提升了通信性能和感知精度，验证了Rydberg原子接收器在6G网络中的潜力。

Conclusion: 该研究成功开发了RIS辅助的ISAC框架，通过Rydberg原子接收器和联合优化算法，为6G网络的集成感知与通信系统提供了有效解决方案。

Abstract: In this paper, we investigate a reconfigurable intelligent surface (RIS)-assisted integrated sensing and communications (ISAC) framework equipped with multiple Rydberg atomic receiver (RAR)-aided users. By leveraging the reference-assisted reception mechanism of RARs, we develop a unified signal model that jointly captures downlink multi-user communication with RARs and monostatic radar sensing. To explicitly balance communication performance and sensing accuracy, we formulate a Cramer-Rao bound (CRB)-constrained utility maximization problem. To address these challenges, we propose a joint optimization framework that combines fractional programming (FP), majorization-minimization (MM), and the alternating direction method of multipliers (ADMM). Simulation results demonstrate that the proposed framework consistently outperforms the conventional approach over a wide range of system environments, thereby highlighting the importance of the proposed framework in unlocking the potential of RARs for 6G.

</details>


### [12] [Radar-Based Identification of Individuals Using Heartbeat Features Extracted from Signal Amplitude and Phase](https://arxiv.org/abs/2601.06824)
*Haruto Kobayashi,Takuya Sakamoto*

Main category: eess.SP

TL;DR: 提出基于毫米波雷达心跳特征的非接触式身份识别方法，通过分析振幅、相位和复数信号的贡献，并融合三种特征提升识别准确率


<details>
  <summary>Details</summary>
Motivation: 现有基于毫米波雷达的身份识别方法主要使用复数信号谱图，但忽略了不同信号分量（振幅、相位）对识别准确率的贡献差异，需要明确各分量的作用并探索融合方法

Method: 首先分别评估基于振幅、相位和复数信号的谱图识别性能，然后提出特征融合方法整合三种表示，使用79GHz雷达系统进行实验验证

Result: 在6名参与者的实验中，提出的方法实现了97.67%的身份识别准确率，证明了分量分析和融合方法的有效性

Conclusion: 通过系统分析振幅、相位和复数信号对身份识别的贡献，并融合这些特征，显著提升了基于毫米波雷达心跳特征的非接触式身份识别性能

Abstract: This study proposes a non-contact method for identifying individuals through the use of heartbeat features measured with millimeter-wave radar. Although complex-valued radar signal spectrograms are commonly used for this task, little attention has been paid to the choice of signal components, namely, whether to use amplitude, phase, or the complex signal itself. Although spectrograms can be constructed independently from amplitude or phase information, their respective contributions to identification accuracy remain unclear. To address this issue, we first evaluate identification performance using spectrograms derived separately from amplitude, phase, and complex signals. We then propose a feature fusion method that integrates these three representations to enhance identification accuracy. Experiments conducted with a 79-GHz radar system and involving six participants achieved an identification accuracy of 97.67%, demonstrating the effectiveness of the proposed component-wise analysis and integration approach.

</details>


### [13] [Movable Beyond-Diagonal Reconfigurable Intelligent Surfaces: Moving, Interconnecting, or Both?](https://arxiv.org/abs/2601.06837)
*Shuyue Xu,Matteo Nerini,Bruno Clerckx*

Main category: eess.SP

TL;DR: 提出移动超对角可重构智能表面设计，结合单元间连接性和可移动性增强信道性能，通过联合优化波束成形、RIS配置和单元位置最大化多用户MISO系统的和速率。


<details>
  <summary>Details</summary>
Motivation: 传统RIS存在连接性限制和固定位置约束，无法充分利用空间自由度。需要结合可移动性和超对角连接结构来增强信道质量，适应不同场景需求。

Method: 提出MA-BD-RIS辅助多用户MISO系统，开发高效算法：闭式波束成形、低复杂度部分近端交替方向乘子法用于BD-RIS设计、连续凸近似用于单元位置优化。

Result: 仿真表明：高移动性结构在小规模RIS和丰富散射场景中表现优越，而高连接性结构在大规模RIS和大规模发射阵列配置中占主导地位。

Conclusion: MA-BD-RIS设计通过结合可移动性和超对角连接性，为不同场景提供灵活的性能优化方案，显著提升系统性能。

Abstract: This letter proposes a movable beyond-diagonal reconfigurable intelligent surfaces (MA-BD-RIS) design, combining inter-element connectivity and movability for channel enhancement. We study a MA-BD-RIS assisted multi-user multiple input single output system where beamforming, BD-RIS configuration, and elements positions are jointly optimized to maximize the sum-rate. An efficient algorithm is developed, incorporating closed-form beamforming, a low-complexity partially proximal alternating direction method of multipliers for BD-RIS design, and successive convex approximation for element placement. Simulations show that the high-movability structure yields superior performance in small-scale RIS and rich scattering scenarios, while the high-connectivity structure dominates in large-scale RIS and massive transmit array configurations.

</details>


### [14] [Deep Learning Based Channel Extrapolation for Dual-Band Massive MIMO Systems](https://arxiv.org/abs/2601.06858)
*Qikai Xiao,Kehui Li,Binggui Zhou,Shaodan Ma*

Main category: eess.SP

TL;DR: 提出MDFCE方法，通过融合多域特征将sub-6 GHz CSI外推到mmWave CSI，减少毫米波信道估计的导频开销


<details>
  <summary>Details</summary>
Motivation: 毫米波大规模MIMO系统需要高精度CSI，但直接估计需要大量导频开销且受路径损耗和阻塞衰减影响。sub-6 GHz和毫米波双频段系统需要高效的信道获取方法

Method: 提出多域融合信道外推器(MDFCE)，结合专家混合框架和多头自注意力机制，融合sub-6 GHz CSI的多域特征来学习到毫米波CSI的映射关系

Result: MDFCE在多种天线阵列规模和信噪比水平下，相比现有方法能用更少的训练导频获得更优性能，且计算效率更高

Conclusion: MDFCE为双频段大规模MIMO系统提供了一种高效的毫米波信道获取方案，显著减少了导频开销并提高了计算效率

Abstract: Future wireless communication systems will increasingly rely on the integration of millimeter wave (mmWave) and sub-6 GHz bands to meet heterogeneous demands on high-speed data transmission and extensive coverage. To fully exploit the benefits of mmWave bands in massive multiple-input multiple-output (MIMO) systems, highly accurate channel state information (CSI) is required. However, directly estimating the mmWave channel demands substantial pilot overhead due to the large CSI dimension and low signal-to-noise ratio (SNR) led by severe path loss and blockage attenuation. In this paper, we propose an efficient \textbf{M}ulti-\textbf{D}omain \textbf{F}usion \textbf{C}hannel \textbf{E}xtrapolator (MDFCE) to extrapolate sub-6 GHz band CSI to mmWave band CSI, so as to reduce the pilot overhead for mmWave CSI acquisition in dual band massive MIMO systems. Unlike traditional channel extrapolation methods based on mathematical modeling, the proposed MDFCE combines the mixture-of-experts framework and the multi-head self-attention mechanism to fuse multi-domain features of sub-6 GHz CSI, aiming to characterize the mapping from sub-6 GHz CSI to mmWave CSI effectively and efficiently. The simulation results demonstrate that MDFCE can achieve superior performance with less training pilots compared with existing methods across various antenna array scales and signal-to-noise ratio levels while showing a much higher computational efficiency.

</details>


### [15] [Continuous Energy Landscape Model for Analyzing Brain State Transitions](https://arxiv.org/abs/2601.06991)
*Triet M. Tran,Seyed Majid Razavi,Dee H. Wu,Sina Khanmohammadi*

Main category: eess.SP

TL;DR: 提出基于图神经网络的连续能量景观框架，直接学习fMRI信号的连续精度矩阵，避免二值化信息损失，在合成和真实fMRI数据上优于传统二值模型。


<details>
  <summary>Details</summary>
Motivation: 传统能量景观模型依赖二值化脑状态表示，导致信息损失严重，且随着脑区数量增加，可能状态数指数增长，使得能量值计算不可行。

Method: 提出连续能量景观框架，使用图神经网络直接从fMRI信号学习连续精度矩阵，在能量景观计算中保留完整的信号值范围。

Result: 在合成数据（SLDS和Kuramoto模型）上，连续能量模型获得更高似然度，更准确恢复盆地几何、状态占据和转移动态。在真实fMRI数据上，工作记忆和执行功能预测AUC提高0.27，反应时间预测解释方差提高0.35。

Conclusion: 利用完整信号值的连续能量景观模型能更好捕捉神经元动态，对神经系统疾病的诊断和监测有重要意义。

Abstract: Energy landscape models characterize neural dynamics by assigning energy values to each brain state that reflect their stability or probability of occurrence. The conventional energy landscape models rely on binary brain state representation, where each region is considered either active or inactive based on some signal threshold. However, this binarization leads to significant information loss and an exponential increase in the number of possible brain states, making the calculation of energy values infeasible for large numbers of brain regions. To overcome these limitations, we propose a novel continuous energy landscape framework that employs Graph Neural Networks (GNNs) to learn a continuous precision matrix directly from functional MRI (fMRI) signals, preserving the full range of signal values during energy landscape computation. We validated our approach using both synthetic data and real-world fMRI datasets from brain tumor patients. Our results on synthetic data generated from a switching linear dynamical system (SLDS) and a Kuramoto model show that the continuous energy model achieved higher likelihood and more accurate recovery of basin geometry, state occupancy, and transition dynamics than conventional binary energy landscape models. In addition, results from the fMRI dataset indicate a 0.27 increase in AUC for predicting working memory and executive function, along with a 0.35 improvement in explained variance (R2) for predicting reaction time. These findings highlight the advantages of utilizing the full signal values in energy landscape models for capturing neuronal dynamics, with strong implications for diagnosing and monitoring neurological disorders.

</details>


### [16] [Autofocus Method for Human-Body Imaging under Respiratory Motion Using Synthetic Aperture Radar](https://arxiv.org/abs/2601.07099)
*Masaya Kato,Takuya Sakamoto*

Main category: eess.SP

TL;DR: 提出一种针对呼吸运动条件下人体SAR成像的有效自聚焦方法，通过分离空间-时间频域雷达回波并分别估计相位误差，显著提升图像质量。


<details>
  <summary>Details</summary>
Motivation: 在呼吸运动条件下，人体不同部位会产生不同的运动，导致传统合成孔径雷达成像方法难以对所有散射点同时聚焦，影响图像质量。

Method: 将雷达回波在空间和时间频率域进行分离，对每个分离后的回波分别估计相位误差，然后补偿这些误差以生成聚焦良好的SAR图像。

Result: 实验显示，与传统方法相比，该方法将Muller-Buffington锐度指标提升了5.1倍，并将相对于参考点云的均方根误差从34mm降低到20mm。

Conclusion: 该方法能有效抑制呼吸运动引起的相位误差，即使在人体不同部位存在不同运动的情况下，也能生成对所有散射点都聚焦良好的SAR图像。

Abstract: This study presents an effective autofocusing approach for synthetic aperture radar imaging of the human body under conditions of respiratory motion. The proposed method suppresses respiratory-motion-induced phase errors by separating radar echoes in the spatial- and time-frequency domains and estimating phase errors individually for each separated echo. By compensating for the estimated phase errors, synthetic aperture radar images focused on all scattering points are generated, even when multiple body parts exhibit different motions due to respiration. The performance of the proposed method is evaluated through experiments with four participants in the supine position. Compared with a conventional method, the proposed approach improves image quality by a factor of 5.1 in terms of Muller-Buffington sharpness, and reduces the root-mean-square error with respect to a reference point cloud from 34 mm to 20 mm.

</details>


### [17] [Antenna Coding Optimization for Pixel Antenna Empowered MIMO Wireless Power Transfer](https://arxiv.org/abs/2601.07324)
*Yijun Chen,Shanpu Shen,Tianrui Qiao,Hongyu Li,Kai-Kit Wong,Ross Murch*

Main category: eess.SP

TL;DR: 提出利用像素天线编码增强MIMO无线功率传输系统，通过联合优化天线编码、波束成形和整流器非线性，显著提升输出直流功率。


<details>
  <summary>Details</summary>
Motivation: 传统MIMO WPT系统使用固定天线配置，限制了性能提升。像素天线编码为系统提供了新的自由度，可以联合利用天线编码、波束成形和整流器非线性来增强输出直流功率。

Method: 1) 提出基于波束空间信道模型的MIMO WPT系统模型，支持二进制和连续天线编码；2) 使用非线性整流器模型制定联合天线编码和波束成形优化问题；3) 提出两种高效的闭式逐次凸逼近算法优化波束成形；4) 基于K-means聚类提出码本设计以降低计算复杂度。

Result: 二进制天线编码相比传统固定天线配置系统提升输出直流功率超过15dB；连续天线编码进一步改善6dB；提出的码本设计比先前设计性能提升达40%，且计算复杂度降低。

Conclusion: 像素天线编码为MIMO WPT系统提供了显著性能提升，验证了利用天线编码增强无线功率传输系统的潜力，特别是在输出直流功率方面取得了重大改进。

Abstract: We investigate antenna coding utilizing pixel antennas as a new degree of freedom for enhancing multiple-input multiple-output (MIMO) wireless power transfer (WPT) systems. The objective is to enhance the output direct current (DC) power under RF combining and DC combining schemes by jointly exploiting gains from antenna coding, beamforming, and rectenna nonlinearity. We first propose the MIMO WPT system model with binary and continuous antenna coding using the beamspace channel model and formulate the joint antenna coding and beamforming optimization using a nonlinear rectenna model. We propose two efficient closed-form successive convex approximation algorithms to efficiently optimize the beamforming. To further reduce the computational complexity, we propose codebook-based antenna coding designs for output DC power maximization based on K-means clustering. Results show that the proposed pixel antenna empowered MIMO WPT system with binary antenna coding increases output DC power by more than 15 dB compared with conventional systems with fixed antenna configuration. With continuous antenna coding, the performance improves another 6 dB. Moreover, the proposed codebook design outperforms previous designs by up to 40% and shows good performance with reduced computational complexity. Overall, the significant improvement in output DC power verifies the potential of leveraging antenna coding utilizing pixel antennas to enhance WPT systems.

</details>


### [18] [PIDT: Physics-Informed Digital Twin for Optical Fiber Parameter Estimation](https://arxiv.org/abs/2601.07436)
*Zicong Jiang,Magnus Karlsson,Erik Agrell,Christian Häger*

Main category: eess.SP

TL;DR: 提出物理信息数字孪生(PIDT)：一种结合参数化分步方法和物理信息损失的光纤参数估计方法，相比之前的神经算子具有更高精度、更快收敛速度和更低复杂度


<details>
  <summary>Details</summary>
Motivation: 传统光纤参数估计方法存在精度不足、收敛慢或复杂度高的问题，需要一种更高效准确的参数估计方法

Method: 结合参数化分步方法和物理信息损失函数，创建物理信息数字孪生模型进行光纤参数估计

Result: 相比之前的神经算子方法，PIDT在精度、收敛速度和复杂度方面都有显著改进

Conclusion: PIDT为光纤参数估计提供了一种更高效准确的方法，结合了物理模型和机器学习优势

Abstract: We propose physics-informed digital twin (PIDT): a fiber parameter estimation approach that combines a parameterized split-step method with a physics-informed loss. PIDT improves accuracy and convergence speed with lower complexity compared to previous neural operators.

</details>


### [19] [Vector Quantized-Aided XL-MIMO CSI Feedback with Channel Adaptive Transmission](https://arxiv.org/abs/2601.07584)
*Yuhang Ma,Nan Ma,Jianqiao Chen,Wenkai Liu*

Main category: eess.SP

TL;DR: 提出VQ-DJSCC-F方案，结合向量量化与深度联合信源信道编码，用于6G XL-MIMO系统的CSI反馈，在考虑近场效应下实现高精度低开销反馈。


<details>
  <summary>Details</summary>
Motivation: 6G XL-MIMO系统的大规模天线阵列导致CSI反馈开销巨大，现有量化方法面临量化精度有限和信道鲁棒性不足的双重挑战，特别是在压缩高维信道特征时。

Method: 1) 利用近场信道在极坐标-延迟域的稀疏性提取能量集中特征降维；2) 同时设计Transformer和CNN架构分层提取CSI特征；3) 使用VQ模块将特征投影到离散潜在空间；4) 引入熵损失正则化和EMA更新策略最大化量化精度；5) 开发注意力机制驱动的信道自适应模块减轻无线信道衰落对索引序列传输的影响。

Result: 仿真结果表明，所提方案在不同信道条件下实现了优越的CSI重建精度，同时具有更低的反馈开销。

Conclusion: VQ-DJSCC-F方案通过结合向量量化、深度联合信源信道编码和信道自适应机制，有效解决了XL-MIMO系统中CSI反馈的高精度和低开销需求，为6G近场通信提供了有效的解决方案。

Abstract: Efficient channel state information (CSI) feedback is critical for 6G extremely large-scale multiple-input multiple-output (XL-MIMO) systems to mitigate channel interference. However, the massive antenna scale imposes a severe burden on feedback overhead. Meanwhile, existing quantized feedback methods face dual challenges of limited quantization precision and insufficient channel robustness when compressing high-dimensional channel features into discrete symbols. To reduce these gaps, guided by the deep joint source-channel coding (DJSCC) framework, we propose a vector quantized (VQ)-aided scheme for CSI feedback in XL-MIMO systems considering the near-field effect, named VQ-DJSCC-F. Firstly, taking advantage of the sparsity of near-field channels in the polar-delay domain, we extract energy-concentrated features to reduce dimensionality. Then, we simultaneously design the Transformer and CNN (convolutional neural network) architectures as the backbones to hierarchically extract CSI features, followed by VQ modules projecting features into a discrete latent space. The entropy loss regularization in synergy with an exponential moving average (EMA) update strategy is introduced to maximize quantization precision. Furthermore, we develop an attention mechanism-driven channel adaptation module to mitigate the impact of wireless channel fading on the transmission of index sequences. Simulation results demonstrate that the proposed scheme achieves superior CSI reconstruction accuracy with lower feedback overheads under varying channel conditions.

</details>


### [20] [Learning to Unfold Fractional Programming for Multi-Cell MU-MIMO Beamforming with Graph Neural Networks](https://arxiv.org/abs/2601.07630)
*Zihan Jiao,Xinping Yi,Shi Jin*

Main category: eess.SP

TL;DR: 论文提出在MU-MIMO系统中，FP方法优化波束赋形有效但计算复杂，FastFP通过避免大维矩阵求逆降低复杂度，DeepFP通过学习展开FastFP算法实现更快收敛


<details>
  <summary>Details</summary>
Motivation: 在多小区多用户MIMO系统中，分数规划方法虽然能有效优化波束赋形向量，但面临计算复杂度高的问题，需要更高效的解决方案

Method: 提出两种改进方法：FastFP通过避免大维矩阵求逆来降低计算复杂度；DeepFP通过学习展开FastFP算法来加速收敛

Result: FastFP显著降低了计算复杂度，DeepFP进一步实现了更快的收敛速度

Conclusion: 通过FastFP和DeepFP方法，成功解决了传统FP方法在多小区MU-MIMO系统中的高计算复杂度问题，实现了更高效的波束赋形优化

Abstract: In the multi-cell multiuser multi-input multi-output (MU-MIMO) systems, fractional programming (FP) has demonstrated considerable effectiveness in optimizing beamforming vectors, yet it suffers from high computational complexity. Recent improvements demonstrate reduced complexity by avoiding large-dimension matrix inversions (i.e., FastFP) and faster convergence by learning to unfold the FastFP algorithm (i.e., DeepFP).

</details>


### [21] [Lagrangian Grid-based Estimation of Nonlinear Systems with Invertible Dynamics](https://arxiv.org/abs/2601.07721)
*Jindřich Duník,Jan Krejčí,Jakub Matoušek,Marek Brandner,Yeongkwon Choe*

Main category: eess.SP

TL;DR: 提出非线性拉格朗日网格滤波器，将计算复杂度从二次降低到对数线性，保持原网格滤波器的鲁棒性、准确性和确定性


<details>
  <summary>Details</summary>
Motivation: 解决非线性非高斯系统的状态估计问题，特别是贝叶斯递归关系的数值解。现有网格滤波器（GbF）在线性系统中表现良好，但需要扩展到非线性系统

Method: 基于最近开发的线性系统拉格朗日网格滤波器，扩展到具有可逆非线性动力学的系统。通过拉格朗日方法降低计算复杂度

Result: 提出的非线性拉格朗日GbF将标准GbF的计算复杂度从二次降低到对数线性，同时保持了原始GbF的所有优势：鲁棒性、准确性和确定性行为

Conclusion: 非线性拉格朗日网格滤波器在计算效率上显著优于标准网格滤波器，同时保持了良好的估计性能，为非线性非高斯系统状态估计提供了有效的数值解决方案

Abstract: This paper deals with the state estimation of non-linear and non-Gaussian systems with an emphasis on the numerical solution to the Bayesian recursive relations. In particular, this paper builds upon the Lagrangian grid-based filter (GbF) recently-developed for linear systems and extends it for systems with nonlinear dynamics that are invertible. The proposed nonlinear Lagrangian GbF reduces the computational complexity of the standard GbFs from quadratic to log-linear, while preserving all the strengths of the original GbF such as robustness, accuracy, and deterministic behaviour. The proposed filter is compared with the particle filter in several numerical studies using the publicly available MATLAB\textregistered\ implementation\footnote{https://github.com/pesslovany/Matlab-LagrangianPMF}.

</details>


### [22] [Tensor Decompositions for Online Grid-Based Terrain-Aided Navigation](https://arxiv.org/abs/2601.07728)
*J. Matoušek,J. Krejčí,J. Duník,R. Zanetti*

Main category: eess.SP

TL;DR: 提出一种实用的网格化状态估计方法，适用于具有可逆线性动力学和高度非线性测量的高维模型，通过利用可分解的模型结构实现实时估计


<details>
  <summary>Details</summary>
Motivation: 现有基于张量分解的方法大多停留在概念验证阶段，无法为高维模型提供实用解决方案。需要开发能够处理大状态维度、具有可分解结构模型的实时状态估计方法

Method: 采用拉格朗日公式进行时间更新，利用低秩张量分解紧凑表示和传播状态密度。利用块对角动力学和稀疏耦合测量维度等可分解模型结构，实现高效计算

Result: 该方法能够实现大状态维度模型的实时估计，显著扩展了网格化滤波器在传统低维应用之外的实际应用范围。计算复杂度和估计精度取决于模型的具体结构

Conclusion: 提出了一种实用且可扩展的网格化状态估计方法，虽然在地形辅助导航背景下演示，但适用于各种具有可分解结构的模型。提供了可复现的源代码

Abstract: This paper presents a practical and scalable grid-based state estimation method for high-dimensional models with invertible linear dynamics and with highly non-linear measurements, such as the nearly constant velocity model with measurements of e.g. altitude, bearing, and/or range. Unlike previous tensor decomposition-based approaches, which have largely remained at the proof-of-concept stage, the proposed method delivers an efficient and practical solution by exploiting decomposable model structure-specifically, block-diagonal dynamics and sparsely coupled measurement dimensions. The algorithm integrates a Lagrangian formulation for the time update and leverages low-rank tensor decompositions to compactly represent and effectively propagate state densities. This enables real-time estimation for models with large state dimension, significantly extending the practical reach of grid-based filters beyond their traditional low-dimensional use. Although demonstrated in the context of terrain-aided navigation, the method is applicable to a wide range of models with decomposable structure. The computational complexity and estimation accuracy depend on the specific structure of the model. All experiments are fully reproducible, with source code provided alongside this paper (GitHub link: https://github.com/pesslovany/Matlab-LagrangianPMF).

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [23] [Context Video Semantic Transmission with Variable Length and Rate Coding over MIMO Channels](https://arxiv.org/abs/2601.06059)
*Bingyan Xie,Yongpeng Wu,Wenjun Zhang,Derrick Wing Kwan Ng,Merouane Debbah*

Main category: cs.IT

TL;DR: 提出CVST框架，在MIMO信道下实现视频语义传输，通过上下文-信道关联映射和多参考熵编码机制，显著提升无线视频传输性能。


<details>
  <summary>Details</summary>
Motivation: 现有语义通信方案主要针对简单信道（AWGN或Rayleigh衰落）优化，忽略了实际部署中普遍存在的MIMO环境，这严重阻碍了实际应用。需要填补这一空白。

Method: 提出CVST框架：1）基于高效上下文视频传输骨干网络；2）学习上下文-信道关联映射，明确特征组与MIMO子信道关系；3）设计多参考熵编码机制，实现信道状态感知的变长编码；4）采用棋盘格特征调制策略，在单一训练模型中实现多速率点。

Result: CVST在性能上显著优于各种标准分离编码方法和最近的无线视频语义通信方法，展示了实质性性能提升。

Conclusion: CVST框架成功解决了MIMO环境下的视频语义传输问题，通过上下文-信道关联映射和多参考变长速率编码方案，为实际部署提供了灵活高效的解决方案。

Abstract: The evolution of semantic communications has profoundly impacted wireless video transmission, whose applications dominate driver of modern bandwidth consumption. However, most existing schemes are predominantly optimized for simple additive white Gaussian noise or Rayleigh fading channels, neglecting the ubiquitous multiple-input multiple-output (MIMO) environments that critically hinder practical deployment. To bridge this gap, we propose the context video semantic transmission (CVST) framework under MIMO channels. Building upon an efficient contextual video transmission backbone, CVST effectively learns a context-channel correlation map to explicitly formulate the relationships between feature groups and MIMO subchannels. Leveraging these channel-aware features, we design a multi-reference entropy coding mechanism, enabling channel state-aware variable length coding. Furthermore, CVST incorporates a checkerboard-based feature modulation strategy to achieve multiple rate points within a single trained model, thereby enhancing deployment flexibility. These innovations constitute our multi-reference variable length and rate coding (MR-VLRC) scheme. By integrating contextual transmission with MR-VLRC, CVST demonstrates substantial performance gains over various standardized separated coding methods and recent wireless video semantic communication approaches. The code is available at https://github.com/xie233333/CVST.

</details>


### [24] [Jamming Detection in Cell-Free MIMO with Dynamic Graphs](https://arxiv.org/abs/2601.06075)
*Ali Hossary,Laura Crosara,Stefano Tomasin*

Main category: cs.IT

TL;DR: 提出基于动态图和图卷积神经网络的干扰检测框架，用于无蜂窝大规模MIMO系统中的干扰攻击检测


<details>
  <summary>Details</summary>
Motivation: 干扰攻击对无线网络构成严重威胁，特别是在无蜂窝大规模MIMO系统中，分布式接入点和用户设备形成的复杂时变拓扑结构使得干扰检测更加困难

Method: 将网络建模为动态图以捕捉通信链路的演化，采用GCN-Transformer模型通过监督学习训练图嵌入来识别恶意干扰

Result: 在模拟场景中（包含移动用户设备、不同干扰条件和信道衰落）的性能评估显示，该方法在准确率和F1分数指标上取得了有希望的结果

Conclusion: 提出的动态图与GCN-Transformer结合的方法能够有效检测无蜂窝大规模MIMO系统中的干扰攻击

Abstract: Jamming attacks pose a critical threat to wireless networks, particularly in cell-free massive MIMO systems, where distributed access points and user equipment (UE) create complex, time-varying topologies. This paper proposes a novel jamming detection framework leveraging dynamic graphs and graph convolutional neural networks (GCN) to address this challenge. By modeling the network as a dynamic graph, we capture evolving communication links and detect jamming attacks as anomalies in the graph evolution. A GCN-Transformer-based model, trained with supervised learning, learns graph embeddings to identify malicious interference. Performance evaluation in simulated scenarios with moving UEs, varying jamming conditions and channel fadings, demonstrates the method's effectiveness, which is assessed through accuracy and F1 score metrics, achieving promising results for effective jamming detection.

</details>


### [25] [One if by Land, Two if by Sea, Three if by Four Seas, and More to Come -- Values of Perception, Prediction, Communication, and Common Sense in Decision Making](https://arxiv.org/abs/2601.06077)
*Aolin Xu*

Main category: cs.IT

TL;DR: 该论文为决策中的感知、预测、通信和常识价值提供了严格的决策论定义，这些定义与信息论量（如熵和互信息）具有数学相似性，并能回答自主决策系统设计中的实际问题。


<details>
  <summary>Details</summary>
Motivation: 论文旨在为决策过程中的感知、预测、通信和常识等概念提供严格的数学定义，这些概念在自主决策系统设计中至关重要，但缺乏形式化的理论框架。作者希望建立决策论与信息论之间的联系，并为实际系统设计提供指导。

Method: 作者采用决策论框架，定义了感知、预测、通信和常识的价值量。这些定义具有信息论类似物，与香农熵和互信息共享关键数学性质，并在特定设置下可简化为这些信息论量。通过理论分析揭示了感知与预测的相互作用。

Result: 研究发现：1）没有预测的感知价值可能为负值；2）感知与预测结合的价值以及单独预测的价值总是非负的。这些定义能够回答自主决策系统中的实际问题，如是否需要观察和预测特定智能体、其重要性如何、以及观察和预测的最佳顺序等。

Conclusion: 该研究为决策中的信息处理操作提供了形式化框架，建立了决策论与信息论的联系。定义的量不仅对自主决策系统设计有实用价值，还可能为认知科学和神经科学提供见解，帮助理解自然决策者如何利用不同来源和操作获得的信息。

Abstract: This work aims to rigorously define the values of perception, prediction, communication, and common sense in decision making. The defined quantities are decision-theoretic, but have information-theoretic analogues, e.g., they share some simple but key mathematical properties with Shannon entropy and mutual information, and can reduce to these quantities in particular settings. One interesting observation is that, the value of perception without prediction can be negative, while the value of perception together with prediction and the value of prediction alone are always nonnegative. The defined quantities suggest answers to practical questions arising in the design of autonomous decision-making systems. Example questions include: Do we need to observe and predict the behavior of a particular agent? How important is it? What is the best order to observe and predict the agents? The defined quantities may also provide insights to cognitive science and neural science, toward the understanding of how natural decision makers make use of information gained from different sources and operations.

</details>


### [26] [Deep Q-Network Based Resilient Drone Communication:Neutralizing First-Order Markov Jammers](https://arxiv.org/abs/2601.06095)
*Andrii Grekhov,Volodymyr Kharchenko,Vasyl Kondratiuk*

Main category: cs.IT

TL;DR: 基于深度强化学习的抗干扰通信解决方案，在16信道环境中使用跳频扩频技术对抗一阶反应式干扰，通过自训练学习均匀随机跳频策略，结合前向纠错码显著降低丢包率。


<details>
  <summary>Details</summary>
Motivation: 现代电子战场景中，通信系统面临智能干扰威胁，传统跳频策略可能被预测和干扰。需要开发自主、弹性的通信方案来对抗能够学习并预测传输模式的智能干扰器。

Method: 采用深度Q网络（DQN）作为发射机，在16信道环境中连续选择下一个跳频信道。面对一阶反应式干扰（利用观测到的转移统计来预测和中断传输），通过自训练学习策略。系统评估了瑞利衰落和加性噪声环境下，Bose Chaudhuri Hocquenghem（BCH）前向纠错码的影响。

Result: 提出的智能体学习到了均匀随机跳频策略，有效抵消了干扰器的预测优势。即使中等冗余度的前向纠错码也能显著减少丢包。学习动态、信道利用分布、epsilon贪婪衰减、累积奖励、BER和SNR演化以及详细丢包表都证实了收敛到接近最优的抗干扰策略。

Conclusion: 该研究为现代电子战场景中的自主弹性通信提供了实用框架，证明了深度强化学习结合前向纠错码能够有效对抗智能干扰，实现可靠的通信保障。

Abstract: Deep Reinforcement Learning based solution for jamming communications using Frequency Hopping Spread Spectrum technology in a 16 channel radio environment is presented. Deep Q Network based transmitter continuously selects the next frequency hopping channel while facing first order reactive jamming, which uses observed transition statistics to predict and interrupt transmissions. Through self training, the proposed agent learns a uniform random frequency hopping policy that effectively neutralizes the predictive advantage of the jamming. In the presence of Rayleigh fading and additive noise, the impact of forward error correction Bose Chaudhuri Hocquenghem type codes is systematically evaluated, demonstrating that even moderate redundancy significantly reduces packet loss. Extensive visualization of the learning dynamics, channel utilization distribution, epsilon greedy decay, cumulative reward, BER and SNR evolution, and detailed packet loss tables confirms convergence to a near optimal jamming strategy. The results provide a practical framework for autonomous resilient communications in modern electronic warfare scenarios.

</details>


### [27] [Optimal Beamforming for Uplink Covert Communication in MIMO GEO Satellite-Terrestrial Systems](https://arxiv.org/abs/2601.06110)
*Zewei Guo,Ranran Sun,Yulong Shen,Xiaohong Jiang*

Main category: cs.IT

TL;DR: 该论文研究了MIMO卫星-地面系统中的上行隐蔽通信，提出了基于波束成形和天线方向设置的隐蔽传输方案，并在完美和不完美信道估计两种场景下进行了性能建模和优化设计。


<details>
  <summary>Details</summary>
Motivation: 随着卫星通信的广泛应用，确保卫星-地面系统通信的隐蔽性变得越来越重要。现有研究主要关注地面隐蔽通信，对卫星-地面系统的隐蔽通信研究不足，特别是在多天线MIMO场景下。

Method: 1. 提出基于波束成形和默认天线方向的Alice-Bob上行隐蔽传输方案
2. 在完美信道估计场景下：建立检测错误概率、传输中断概率和隐蔽率的理论模型，探索最优波束成形设计和联合最优波束成形-天线方向设计
3. 在不完美信道估计场景下：扩展性能建模和优化设计
4. 应用半定松弛、交替优化、罗德里格斯旋转公式和一维搜索算法解决优化问题

Result: 1. 建立了MIMO卫星-地面系统上行隐蔽通信的理论性能模型
2. 开发了有效的优化算法解决波束成形和天线方向设计问题
3. 数值结果验证了理论分析，并证明了波束成形和天线方向设计对提升MIMO GEO卫星-地面系统上行隐蔽通信效率的有效性

Conclusion: 该论文成功解决了MIMO卫星-地面系统中的上行隐蔽通信问题，提出的波束成形和天线方向设计方案能有效提升隐蔽通信性能，为卫星隐蔽通信系统设计提供了理论和技术支持。

Abstract: This paper investigates the uplink covert communication in a multiple-input multiple-output (MIMO) satellite-terrestrial system consisting of an Earth station transmitter Alice, a geosynchronous Earth orbit (GEO) satellite receiver Bob, and multiple GEO satellite wardens around Bob, where each node in the system is equipped with an array of directional antennas. Based on beamforming and the default antenna orientation setting, we first propose a scheme for covert Alice-Bob uplink transmission. Under the perfect channel estimation scenario, we provide theoretical modeling for the system performance in terms of detection error probability (DEP), transmission outage probability (TOP) and covert rate (CR), and then explore the optimal beamforming (OB) design as well as the joint optimal beamforming and antenna orientation (JO-BA) design for CR maximization. We then extend our study to the imperfect channel estimation scenario, and conduct related performance modeling and OB/JO-BA designs for CR maximization. We also apply the techniques of semidefinite relaxation, alternating optimization, Rodrigues' rotation formula and 1-D search algorithm to develop efficient algorithms to solve the above optimization problems. Finally, extensive numerical results are presented to verify our theoretical results and to illustrate the efficiency of beamforming and antenna orientation design for supporting the uplink covert communication in MIMO GEO satellite-terrestrial systems.

</details>


### [28] [Range-Coder with fast Adaptation and Table-Based Decoding](https://arxiv.org/abs/2601.06120)
*Tilo Strutz,Roman Rischke*

Main category: cs.IT

TL;DR: 提出一种基于环形缓冲区的自适应表解码方法，通过位运算替代除法，显著加速区间编码过程


<details>
  <summary>Details</summary>
Motivation: 传统区间熵编码方法（如算术编码、范围编码、ANS）在解码时需要进行搜索操作，虽然已有O(1)复杂度的表解码方法，但符号统计的自适应更新会因表调整耗时过长而不可行

Method: 使用环形缓冲区技术实现自适应表解码过程，同时在编码器和解码器核心例程中用位运算替代除法操作

Result: 静态模式下编码时间减少约40%；自适应模式下，对于12-64个不同符号的字母表，整体编码+解码时间快于其他方法

Conclusion: 提出的环形缓冲区自适应表解码方法有效解决了传统表解码中自适应更新耗时的问题，显著提升了区间熵编码的性能

Abstract: The transmission or storage of signals typically involves data compression. The final processing step in compression systems is generally an entropy coding stage, which converts symbols into a bit stream based on their probability distribution. A distinct class of entropy coding methods operates not by mapping input symbols to discrete codewords but by operating on intervals or ranges. This approach enables a more accurate approximation of the source entropy, particularly for sources with highly skewed or varying symbol distributions. Representative techniques in this category include traditional arithmetic coding, range coding, and methods based on asymmetric numeral systems (ANS). The complexity of these methods depends mainly on three processing steps: the core routines of encoding and decoding doing the calculations, the interval-based determination of the correct symbol at decoder, and the efforts of keeping updated with respect to the varying symbol distribution.
  The interval-based symbol determination at decoder typically demands for a searching procedure. In previous literature, it could be shown that the search can be replaced by a table-based approach with only O(1)-complexity but having the side-effect that the adaptation of the symbols statistic becomes infeasible because of the high time-consumption of adapting the table.
  We propose an adaptation process using a ring-buffer technique enabling the adaptive table-based decoding procedure as well as the replacement of a division by a bit-shift operation at encoder and decoder core routines. This accelerates the coding process significantly. In static (non-adaptive) mode, the coding time can be reduced by about 40 percent. In adaptive mode, the proposed technique is faster than alternative approaches for alphabets from about 12 to 64 different symbol when comparing the overall encoder+decoder time.

</details>


### [29] [Extended Target Adaptive Beamforming for ISAC:A Perspective of Predictive Error Ellipse](https://arxiv.org/abs/2601.06125)
*Shengcai Zhou,Luping Xiang,Yi Wang,Kun Yang,Kai Kit Wong,Chan-Byoung Chae*

Main category: cs.IT

TL;DR: 该论文推导了OFDM波形和UPA配置下雷达参数估计的CRB，并针对V2X网络中车辆作为扩展目标的情况，提出了两种NR-V2X兼容的波束赋形方案，分别用于初始波束建立阶段和波束调整阶段，显著提高了通信速率。


<details>
  <summary>Details</summary>
Motivation: 利用通信信号提取运动参数已成为V2X网络的关键方向。准确建模通信信号与感知性能之间的关系对系统发展至关重要。现有工作主要依赖定性分析，缺乏定量理论支撑。

Method: 1. 推导OFDM波形和UPA配置下的雷达参数估计CRB；2. 针对扩展目标车辆，提出两种NR-V2X兼容波束赋形方案：初始阶段基于预测误差椭圆并集的波束赋形，调整阶段基于散射体和通信接收机位置的自适应最窄波束策略；3. 使用最小包围椭圆算法和定制天线控制方法解决波束设计问题。

Result: 仿真验证表明，在相同SNR条件下，与传统的波束扫描相比：使用32*32发射天线阵列时，可实现速率提高32.4%；使用8*8阵列时，可实现速率提高5.2%。

Conclusion: 该研究为V2X网络中通信信号与感知性能的关系提供了定量理论分析框架，提出的波束赋形方案能有效提高系统性能，特别是在大规模天线阵列下效果显著，为未来V2X网络设计提供了重要参考。

Abstract: Utilizing communication signals to extract motion parameters has emerged as a key direction in Vehicle-to- Everything (V2X) networks. Accurately modeling the relationship between communication signals and sensing performance is critical for the advancement of such systems. Unlike prior work that relies primarily on qualitative analysis, this paper derives the Cramér-Rao Bound (CRB) for radar parameter estimation in the context of Orthogonal Frequency Division Multiplexing (OFDM) waveforms and Uniform Planar Array (UPA) configurations. Recognizing that vehicles may act as extended targets, we propose two New Radio (NR)-V2X-compatible beamforming schemes tailored to different phases of the communication process. During the initial beam establishment phase, we develop a beamforming approach based on the union of predictive error ellipses, which enhances scatterer localization through temporally assisted beam training. In the beam adjustment phase, we introduce an adaptive narrowest-beam strategy that leverages the positions of scatterers and the communication receiver (CR), enabling effective tracking with reduced complexity. The beam design problem is addressed using the minimum enclosing ellipse algorithm and tailored antenna control methods. Simulation results validate the proposed approach, showing up to a 32.4% improvement in achievable rate with a 32*32 transmit antenna array and a 5.2% gain with an 8*8 array, compared to conventional beam sweeping under identical SNR conditions.

</details>


### [30] [Channel Knowledge Map Construction via Guided Flow Matching](https://arxiv.org/abs/2601.06156)
*Ziyu Huang,Yong Zeng,Shen Fu,Xiaoli Xu,Hongyang Du*

Main category: cs.IT

TL;DR: 提出基于线性传输引导流匹配(LT-GFM)的新框架，用于高效构建信道知识地图(CKM)，相比扩散模型推理速度提升25倍


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散模型(如DDPM)的CKM构建方法依赖迭代随机采样，推理速度过慢，难以满足无线网络实时应用需求

Method: 采用线性传输引导流匹配(LT-GFM)，将CKM生成建模为确定性常微分方程(ODE)，遵循线性最优传输路径；提出统一架构支持信道增益地图(CGM)和空间相关地图(SCM)构建；集成环境语义(如建筑掩码)实现物理信息约束

Result: LT-GFM在分布保真度上显著优于DDPM(FID更低)，推理速度比DDPM快25倍

Conclusion: LT-GFM框架在保持高保真度的同时大幅提升CKM构建效率，为环境感知无线网络的实时应用提供了可行解决方案

Abstract: The efficient construction of accurate channel knowledge maps (CKMs) is crucial for unleashing the full potential of environment-aware wireless networks, yet it remains a difficult ill-posed problem due to the sparsity of available location-specific channel knowledge data. Although diffusion-based methods such as denoising diffusion probabilistic models (DDPMs) have been exploited for CKM construction, they rely on iterative stochastic sampling, rendering them too slow for real-time wireless applications. To bridge the gap between high fidelity and efficient CKM construction, this letter introduces a novel framework based on linear transport guided flow matching (LT-GFM). Deviating from the noise-removal paradigm of diffusion models, our approach models the CKM generation process as a deterministic ordinary differential equation (ODE) that follows linear optimal transport paths, thereby drastically reducing the number of required inference steps. We propose a unified architecture that is applicable to not only the conventional channel gain map (CGM) construction, but also the more challenging spatial correlation map (SCM) construction. To achieve physics-informed CKM constructions, we integrate environmental semantics (e.g., building masks) for edge recovery and enforce Hermitian symmetry for property of the SCM. Simulation results verify that LT-GFM achieves superior distributional fidelity with significantly lower Fréchet Inception Distance (FID) and accelerates inference speed by a factor of 25 compared to DDPMs.

</details>


### [31] [Large Multimodal Model-Aided Scheduling for 6G Autonomous Communications](https://arxiv.org/abs/2601.06211)
*Sunwoo Kim,Byonghyo Shim*

Main category: cs.IT

TL;DR: 提出基于大型多模态模型（LMM）的调度技术，通过视觉感知和导频信号预测未来信道参数，实现预判性信道感知调度，在6G环境中提升吞吐量30%以上。


<details>
  <summary>Details</summary>
Motivation: 随着AI功能在自主设备中的指数级增长，中央单元需要处理LMM来有效控制设备。在6G环境中，用户微小移动可能导致信道突变，传统调度技术难以应对这种挑战。

Method: 利用LMM分析视觉感知信息和导频信号，预测未来信道参数（距离、角度、路径增益）。通过LMM从视觉信息预测可靠路径存在和用户几何信息，结合导频信号的过去信道状态，准确预测未来信道参数，实现预判性信道感知调度决策。

Result: 数值评估显示，所提技术相比传统调度技术实现了超过30%的吞吐量增益。

Conclusion: 提出的LMM-based调度技术能有效应对6G环境中信道突变挑战，通过预测未来信道参数实现预判性调度，显著提升系统吞吐量。

Abstract: Recently, large language models (LLMs) have gained significant attention for their ability to generate fast and accurate answer to the given query. These models have evolved into large multimodal models (LMMs), which can interpret and analyze multimodal inputs such as images and text. With the exponential growth of AI functionalities in autonomous devices, the central unit (CU), a digital processing unit performing AI inference, needs to handle LMMs to effectively control these devices. To ensure seamless command delivery to devices, the CU must perform the scheduling, which involves resource block (RB) allocation for data transmission and modulation and coding scheme (MCS) index selection based on the channel conditions. This task is challenging in many practical environments in 6G, where even small user movement can cause abrupt channel changes. In this paper, we propose a novel LMM-based scheduling technique to address this challenge. Our key idea is to leverage LMM to predict future channel parameters (e.g., distance, angles, and path gain) by analyzing the visual sensing information as well as pilot signals. By exploiting LMMs to predict the presence of reliable path and geometric information of users from the visual sensing information, and then combining these with past channel states from pilot signals, we can accurately predict future channel parameters. Using these predictions, we can preemptively make channel-aware scheduling decisions. From the numerical evaluations, we show that the proposed technique achieves more than 30% throughput gain over the conventional scheduling techniques.

</details>


### [32] [Robust and Secure Blockage-Aware Pinching Antenna-assisted Wireless Communication](https://arxiv.org/abs/2601.06430)
*Ruotong Zhao,Shaokang Hu,Deepak Mishra,Derrick Wing Kwan Ng*

Main category: cs.IT

TL;DR: 提出一种针对阻塞感知的捏合天线系统，在存在多天线窃听者和不完美CSI的情况下，通过联合优化波束成形、人工噪声、天线功率分配和位置，实现安全鲁棒的无线通信。


<details>
  <summary>Details</summary>
Motivation: 传统线性CSI误差边界对于空间分布的天线架构过于保守，且固定天线系统在面对阻塞效应时性能受限，需要设计能适应阻塞效应并利用天线几何结构的安全通信方案。

Method: 开发几何感知的不确定性集合来联合表征窃听者位置和阵列方向误差；提出基于块坐标下降、惩罚方法、MM算法、S-过程和Lipschitz代理函数的低复杂度迭代算法，联合优化波束成形、AN协方差、天线功率比分配和位置。

Result: 所提算法相比传统固定天线系统提升4.7dB的和速率，自适应天线定位能保持对合法用户的视距连接，同时利用波导几何结构破坏窃听信道；忽略阻塞效应会导致性能下降和安全保障不足。

Conclusion: 提出的阻塞感知捏合天线系统通过几何感知的鲁棒设计和自适应天线定位，在存在窃听者和不完美CSI的情况下，实现了显著提升的和速率和安全性能，验证了考虑阻塞效应的重要性。

Abstract: In this work, we investigate a blockage-aware pinching antenna (PA) system designed for secure and robust wireless communication. The considered system comprises a base station equipped with multiple waveguides, each hosting multiple PAs, and serves multiple single-antenna legitimate users in the presence of multi-antenna eavesdroppers under imperfect channel state information (CSI). To safeguard confidential transmissions, artificial noise (AN) is deliberately injected to degrade the eavesdropping channels. Recognizing that conventional linear CSI-error bounds become overly conservative for spatially distributed PA architectures, we develop new geometry-aware uncertainty sets that jointly characterize eavesdroppers position and array-orientation errors. Building upon these sets, we formulate a robust joint optimization problem that determines per-waveguide beamforming and AN covariance, individual PA power-ratio allocation, and PA positions to maximize the system sum rate subject to secrecy constraints. The highly non-convex design problem is efficiently addressed via a low computational complexity iterative algorithm that capitalizes on block coordinate descent, penalty-based methods, majorization-minimization, the S-procedure, and Lipschitz-based surrogate functions. Simulation results demonstrate that sum rates for the proposed algorithm outperforms conventional fixed antenna systems by 4.7 dB, offering substantially improved rate and secrecy performance. In particular, (i) adaptive PA positioning preserves LoS to legitimate users while effectively exploiting waveguide geometry to disrupt eavesdropper channels, and (ii) neglecting blockage effects in the PA system significantly impacts the system design, leading to performance degradation and inadequate secrecy guarantees.

</details>


### [33] [Error correction methods based on two-faced processes](https://arxiv.org/abs/2601.06447)
*Boris Ryabko*

Main category: cs.IT

TL;DR: 提出一种新的通信信道纠错方法，通过增加符号间相互依赖性来显著降低误码率，编解码复杂度为线性


<details>
  <summary>Details</summary>
Motivation: 解决通信信道中的纠错问题，传统方法可能效率不高或复杂度较高，需要一种能显著降低误码率且复杂度可控的新方法

Method: 通过变换输入序列，显著增加符号间的相互依赖性，在信道传输后利用这种特性进行纠错

Result: 剩余误码率显著降低，编码和解码的复杂度为线性

Conclusion: 该方法提供了一种高效的纠错方案，在保持线性复杂度的同时显著改善了误码率性能

Abstract: A new approach to the problem of error correction in communication channels is proposed, in which the input sequence is transformed in such a way that the interdependence of symbols is significantly increased. Then, after the sequence is transmitted over the channel, this property is used for error correction so that the remaining error rate is significantly reduced. The complexity of encoding and decoding is linear.

</details>


### [34] [Function-Correcting Partition codes](https://arxiv.org/abs/2601.06450)
*Charul Rajput,B. Sundar Rajan,Ragnar Freij-Hollanti,Camilla Hollanti*

Main category: cs.IT

TL;DR: 本文引入函数校正分区码(FCPCs)，作为函数校正码(FCCs)的自然推广，用于同时保护多个函数并节省带宽。


<details>
  <summary>Details</summary>
Motivation: 现有的函数校正码(FCCs)只能保护单个函数，当需要保护多个函数时，需要为每个函数单独构建编码，导致带宽效率低下。本文旨在开发一种统一的编码框架，能够同时保护多个函数，从而节省带宽资源。

Method: 1. 定义函数校正分区码(FCPCs)作为FCCs的推广，基于域分区构建系统映射；2. 使用域分区的连接构造同时保护多个函数的单一编码；3. 引入分区冗余增益和分区速率增益来衡量带宽节省；4. 针对线性函数，通过核的交集的陪集分区进行专门化；5. 构建分区图，通过寻找合适团来获得最优冗余；6. 引入块保持收缩概念来简化寻找最优冗余的问题。

Result: 1. 证明了任何t-错误校正函数码((f,t)-FCC)都是相对于由f诱导的域分区的FCPC；2. 展示了在权重分区和支持分区的分区图中存在全尺寸团，从而获得最优冗余；3. 提出的FCPCs框架能够同时保护多个函数，节省带宽；4. FCPCs提供了部分隐私保护，因为只需要向发送方揭示函数的域分区。

Conclusion: 函数校正分区码(FCPCs)是函数校正码(FCCs)的有效推广，能够同时保护多个函数，显著节省带宽。通过分区图分析和块保持收缩技术，可以获得最优冗余编码。此外，FCPCs还提供了部分隐私保护的优势，在实际应用中具有重要价值。

Abstract: We introduce function-correcting partition codes (FCPCs) that are a natural generalization of function-correcting codes (FCCs). A $t$-error function-correcting partition code is an $(\mathcal{P},t)$-encoding defined directly on a partition $\mathcal{P}$ of $\mathbb{F}_q^k$. For a partition $\mathcal{P}=\{P_1,P_2,\ldots,P_E\}$ a systematic mapping $\mathcal{C}_{\mathcal{P}} : \mathbb{F}_q^k \rightarrow \mathbb{F}_q^{k+r}$ is called a \emph{$(\mathcal{P},t)$-encoding} if for all $u\in P_i$ and $v\in P_j$ with $i\neq j$, $d\big(\mathcal{C}_{\mathcal{P}}(u), \mathcal{C}_{\mathcal{P}}(v)\big)\ge 2t+1.$ We show that any $t$-error correcting code for a function $f$, denoted by $(f,t)$-FCC is exactly an FCPC with respect to the domain partition induced by $f$, which makes these codes a natural generalization of FCCs. We use the join of domain partitions to construct a single code that protects multiple functions simultaneously. We define the notion of partition redundancy gain and partition rate gain to measure the bandwidth saved by using a single FCPC for multiple functions instead of constructing separate FCCs for each function. We specialize this to linear functions via coset partition of the intersection of their kernels. Then, we associate a partition graph to any given partition of $\mathbb{F}_q^k$, and show that the existence of a suitable clique in this graph yields a set of representative information vectors that achieves the optimal redundancy. We showed the existence of a full-size clique in the partition graphs of weight partition and support partition. Finally, we introduce the notion of a block-preserving contraction for a partition, which helps reduce the problem of finding optimal redundancy for an FCPC. We observe that FCPCs naturally provide a form of partial privacy, in the sense that only the domain partition of the function needs to be revealed to the transmitter.

</details>


### [35] [Algorithms for Computing the Petz-Augustin Capacity](https://arxiv.org/abs/2601.06492)
*Chun-Neng Chu,Wei-Fu Tseng,Yen-Huan Li*

Main category: cs.IT

TL;DR: 提出首个具有非渐近收敛保证的算法，用于计算Petz-Augustin容量，该容量推广了信道容量并刻画了经典-量子信道编码的最优误差指数。


<details>
  <summary>Details</summary>
Motivation: Petz-Augustin容量作为信道容量的推广，在经典-量子信道编码中表征最优误差指数，但之前缺乏具有非渐近收敛保证的高效计算方法。

Method: 1. 对于Petz-Rényi信息最大化：利用凸Hölder-光滑优化问题特性，应用Nesterov的通用快速梯度法；2. 对于Petz-Augustin信息最大化：采用双层方法，将目标函数相对于负香农熵视为光滑函数，用熵镜像下降法优化，每步通过新的不动点算法计算Petz-Augustin信息。

Result: 为Petz-Augustin容量计算提供了首个具有非渐近收敛保证的算法，建立了不动点算法的Thompson度量收缩性，将He等人(2024)的Blahut-Arimoto算法镜像下降解释推广到量子情形。

Conclusion: 本文为计算Petz-Augustin容量提供了高效且理论保证的算法框架，解决了经典-量子信道编码中关键容量计算问题，将经典信息论优化方法成功推广到量子领域。

Abstract: We propose the first algorithms with non-asymptotic convergence guarantees for computing the Petz-Augustin capacity, which generalizes the channel capacity and characterizes the optimal error exponent in classical-quantum channel coding. This capacity can be equivalently expressed as the maximization of two generalizations of mutual information: the Petz-Rényi information and the Petz-Augustin information. To maximize the Petz-Rényi information, we show that it corresponds to a convex Hölder-smooth optimization problem, and hence the universal fast gradient method of Nesterov (2015), along with its convergence guarantees, readily applies. Regarding the maximization of the Petz-Augustin information, we adopt a two-layered approach: we show that the objective function is smooth relative to the negative Shannon entropy and can be efficiently optimized by entropic mirror descent; each iteration of entropic mirror descent requires computing the Petz-Augustin information, for which we propose a novel fixed-point algorithm and establish its contractivity with respect to the Thompson metric. Notably, this two-layered approach can be viewed as a generalization of the mirror-descent interpretation of the Blahut-Arimoto algorithm due to He et al. (2024).

</details>


### [36] [On the Number of Subsequences in the Nonbinary Deletion Channel](https://arxiv.org/abs/2601.06493)
*Han Li,Xiang Wang,Fang-Wei Fu*

Main category: cs.IT

TL;DR: 研究非二进制字符串在删除信道中经过t次删除后的子序列数量，提出了r-run非二进制字符串子序列数量的改进边界，并找到了具有最大子序列数的字符串族。


<details>
  <summary>Details</summary>
Motivation: 在删除信道中，确定长度为n的字符串U经过t次删除后产生的子序列数量是一个重要问题。已知子序列数量与字符串的run数（连续相同字符的最大子串）密切相关，但现有研究主要针对二进制字符串，对非二进制字符串的研究不足。

Method: 研究非二进制字符串在删除信道中的子序列数量问题，分析r-run非二进制字符串的特性，推导子序列数量的边界条件，并识别出在任意t次删除下具有最大子序列数的字符串族。

Result: 提出了r-run非二进制字符串子序列数量的改进边界，表征了在任意t次删除下具有最大子序列数的字符串族，并证明该数量可以在多项式时间内计算。

Conclusion: 该研究扩展了删除信道中子序列数量问题的理论框架，为非二进制字符串提供了更精确的边界分析，并识别了具有最大子序列数的优化字符串结构，为相关应用提供了理论基础。

Abstract: In the deletion channel, an important problem is to determine the number of subsequences derived from a string $U$ of length $n$ when subjected to $t$ deletions. It is well-known that the number of subsequences in the setting exhibits a strong dependence on the number of runs in the string $U$, where a run is defined as a maximal substring of identical characters. In this paper we study the number of subsequences of a non-binary string in this scenario, and propose some improved bounds on the number of subsequences of $r$-run non-binary strings. Specifically, we characterize a family of $r$-run non-binary strings with the maximum number of subsequences under any $t$ deletions, and show that this number can be computed in polynomial time.

</details>


### [37] [Coding for Fading Channels with Imperfect CSI at the Transmitter and Quantized Feedback](https://arxiv.org/abs/2601.06501)
*Yuhan Yang,Haoheng Yuan,Chao Qi,Fan Cheng,Bin Dai*

Main category: cs.IT

TL;DR: 该论文针对具有记忆的信道模型，提出了两种基于Schalkwijk-Kailath方案的扩展：1）针对2路径准静态衰落信道设计SK型方案，利用第二路径信号作为中继增强传输速率；2）针对任意多径衰落信道，提出将时域信道转换为频域MIMO信道的SK型方案。


<details>
  <summary>Details</summary>
Motivation: 经典Schalkwijk-Kailath方案在高斯噪声信道中具有极低的编码复杂度和双指数衰减的解码错误率，但如何将其扩展到具有记忆的信道模型尚未解决。论文旨在解决这一扩展问题。

Method: 1）针对2路径准静态衰落信道：将第二路径信号视为中继，采用放大转发策略，利用干扰路径信号增强传输速率；2）针对任意多径衰落信道：提出SK型方案，将时域信道转换为频域MIMO信道进行处理。

Result: 论文展示了第二路径信号可以作为中继帮助增强传输速率，并提出了适用于多径衰落信道的SK型方案，成功将时域信道转换为频域MIMO信道。

Conclusion: 该研究成功将经典的SK方案扩展到具有记忆的信道模型，为2路径和多径衰落信道提供了有效的SK型编码方案，解决了该领域长期存在的问题。

Abstract: The classical Schalkwijk-Kailath (SK) scheme for the additive Gaussian noise channel with noiseless feedback is highly efficient since its coding complexity is extremely low and the decoding error doubly exponentially decays as the coding blocklength tends to infinity. However, how to extend the SK scheme to channel models with memory has yet to be solved. In this paper, we first investigate how to design SK-type scheme for the 2-path quasi-static fading channel with noiseless feedback. By viewing the signal of the second path as a relay and adopting an amplify-and-forward (AF) relay strategy, we show that the interference path signal can help to enhance the transmission rate. Besides this, for arbitrary multi-path fading channel with feedback, we also present an SK-type scheme for such a model, which
  transforms the time domain channel into a frequency domain MIMO channel.

</details>


### [38] [Some New Results on Sequence Reconstruction Problem for Deletion Channels](https://arxiv.org/abs/2601.06503)
*Xiang Wang,Weijun Fang,Han Li,Fang-Wei Fu*

Main category: cs.IT

TL;DR: 该论文解决了序列重构问题中的一个开放性问题，证明了当n≥13时，N(n,3,4)=20n-166，并给出了N(n,3,t)的下界。


<details>
  <summary>Details</summary>
Motivation: 序列重构问题由Levenshtein在2001年提出，在组合学中相当于确定N(n,d,t)的值。Pham、Goyal和Kiah提出了一个开放性问题：确定N(n,3,4)的确切值。本文旨在解决这个问题。

Method: 作者通过组合数学方法，为N(n,3,t)（当n≥13且t≥4时）建立了一个下界。特别地，对于t=4的情况，他们证明了该下界是紧的。

Result: 主要结果是：对于所有n≥13，N(n,3,4)=20n-166。这解决了Pham等人提出的开放性问题。同时，论文还给出了N(n,3,t)在更一般情况下的下界。

Conclusion: 该研究完全解决了序列重构问题中关于N(n,3,4)的开放性问题，证明了其精确表达式为20n-166（n≥13），为相关组合问题的研究提供了重要进展。

Abstract: Levenshtein first introduced the sequence reconstruction problem in $2001$. In the realm of combinatorics, the sequence reconstruction problem is equivalent to determining the value of $N(n,d,t)$, which represents the maximum size of the intersection of two metric balls of radius $t$, given that the distance between their centers is at least $d$ and the sequence length is $n$. In this paper, We present a lower bound on $N(n,3,t)$ for $n\geq 13$ and $t \geq 4$. For $t=4$, we prove that this lower bound is tight. This settles an open question posed by Pham, Goyal, and Kiah, confirming that $N(n,3,4)=20n-166$ for all $n \geq 13$.

</details>


### [39] [Visible Light Communication using Led-Based AR Markers for Robot Localization](https://arxiv.org/abs/2601.06527)
*Wataru Uemura,Shogo Kawasaki*

Main category: cs.IT

TL;DR: 提出一种将ArUco标记实现为照明形式的方法，通过LED阵列按标记网格排列，利用人眼无法察觉的闪烁频率差异编码信息，使标记在保持均匀亮度的同时能被相机识别。


<details>
  <summary>Details</summary>
Motivation: 随着移动机器人在日常环境中的广泛应用，视觉标记在机器人定位中扮演重要角色。在人机协作环境中（如工厂单元制造系统或家庭伴侣机器人），需要设计既自然又不显眼的标记，以减少对人类用户的干扰。

Method: 将LED按照ArUco标记的网格模式排列，每个LED的闪烁频率根据对应网格单元的黑白状态确定。人眼看到的是均匀亮度，而相机可以捕捉闪烁频率的差异，从而重建黑白模式并识别标记信息。

Result: 开发了原型系统，并通过实验评估了在不同距离和视角下对ArUco标记的识别准确率，验证了该方法的可行性。

Conclusion: 提出的照明式ArUco标记方法能够在保持对人眼友好的外观的同时，为机器人提供可靠的定位信息，适用于人机协作环境。

Abstract: A method of information transmission using visual markers has been widely studied. In this approach, information or identifiers (IDs) are encoded in the black-and-white pattern of each marker. By analyzing the geometric properties of the marker frame - such as its size, distortion, and coordinates - the relative position and orientation between the camera and the marker can be estimated. Furthermore, by associating the positional information of each marker with its corresponding ID, the position of the camera that takes the image picture can be calculated. In the field of mobile robotics, such markers are commonly utilized for robot localization. As mobile robots become more widely used in everyday environments, such visual markers are expected to be utilized across various contexts. In environments where robots collaborate with humans - such as in cell-based manufacturing systems in factories or in domestic settings with partner robots - it is desirable for such markers to be designed in a manner that appears natural and unobtrusive to humans. In this paper, we propose a method for implementing an ArUco marker in the form of illumination. In the proposed method, LEDs are arranged in accordance with the grid pattern of the marker, and the blinking frequency of each LED is determined based on the corresponding black or white cell. As a result, the illumination appears uniformly bright to the human eye, while the camera can capture variations in the blinking frequency. From these differences, the black-and-white pattern can be reconstructed, enabling the identification of the marker's tag information. We develop a prototype system, and conduct experiments which are conducted to evaluate its performance in terms of recognition accuracy under varying distances and viewing angles with respect to the ArUco marker.

</details>


### [40] [Hard Thresholding Pursuit Algorithms for Least Absolute Deviations Problem](https://arxiv.org/abs/2601.06558)
*Jiao Xu,Peng Li,Bing Zheng*

Main category: cs.IT

TL;DR: GFHTP₁算法在LAD准则下表现出色，无需信号稀疏度先验信息且无参数设计，在抗异常值和计算效率方面优于现有算法。


<details>
  <summary>Details</summary>
Motivation: 研究自适应迭代硬阈值算法的鲁棒性，特别是在存在异常值污染的场景下。当前大多数算法需要信号稀疏度的先验信息，且参数调优复杂，需要开发更简单有效的算法。

Method: 采用分级快速硬阈值追踪(GFHTP₁)算法，这是一种自适应迭代硬阈值算法的变体。该算法基于最小绝对偏差(LAD)准则，无需信号稀疏度先验信息，且设计为无参数算法。

Result: 数值实验表明，GFHTP₁算法在鲁棒性和计算效率方面始终优于竞争算法。该算法能有效处理被任意幅度异常值污染的少数测量值。

Conclusion: GFHTP₁算法是一种简单有效的稀疏信号恢复方法，无需参数调优和稀疏度先验信息，在存在异常值的情况下表现出优越的性能。

Abstract: Least absolute deviations (LAD) is a statistical optimality criterion widely utilized in scenarios where a minority of measurements are contaminated by outliers of arbitrary magnitudes. In this paper, we delve into the robustness of the variant of adaptive iterative hard thresholding to outliers, known as graded fast hard thresholding pursuit (GFHTP$_1$) algorithm. Unlike the majority of the state-of-the-art algorithms in this field, GFHTP$_1$ does not require prior information about the signal's sparsity. Moreover, its design is parameterless, which not only simplifies the implementation process but also removes the intricacies of parameter optimization. Numerical experiments reveal that the GFHTP$_1$ algorithm consistently outperforms competing algorithms in terms of both robustness and computational efficiency.

</details>


### [41] [TCLNet: A Hybrid Transformer-CNN Framework Leveraging Language Models as Lossless Compressors for CSI Feedback](https://arxiv.org/abs/2601.06588)
*Zijiu Yang,Qianqian Yang,Shunpu Tang,Tingting Yang,Zhiguo Shi*

Main category: cs.IT

TL;DR: TCLNet是一个用于FDD大规模MIMO系统CSI压缩的统一框架，结合了Transformer-CNN架构进行有损压缩和混合语言模型-因子化模型进行无损压缩，在重建精度和传输效率方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 在FDD大规模MIMO系统中，下行链路CSI对实现高频谱和能量效率至关重要，但随着天线数量增加，CSI反馈开销成为主要瓶颈。现有基于深度学习的CSI压缩方法在捕捉CSI的局部和全局特征方面存在限制，影响了压缩效率。

Method: 提出TCLNet统一CSI压缩框架：1) 有损压缩模块采用混合Transformer-CNN架构，联合利用局部特征和全局上下文；2) 无损压缩模块采用混合语言模型和因子化模型设计，自适应切换上下文感知编码和并行编码以优化率失真复杂度权衡。

Result: 在真实世界和模拟数据集上的实验表明，TCLNet在重建精度和传输效率方面优于现有方法，在不同场景下实现了高达5dB的性能增益。此外，研究还展示了通过精心设计的提示，大型语言模型可以作为零样本CSI无损压缩器。

Conclusion: TCLNet通过创新的混合架构有效解决了CSI压缩中的局部和全局特征捕捉问题，显著提升了压缩效率，为大规模MIMO系统中的CSI反馈提供了有效的解决方案，并展示了LLM在CSI无损压缩中的潜力。

Abstract: In frequency division duplexing (FDD) massive multiple-input multiple-output (MIMO) systems, downlink channel state information (CSI) plays a crucial role in achieving high spectrum and energy efficiency. However, the CSI feedback overhead becomes a major bottleneck as the number of antennas increases. Although existing deep learning-based CSI compression methods have shown great potential, they still face limitations in capturing both local and global features of CSI, thereby limiting achievable compression efficiency. To address these issues, we propose TCLNet, a unified CSI compression framework that integrates a hybrid Transformer-CNN architecture for lossy compression with a hybrid language model (LM) and factorized model (FM) design for lossless compression. The lossy module jointly exploits local features and global context, while the lossless module adaptively switches between context-aware coding and parallel coding to optimize the rate-distortion-complexity (RDC) trade-off. Extensive experiments on both real-world and simulated datasets demonstrate that the proposed TCLNet outperforms existing approaches in terms of reconstruction accuracy and transmission efficiency, achieving up to a 5 dB performance gain across diverse scenarios. Moreover, we show that large language models (LLMs) can be leveraged as zero-shot CSI lossless compressors via carefully designed prompts.

</details>


### [42] [Symplectic Hulls over a Non-Unital Ring](https://arxiv.org/abs/2601.06609)
*Anup Kushwaha,Om Prakash*

Main category: cs.IT

TL;DR: 该论文研究了非单位环E上辛包络的结构性质，包括生成矩阵刻画、辛包络秩扩展技术、置换等价性和辛包络变化问题，并应用于小长度最优码分类


<details>
  <summary>Details</summary>
Motivation: 研究非单位环E上线性码的辛包络性质，旨在理解其代数结构并应用于编码理论，特别是分类最优码

Method: 首先识别左、右和双边辛包络的剩余码和挠码，刻画自由E-线性码双边辛包络的生成矩阵；探索两个自由E-线性码和的辛包络；提出两种扩展技术将较小长度和辛包络秩的码扩展为较大码；研究置换等价性和辛包络变化问题

Result: 建立了非单位环E上辛包络的完整理论框架，包括生成矩阵刻画、扩展技术、等价性判据，并成功分类了小长度自由E-线性最优码

Conclusion: 该研究为非单位环上线性码的辛包络理论提供了系统分析，扩展技术可用于构造更大参数码，分类结果为最优码设计提供了理论依据

Abstract: This paper presents the study of the symplectic hulls over a non-unital ring $ E= \langle κ,τ\mid 2 κ=2 τ=0,~ κ^2=κ,~ τ^2=τ,~ κτ=κ,~ τκ=τ\rangle$. We first identify the residue and torsion codes of the left, right, and two-sided symplectic hulls, and characterize the generator matrix of the two-sided symplectic hull of a free $E$-linear code. Then, we explore the symplectic hull of the sum of two free $E$-linear codes. Subsequently, we provide two build-up techniques that extend a free $E$-linear code of smaller length and symplectic hull-rank to one of larger length and symplectic hull-rank. Further, for free $E$-linear codes, we discuss the permutation equivalence and investigate the symplectic hull-variation problem. An application of this study is given by classifying the free $E$-linear optimal codes for smaller lengths.

</details>


### [43] [The Sample Complexity of Lossless Data Compression](https://arxiv.org/abs/2601.06688)
*Terence Viaud,Ioannis Kontoyiannis*

Main category: cs.IT

TL;DR: 本文提出了一种新的无损数据压缩基本极限分析框架，强调真正的非渐近结果，定义了压缩的样本复杂度概念，并建立了与Rényi熵的紧密联系。


<details>
  <summary>Details</summary>
Motivation: 现有数据压缩理论主要关注渐近性能，缺乏对有限块长下压缩性能的精确分析。本文旨在建立非渐近框架，研究在特定速率和超额率概率下压缩给定源所需的最小块长。

Method: 引入样本复杂度作为核心度量，定义为在指定速率和超额率概率下压缩源所需的最小块长。通过将压缩问题与假设检验问题联系起来，利用现有的假设检验样本复杂度结果。分析不同类型编码器（变长码、前缀码、定长码）的样本复杂度关系。

Result: 1. 任意源的变长码、前缀码和定长码样本复杂度紧密耦合；2. 无记忆源的样本复杂度由1/2阶Rényi熵而非香农熵决定；3. 获得了具有显式常数的非渐近界；4. 马尔可夫源的样本复杂度由1/2阶Rényi熵率决定；5. 通用数据压缩的样本复杂度由族中元素与均匀分布的最小1/2阶Rényi散度决定。

Conclusion: 本文建立了数据压缩的非渐近理论框架，揭示了Rényi熵在有限块长压缩中的核心作用，为压缩算法的实际设计提供了理论基础，并建立了压缩与假设检验问题的深刻联系。

Abstract: A new framework is introduced for examining and evaluating the fundamental limits of lossless data compression, that emphasizes genuinely non-asymptotic results. The {\em sample complexity} of compressing a given source is defined as the smallest blocklength at which it is possible to compress that source at a specified rate and to within a specified excess-rate probability. This formulation parallels corresponding developments in statistics and computer science, and it facilitates the use of existing results on the sample complexity of various hypothesis testing problems. For arbitrary sources, the sample complexity of general variable-length compressors is shown to be tightly coupled with the sample complexity of prefix-free codes and fixed-length codes. For memoryless sources, it is shown that the sample complexity is characterized not by the source entropy, but by its Rényi entropy of order~$1/2$. Nonasymptotic bounds on the sample complexity are obtained, with explicit constants. Generalizations to Markov sources are established, showing that the sample complexity is determined by the source's Rényi entropy rate of order~$1/2$. Finally, bounds on the sample complexity of universal data compression are developed for arbitrary families of memoryless sources. There, the sample complexity is characterized by the minimum Rényi divergence of order~$1/2$ between elements of the family and the uniform distribution. The connection of this problem with identity testing and with the associated separation rates is explored and discussed.

</details>


### [44] [Study of Adaptive Reliability-Driven Conditional Innovation Decoding for LDPC Codes](https://arxiv.org/abs/2601.06732)
*Hassan Touati,Rodrigo C. de Lamare*

Main category: cs.IT

TL;DR: 提出AR-CID解码算法用于LDPC码，通过消息质量检查和消息传递精化两阶段，在残差置信传播框架下实现快速收敛，适合低延迟应用


<details>
  <summary>Details</summary>
Motivation: 现有LDPC解码算法在收敛速度和延迟性能方面仍有改进空间，特别是在低延迟应用场景中需要更高效、更快速的解码方案

Method: 提出自适应可靠性驱动的条件创新(AR-CID)解码算法，包含消息质量检查阶段和消息传递精化阶段，集成到残差置信传播解码策略中

Result: AR-CID算法在多种LDPC码（包括短码和中长码）上，在广泛信道条件下优于竞争解码技术，具有极快的收敛速度

Conclusion: AR-CID解码算法性能优越，收敛速度快，特别适合低延迟应用，为LDPC码解码提供了高效解决方案

Abstract: In this work, we present an adaptive reliability-driven conditional innovation (AR-CID) decoding algorithm for low-density parity check (LDPC) codes. The proposed AR-CID decoding algorithm consists of one stage of message quality checking and another stage of message passing refinement, which are incorporated into a residual belief propagation decoding strategy. An analysis of the AR-CID decoding algorithm is carried out along with a study of its computational complexity and latency characteristics. Simulation results for several examples of LDPC codes, including short and medium-length codes over an extended range of channel conditions, indicate that the proposed AR-CID decoding algorithm outperforms competing decoding techniques and has an extremely fast convergence, making it particularly suitable for low-delay applications.

</details>


### [45] [Optimal Rate Region for Multi-server Secure Aggregation with User Collusion](https://arxiv.org/abs/2601.06836)
*Zhou Li,Xiang Zhang,Kai Wan,Hua Sun,Mingyue Ji,Giuseppe Caire*

Main category: cs.IT

TL;DR: 该论文研究了多服务器安全聚合问题，在存在用户合谋的两跳网络中，完全刻画了最优速率区域，发现多服务器架构相比单服务器能显著降低所需密钥随机性。


<details>
  <summary>Details</summary>
Motivation: 安全聚合是隐私保护分布式学习系统中的基本原语，但现有研究主要关注单服务器场景。在多服务器架构下，用户仅与关联服务器通信，服务器之间交换消息以联合恢复全局和，需要研究在用户合谋情况下的最优通信和密钥效率。

Method: 采用信息论安全框架，允许最多T个用户与任何服务器合谋。通过线性密钥构造实现方案，确保正确性和对合谋用户的安全性。逆证明基于正确性和安全约束推导的紧熵界。

Result: 完全刻画了最优速率区域：最小通信和个体密钥速率均为每个输入符号1个符号，最优源密钥速率为min{U+V+T-2, UV-1}，其中U为服务器数量，V为每服务器用户数。多服务器架构相比单服务器能显著降低所需密钥随机性。

Conclusion: 研究揭示了安全性与密钥效率之间的基本权衡，表明多服务器架构在存在用户合谋的情况下能有效降低密钥需求，为多服务器系统中的安全聚合提供了完整的信息论刻画。

Abstract: Secure aggregation is a fundamental primitive in privacy-preserving distributed learning systems, where an aggregator aims to compute the sum of users' inputs without revealing individual data. In this paper, we study a multi-server secure aggregation problem in a two-hop network consisting of multiple aggregation servers and multiple users per server, under the presence of user collusion. Each user communicates only with its associated server, while the servers exchange messages to jointly recover the global sum. We adopt an information-theoretic security framework, allowing up to $T$ users to collude with any server.
  We characterize the complete optimal rate region in terms of user-to-server communication rate, server-to-server communication rate, individual key rate, and source key rate. Our main result shows that the minimum communication and individual key rates are all one symbol per input symbol, while the optimal source key rate is given by $\min\{U+V+T-2,\, UV-1\}$, where $U$ denotes the number of servers and $V$ the number of users per server. The achievability is established via a linear key construction that ensures correctness and security against colluding users, while the converse proof relies on tight entropy bounds derived from correctness and security constraints.
  The results reveal a fundamental tradeoff between security and key efficiency and demonstrate that the multi-server architecture can significantly reduce the required key randomness compared to single-server secure aggregation. Our findings provide a complete information-theoretic characterization of secure aggregation in multi-server systems with user collusion.

</details>


### [46] [Large Artificial Intelligence Models for Future Wireless Communications](https://arxiv.org/abs/2601.06906)
*Chong Huang,Gaojie Chen,Pei Xiao,Zhu Han,Rahim Tafazolli*

Main category: cs.IT

TL;DR: 本文探讨了大型AI模型与无线通信的融合潜力，分析了现有AI驱动应用和未来挑战，提出了大型AI模型在无线通信中的架构设计，并讨论了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 随着无线网络日益复杂，传统优化管理方法面临挑战，而大型AI模型凭借其广泛的参数空间和增强的学习能力，能够为这些挑战提供创新解决方案，并具备实时学习、适应和优化的能力。

Method: 提出未来无线通信中大型AI模型的架构设计，分析其在数据分析、资源分配和实时适应方面的优势，讨论能源、架构设计、隐私、安全、伦理和监管等方面的潜在挑战及相应解决方案。

Result: 系统性地阐述了大型AI模型与无线通信融合的潜力、挑战和解决方案，为这一新兴领域的研究奠定了基础框架。

Conclusion: 大型AI模型与无线通信的融合将带来变革性影响，虽然面临诸多挑战，但通过合理的架构设计和解决方案，有望推动无线通信技术进入新的发展阶段，并为未来研究指明了方向。

Abstract: The anticipated integration of large artificial intelligence (AI) models with wireless communications is estimated to usher a transformative wave in the forthcoming information age. As wireless networks grow in complexity, the traditional methodologies employed for optimization and management face increasingly challenges. Large AI models have extensive parameter spaces and enhanced learning capabilities and can offer innovative solutions to these challenges. They are also capable of learning, adapting and optimizing in real-time. We introduce the potential and challenges of integrating large AI models into wireless communications, highlighting existing AIdriven applications and inherent challenges for future large AI models. In this paper, we propose the architecture of large AI models for future wireless communications, introduce their advantages in data analysis, resource allocation and real-time adaptation, discuss the potential challenges and corresponding solutions of energy, architecture design, privacy, security, ethical and regulatory. In addition, we explore the potential future directions of large AI models in wireless communications, laying the groundwork for forthcoming research in this area.

</details>


### [47] [Caching Yields up to 5x Spectral Efficiency in Multi-Beam Satellite Communications](https://arxiv.org/abs/2601.06925)
*Hui Zhao,Dirk Slock,Petros Elia*

Main category: cs.IT

TL;DR: 将向量编码缓存(VCC)集成到多波束卫星通信系统中，即使有限的接收端缓存也能显著提升频谱效率，实现300-550%的性能增益。


<details>
  <summary>Details</summary>
Motivation: 卫星通信系统需要提高频谱效率以缩小与有线网络的性能差距。传统方法依赖多播、预取或文件流行度，而VCC提供了一种纯物理层的解决方案。

Method: 将VCC集成到多波束卫星通信中，利用缓存内容抑制干扰，实现多个预编码信号向量的并发传输。采用Rician-shadowed衰落信道模型，考虑匹配滤波预编码、CSI获取开销和CSI不完美等实际因素。

Result: 推导出VCC在SATCOM中的平均和速率和频谱效率增益的闭式表达式。数值仿真验证显示，与传统多用户MISO SATCOM相比，VCC可实现300%到550%的频谱效率增益。

Conclusion: VCC作为一种纯物理层解决方案，能显著提升卫星通信系统的频谱效率，缩小卫星网络与有线网络之间的性能差距，是未来高吞吐量SATCOM系统的关键技术。

Abstract: This paper examines the integration of vector coded caching (VCC) into multi-beam satellite communications (SATCOM) systems and demonstrates that even limited receiver-side caching can substantially enhance spectral efficiency. By leveraging cached content to suppress interference, VCC enables the concurrent transmission of multiple precoded signal vectors that would otherwise require separate transmission resources. This leads to a multiplicative improvement in resource utilization in SATCOM. To characterize this performance, we model the satellite-to-ground channel using Rician-shadowed fading and after incorporating practical considerations such as matched-filter precoding, channel state information (CSI) acquisition overhead as well as CSI imperfections at the transmitter, we here derive closed-form expressions for the average sum rate and spectral efficiency gain of VCC in SATCOM. Our analysis, tightly validated through numerical simulations, reveals that VCC can yield spectral efficiency gains of 300% to 550% over traditional multi-user MISO SATCOM with the same resources. These gains -- which have nothing to do with multicasting, prefetching gains nor file popularity -- highlight VCC as a pure physical-layer solution for future high-throughput SATCOM systems, significantly narrowing the performance gap between satellite and wired networks.

</details>


### [48] [Generalization Bounds for Transformer Channel Decoders](https://arxiv.org/abs/2601.06969)
*Qinshan Zhang,Bin Chen,Yong Jiang,Shu-Tao Xia*

Main category: cs.IT

TL;DR: 本文首次为Transformer信道解码器（ECCT）提供了理论泛化保证，通过比特级Rademacher复杂度推导了泛化误差上界，并证明基于奇偶校验的掩码注意力能通过稀疏性获得更紧的界。


<details>
  <summary>Details</summary>
Motivation: Transformer信道解码器（如ECCT）在信道解码中表现出强大的经验性能，但其泛化行为缺乏理论理解。本文旨在从学习理论角度研究ECCT的泛化性能，填补这一理论空白。

Method: 通过建立乘性噪声估计误差与误码率（BER）之间的联系，使用比特级Rademacher复杂度推导泛化误差上界。分析包括单层和多层ECCT，并证明基于奇偶校验的掩码注意力通过诱导稀疏性降低覆盖数，从而获得更紧的泛化界。

Result: 推导出依赖于码长、模型参数和训练集大小的泛化误差上界，证明了基于奇偶校验的掩码注意力能通过稀疏性获得更紧的理论界。这是首次为该类解码器提供理论泛化保证。

Conclusion: 本文首次为Transformer信道解码器提供了理论泛化保证，建立了乘性噪声估计误差与BER的联系，推导了基于比特级Rademacher复杂度的泛化界，并证明了奇偶校验掩码注意力的稀疏性优势，为该类模型的可靠性提供了理论支撑。

Abstract: Transformer channel decoders, such as the Error Correction Code Transformer (ECCT), have shown strong empirical performance in channel decoding, yet their generalization behavior remains theoretically unclear. This paper studies the generalization performance of ECCT from a learning-theoretic perspective. By establishing a connection between multiplicative noise estimation errors and bit-error-rate (BER), we derive an upper bound on the generalization gap via bit-wise Rademacher complexity. The resulting bound characterizes the dependence on code length, model parameters, and training set size, and applies to both single-layer and multi-layer ECCTs. We further show that parity-check-based masked attention induces sparsity that reduces the covering number, leading to a tighter generalization bound. To the best of our knowledge, this work provides the first theoretical generalization guarantees for this class of decoders.

</details>


### [49] [Quantum Optical Integrated Sensing and Communication with Homodyne BPSK Detection](https://arxiv.org/abs/2601.07034)
*Ioannis Krikidis*

Main category: cs.IT

TL;DR: 提出一种量子集成传感与通信方案，使用BPSK调制和零差检测，在未知相位旋转的高斯信道中实现联合符号检测与相位估计


<details>
  <summary>Details</summary>
Motivation: 在量子光学链路中，需要在未知相位旋转的信道上同时实现可靠通信和精确传感，传统方法难以平衡通信可靠性和传感精度

Method: 采用BPSK调制和零差检测，设计最小化误码率同时满足Fisher信息约束的优化问题，开发包含内层EM算法（联合检测与估计）和外层自适应本地振荡器相位调谐的迭代算法

Result: 数值结果验证了所提方法的有效性，并展示了通信可靠性和传感精度之间的基本权衡关系

Conclusion: 该量子集成传感与通信方案能够在未知相位旋转的信道上有效工作，通过迭代算法实现了通信与传感性能的优化平衡

Abstract: In this letter, we propose a quantum integrated sensing and communication scheme for a quantum optical link using binary phase-shift keying modulation and homodyne detection. The link operates over a phase-insensitive Gaussian channel with an unknown deterministic phase rotation, where the homodyne receiver jointly carries out symbol detection and phase estimation. We formulate a design problem that minimizes the bit-error rate subject to a Fisher information-based constraint on estimation accuracy. To solve it, we develop an iterative algorithm composed of an inner expectation-maximization loop for joint detection and estimation and an outer loop that adaptively retunes the local oscillator phase. Numerical results confirm the effectiveness of the proposed approach and demonstrate a fundamental trade-off between communication reliability and sensing accuracy.

</details>


### [50] [Random Access in DNA Storage: Algorithms, Constructions, and Bounds](https://arxiv.org/abs/2601.07053)
*Chen Wang,Eitan Yaakobi*

Main category: cs.IT

TL;DR: 提出计算DNA数据存储随机访问问题中期望读取次数的O(n)算法，推导显式公式，构造新码改进已知上界，并建立更紧的理论下界。


<details>
  <summary>Details</summary>
Motivation: DNA数据存储走向实际应用，需要最小化测序覆盖深度以降低成本和检索延迟。随机访问问题评估从n个编码链中恢复特定信息链所需的期望读取次数。

Method: 提出计算期望读取次数的O(n)复杂度算法；推导平均和最大期望读取次数的显式公式；构造新的码设计；建立更紧的理论下界。

Result: 将k=3时的最佳上界从0.8815k改进到0.8811k；k=4时达到0.8629k上界；证明n=k+1时简单奇偶校验码的最优性；建立改进的理论下界。

Conclusion: 提出的算法和理论分析为DNA数据存储随机访问问题提供了有效的解决方案，改进了现有性能界限，并证明了特定情况下的最优码结构。

Abstract: As DNA data storage moves closer to practical deployment, minimizing sequencing coverage depth is essential to reduce both operational costs and retrieval latency. This paper addresses the recently studied Random Access Problem, which evaluates the expected number of read samples required to recover a specific information strand from $n$ encoded strands. We propose a novel algorithm to compute the exact expected number of reads, achieving a computational complexity of $O(n)$ for fixed field size $q$ and information length $k$. Furthermore, we derive explicit formulas for the average and maximum expected number of reads, enabling an efficient search for optimal generator matrices under small parameters. Beyond theoretical analysis, we present new code constructions that improve the best-known upper bound from $0.8815k$ to $0.8811k$ for $k=3$, and achieve an upper bound of $0.8629k$ for $k=4$ for sufficiently large $q$. We also establish a tighter theoretical lower bound on the expected number of reads that improves upon state-of-the-art bounds. In particular, this bound establishes the optimality of the simple parity code for the case of $n=k+1$ across any alphabet $q$.

</details>


### [51] [Score-Based VAMP with Fisher-Information-Based Onsager Correction](https://arxiv.org/abs/2601.07095)
*Tadashi Wadayama,Takumi Takahashi*

Main category: cs.IT

TL;DR: SC-VAMP是一种基于分数的向量近似消息传递变体，通过条件Fisher信息计算Onsager校正，实现无雅可比矩阵实现，适用于复杂黑盒推理问题。


<details>
  <summary>Details</summary>
Motivation: 传统VAMP方法需要解析导数，限制了其在复杂黑盒推理问题中的应用。本文旨在开发一种无需解析导数的VAMP变体，能够处理显式建模不可行的复杂推理场景。

Method: 提出SC-VAMP方法：1) 使用条件Fisher信息表达和计算Onsager校正；2) 利用学习到的分数函数通过Tweedie公式构建非线性MMSE估计器；3) 从分数-范数统计中推导相应的Onsager项；4) 结合随机正交/酉混合处理结构化或相关感知设置。

Result: SC-VAMP实现了无雅可比矩阵的VAMP实现，能够处理先验或似然函数没有解析导数的复杂黑盒推理问题，扩展了VAMP在非理想、结构化或相关感知设置中的应用范围。

Conclusion: SC-VAMP通过分数函数和条件Fisher信息成功扩展了VAMP框架，使其适用于复杂黑盒推理问题。同时，利用熵中心极限定理为状态演化中的高斯近似提供了信息论视角，深化了对解耦原理的理解。

Abstract: We propose score-based VAMP (SC-VAMP), a variant of vector approximate message passing (VAMP) in which the Onsager correction is expressed and computed via conditional Fisher information, thereby enabling a Jacobian-free implementation. Using learned score functions, SC-VAMP constructs nonlinear MMSE estimators through Tweedie's formula and derives the corresponding Onsager terms from the score-norm statistics, avoiding the need for analytical derivatives of the prior or likelihood. When combined with random orthogonal/unitary mixing to mitigate non-ideal, structured or correlated sensing settings, the proposed framework extends VAMP to complex black-box inference problems where explicit modeling is intractable. Finally, by leveraging the entropic CLT, we provide an information-theoretic perspective on the Gaussian approximation underlying SE, offering insight into the decoupling principle beyond idealized i.i.d. settings, including nonlinear regimes.

</details>


### [52] [PASS-Enabled Covert Communications With Distributed Cooperative Wardens](https://arxiv.org/abs/2601.07147)
*Ji He*

Main category: cs.IT

TL;DR: 研究分布式监控下的PASS辅助下行隐蔽通信，多监管者采用多数投票融合检测，通过双波导架构同时传输隐蔽信息和随机干扰，分析系统级检测性能并优化隐蔽率


<details>
  <summary>Details</summary>
Motivation: 分布式监控环境下的隐蔽通信面临严峻挑战，多个监管者通过协作检测显著提高了检测能力。需要研究在这种多监管者多数投票融合检测的场景下，如何利用PASS（可编程天线表面）技术实现可靠的隐蔽通信

Method: 采用双波导架构同时传输隐蔽信息和随机干扰，考虑三种PASS功率辐射定律（通用、比例、相等）。通过PGF-ESP框架和基于断点的阈值域划分，推导系统级检测错误概率的闭式表达式。提出MM-BCD-SCA算法解决非凸优化问题

Result: 获得了系统级检测错误概率的闭式表达式，提出的优化算法能有效解决隐蔽率最大化问题。数值结果验证了理论分析，展示了协作监控和PASS辐射定律对隐蔽性-速率权衡的影响

Conclusion: 该研究为分布式监控环境下的隐蔽通信提供了系统级分析框架和优化方法，证明了PASS技术在对抗多监管者协作检测方面的有效性，为实际隐蔽通信系统设计提供了理论指导

Abstract: This paper investigates PASS-enabled downlink covert communication in the presence of distributed surveillance, where multiple wardens perform signal detection and fuse their local binary decisions via majority-voting rule. We consider a dual-waveguide architecture that simultaneously delivers covert information and randomized jamming to hide the transmission footprint, incorporating three representative PASS power-radiation laws-general, proportional, and equal. To characterize the system-level detectability, we derive closed-form expressions for local false-alarm and miss-detection probabilities. By leveraging a probability-generating-function (PGF) and elementary-symmetric-polynomial (ESP) framework, combined with a breakpoint-based partition of the threshold domain, we obtain explicit closed-form characterizations of the system-level detection error probability (DEP) under non-i.i.d. majority-voting fusion. Building on this analytical framework, we formulate a robust optimization problem to maximize the average covert rate subject to covertness constraint. To solve the resulting nonconvex design, we develop an MM-BCD-SCA algorithm that produces tractable alternating updates for power/radiation variables and PA positions via convex surrogates and inner approximations of the DEP value function. Numerical results validate the theoretical analysis and demonstrate the impact of cooperative monitoring and PASS radiation laws on the covertness-rate tradeoff.

</details>


### [53] [Sentiment Analysis on Movie Reviews: A Deep Dive into Modern Techniques and Open Challenges](https://arxiv.org/abs/2601.07235)
*Agnivo Gosai,Shuvodeep De,Karun Thankachan*

Main category: cs.IT

TL;DR: 电影评论情感分析方法的全面综述，涵盖从传统机器学习到深度学习及大语言模型的演进，重点关注领域特定挑战和未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 电影评论情感分析是自然语言处理领域的基准任务，对推动该领域发展起到了核心作用。现有综述多关注文本处理流程，缺乏对领域特定挑战（如讽刺、否定、上下文歧义）和新兴问题（如可解释性、公平性）的系统分析。

Method: 采用比较性、挑战驱动的分析方法，回顾从早期基于词典和经典机器学习方法到现代深度学习架构和大语言模型的技术演进。涵盖IMDb、Rotten Tomatoes、SST-2等常用数据集，以及从朴素贝叶斯、支持向量机到LSTM、BERT和基于注意力的Transformer等模型。特别关注多模态情感分析，整合电影预告片和片段的文本、音频和视觉线索。

Result: 提供了电影评论情感分析领域的全面技术路线图，系统比较了不同建模范式在解决领域特定问题上的表现。识别了讽刺、否定、上下文歧义和领域转移等开放性问题，并总结了多模态方法的最新进展。

Conclusion: 该综述为电影评论情感分析领域提供了既包含成熟解决方案又突出未解决挑战的领域聚焦路线图。未来研究方向包括零样本/少样本学习、混合符号-神经模型、实时部署考虑等，旨在构建更准确、可泛化和可解释的情感分析系统。

Abstract: This paper presents a comprehensive survey of sentiment analysis methods for movie reviews, a benchmark task that has played a central role in advancing natural language processing. We review the evolution of techniques from early lexicon-based and classical machine learning approaches to modern deep learning architectures and large language models, covering widely used datasets such as IMDb, Rotten Tomatoes, and SST-2, and models ranging from Naive Bayes and support vector machines to LSTM networks, BERT, and attention-based transformers. Beyond summarizing prior work, this survey differentiates itself by offering a comparative, challenge-driven analysis of how these modeling paradigms address domain-specific issues such as sarcasm, negation, contextual ambiguity, and domain shift, which remain open problems in existing literature. Unlike earlier reviews that focus primarily on text-only pipelines, we also synthesize recent advances in multimodal sentiment analysis that integrate textual, audio, and visual cues from movie trailers and clips. In addition, we examine emerging concerns related to interpretability, fairness, and robustness that are often underexplored in prior surveys, and we outline future research directions including zero-shot and few-shot learning, hybrid symbolic--neural models, and real-time deployment considerations. Overall, this abstract provides a domain-focused roadmap that highlights both established solutions and unresolved challenges toward building more accurate, generalizable, and explainable sentiment analysis systems for movie review data.

</details>


### [54] [Bias-Aware BP Decoding of Quantum Codes via Directional Degeneracy](https://arxiv.org/abs/2601.07240)
*Mohammad Rowshan*

Main category: cs.IT

TL;DR: 该论文提出了一种针对量子CSS码的方向感知置信传播解码方法，利用各向异性Tanner图结构和偏置噪声特性，通过方向权重和退化枚举器来提升解码性能。


<details>
  <summary>Details</summary>
Motivation: 量子CSS码的Tanner图通常具有各向异性结构，且量子噪声可能呈现方向性偏置。传统解码方法未充分利用这些结构特性，导致解码性能受限。需要开发能够利用方向性信息来提升解码效果的方法。

Method: 1. 在Tanner图边上分配方向权重，聚合成每个量子位的方向权重；2. 定义方向退化枚举器来量化退化沿特定方向的集中程度；3. 使用偏置参数β将权重映射为位置相关的对数似然比，产生各向异性先验；4. 将各向异性先验直接集成到标准BP→OSD解码器中，无需改变码构造。

Result: 1. 推导了方向距离与汉明距离之间的关系界限；2. 给出了退化错误类数量关于距离、码率和方向偏置的上界；3. 提供了方向枚举器的MacWilliams型表达式；4. 有限长度仿真显示在中等物理错误率下，逻辑错误率显著降低（通常一个数量级）。

Conclusion: 适度的各向异性是获得硬件感知解码增益的简单有效途径。该方法通过利用量子码的固有方向性结构，在不改变码构造的情况下，显著提升了BP解码器的性能，为量子纠错解码提供了新的优化方向。

Abstract: We study directionally informed belief propagation (BP) decoding for quantum CSS codes, where anisotropic Tanner-graph structure and biased noise concentrate degeneracy along preferred directions. We formalize this by placing orientation weights on Tanner-graph edges, aggregating them into per-qubit directional weights, and defining a \emph{directional degeneracy enumerator} that summarizes how degeneracy concentrates along those directions. A single bias parameter~$β$ maps these weights into site-dependent log-likelihood ratios (LLRs), yielding anisotropic priors that plug directly into standard BP$\rightarrow$OSD decoders without changing the code construction. We derive bounds relating directional and Hamming distances, upper bound the number of degenerate error classes per syndrome as a function of distance, rate, and directional bias, and give a MacWilliams-type expression for the directional enumerator. Finite-length simulations under code-capacity noise show significant logical error-rate reductions -- often an order of magnitude at moderate physical error rates -- confirming that modest anisotropy is a simple and effective route to hardware-aware decoding gains.

</details>


### [55] [Rate-distortion Theory on Non-compact Spaces: A Concentration-compactness Approach](https://arxiv.org/abs/2601.07246)
*Jiayang Zou,Luyao Fan,Jiayang Gao,Jia Wang*

Main category: cs.IT

TL;DR: 将集中紧致原理引入率失真泛函分析，在非紧致空间中建立了最优重构分布的存在性定理


<details>
  <summary>Details</summary>
Motivation: 经典率失真理论中的最优重构分布存在性结果依赖于紧致性假设，这在非紧致空间中经常不成立。需要建立适用于一般非紧致空间的统一存在性理论。

Method: 将集中紧致原理引入率失真泛函的分析中，在失真函数满足温和的强制性条件下，建立最优重构分布的存在性。

Result: 在非紧致空间中，只要失真函数满足适当的强制性条件，就能保证最优重构分布的存在性，为一般率失真问题提供了统一透明的存在性定理。

Conclusion: 通过引入集中紧致原理，成功解决了非紧致空间中率失真理论的最优重构分布存在性问题，扩展了经典理论的应用范围。

Abstract: In this paper, we study rate-distortion theory for general sources with an emphasis on the existence of optimal reconstruction distributions. Classical existence results rely on compactness assumptions that are often violated in non-compact settings. By introducing the concentration-compactness principle into the analysis of the rate-distortion functional, we establish the existence of optimal reconstructions under mild coercivity conditions on the distortion function. Our results provide a unified and transparent existence theorem for rate-distortion problems on general non-compact spaces.

</details>


### [56] [Engineering Favorable Propagation: Near-Field IRS Deployment for Spatial Multiplexing](https://arxiv.org/abs/2601.07317)
*Yuxuan Chen,Qingqing Wu,Guangji Chen,Qiaoyan Peng,Wen Chen*

Main category: cs.IT

TL;DR: 利用稀疏阵列的大孔径和近场球面波前，通过智能反射面(IRS)在基站近场的战略部署，解决远场级联信道秩不足问题，提升空间复用能力


<details>
  <summary>Details</summary>
Motivation: IRS辅助MIMO系统中，强视距链路导致级联信道秩不足，限制了空间复用能力。需要克服远场级联信道的秩缺陷问题

Method: 利用稀疏阵列大孔径产生近场球面波前，建立确定性部署准则，将IRS战略性地放置在基站近场。基于物理信道模型分析级联信道的秩特性和用户间相关性，推导闭式有利传播度量

Result: 部署准则能有效降低用户间信道相关性，增强有效自由度。基于统计CSI的低复杂度MRT预编码方案和联合优化算法相比基准方案获得显著性能增益

Conclusion: 通过几何驱动的IRS近场部署策略，可以克服远场级联信道的秩缺陷问题，为IRS辅助MIMO系统提供有效的空间复用解决方案

Abstract: In intelligent reflecting surface IRS assisted multiple input multiple output MIMO systems, a strong line of sight LoS link is required to compensate for the severe cascaded path loss. However, such a link renders the effective channel highly rank deficient and fundamentally limits spatial multiplexing. To overcome this limitation, this paper leverages the large aperture of sparse arrays to harness near field spherical wavefronts, and establishes a deterministic deployment criterion that strategically positions the IRS in the near field of a base station BS. This placement exploits the spherical wavefronts of the BS IRS link to engineer decorrelated channels, thereby fundamentally overcoming the rank deficiency issue in far field cascaded channels. Based on a physical channel model for the sparse BS array and the IRS, we characterize the rank properties and inter user correlation of the cascaded BS IRS user channel. We further derive a closed form favorable propagation metric that reveals how the sparse array geometry and the IRS position can be tuned to reduce inter user channel correlation. The resulting geometry driven deployment rule provides a simple guideline for creating a favorable propagation environment with enhanced effective degrees of freedom. The favorable channel statistics induced by our deployment criterion enable a low complexity maximum ratio transmission MRT precoding scheme. This serves as the foundation for an efficient algorithm that jointly optimizes the IRS phase shifts and power allocation based solely on long term statistical channel state information CSI. Simulation results validate the effectiveness of our deployment criterion and demonstrate that our optimization framework achieves significant performance gains over benchmark schemes.

</details>


### [57] [Performance Bounds of Joint Detection with Kalman Filtering and Channel Decoding for Wireless Networked Control Systems](https://arxiv.org/abs/2601.07322)
*Jinnan Piao,Dong Li,Zhibo Li,Ming Yang,Xueting Yu,Jincheng Dai*

Main category: cs.IT

TL;DR: 该论文将联合检测视为最大后验概率解码，推导了考虑系统干扰、量化间隔和权重分布的成对错误概率上下界，并通过无限状态马尔可夫链分析连续丢包，最终获得MAP性能界限。


<details>
  <summary>Details</summary>
Motivation: 传统联合检测使用卡尔曼滤波估计控制输出的先验概率来辅助信道解码，但需要更精确的性能界限分析。本文旨在建立联合检测作为最大后验概率解码的理论框架，并推导考虑实际系统因素的性能界限。

Method: 1. 将联合检测视为MAP解码，基于成对错误概率推导考虑系统干扰、量化间隔和权重分布的上下界；2. 推导SNR趋于无穷且系统干扰趋于零时的极限界；3. 构建无限状态马尔可夫链描述控制系统的连续丢包特性；4. 将MAP界近似为从无丢包状态到连续单丢包状态的转移概率界限。

Result: 仿真结果显示：(64,16)极化码和16位CRC的MAP性能随着SNR增加与极限上界重合；在块错误率10^{-3}时，相比有限块率的正态近似有3.0dB的性能增益。

Conclusion: 本文成功建立了联合检测的MAP解码理论框架，推导了考虑实际系统因素的性能界限，并通过仿真验证了所提方法的有效性，为控制系统中的信道解码提供了理论指导和性能评估工具。

Abstract: The joint detection uses Kalman filtering (KF) to estimate the prior probability of control outputs to assist channel decoding. In this paper, we regard the joint detection as maximum a posteriori (MAP) decoding and derive the lower and upper bounds based on the pairwise error probability considering system interference, quantization interval, and weight distribution. We first derive the limiting bounds as the signal-to-noise ratio (SNR) goes to infinity and the system interference goes to zero. Then, we construct an infinite-state Markov chain to describe the consecutive packet losses of the control systems to derive the MAP bounds. Finally, the MAP bounds are approximated as the bounds of the transition probability from the state with no packet loss to the state with consecutive single packet loss. The simulation results show that the MAP performance of $\left(64,16\right)$ polar code and 16-bit CRC coincides with the limiting upper bound as the SNR increases and has $3.0$dB performance gain compared with the normal approximation of the finite block rate at block error rate $10^{-3}$.

</details>


### [58] [On the Extremal Source Key Rates for Secure Storage over Graphs](https://arxiv.org/abs/2601.07340)
*Zhou Li*

Main category: cs.IT

TL;DR: 该论文研究了图上的安全存储编码，其中多个独立源符号在满足边正确性和安全性约束下被编码存储在图的节点中。对于每条边，其两个相邻节点必须能够恢复指定的源符号子集，同时不泄露其他源符号的任何信息。为了满足安全性要求，可以使用共享源密钥。论文研究了源密钥容量的极值，并为几种基本设置提供了完整的图特征描述。


<details>
  <summary>Details</summary>
Motivation: 研究图上的安全存储系统，其中源符号存储在图的节点中，要求每条边的两个相邻节点能够恢复特定的源符号子集，同时保证其他源符号的安全性。这种模型在分布式存储和安全通信中具有实际应用价值。

Method: 采用图论和信息论方法，分析源密钥容量（源符号大小与源密钥大小的比值）的极值。研究两种主要情况：1）每条边关联单个源符号时，特征化源密钥容量等于1的所有图；2）每条边关联多个源符号时，识别在温和结构条件下达到相应极值容量的图类。同时特征化无需源密钥即可实现安全存储的所有图。

Result: 1）对于每条边关联单个源符号的情况，完全特征化了源密钥容量等于1的所有图；2）对于每条边关联多个源符号的情况，识别了一大类在温和结构条件下达到相应极值容量的图；3）特征化了所有无需源密钥即可实现安全存储的图。

Conclusion: 论文为图上的安全存储系统提供了源密钥容量的完整图特征描述，包括极值容量情况和无需密钥的情况。这些结果为分布式安全存储系统的设计提供了理论基础，并揭示了图结构与安全存储能力之间的深刻联系。

Abstract: This paper investigates secure storage codes over graphs, where multiple independent source symbols are encoded and stored at graph nodes subject to edge-wise correctness and security constraints. For each edge, a specified subset of source symbols must be recoverable from its two incident nodes, while no information about the remaining sources is revealed. To meet the security requirement, a shared source key may be employed. The ratio between the source symbol size and the source key size defines the source key rate, and the supremum of all achievable rates is referred to as the source key capacity.
  We study extremal values of the source key capacity in secure storage systems and provide complete graph characterizations for several fundamental settings. For the case where each edge is associated with a single source symbol, we characterize all graphs whose source key capacity equals one. We then generalize this result to the case where each edge is associated with multiple source symbols and identify a broad class of graphs that achieve the corresponding extremal capacity under a mild structural condition. In addition, we characterize all graphs for which secure storage can be achieved without using any source key.

</details>


### [59] [Fast and Provable Nonconvex Robust Matrix Completion](https://arxiv.org/abs/2601.07355)
*Yichen Fu,Tianming Wang,Ke Wei*

Main category: cs.IT

TL;DR: 本文提出了一种名为ARMC的高效非凸鲁棒矩阵补全方法，通过引入子空间投影改进奇异值阈值方法，在理论和实验上均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 鲁棒矩阵补全问题在存在异常值和噪声的情况下具有重要应用价值，现有方法在计算效率和理论保证方面存在不足，需要开发更优的非凸方法。

Method: 提出ARMC方法，在更新低秩部分时引入子空间投影到奇异值阈值方法中，使用留一法技术进行理论分析，建立对稀疏异常值和随机噪声的理论保证。

Result: 在合成和真实数据上的数值实验表明ARMC优于现有非凸RMC方法；理论分析建立了比凸方法更好的样本复杂度和异常值稀疏度界限。

Conclusion: ARMC是一种计算高效且理论保证优越的鲁棒矩阵补全方法，在存在异常值和噪声的情况下具有更好的性能。

Abstract: This paper studies the robust matrix completion problem and a computationally efficient non-convex method called ARMC has been proposed. This method is developed by introducing subspace projection to a singular value thresholding based method when updating the low rank part. Numerical experiments on synthetic and real data show that ARMC is superior to existing non-convex RMC methods. Through a refined analysis based on the leave-one-out technique, we have established the theoretical guarantee for ARMC subject to both sparse outliers and stochastic noise. The established bounds for the sample complexity and outlier sparsity are better than those established for a convex approach that also considers both outliers and stochastic noise.

</details>


### [60] [Novel Decoding Algorithm for Noiseless Non-Adaptive Group Testing](https://arxiv.org/abs/2601.07388)
*Manuel Franco-Vivo*

Main category: cs.IT

TL;DR: 提出W-SCOMP算法改进非自适应群组检测性能，理论证明和实验验证其优于现有方法


<details>
  <summary>Details</summary>
Motivation: COVID-19疫情凸显了非自适应群组检测的时间效率优势，需要提高现有方案的性能以更好地识别缺陷物品子集

Method: 提出加权顺序组合正交匹配追踪(W-SCOMP)算法，开发模拟框架进行对比评估

Result: 理论证明W-SCOMP在无噪声非自适应群组检测中优于其他算法，实验验证与理论结果一致

Conclusion: 扩展了可用的解码算法范围，增进了对无噪声非自适应群组检测的理解

Abstract: Group testing enables the identification of a small subset of defective items within a larger population by performing tests on pools of items rather than on each item individually. Over the years, it has not only attracted attention from the academic community, but has also demonstrated its potential in addressing real-world problems such as infectious disease screening, drug discovery and manufacturing quality control. With the emergence of the COVID-19 pandemic, interest in group testing has grown further, particularly in non-adaptive testing, due to its time efficiency compared to adaptive approaches. This highlights the importance of improving the performance currently achievable in such a scheme. This article focuses on advancing the field of noiseless non-adaptive group testing. The main objective of this work is to study and maximize the probability of successfully identifying the subset of defective items while performing as few tests as possible. To this end, we first note current well-known decoding algorithms, as well as established test design strategies for assigning items to pools. From this review, we identify key opportunities for improvement that inform the development of new decoding algorithms. Specifically, we propose a novel method, Weighted Sequential Combinatorial Orthogonal Matching Pursuit (W-SCOMP), to enhance the efficiency of existing detection procedures. Theoretical results demonstrate that W-SCOMP outperforms other algorithms in noiseless non-adaptive group testing. Furthermore, we develop a simulation framework to model the group testing process and conduct comparative evaluations between the proposed and existing algorithms. The empirical results are consistent with the theoretical findings. Overall, our work expands the range of available decoding algorithms and contributes to the broader understanding of noiseless non-adaptive group testing.

</details>


### [61] [Center-Fed Pinching Antenna System (C-PASS) Aided Wireless Communications](https://arxiv.org/abs/2601.07424)
*Xu Gan,Yuanwei Liu*

Main category: cs.IT

TL;DR: C-PASS天线系统通过可控功率分配实现双自由度，提出PS、DS、TS三种协议，分别采用不同优化方法解决和速率最大化问题，在不同功率区域各有优势。


<details>
  <summary>Details</summary>
Motivation: 传统PASS天线系统自由度有限，需要设计新型中心馈电夹持天线系统(C-PASS)来提升性能，通过可控功率分配实现双自由度增强。

Method: 提出C-PASS基本信号模型和三种操作协议：功率分配(PS)、方向切换(DS)、时间切换(TS)。针对每种协议，分别采用加权最小均方误差重构、惩罚算法、分解优化等方法解决联合传输和夹持波束成形优化问题。

Result: 数值结果表明：在低功率区域，TS协议表现最优；在高功率区域，PS和DS协议由于增强的自由度能够实现显著更高的速率。

Conclusion: C-PASS系统通过可控功率分配实现双自由度增强，三种操作协议在不同功率区域各有优势，为未来天线系统设计提供了新的架构和优化框架。

Abstract: The novel architecture of the center-fed pinching antenna system (C-PASS) is investigated, where the waveguide-fed signal is divided into two propagation directions through controllable power splitting. By doing so, a doubled degree of freedom (DoF) is achieved compared to conventional PASS. Based on the new designed basic signal model of C-PASS, three practical operating protocols for C-PASS are proposed, namely power splitting (PS), direction switching (DS), and time switching (TS). Then, the sum-rate maximization problem for the joint optimization of transmit and pinching beamforming is formulated for each of the proposed protocols. 1) For PS, the highly coupled non-convex problem is first transformed into a tractable form via the weighted minimum mean square error reformulation and solved using the alternating optimization framework; 2) For DS, the above approach is subsequently extended to solve the mixed-integer constraints inherent for DS via the penalty-based algorithm; 3) For TS, the optimization problem can be decomposed into two subproblems and solved using the similar iterative techniques, while its optimal time allocation ratio is derived in closed form. Finally, numerical results reveal that TS is superior in the low-power regime, while PS and DS achieve significantly higher rates in the high-power regime due to the enhanced DoF.

</details>


### [62] [Secure Joint Source-Channel Coding for the AWGN Channel with Feedback: A Finite Blocklength Analysis](https://arxiv.org/abs/2601.07472)
*Sheng Su,Yuhan Yang,Chao Qi,Xuan He,Bin Dai,Xiaohu Tang*

Main category: cs.IT

TL;DR: 本文研究AWGN窃听信道在有限码长下的反馈方案，证明经典SK方案非最优，提出改进方案并建立有限码长逆定理


<details>
  <summary>Details</summary>
Motivation: 在无限码长下，AWGN窃听信道有噪声反馈时，经典Schalkwijk-Kailath方案能达到保密容量。但在有限码长下，该方案是否最优尚不清楚，需要研究有限码长下的最优方案和性能界限。

Method: 1. 分析经典SK方案在有限码长下的性能；2. 提出改进的SK方案；3. 建立AWGN窃听信道反馈模型的有限码长逆定理

Result: 1. 证明经典SK方案在有限码长下非最优；2. 提出的改进SK方案性能优于经典方案；3. 建立了有限码长逆定理，该定理也可用于无保密约束的相同模型

Conclusion: 本文首次研究了AWGN窃听信道在有限码长下的反馈方案优化问题，证明了经典SK方案在有限码长下非最优，提出了改进方案并建立了有限码长逆定理，通过数值例子进一步验证了结果。

Abstract: In the literature, it has been shown that the secrecy capacity of the additive white Gaussian noise (AWGN) wiretap channel with noise-free feedback equals the capacity of the same model without secrecy constraint, and the classical Schalkwijk-Kailath (SK) scheme achieves the secrecy capacity. In this paper, we show that in finite blocklength regime, the SK scheme is not optimal, and propose a modified SK scheme which may perform better than the classical one. Besides this, this paper establishes a finite blocklength converse for the AWGN wiretap channel with feedback, which can also be viewed as a converse for the same model without secrecy constraint. To the best of the authors' knowledge, this is the first paper to address such a problem, and the results of this paper are further explained via numerical examples.

</details>


### [63] [Frequency-Adaptive Multi-Band Architecture for Upper Mid-Band MIMO Systems](https://arxiv.org/abs/2601.07489)
*Emiel Vanspranghels,Zhuangzhuang Cui,Sofie Pollin*

Main category: cs.IT

TL;DR: 该论文研究了FR3频段（7-24GHz）在6G中的传播特性和MIMO性能，提出了一种频率自适应的多频段MIMO架构，通过资源重分配在频谱增益和MIMO增益之间进行动态权衡。


<details>
  <summary>Details</summary>
Motivation: FR3频段作为6G的潜在频谱资源，其传播特性和MIMO性能随频率和环境变化显著，且频谱可用性可能因现有用户而间歇性中断，需要研究其实际性能并设计适应性架构。

Method: 使用Sionna RT射线追踪在典型室内外场景中评估7、10、14、20和24GHz频段的SISO和MIMO配置，并提出了基于ADC/DAC和基带处理资源重分配的频率自适应多频段MIMO架构。

Result: FR3频段表现出介于sub-6GHz和毫米波之间的传播特性，支持有意义的空间复用但具有强烈的场景依赖性；自适应资源重分配在子频段不可用或复用增益集中在特定频率时特别有益。

Conclusion: FR3频段是6G的有前景频谱资源，提出的频率自适应MIMO架构能够动态权衡频谱增益和MIMO增益，在频谱可用性和信道约束下优化系统性能。

Abstract: FR3 ($\approx$7-24 GHz), also referred to as the upper mid-band, has recently emerged as promising spectrum for 6G; however, its propagation and MIMO characteristics vary significantly with frequency and environment, and spectrum availability may be intermittent due to incumbents. Using site-specific ray tracing (Sionna RT) in representative indoor and outdoor scenarios, we evaluate 7, 10, 14, 20, and 24 GHz under SISO and MIMO configurations. The results show that FR3 exhibits propagation characteristics intermediate between sub-6 GHz and mmWave bands while supporting meaningful spatial multiplexing, albeit with strong site dependence. Motivated by these findings, we propose a fully digital frequency-adaptive multi-band MIMO architecture that repurposes ADCs/DACs and baseband processing resources across FR3 subbands via switching, enabling dynamic trade-offs between bandwidth (spectrum gain) and antenna consolidation (MIMO gain) under availability and channel constraints. Simulation results demonstrate that exploiting additional spectrum is often optimal, while adaptive resource repurposing becomes beneficial when subbands are unavailable or when multiplexing gains are concentrated at specific frequencies.

</details>


### [64] [A Parity-Consistent Decomposition Method for the Weight Distribution of Pre-Transformed Polar Codes](https://arxiv.org/abs/2601.07515)
*Yang Liu,Bolin Wu,Yuxin Han,Kai Niu*

Main category: cs.IT

TL;DR: 提出基于奇偶一致性分解(PCD)的高效算法，用于计算预变换极化码的汉明重量分布，通过构建扩展信息集和等价类理论显著降低计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 预变换极化码中预变换矩阵引入了比特依赖性，使得传统的重量分布计算方法变得复杂且计算量大，需要更高效的算法来解决这一问题。

Method: 1) 提出迭代算法构建扩展信息集，通过将信息比特扩展为0和1来消除比特相关性，从而使用PCD方法递归计算重量分布；2) 建立预变换极化码的等价类理论，选择最小化扩展信息集大小的预变换矩阵来优化计算过程。

Result: 数值结果表明，与现有确定性算法相比，所提方法显著降低了计算复杂度。

Conclusion: 本文提出的基于PCD的算法通过扩展信息集和等价类理论，为预变换极化码的重量分布计算提供了一种高效解决方案，大幅减少了计算负担。

Abstract: This paper introduces an efficient algorithm based on the Parity-Consistent Decomposition (PCD) method to determine the WD of pre-transformed polar codes. First, to address the bit dependencies introduced by the pre-transformation matrix, we propose an iterative algorithm to construct an \emph{Expanded Information Set}. By expanding the information bits within this set into 0s and 1s, we eliminate the correlations among information bits, thereby enabling the recursive calculation of the Hamming weight distribution using the \emph{PCD method}. Second, to further reduce computational complexity, we establish the theory of equivalence classes for pre-transformed polar codes. Codes within the same equivalence class share an identical weight distribution but correspond to different \emph{Expanded Information Set} sizes. By selecting the pre-transformation matrix that minimizes the \emph{Expanded Information Set} size within an equivalence class, we optimize the computation process. Numerical results demonstrate that the proposed method significantly reduces computational complexity compared to existing deterministic algorithms.

</details>


### [65] [Sparse Point-wise Privacy Leakage: Mechanism Design and Fundamental Limits](https://arxiv.org/abs/2601.07523)
*Amirreza Zamani,Sajad Daei,Parastoo Sadeghi,Mikael Skoglund*

Main category: cs.IT

TL;DR: 提出稀疏点式隐私泄漏机制，将隐私保护问题转化为稀疏二次优化，使用SDP松弛提供多项式时间解法


<details>
  <summary>Details</summary>
Motivation: 研究信息论隐私机制设计问题，其中代理只能访问有用数据Y（与敏感数据X相关），需要设计既能保护隐私又能保持效用的披露数据U

Method: 引入稀疏点式隐私泄漏准则，在高隐私机制下使用信息几何方法获得互信息的局部二次近似，将问题转化为稀疏Rayleigh商最大化问题，提出SDP松弛和舍入算法

Result: 证明了最优解可限制为均匀分布的二元变量U，对于小字母表可通过组合枚举求解，对于高维问题SDP松弛在多项式时间内可解，并识别了稀疏阈值

Conclusion: 提出的稀疏隐私机制设计框架将隐私保护问题转化为可计算的优化问题，SDP松弛提供了实用的多项式时间解法，为高维隐私机制设计提供了理论保证

Abstract: We study an information-theoretic privacy mechanism design problem, where an agent observes useful data $Y$ that is arbitrarily correlated with sensitive data $X$, and design disclosed data $U$ generated from $Y$ (the agent has no direct access to $X$). We introduce \emph{sparse point-wise privacy leakage}, a worst-case privacy criterion that enforces two simultaneous constraints for every disclosed symbol $u\in\mathcal{U}$: (i) $u$ may be correlated with at most $N$ realizations of $X$, and (ii) the total leakage toward those realizations is bounded. In the high-privacy regime, we use concepts from information geometry to obtain a local quadratic approximation of mutual information which measures utility between $U$ and $Y$. When the leakage matrix $P_{X|Y}$ is invertible, this approximation reduces the design problem to a sparse quadratic maximization, known as the Rayleigh-quotient problem, with an $\ell_0$ constraint. We further show that, for the approximated problem, one can without loss of optimality restrict attention to a binary released variable $U$ with a uniform distribution. For small alphabet sizes, the exact sparsity-constrained optimum can be computed via combinatorial support enumeration, which quickly becomes intractable as the dimension grows. For general dimensions, the resulting sparse Rayleigh-quotient maximization is NP-hard and closely related to sparse principal component analysis (PCA). We propose a convex semidefinite programming (SDP) relaxation that is solvable in polynomial time and provides a tractable surrogate for the NP-hard design, together with a simple rounding procedure to recover a feasible leakage direction. We also identify a sparsity threshold beyond which the sparse optimum saturates at the unconstrained spectral value and the SDP relaxation becomes tight.

</details>


### [66] [Estimators for Substitution Rates in Genomes from Read Data](https://arxiv.org/abs/2601.07546)
*Shiv Pratap Singh Rathore,Navin Kashyap*

Main category: cs.IT

TL;DR: 该论文研究了从噪声测序读数中估计两个序列之间突变率的问题，将现有的无对齐方法扩展到测序框架，提出了多种估计器并提供了理论保证。


<details>
  <summary>Details</summary>
Motivation: 现有无对齐方法通常假设可以直接访问完整序列，但在实际测序场景中只能观察到噪声读数，需要开发适用于测序框架的突变率估计方法。

Method: 使用简单模型（突变和测序错误均为替换），提出了多种估计器，为其中一个提供了理论保证，并通过模拟评估其他估计器的性能。

Result: 论文开发了适用于测序框架的突变率估计方法，通过模拟验证了所提估计器的有效性。

Conclusion: 成功将无对齐突变率估计方法扩展到实际测序场景，为从噪声测序读数中准确估计突变率提供了可行的解决方案。

Abstract: We study the problem of estimating the mutation rate between two sequences from noisy sequencing reads. Existing alignment-free methods typically assume direct access to the full sequences. We extend these methods to the sequencing framework, where only noisy reads from the sequences are observed. We use a simple model in which both mutations and sequencing errors are substitutions. We propose multiple estimators, provide theoretical guarantees for one of them, and evaluate the others through simulations.

</details>


### [67] [On the Sequence Reconstruction Problem for the Single-Deletion Two-Substitution Channel](https://arxiv.org/abs/2601.07547)
*Wentu Song,Kui Cai,Tony Q. S. Quek*

Main category: cs.IT

TL;DR: 研究单删除双替换信道下的序列重构问题，证明了当两个q元长度为n的序列汉明距离d≥2时，其错误球交集大小的上界为(q²-1)n²-(3q²+5q-5)n+O_q(1)，且该上界在常数范围内是紧的。


<details>
  <summary>Details</summary>
Motivation: 现有序列重构研究主要关注单一错误类型（插入、删除或替换），但对于混合错误类型的信道（如同时允许删除和替换）了解较少。本文研究单删除双替换信道下的序列重构问题，旨在确定保证正确重构所需的最小错误副本数。

Method: 研究单删除双替换信道（允许一个删除和最多两个替换）下的序列重构问题。通过分析两个q元长度n序列的汉明距离d≥2时，其错误球交集的大小，推导出上界表达式。

Result: 证明了当两个q元长度n序列的汉明距离d≥2时，其错误球交集大小的上界为(q²-1)n²-(3q²+5q-5)n+O_q(1)，其中O_q(1)是与n无关但依赖于q的常数。同时证明该上界在常数范围内是紧的。

Conclusion: 本文解决了单删除双替换信道下的序列重构问题，给出了错误球交集大小的精确上界，填补了混合错误类型信道研究的空白，为序列重构理论提供了重要结果。

Abstract: The Levenshtein sequence reconstruction problem studies the reconstruction of a transmitted sequence from multiple erroneous copies of it. A fundamental question in this field is to determine the minimum number of erroneous copies required to guarantee correct reconstruction of the original sequence. This problem is equivalent to determining the maximum possible intersection size of two error balls associated with the underlying channel. Existing research on the sequence reconstruction problem has largely focused on channels with a single type of error, such as insertions, deletions, or substitutions alone. However, relatively little is known for channels that involve a mixture of error types, for instance, channels allowing both deletions and substitutions. In this work, we study the sequence reconstruction problem for the single-deletion two-substitution channel, which allows one deletion and at most two substitutions applied to the transmitted sequence. Specifically, we prove that if two $q$-ary length-$n$ sequences have the Hamming distance $d\geq 2$, where $q\geq 2$ is any fixed integer, then the intersection size of their error balls under the single-deletion two-substitution channel is upper bounded by $(q^2-1)n^2-(3q^2+5q-5)n+O_q(1)$, where $O_q(1)$ is a constant independent from $n$ but dependent on $q$. Moreover, we show that this upper bound is tight up to an additive constant.

</details>


### [68] [A $q$-Polymatroid Framework for Information Leakage in Secure Linear Network Coding](https://arxiv.org/abs/2601.07567)
*Eimear Byrne,Johan Vester Dinesen,Ragnar Freij-Hollanti,Camilla Hollanti*

Main category: cs.IT

TL;DR: 研究基于嵌套秩度量码的安全线性网络编码方案中的信息泄露问题，揭示了信息泄露量与相关q-多拟阵的条件秩函数之间的关系，并建立了秩度量设置下的Massey对应和q-模拟Brickell-Davenport定理。


<details>
  <summary>Details</summary>
Motivation: 研究安全线性网络编码方案中的信息泄露问题，特别是当攻击者观察到网络链路子集时，需要量化信息泄露量并建立理论框架来分析安全性能。

Method: 使用嵌套秩度量码构建安全线性网络编码方案，通过q-多拟阵理论分析信息泄露，引入q-多拟阵端口和q-访问结构概念，并扩展Massey对应到秩度量设置。

Result: 证明了信息泄露量由底层秩度量码对关联的可表示q-多拟阵的条件秩函数刻画，建立了秩度量设置下的Massey对应，并证明了q-模拟的Brickell-Davenport定理。

Conclusion: 该研究为安全线性网络编码的信息泄露分析提供了理论框架，建立了秩度量码与q-多拟阵之间的深刻联系，扩展了传统访问结构理论到q-模拟领域。

Abstract: We study information leakage in secure linear network coding schemes based on nested rank-metric codes. We show that the amount of information leaked to an adversary that observes a subset of network links is characterized by the conditional rank function of a representable $q$-polymatroid associated with the underlying rank-metric code pair. Building on this connection, we introduce the notions of $q$-polymatroid ports and $q$-access structures and describe their structural properties. Moreover, we extend Massey's correspondence between minimal codewords and minimal access sets to the rank-metric setting and prove a $q$-analogue of the Brickell--Davenport theorem.

</details>


### [69] [Clipped Affine Policy: Low-Complexity Near-Optimal Online Power Control for Energy Harvesting Communications over Fading Channels](https://arxiv.org/abs/2601.07622)
*Hao Wu,Shengtian Yang,Huiguo Gao,Diao Wang,Jun Chen,Guanding Yu*

Main category: cs.IT

TL;DR: 论文提出了一种基于线性策略近似的能量收集通信在线功率控制方法，包括乐观和鲁棒两种裁剪仿射策略，并结合强化学习实现高效优化。


<details>
  <summary>Details</summary>
Motivation: 研究无线衰落信道中点对点能量收集通信的在线功率控制问题，旨在在计算复杂度和最优性之间取得良好平衡，解决现有方法的性能限制。

Method: 推导了功率控制问题Bellman方程中相对值函数的线性策略近似，得到乐观和鲁棒两种裁剪仿射策略（电池水平和信道SNR系数倒数的裁剪仿射函数），并提出了领域知识增强的强化学习算法，可扩展到具有能量和/或信道前瞻的场景。

Result: 鲁棒裁剪仿射策略（结合RL，最多使用五个参数）在各种场景下均优于现有方法，相对于最优策略的性能损失小于2%，在计算复杂度和最优性之间取得了良好平衡。

Conclusion: 提出的线性策略近似和领域知识增强的强化学习方法为能量收集通信提供了高效、接近最优的在线功率控制解决方案，特别适用于具有前瞻信息的场景。

Abstract: This paper investigates online power control for point-to-point energy harvesting communications over wireless fading channels. A linear-policy-based approximation is derived for the relative-value function in the Bellman equation of the power control problem. This approximation leads to two fundamental power control policies: optimistic and robust clipped affine policies, both taking the form of a clipped affine function of the battery level and the reciprocal of channel signal-to-noise ratio coefficient. They are essentially battery-limited weighted directional waterfilling policies operating between adjacent time slots. By leveraging the relative-value approximation and derived policies, a domain-knowledge-enhanced reinforcement learning (RL) algorithm is proposed for online power control. The proposed approach is further extended to scenarios with energy and/or channel lookahead. Comprehensive simulation results demonstrate that the proposed methods achieve a good balance between computational complexity and optimality. In particular, the robust clipped affine policy (combined with RL, using at most five parameters) outperforms all existing approaches across various scenarios, with less than 2\% performance loss relative to the optimal policy.

</details>


### [70] [New $X$-Secure $T$-Private Information Retrieval Schemes via Rational Curves and Hermitian Curves](https://arxiv.org/abs/2601.07676)
*Yuan Gao,Weijun Fang,Jingke Xu,Jiejing Wen*

Main category: cs.IT

TL;DR: 本文提出了一种新的XSTPIR方案构建方法，通过提高已有曲线上有理点的利用效率，而不是追求更高亏格和更多有理点的曲线，从而获得了更高的最大PIR率。


<details>
  <summary>Details</summary>
Motivation: 现有XSTPIR方案主要通过使用更高亏格和更多有理点的曲线（如Hermitian曲线）来提高最大PIR率。本文提出不同的视角：通过提高已有曲线上有理点的利用效率来实现相同目标。

Method: 引入多项式空间span{1,x,...,x^{k-1}}的新基族替代拉格朗日插值基，基于有理曲线和Hermitian曲线分别开发了两个新的XSTPIR方案族。

Result: 参数比较显示新方案性能更优：基于Hermitian曲线的方案在q^2≥14^2且X+T≥4q时提供已知最大PIR率；在q^2≥28^2且X+T≥4时，两个方案共同提供已知最大PIR率。

Conclusion: 通过提高有理点利用效率而非追求更高亏格曲线，可以构建性能更优的XSTPIR方案，为XSTPIR方案设计提供了新的有效方向。

Abstract: $X$-secure and $T$-private information retrieval (XSTPIR) is a variant of private information retrieval where data security is guaranteed against collusion among up to $X$ servers and the user's retrieval privacy is guaranteed against collusion among up to $T$ servers. Recently, researchers have constructed XSTPIR schemes through the theory of algebraic geometry codes and algebraic curves, with the aim of obtaining XSTPIR schemes that have higher maximum PIR rates for fixed field size and $X,T$ (the number of servers $N$ is not restricted). The mainstream approach is to employ curves of higher genus that have more rational points, evolving from rational curves to elliptic curves to hyperelliptic curves and, most recently, to Hermitian curves.
  In this paper, we propose a different perspective: with the shared goal of constructing XSTPIR schemes with higher maximum PIR rates, we move beyond the mainstream approach of seeking curves with higher genus and more rational points. Instead, we aim to achieve this goal by enhancing the utilization efficiency of rational points on curves that have already been considered in previous work. By introducing a family of bases for the polynomial space $\text{span}_{\mathbb{F}_q}\{1,x,\dots,x^{k-1}\}$ as an alternative to the Lagrange interpolation basis, we develop two new families of XSTPIR schemes based on rational curves and Hermitian curves, respectively. Parameter comparisons demonstrate that our schemes achieve superior performance. Specifically, our Hermitian-curve-based XSTPIR scheme provides the largest known maximum PIR rates when the field size $q^2\geq 14^2$ and $X+T\geq 4q$. Moreover, for any field size $q^2\geq 28^2$ and $X+T\geq 4$, our two XSTPIR schemes collectively provide the largest known maximum PIR rates.

</details>


### [71] [Weak Composition Lattices and Ring-Linear Anticodes](https://arxiv.org/abs/2601.07725)
*Jessica Bariffi,Drisana Bhatia,Giuseppe Cotardo,Violetta Weger*

Main category: cs.IT

TL;DR: 论文研究环Z/p^sZ上的Lee度量线性码，引入并刻画了最优Lee度量反码，建立了反码格与弱组合格之间的双射，并应用该对应关系通过反码方法引入新的Lee度量码不变量。


<details>
  <summary>Details</summary>
Motivation: 格论和偏序集在编码理论中日益重要，为研究纠错码的结构和代数性质提供了组合框架。受最近连接格论、反码和编码理论不变量的研究启发，本文研究带有Lee度量的环线性码。

Method: 引入并刻画环Z/p^sZ上的最优Lee度量反码，展示这类反码族可按子类型自然划分，并在包含关系下形成格。建立该格与按支配序排列的弱组合格之间的双射。

Result: 证明了最优Lee度量反码族形成格结构，并建立了该格与弱组合格之间的对应关系。利用这一对应关系，通过反码方法为Lee度量码引入了新的不变量。

Conclusion: 通过研究环Z/p^sZ上的Lee度量反码，建立了反码格与弱组合格之间的对应关系，为Lee度量码提供了新的组合不变量，扩展了格论在编码理论中的应用。

Abstract: Lattices and partially ordered sets have played an increasingly important role in coding theory, providing combinatorial frameworks for studying structural and algebraic properties of error-correcting codes. Motivated by recent works connecting lattice theory, anticodes, and coding-theoretic invariants, we investigate ring-linear codes endowed with the Lee metric. We introduce and characterize optimal Lee-metric anticodes over the ring $\mathbb{Z}/p^s\mathbb{Z}$. We show that the family of such anticodes admits a natural partition into subtypes and forms a lattice under inclusion. We establish a bijection between this lattice and a lattice of weak compositions ordered by dominance. As an application, we use this correspondence to introduce new invariants for Lee-metric codes via an anticode approach.

</details>


### [72] [Lossy Source Coding with Broadcast Side Information](https://arxiv.org/abs/2601.07797)
*Yiqi Chen,Holger Boche,Marc Geitz*

Main category: cs.IT

TL;DR: 研究带广播边信息的信源编码问题，边信息通过噪声广播信道发送给两个接收器，给出了速率-失真-带宽四元组的外界和分离方案的可行域，在二次高斯情况下比较了分离方案与未编码方案。


<details>
  <summary>Details</summary>
Motivation: 研究边信息通过噪声广播信道传输的信源编码问题，这种场景在实际通信系统中很常见，需要分析边信息传输质量对信源编码性能的影响。

Method: 建立了带广播边信息的信源编码模型，推导了速率-失真-带宽四元组的外界，提出了基于分离方案的可行域，并在二次高斯情况下进行了具体分析。

Result: 给出了RDB四元组的外界和分离方案的可行域，提供了完全表征的特殊情况，在二次高斯情况下比较了分离方案与未编码方案的性能。

Conclusion: 该研究为带广播边信息的信源编码问题提供了理论框架和分析工具，分离方案在某些情况下优于未编码方案，为实际系统设计提供了指导。

Abstract: This paper considers the source coding problem with broadcast side information. The side information is sent to two receivers through a noisy broadcast channel. We provide an outer bound of the rate--distortion--bandwidth (RDB) quadruples and achievable RDB quadruples when the helper uses a separation-based scheme. Some special cases with full characterization are also provided. We then compare the separation-based scheme with the uncoded scheme in the quadratic Gaussian case.

</details>
