<div id=toc></div>

# Table of Contents

- [cs.IT](#cs.IT) [Total: 2]
- [eess.SP](#eess.SP) [Total: 13]


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [1] [CSGO: Generalized Optimization for Cold Start in Wireless Collaborative Edge LLM Systems](https://arxiv.org/abs/2508.11287)
*Xuran Liu,Nan Xue,Rui Bao,Yaping Sun,Zhiyong Chen,Meixia Tao,Xiaodong Xu,Shuguang Cui*

Main category: cs.IT

TL;DR: 提出了一种延迟感知调度框架，通过重叠模型加载与计算和通信来最小化推理延迟。


<details>
  <summary>Details</summary>
Motivation: 在边缘设备上部署大语言模型时，资源有限导致冷启动延迟问题，现有方法未能有效解决。

Method: 设计了一个动态调整层分区和分配的框架，将问题建模为混合整数非线性规划，并采用动态规划算法优化。

Result: 实验结果显示，该方法显著降低了冷启动延迟。

Conclusion: 该框架有效减少了推理延迟，提升了边缘设备上大语言模型的部署效率。

Abstract: While deploying large language models on edge devices promises low-latency
and privacy-preserving AI services, it is hindered by limited device resources.
Although pipeline parallelism facilitates distributed inference, existing
approaches often ignore the cold-start latency caused by on-demand model
loading. In this paper, we propose a latency-aware scheduling framework that
overlaps model loading with computation and communication to minimize total
inference latency. Based on device and model parameters, the framework
dynamically adjusts layer partitioning and allocation to effectively hide
loading time, thereby eliminating as many idle periods as possible. We
formulate the problem as a Mixed-Integer Non-Linear Program and design an
efficient dynamic programming algorithm to optimize model partitioning and
device assignment. Experimental results show that the proposed method
significantly reduces cold-start latency compared to baseline strategies.

</details>


### [2] [Dynamic Quality-Latency Aware Routing for LLM Inference in Wireless Edge-Device Networks](https://arxiv.org/abs/2508.11291)
*Rui Bao,Nan Xue,Yaping Sun,Zhiyong Chen*

Main category: cs.IT

TL;DR: 论文提出了一种动态路由框架，用于在无线边缘设备协作环境中平衡LLM推理质量和延迟，显著降低了响应延迟和大模型调用。


<details>
  <summary>Details</summary>
Motivation: 无线通信与LLM结合可提供智能服务，但边缘设备部署中存在推理质量与延迟的权衡问题。

Method: 提出动态路由框架，结合轻量级移动设备模型和边缘服务器强大模型，针对单轮和多轮查询设计成本模型。

Result: 实验显示框架在保持推理质量的同时，平均延迟降低5-15%，大模型调用减少10-20%。

Conclusion: 该框架有效解决了边缘设备部署中的资源分配问题，提升了服务效率。

Abstract: The integration of wireless communications and Large Language Models (LLMs)
is poised to unlock ubiquitous intelligent services, yet deploying them in
wireless edge-device collaborative environments presents a critical trade-off
between inference quality and end-to-end latency. A fundamental mismatch exists
between task complexity and resource allocation: offloading simple queries
invites prohibitive latency, while on-device models lack the capacity for
demanding computations. To address this challenge, we propose a dynamic,
quality-latency aware routing framework that orchestrates inference between a
lightweight model on the mobile device and a powerful model on the edge server.
Our framework employs two distinct cost models: for single-turn queries, it
fuses a BERT-predicted semantic score with communication and computation
overheads; for multi-turn dialogues, it further quantifies context-aware costs
arising from model switching and KV-cache management. While maintaining full
inference quality, extensive experiments demonstrate that our framework cuts
average response latency by 5-15% and reduces large model invocations by 10-20%
against competitive baselines on MMLU, GSM8K, and MT-Bench-101 benchmarks.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [3] [Multi-Satellite Cooperative MIMO Transmission: Statistical CSI-Aware RSMA Precoding Design](https://arxiv.org/abs/2508.11132)
*Sangwon Jo,Seok-Hwan Park*

Main category: eess.SP

TL;DR: 研究了多LEO卫星系统中的卫星间协作传输，提出基于统计CSI的RSMA方案，性能接近瞬时CSI且优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 提升多LEO卫星系统的频谱效率，解决瞬时CSI获取困难的问题。

Method: 设计MIMO预编码和RSMA方案，基于统计CSI优化最大最小公平速率，采用闭式上界和WMMSE算法。

Result: 仿真显示，基于统计CSI的RSMA方案性能接近瞬时CSI，显著优于传统空间分割多址。

Conclusion: 统计CSI的RSMA方案在多LEO卫星系统中具有高效性和实用性。

Abstract: We investigate inter-satellite cooperative transmission in a multiple
low-Earth orbit (LEO) satellite communication system to enhance spectral
efficiency. Specifically, we design multiple-input multipleoutput (MIMO)
precoding at LEO satellites for cooperative rate-splitting multiple access
(RSMA). Given the difficulty of acquiring instantaneous channel state
information (iCSI) due to long delays and Doppler effects, we formulate an
ergodic max-min fairness rate (MMFR) maximization problem based on statistical
CSI (sCSI). To address the challenge of ergodic rate evaluation, we approximate
the problem using closed-form upper bounds and develop a weighted minimum mean
squared error-based algorithm to obtain a stationary point. Simulation results
demonstrate that the proposed sCSI-based RSMA scheme approaches iCSI-based
performance and significantly outperforms conventional space-division multiple
access.

</details>


### [4] [Beyond Diagonal Reconfigurable Intelligent Surface Enabled Sensing: Cramer-Rao Bound Optimization](https://arxiv.org/abs/2508.11292)
*Xiaoqi Zhang,Liang Liu,Shuowen Zhang,Haijun Zhang*

Main category: eess.SP

TL;DR: 本文研究了BD-RIS在6G感知中的增益，提出了一种基于自适应黎曼最速上升算法的优化方案，显著提升了目标定位性能。


<details>
  <summary>Details</summary>
Motivation: 尽管BD-RIS在通信中的优势已被广泛研究，但其在6G感知中的增益仍未知，因此本文旨在探索BD-RIS辅助感知的潜力。

Method: 通过推导CRB并设计基于自适应黎曼最速上升算法的优化方案，满足非凸单位约束，最小化CRB。

Result: 数值结果表明，所提出的BD-RIS辅助目标定位方法具有优越的感知性能。

Conclusion: BD-RIS在6G感知中展现出显著优势，为未来无线感知技术提供了新思路。

Abstract: Recently, beyond diagonal reconfigurable intelligent surface (BD-RIS) has
emerged as a more flexible solution to engineer the wireless propagation
channels, thanks to its non-diagonal reflecting matrix. Although the gain of
the BD-RIS over the conventional RIS in communication has been revealed in many
works, its gain in 6G sensing is still unknown. This motivates us to study the
BD-RIS assisted sensing in this letter. Specifically, we derive the Cramer-Rao
bound (CRB) for estimating the angle-of-arrival (AOA) from the target to the
BD-RIS under the constraint that the BD-RIS scattering matrix is unitary. To
minimize the CRB, we develop an optimization scheme based on an adaptive
Riemannian steepest ascent algorithm that can satisfy the non-convex unitary
constraint. Numerical results demonstrate that the proposed BD-RIS-assisted
target localization method achieves superior sensing performance.

</details>


### [5] [Distributed Integrated Sensing, Localization, and Communications over LEO Satellite Constellations](https://arxiv.org/abs/2508.11029)
*Yuchen Zhang,Francis Soualle,Musa Furkan Keskin,Yuan Liu,Linlong Wu,José A. del Peral-Rosado,Bhavani Shankar M. R.,Gonzalo Seco-Granados,Henk Wymeersch,Tareq Y. Al-Naffouri*

Main category: eess.SP

TL;DR: 本文提出了一种名为DISLAC的分布式集成感知、定位和通信方法，通过LEO卫星间的协作解决其资源限制问题，提升6G应用的性能。


<details>
  <summary>Details</summary>
Motivation: LEO卫星在6G应用中面临功率、天线孔径和机载处理能力的限制，需要创新方法突破这些瓶颈。

Method: 采用分布式MIMO架构，通过卫星间链路实现协作，提升吞吐量、定位精度和感知鲁棒性。

Result: 案例研究表明DISLAC能显著改善性能，并分析了同步、天线可重构性和ISL设计等关键问题。

Conclusion: 文章总结了DISLAC的潜力，并提出了未来非地面网络中实际部署的研究方向。

Abstract: Low Earth orbit (LEO) satellite constellations are rapidly becoming essential
enablers of next-generation wireless systems, offering global broadband access,
high-precision localization, and reliable sensing beyond terrestrial coverage.
However, the inherent limitations of individual LEO satellites, including
restricted power, limited antenna aperture, and constrained onboard processing,
hinder their ability to meet the growing demands of 6G applications. To address
these challenges, this article introduces the concept of distributed integrated
sensing, localization, and communication (DISLAC) over LEO constellations,
inspired by distributed multiple input multiple output architectures. By
enabling inter-satellite cooperation through inter-satellite links, DISLAC can
substantially improve throughput, positioning accuracy, and sensing robustness.
We present illustrative case studies that quantify these benefits and analyze
key system-level considerations, including synchronization, antenna
reconfigurability, and ISL design. The article concludes by outlining open
research directions to advance the practical deployment of DISLAC in future
non-terrestrial networks.

</details>


### [6] [Optimizing Rate-CRB Performance for Beyond Diagonal Reconfigurable Intelligent Surface Enabled ISAC](https://arxiv.org/abs/2508.11295)
*Xiaoqi Zhang,Liang Liu,Shuowen Zhang,Weifeng Zhu,Haijun Zhang*

Main category: eess.SP

TL;DR: 论文提出了一种基于BD-RIS的ISAC系统优化方法，通过设计BS波束成形矩阵和BD-RIS散射矩阵，在满足定位精度约束下最大化用户总速率。


<details>
  <summary>Details</summary>
Motivation: 研究如何利用BD-RIS提升ISAC系统的通信和定位性能，克服传统RIS的局限性。

Method: 采用对数障碍法和黎曼最速上升法解决带约束的流形优化问题。

Result: 数值结果表明，所提算法有效，且BD-RIS优于传统RIS。

Conclusion: BD-RIS在ISAC系统中具有显著性能优势，为未来通信与感知一体化提供了新思路。

Abstract: This letter considers a beyond diagonal reconfigurable intelligent surface
(BD-RIS) aided integrated sensing and communication (ISAC) system, where the
BD-RIS can help a multi-antenna base station (BS) serve multiple user
equipments (UEs) and localize a target simultaneously. We formulate an
optimization problem that designs the BS beamforming matrix and the BD-RIS
scattering matrix to maximize UEs' sum rate subject to a localization
Cramer-Rao bound (CRB) constraint and an additional unitary matrix constraint
for the scattering matrix. Because unitary matrices form a manifold, our
problem belongs to constrained manifold optimization. This letter proposes a
log-barrier based Riemannian steepest ascent method to solve this problem
effectively. Numerical results verify the effectiveness of our algorithm and
the performance gain of the BD-RIS aided ISAC systems over the conventional RIS
aided ISAC systems.

</details>


### [7] [Near-Field Variable-Width Beam Coverage and Codebook Design for XL-RIS](https://arxiv.org/abs/2508.11178)
*Yida Zhang,Qiuyan Liu,Qiang Wang,Hongtao Luo,Yuqi Xia*

Main category: eess.SP

TL;DR: 提出了一种针对XL-RIS的近场可变宽度波束生成算法，解决了传统XL-RIS波束宽度窄导致的波束对准和广播复杂性问题，提高了用户设备的频谱效率和通信可靠性。


<details>
  <summary>Details</summary>
Motivation: XL-RIS的高波束增益虽能缓解高频电磁波衰减导致的基站覆盖问题，但其窄波束宽度增加了波束对准和广播的复杂性，亟需解决方案。

Method: 提出了一种基于近场假设的可变宽度波束生成算法，并将其应用于XL-RIS的近场码本设计，支持任意形状码字区域的波束覆盖和多XL-RIS系统的联合码本生成。

Result: 仿真结果表明，该方案在码字区域内能显著提高用户设备的频谱效率并降低通信中断概率，同时对码字区域位置和面积变化具有更好的鲁棒性。

Conclusion: 该算法有效解决了XL-RIS窄波束宽度带来的问题，提升了系统性能，适用于多XL-RIS系统的联合优化。

Abstract: To mitigate the issue of limited base station coverage caused by severe
high-frequency electromagnetic wave attenuation, Extremely Large Reconfigurable
Intelligent Surface (XL-RIS) has garnered significant attention due to its high
beam gain. However, XL-RIS exhibits a narrower beam width compared to
traditional RIS, which increases the complexity of beam alignment and
broadcast. To address this problem, we propose a variable-width beam generation
algorithm under the near-field assumption and apply it to the near-field
codebook design for XL-RIS. Our algorithm can achieve beam coverage for
arbitrarily shaped codeword regions and generate a joint codebook for the
multi-XL-RIS system. The simulation results demonstrate that our proposed
scheme enables user equipment (UE) to achieve higher spectral efficiency and
lower communication outage probability within the codeword region compared to
existing works. Furthermore, our scheme exhibits better robustness to codeword
region location and area variations.

</details>


### [8] [KAN-HAR: A Human activity recognition based on Kolmogorov-Arnold Network](https://arxiv.org/abs/2508.11186)
*Mohammad Alikhani*

Main category: eess.SP

TL;DR: 该论文提出了一种基于Kolmogorov-Arnold网络（KAN）和单三轴加速度计的人体活动识别方法，具有更高的参数效率和可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统深度学习方法在人体活动识别（HAR）中需要大量参数调优且缺乏可解释性，因此探索更高效和可解释的替代方案。

Method: 使用MotionSense数据集，预处理和归一化加速度计和陀螺仪数据，通过KAN进行特征学习和分类。

Result: KAN在分类性能上与传统深度神经网络相当或更优，同时参数数量显著减少。

Conclusion: KAN架构是一种高效且可解释的HAR系统替代方案，适用于实际应用。

Abstract: Human Activity Recognition (HAR) plays a critical role in numerous
applications, including healthcare monitoring, fitness tracking, and smart
environments. Traditional deep learning (DL) approaches, while effective, often
require extensive parameter tuning and may lack interpretability. In this work,
we investigate the use of a single three-axis accelerometer and the
Kolmogorov--Arnold Network (KAN) for HAR tasks, leveraging its ability to model
complex nonlinear relationships with improved interpretability and parameter
efficiency. The MotionSense dataset, containing smartphone-based motion sensor
signals across various physical activities, is employed to evaluate the
proposed approach. Our methodology involves preprocessing and normalization of
accelerometer and gyroscope data, followed by KAN-based feature learning and
classification. Experimental results demonstrate that the KAN achieves
competitive or superior classification performance compared to conventional
deep neural networks, while maintaining a significantly reduced parameter
count. This highlights the potential of KAN architectures as an efficient and
interpretable alternative for real-world HAR systems. The open-source
implementation of the proposed framework is available at the Project's GitHub
Repository.

</details>


### [9] [Enabling low-power massive MIMO with ternary ADCs for AIoT sensing](https://arxiv.org/abs/2508.11234)
*Shengheng Liu,Ningning Fu*

Main category: eess.SP

TL;DR: 论文提出了一种使用三值ADC（T-ADCs）的低功耗AIoT解决方案，通过联合导频和数据（JPD）方法优化信道估计，并在噪声方差未知的情况下验证其性能。


<details>
  <summary>Details</summary>
Motivation: 随着网络设备普及和智能需求增长，AIoT的高功耗问题亟待解决，尤其是高分辨率ADC和多射频链的能耗问题。

Method: 采用T-ADCs和JPD方案进行信道估计，提出改进的EM和变分推断EM估计器，分别用于确定性和随机信道。

Result: 理论分析和仿真表明，JPD方案能有效减轻量化效应带来的性能下降，且无需额外导频开销。

Conclusion: T-ADCs和JPD方案在低功耗AIoT中具有可行性，为绿色智能传感提供了有效途径。

Abstract: The proliferation of networked devices and the surging demand for ubiquitous
intelligence have given rise to the artificial intelligence of things (AIoT).
However, the utilization of high-resolution analog-to-digital converters (ADCs)
and numerous radio frequency chains significantly raises power consumption.
This paper explores a cost-effective solution using ternary ADCs (T-ADCs) in
massive multiple-input-multiple-output (MIMO) systems for low-power AIoT and
specifically addresses channel sensing challenges. The channel is first
estimated through a pilot-aided scheme and refined using a joint-pilot-and-data
(JPD) approach. To assess the performance limits of this two-threshold ADC
system, the analysis includes its hardware-ideal counterpart, the parallel
one-bit ADCs (PO-ADCs) and a realistic scenario where noise variance is unknown
at the receiver is considered. Analytical findings indicate that the JPD scheme
effectively mitigates performance degradation in channel estimation due to
coarse quantization effects under mild conditions, without necessitating
additional pilot overhead. For deterministic and random channels, we propose
modified expectation maximization (EM) and variational inference EM estimators,
respectively. Extensive simulations validate the theoretical results and
demonstrate the effectiveness of the proposed estimators in terms of mean
square error and symbol error rate, which showcases the feasibility of
implementing T-ADCs and the associated JPD scheme for greener AIoT smart
sensing.

</details>


### [10] [Temporally-Similar Structure-Aware Spatiotemporal Fusion of Satellite Images](https://arxiv.org/abs/2508.11259)
*Ryosuke Isono,Shunsuke Ono*

Main category: eess.SP

TL;DR: 提出了一种新的时空融合框架TSSTF，通过TGTV和TGEC机制解决噪声环境下卫星图像融合中的结构细节丢失问题。


<details>
  <summary>Details</summary>
Motivation: 现有噪声鲁棒的时空融合方法常导致空间结构细节丢失，TSSTF旨在解决这一问题。

Method: 引入TGTV和TGEC机制，将时空融合任务建模为约束优化问题，并开发了高效的求解算法。

Result: TSSTF在无噪声条件下与现有方法相当，在噪声条件下表现更优。

Conclusion: TSSTF在噪声环境下能有效保留结构细节，提供了推荐参数以增强实用性和可重复性。

Abstract: This paper proposes a novel spatiotemporal (ST) fusion framework for
satellite images, named Temporally-Similar Structure-Aware ST fusion (TSSTF).
ST fusion is a promising approach to address the trade-off between the spatial
and temporal resolution of satellite images. In real-world scenarios, observed
satellite images are severely degraded by noise due to measurement equipment
and environmental conditions. Consequently, some recent studies have focused on
enhancing the robustness of ST fusion methods against noise. However, existing
noise-robust ST fusion approaches often fail to capture fine spatial structure,
leading to oversmoothing and artifacts. To address this issue, TSSTF introduces
two key mechanisms: Temporally-Guided Total Variation (TGTV) and
Temporally-Guided Edge Constraint (TGEC). TGTV is a novel regularization
function that promotes spatial piecewise smoothness while preserving structural
details, guided by a reference high spatial resolution image acquired on a
nearby date. TGEC enforces consistency in edge locations between two temporally
adjacent images, while allowing for spectral variations. We formulate the ST
fusion task as a constrained optimization problem incorporating TGTV and TGEC,
and develop an efficient algorithm based on a preconditioned primal-dual
splitting method. Experimental results demonstrate that TSSTF performs
comparably to state-of-the-art methods under noise-free conditions and
outperforms them under noisy conditions. Additionally, we provide a
comprehensive set of recommended parameter values that consistently yield high
performance across diverse target regions and noise conditions, aiming to
enhance reproducibility and practical utility.

</details>


### [11] [Important Bit Prefix M-ary Quadrature Amplitude Modulation for Semantic Communications](https://arxiv.org/abs/2508.11351)
*Haonan Lu,Rui Meng,Xiaodong Xu,Yiming Liu,Ping Zhang,Dusit Niyato*

Main category: eess.SP

TL;DR: 提出了一种基于MQAM的语义通信调制方案IBP-MQAM，通过LDA提取语义并验证其性能优于传统MQAM。


<details>
  <summary>Details</summary>
Motivation: 为语义通信（SemCom）设计专用信道调制方案，提升通信效率。

Method: 提出IBP-MQAM方案，推导重要与非重要符号错误率的近似表达式，并使用LDA量化语义。

Result: IBP-MQAM在语义通信场景中性能优于传统MQAM，并分析了关键参数的影响。

Conclusion: IBP-MQAM为语义通信提供了一种有效的调制方案，具有实际应用潜力。

Abstract: M-ary Quadrature Amplitude Modulation (MQAM) is a commonly used channel
modulation technology in wireless communication systems. To achieve dedicated
channel modulation for semantic communication (SemCom), we propose an
Important-Bit-Prefixed MQAM (IBP-MQAM) scheme and derive its approximate
expression of important symbol error rate (ISER) and unimportant symbol error
rate (USER). By extracting and quantifying text semantics using Latent
Dirichlet Allocation (LDA), we verify that IBP-MQAM achieves improved
performance over MQAM in SemCom scenarios and further analyze the effects of
key system parameters.

</details>


### [12] [Importance-Aware Robust Semantic Transmission for LEO Satellite-Ground Communication](https://arxiv.org/abs/2508.11457)
*Hui Cao,Rui Meng,Xiaodong Xu,Shujun Han,Ping Zhang*

Main category: eess.SP

TL;DR: 提出了一种面向卫星-地面语义通信的IRST框架，解决带宽限制和信道动态性问题。


<details>
  <summary>Details</summary>
Motivation: 6G时代卫星-地面语义通信面临带宽限制和动态SNR波动挑战，需高效任务导向传输方案。

Method: 采用分割模型增强算法提升语义分割精度，任务驱动语义选择优先传输重要内容，堆叠式SNR感知信道编解码器自适应调整编码。

Result: IRST模型在多种条件下表现优于现有基准，具备更强的鲁棒性。

Conclusion: IRST框架为带宽稀缺和信道多变的卫星-地面语义通信提供了高效解决方案。

Abstract: Satellite-ground semantic communication is anticipated to serve a critical
role in the forthcoming 6G era. Nonetheless, task-oriented data transmission in
such systems remains a formidable challenge, primarily due to the dynamic
nature of signal-to-noise ratio (SNR) fluctuations and the stringent bandwidth
limitations inherent to low Earth orbit (LEO) satellite channels. In response
to these constraints, we propose an importance-aware robust semantic
transmission (IRST) framework, specifically designed for scenarios
characterized by bandwidth scarcity and channel variability. The IRST scheme
begins by applying a segmentation model enhancement algorithm to improve the
granularity and accuracy of semantic segmentation. Subsequently, a task-driven
semantic selection method is employed to prioritize the transmission of
semantically vital content based on real-time channel state information.
Furthermore, the framework incorporates a stack-based, SNR-aware channel codec
capable of executing adaptive channel coding in alignment with SNR variations.
Comparative evaluations across diverse operating conditions demonstrate the
superior performance and resilience of the IRST model relative to existing
benchmarks.

</details>


### [13] [Efficient Artifacts Removal for Adaptive Deep Brain Stimulation and a Temporal Event Localization Analysis](https://arxiv.org/abs/2508.11459)
*Tzu-Chi Liu,Po-Lin Chen,Yi-Chieh Chen,Po-Hsun Tu,Chih-Hua Yeh,Mun-Chun Yeap,Chiung-Chu Chen,Hau-Tieng Wu*

Main category: eess.SP

TL;DR: SMARTA+是一种改进的算法，用于解决自适应深部脑刺激（aDBS）中的信号污染问题，具有高效计算能力和灵活设计，适用于实时应用。


<details>
  <summary>Details</summary>
Motivation: 传统DBS存在信号污染问题，现有方法在抑制伪迹和算法灵活性之间存在权衡，SMARTA+旨在解决这些问题。

Method: 开发了SMARTA+算法，能够高效抑制刺激和瞬态直流伪迹，并支持灵活设计，通过半真实和真实患者数据验证其性能。

Result: SMARTA+在伪迹去除效果上与SMARTA相当或更优，计算时间显著减少，且保留了信号频谱和时间结构。

Conclusion: SMARTA+是推动实时闭环aDBS系统发展的有前景工具。

Abstract: Adaptive deep brain stimulation (aDBS) leverages symptom-related biomarkers
to deliver personalized neuromodulation therapy, with the potential to improve
treatment efficacy and reduce power consumption compared to conventional DBS.
However, stimulation-induced signal contamination remains a major technical
barrier to advancing its clinical application. Existing artifact removal
strategies, both front-end and back-end, face trade-offs between artifact
suppression and algorithmic flexibility. Among back-end algorithms, Shrinkage
and Manifold-based Artifact Removal using Template Adaptation (SMARTA) has
shown promising performance in mitigating stimulus artifacts with minimal
distortion to local field potentials (LFPs), but its high computational demand
and inability to handle transient direct current (DC) artifacts limit its use
in real-time applications. To address this, we developed SMARTA+, a
computationally efficient extension of SMARTA capable of suppressing both
stimulus and transient DC artifacts while supporting flexible algorithmic
design. We evaluated SMARTA+ using semi-real aDBS data and real data from
Parkinson's disease patients. Compared to SMARTA and other established methods,
SMARTA+ achieved comparable or superior artifact removal while significantly
reducing computation time. It preserved spectral and temporal structures,
ranging from beta band to high-frequency oscillations, and demonstrated
robustness across diverse stimulation protocols. Temporal event localization
analysis further showed improved accuracy in detecting beta bursts. These
findings support SMARTA+ as a promising tool for advancing real-time,
closed-loop aDBS systems.

</details>


### [14] [Reducing AoI and Improving Throughput for NOMA-assisted SGF Systems: A Hierarchical Learning Approach](https://arxiv.org/abs/2508.11473)
*Yuqin Liu,Mona Jaber,Yan Liu,Arumugam Nallanathan*

Main category: eess.SP

TL;DR: 提出了一种基于非正交多址（NOMA）的半免授权（SGF）框架，通过利用授权用户（GBUs）的剩余资源为免授权用户（GFUs）提供信道接入。通过联合波束成形设计和传输调度优化系统吞吐量并降低GFUs的信息年龄。问题被建模为马尔可夫决策过程，并提出深度强化学习（DRL）和分层学习算法解决。


<details>
  <summary>Details</summary>
Motivation: 解决免授权用户在信道接入中的资源分配和调度问题，优化系统吞吐量并降低信息年龄。

Method: 1) 将问题建模为马尔可夫决策过程；2) 提出基于DRL的传输调度方法；3) 设计分层学习算法，上层策略优化波束成形，下层策略最大化传输时隙利用率。

Result: 1) DRL调度在信息年龄减少上优于基线方法；2) 分层学习算法实现31.82%的增益，同时将GFUs的平均信息年龄控制在1.5时隙内；3) 方法在GFUs数量为GBUs的1-5倍时均有效。

Conclusion: 提出的NOMA辅助SGF框架和分层学习算法能有效提升信道接入效率，降低信息年龄，适用于不同用户规模场景。

Abstract: A non-orthogonal multiple access (NOMA) assisted semi-grant-free (SGF)
framework is proposed to enable channel access for grant-free users (GFUs) by
using residual resources from grant-based users. Under this framework, the
problem of joint beamforming design and transmission scheduling is formulated
to improve the system throughput and reduce the age-of-information of GFUs. The
aforementioned problem is transferred into a Markov Decision Process to model
the changing environment with the transmission/ waiting/ retransmission of
GFUs. In an effort to solve the pertinent problem, firstly, a deep
reinforcement learning (DRL) based transmission scheduling approach is proposed
for determining the optimal transmission probability based on the available
transmission slots and transmission status of GFUs. Secondly, a hierarchical
learning algorithm is proposed to analyze the channel state information of GBUs
and the transmission status of GFUs, and to train an upper-level policy based
on this analysis for beamforming to achieve efficient grant-based transmission,
while a lower-level policy adapts to maximize the utilization of transmission
slots allocated by the upper-level agent. The two policies interact to improve
channel access and avoid collisions. Numerical results reveal that 1) The DRL
based transmission scheduling outperforms existing adaptive and state-dependent
baselines in AoI reduction, where an average
three-time-slots-earlier-transmission can be obtained compared to the
state-dependent choice, and five time slots earlier can be achieved when
comparing to the adaptive choice; 2) The hierarchical learning algorithm is
able to achieve approximately a 31.82% gain while maintaining the average AoI
of GFUs within 1.5 time slots. 3) The effectiveness of the hierarchical
learning scheme in NOMA-assisted SGF system is validated across scenarios with
GFUs counts from 1-5 times of GBUs.

</details>


### [15] [Liquid Crystal-Based RIS Loss-Trade-Off Analysis](https://arxiv.org/abs/2508.11489)
*Bowu Wang,Mohamadreza Delbari,Robin Neuder,Alejandro Jiménez-Sáez,Vahid Jamali*

Main category: eess.SP

TL;DR: 本文研究了基于液晶（LC）技术的可重构智能表面（RIS）在毫米波频段中的相位偏移范围与插入损耗之间的权衡关系，并探讨了其对无线系统性能的影响。


<details>
  <summary>Details</summary>
Motivation: 液晶技术因其低功耗、可扩展性和连续可调相位偏移等优势，成为毫米波频段大型可重构智能表面的潜在解决方案。然而，基于延迟线架构的LC-RIS在相位偏移范围与插入损耗之间存在权衡关系，这一关系尚未在LC-RIS辅助的无线系统中得到研究。

Method: 研究通过配置基站（BS）和RIS，以最小化发射功率，同时满足用户的服务质量（QoS）要求，探讨了LC相位偏移范围对系统性能的影响。

Result: 仿真结果揭示了总发射功率与可达到的数据速率之间存在基本权衡关系，这一关系受LC相位偏移范围的影响。

Conclusion: 研究为LC-RIS在无线通信系统中的实际应用提供了重要见解，强调了相位偏移范围与系统性能之间的权衡关系。

Abstract: Liquid crystal (LC) technology has emerged as a promising solution for large
reconfigurable intelligent surfaces (RISs) at millimeter wave (mmWave) bands,
offering advantages such as low power consumption, scalability, and
continuously tunable phase shifts. For LC-RIS based on the delay-line
architecture, i.e., with dedicated phase shifters, there exists a trade-off
between the maximum achievable phase-shift range and the corresponding
insertion loss, which has not been studied for LC-RIS-assisted wireless systems
yet. In this paper, we investigate this trade-off where a base station (BS) and
an RIS are configured to minimize the transmit power while satisfying a given
quality of service (QoS) for a number of users. Simulation results reveal a
fundamental trade-off between the total transmit power and the achievable data
rate as a function of the LC phase-shift range.

</details>
