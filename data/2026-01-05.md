<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 13]
- [cs.IT](#cs.IT) [Total: 7]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [Neural Brain Fields: A NeRF-Inspired Approach for Generating Nonexistent EEG Electrodes](https://arxiv.org/abs/2601.00012)
*Shahar Ain Kedem,Itamar Zimerman,Eliya Nachmani*

Main category: eess.SP

TL;DR: 提出一种受NeRF启发的EEG处理方法，将脑电信号编码为固定大小的权重向量，实现连续时空重建和虚拟电极生成。


<details>
  <summary>Details</summary>
Motivation: EEG数据具有长度可变、信噪比低、个体差异大、漂移严重、数据集小且不干净等挑战，需要开发有效的深度学习方法。

Method: 借鉴NeRF思想，将EEG电极类比为不同视角的图像，训练神经网络将单个EEG样本编码为固定大小的权重向量，实现信号的连续时空重建。

Result: 方法能够连续可视化任意分辨率的大脑活动，重建原始EEG信号，有效模拟不存在的电极数据，提升下游处理网络性能。

Conclusion: NeRF启发的EEG表示方法为处理脑电信号提供了新思路，能够编码完整信号信息并支持连续时空重建，具有实际应用价值。

Abstract: Electroencephalography (EEG) data present unique modeling challenges because recordings vary in length, exhibit very low signal to noise ratios, differ significantly across participants, drift over time within sessions, and are rarely available in large and clean datasets. Consequently, developing deep learning methods that can effectively process EEG signals remains an open and important research problem. To tackle this problem, this work presents a new method inspired by Neural Radiance Fields (NeRF). In computer vision, NeRF techniques train a neural network to memorize the appearance of a 3D scene and then uses its learned parameters to render and edit the scene from any viewpoint. We draw an analogy between the discrete images captured from different viewpoints used to learn a continuous 3D scene in NeRF, and EEG electrodes positioned at different locations on the scalp, which are used to infer the underlying representation of continuous neural activity. Building on this connection, we show that a neural network can be trained on a single EEG sample in a NeRF style manner to produce a fixed size and informative weight vector that encodes the entire signal. Moreover, via this representation we can render the EEG signal at previously unseen time steps and spatial electrode positions. We demonstrate that this approach enables continuous visualization of brain activity at any desired resolution, including ultra high resolution, and reconstruction of raw EEG signals. Finally, our empirical analysis shows that this method can effectively simulate nonexistent electrodes data in EEG recordings, allowing the reconstructed signal to be fed into standard EEG processing networks to improve performance.

</details>


### [2] [Modeling Day-Long ECG Signals to Predict Heart Failure Risk with Explainable AI](https://arxiv.org/abs/2601.00014)
*Eran Zvuloni,Ronit Almog,Michael Glikson,Shany Brimer Biton,Ilan Green,Izhar Laufer,Offer Amir,Joachim A. Behar*

Main category: eess.SP

TL;DR: 深度学习模型DeepHHF利用24小时单导联心电图数据预测5年内心衰风险，性能优于30秒心电图片段和临床评分


<details>
  <summary>Details</summary>
Motivation: 心衰影响11.8%的65岁以上成年人，降低生活质量和寿命。预防心衰可降低发病率和死亡率。研究者假设人工智能应用于24小时单导联心电图数据可预测5年内心衰风险

Method: 使用Technion-Leumit Holter ECG数据集（69,663条记录，47,729名患者，20年数据）。开发深度学习模型DeepHHF，训练于24小时心电图记录，并与30秒片段模型和临床评分进行比较

Result: DeepHHF的AUC为0.80，优于30秒片段模型和临床评分。高风险个体住院或死亡风险增加两倍。可解释性分析显示模型关注心律失常和心脏异常，关键注意力集中在上午8点至下午3点

Conclusion: 深度学习可有效建模24小时连续心电图数据，捕捉阵发性事件和昼夜节律变化，对可靠风险预测至关重要。基于单导联Holter心电图的人工智能方法无创、廉价、广泛可用，是心衰风险预测的有前景工具

Abstract: Heart failure (HF) affects 11.8% of adults aged 65 and older, reducing quality of life and longevity. Preventing HF can reduce morbidity and mortality. We hypothesized that artificial intelligence (AI) applied to 24-hour single-lead electrocardiogram (ECG) data could predict the risk of HF within five years. To research this, the Technion-Leumit Holter ECG (TLHE) dataset, including 69,663 recordings from 47,729 patients, collected over 20 years was used. Our deep learning model, DeepHHF, trained on 24-hour ECG recordings, achieved an area under the receiver operating characteristic curve of 0.80 that outperformed a model using 30-second segments and a clinical score. High-risk individuals identified by DeepHHF had a two-fold chance of hospitalization or death incidents. Explainability analysis showed DeepHHF focused on arrhythmias and heart abnormalities, with key attention between 8 AM and 3 PM. This study highlights the feasibility of deep learning to model 24-hour continuous ECG data, capturing paroxysmal events and circadian variations essential for reliable risk prediction. Artificial intelligence applied to single-lead Holter ECG is non-invasive, inexpensive, and widely accessible, making it a promising tool for HF risk prediction.

</details>


### [3] [Adaptive Pinching Antenna Optimization via Meta-Learning for Physical-Layer Security in Dynamic Wireless Networks](https://arxiv.org/abs/2601.00115)
*Khalid T. Musri,Akram Y. Sarhan,Osamah A. Abdullah,Hayder Al-Hraishawi*

Main category: eess.SP

TL;DR: 基于梯度的元学习框架，用于在用户位置不确定和物理层安全约束下实时控制波导夹持天线系统，通过元学习实现快速适应动态环境。


<details>
  <summary>Details</summary>
Motivation: 在动态无线环境中，用户位置不确定性和物理层安全需求对波导夹持天线系统的实时控制提出了挑战，需要能够快速适应变化的控制方案。

Method: 提出概率系统模型捕捉定位不完美对性能的影响，建立联合天线位置和发射功率优化问题，采用模型无关元学习（MAML）学习可迁移的初始化参数，实现少样本在线适应。

Result: 仿真结果表明，该框架在中断概率、安全性能和收敛延迟方面显著优于Reptile元学习、非元强化学习、传统优化、静态天线放置和仅功率控制等方法。

Conclusion: 元学习是动态无线环境中可重构夹持天线系统实现安全低延迟控制的有效工具。

Abstract: This paper develops a gradient-based meta-learning framework for real-time control of waveguided pinching-antenna systems under user-location uncertainty and physical-layer security (PLS) constraints. A probabilistic system model is introduced to capture the impact of imperfect localization on outage performance and secrecy. Based on this model, a joint antenna-positioning and transmit-power optimization problem is formulated to satisfy probabilistic reliability and secrecy requirements. To enable rapid adaptation in highly dynamic environments, the proposed approach employs model-agnostic meta-learning (MAML) to learn a transferable initialization across diverse mobility and channel conditions, allowing few-shot online adaptation using limited pilot feedback. Simulation results demonstrate that the proposed framework significantly outperforms Reptile-based meta-learning, non-meta reinforcement learning, conventional optimization, static antenna placement, and power-only control in terms of outage probability, secrecy performance, and convergence latency. These results establish meta-learning as an effective tool for secure and low-latency control of reconfigurable pinching-antenna systems in non-stationary wireless environments.

</details>


### [4] [AI-Driven Channel State Information (CSI) Extrapolation for 6G: Current Situations, Challenges and Future Research](https://arxiv.org/abs/2601.00159)
*Yuan Gao,Zichen Lu,Xinyi Wu,Wenjun Yu,Shengli Liu,Jianbo Du,Yanliang Jin,Shunqing Zhang,Xiaoli Chu,Shugong Xu*

Main category: eess.SP

TL;DR: 该论文首次全面综述了6G通信系统中CSI外推技术的现状、挑战和未来方向，涵盖了性能指标、模型驱动和AI驱动方法、开源数据集以及研究机遇。


<details>
  <summary>Details</summary>
Motivation: 传统信道估计方法在6G高移动性、超大规模MIMO和多频段系统中面临可扩展性挑战，CSI外推技术能通过部分CSI推断完整CSI来显著降低开销，但目前缺乏对SOTA CSI外推技术的全面综述。

Method: 首先分析6G CSI外推的特定性能指标（外推精度、动态场景适应性和算法成本），然后综述时间和频域、天线和多域的模型驱动与AI驱动方法，总结关键见解，并考察可用于训练高性能AI驱动模型的开放数据集和仿真器。

Result: 论文填补了CSI外推技术全面综述的空白，系统梳理了当前技术现状，总结了各种方法的优缺点，并识别了AI驱动方法在满足性能要求方面的潜力。

Conclusion: 论文首次全面综述了CSI外推技术，为6G通信系统优化提供了重要参考，指出了现有研究的关键挑战，并提出了未来的研究方向，特别是AI驱动方法的发展机遇。

Abstract: CSI extrapolation is an effective method for acquiring channel state information (CSI), essential for optimizing performance of sixth-generation (6G) communication systems. Traditional channel estimation methods face scalability challenges due to the surging overhead in emerging high-mobility, extremely large-scale multiple-input multiple-output (EL-MIMO), and multi-band systems. CSI extrapolation techniques mitigate these challenges by using partial CSI to infer complete CSI, significantly reducing overhead. Despite growing interest, a comprehensive review of state-of-the-art (SOTA) CSI extrapolation techniques is lacking. This paper addresses this gap by comprehensively reviewing the current status, challenges, and future directions of CSI extrapolation for the first time. Firstly, we analyze the performance metrics specific to CSI extrapolation in 6G, including extrapolation accuracy, adaption to dynamic scenarios and algorithm costs. We then review both model-driven and artificial intelligence (AI)-driven approaches for time, frequency, antenna, and multi-domain CSI extrapolation. Key insights and takeaways from these methods are summarized. Given the promise of AI-driven methods in meeting performance requirements, we also examine the open-source channel datasets and simulators that could be used to train high-performance AI-driven CSI extrapolation models. Finally, we discuss the critical challenges of the existing research and propose perspective research opportunities.

</details>


### [5] [Edge AI Inference in ISCC Networks: Sensing Accuracy Analysis and Precoding Design](https://arxiv.org/abs/2601.00171)
*Lingyun Xu,Bowen Wang,Huiyong Li,Ziyang Cheng*

Main category: eess.SP

TL;DR: 该论文研究了ISCC网络中边缘AI推理的感知精度与预编码系数之间的关系，提出了判别增益(DG)来表征感知精度，并设计了有效的预编码算法来最大化DG。


<details>
  <summary>Details</summary>
Motivation: 在集成感知、通信和计算(ISCC)网络中，边缘AI推理需要同时考虑感知精度、通信效率和计算性能。然而，感知精度与预编码系数之间的明确关系尚未得到充分研究，这限制了ISCC网络中边缘推理的性能优化。

Method: 1. 构建了空中赋能ISCC网络的系统模型，包括分布式边缘传感器进行特征提取和边缘服务器进行分类
2. 引入判别增益(DG)来量化感知精度，并推导出DG关于预编码系数的显式函数
3. 提出了一种有效的预编码算法来解决非凸的DG最大化问题

Result: 仿真结果验证了所提设计在ISCC网络中边缘推理的有效性和可行性。通过优化预编码系数，显著提升了感知精度和边缘AI推理性能。

Conclusion: 该工作揭示了ISCC网络中感知精度与预编码系数之间的明确关系，为边缘AI推理的预编码设计提供了理论指导和实用算法，推动了ISCC网络在边缘智能应用中的发展。

Abstract: This work explores the relationship between sensing accuracy and precoding coefficients for edge artificial intelligence (AI) inference in integrated sensing, communication and computation (ISCC) networks. We start by constructing a system model of an over-the-air-empowered ISCC network for edge AI inference, involving distributed edge sensors for feature extraction and an edge server for classification. Based on this model, we introduce a discriminant gain (DG) to characterize sensing accuracy and novelly derive an explicit function of the DG about precoding coefficients, giving valuable insights into precoding design. Guided by this, we propose an effective precoding algorithm to solve a non-convex DG-maximization problem. Simulation results verify the effectiveness and feasibility of the proposed design for edge inference in ISCC networks.

</details>


### [6] [Time--to--Digital Converter (TDC)--Based Resonant Compute--in--Memory for INT8 CNNs with Layer--Optimized SRAM Mapping](https://arxiv.org/abs/2601.00434)
*Dhandeep Challagundla,Ignatius Bezzam,Riadul Islam*

Main category: eess.SP

TL;DR: 提出基于时间域计算的存内计算架构，用TDC替代ADC降低功耗和面积，在28nm工艺上实现高能效的神经网络加速


<details>
  <summary>Details</summary>
Motivation: 传统存内计算架构使用ADC转换模拟MAC结果，但ADC带来面积和功耗显著增加以及非线性问题。需要一种更高效的数字化方案来降低存内计算的能耗和面积开销。

Method: 提出谐振时间域存内计算架构，使用8T SRAM单元实现可靠的位级MAC操作，采用4位TDC配合脉冲收缩延迟元件进行数字化，采样率达1 GS/s。结合权重固定的数据映射策略和自动SRAM宏选择算法，实现可扩展的CNN部署。

Result: 在TSMC 28nm工艺上验证8KB SRAM阵列，吞吐量达320 GOPS，能效达38.46 TOPS/W。在6个CNN模型评估中，当SRAM从32KB扩展到256KB时，推理能耗降低达8倍，量化后精度损失最小。

Conclusion: TDC-CiM架构通过消除ADC，用TDC实现低功耗、低面积的模拟MAC结果数字化，结合优化算法实现了高能效、可扩展的神经网络加速方案，为存内计算架构提供了新的设计方向。

Abstract: In recent years, Compute-in-memory (CiM) architectures have emerged as a promising solution for deep neural network (NN) accelerators. Multiply-accumulate~(MAC) is considered a {\textit de facto} unit operation in NNs. By leveraging the inherent parallel processing capabilities of CiM, NNs that require numerous MAC operations can be executed more efficiently. This is further facilitated by storing the weights in SRAM, reducing the need for extensive data movement and enhancing overall computational speed and efficiency. Traditional CiM architectures execute MAC operations in the analog domain, employing an Analog-to-Digital converter (ADC) to convert the analog MAC values into digital outputs. However, these ADCs introduce significant increase in area and power consumption, as well as introduce non-linearities. This work proposes a resonant time-domain compute-in-memory (TDC-CiM) architecture that eliminates the need for an ADC by using a time-to-digital converter (TDC) to digitize analog MAC results with lower power and area cost. A dedicated 8T SRAM cell enables reliable bitwise MAC operations, while the readout uses a 4-bit TDC with pulse-shrinking delay elements, achieving 1 GS/s sampling with a power consumption of only 1.25 mW. In addition, a weight stationary data mapping strategy combined with an automated SRAM macro selection algorithm enables scalable and energy-efficient deployment across CNN workloads. Evaluation across six CNN models shows that the algorithm reduces inference energy consumption by up to 8x when scaling SRAM size from 32~KB to 256~KB, while maintaining minimal accuracy loss after quantization. The feasibility of the proposed architecture is validated on an 8~KB SRAM memory array using TSMC 28~nm technology. The proposed TDC-CiM architecture demonstrates a throughput of 320~GOPS with an energy efficiency of 38.46~TOPS/W.

</details>


### [7] [MIMO-AFDM Outperforms MIMO-OFDM in the Face of Hardware Impairments](https://arxiv.org/abs/2601.00502)
*Zeping Sui,Zilong Liu,Leila Musavian,Yong Liang Guan,Lie-Liang Yang,Lajos Hanzo*

Main category: eess.SP

TL;DR: 研究硬件损伤对MIMO-AFDM系统的影响，发现AFDM在硬件损伤下仍能保持完全分集阶数，相比OFDM对乘性和加性损伤具有更强鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 研究硬件损伤（包括乘性和加性损伤）对MIMO-AFDM系统性能的影响，探索其在现实硬件不完美条件下的表现，并与传统MIMO-OFDM系统进行比较。

Method: 针对小规模MIMO-AFDM系统推导ML检测器的紧致BER上界；针对大规模系统推导LMMSE检测器的闭式BER近似，包括不完美信道估计场景。通过理论分析和仿真验证。

Result: 1) 硬件损伤的AFDM系统仍能保持完全分集阶数；2) 理论BER结果与仿真结果在高信噪比下匹配良好；3) MIMO-AFDM相比MIMO-OFDM对乘性失真（相位噪声、载波频率偏移）更具鲁棒性；4) 在相同加性硬件损伤条件下，MIMO-AFDM始终优于MIMO-OFDM。

Conclusion: AFDM凭借其固有的啁啾信号特性和离散仿射傅里叶变换的扩展效应，相比OFDM具有更强的ICI抗干扰能力，即使在硬件损伤条件下也能实现最大完全分集增益。

Abstract: The impact of both multiplicative and additive hardware impairments (HWIs) on multiple-input multiple-output affine frequency division multiplexing (MIMO-AFDM) systems is investigated. For small-scale MIMO-AFDM systems, a tight bit error rate (BER) upper bound associated with the maximum likelihood (ML) detector is derived. By contrast, for large-scale systems, a closed-form BER approximation associated with the linear minimum mean squared error (LMMSE) detector is presented, including realistic imperfect channel estimation scenarios. Our first key observation is that the full diversity order of a hardware-impaired AFDM system remains unaffected, which is a unique advantage. Furthermore, our analysis shows that 1) the BER results derived accurately predict the simulated ML performance in moderate-to-high signal-to-noise ratios (SNRs), while the theoretical BER curve of the LMMSE detector closely matches that of the Monte-Carlo based one. 2) MIMO-AFDM is more resilient to multiplicative distortions, such as phase noise and carrier frequency offset, compared to its orthogonal frequency division multiplexing (OFDM) counterparts. This is attributed to its inherent chirp signal characteristics; 3) MIMO-AFDM consistently achieves superior BER performance compared to conventional MIMO-OFDM systems under the same additive HWI conditions, as well as different velocity values. The latter is because MIMO-AFDM is also resilient to the additional inter-carrier interference (ICI) imposed by the nonlinear distortions of additive HWIs. In a nutshell, compared to OFDM, AFDM demonstrates stronger ICI resilience and achieves the maximum full diversity attainable gain even under HWIs, thanks to its intrinsic chirp signalling structure as well as to the beneficial spreading effect of the discrete affine Fourier transform.

</details>


### [8] [Parametrized Sharing for Multi-Agent Hybrid DRL for Multiple Multi-Functional RISs-Aided Downlink NOMA Networks](https://arxiv.org/abs/2601.00538)
*Chi-Te Kuo,Li-Hsiang Shen,Jyun-Jhe Huang*

Main category: eess.SP

TL;DR: 提出参数化共享的多智能体混合深度强化学习(PMHRL)方法，优化多MF-RIS辅助的NOMA下行网络，实现最高能效


<details>
  <summary>Details</summary>
Motivation: 传统RIS存在信号覆盖有限和能量依赖外部电源的问题，MF-RIS通过主动RIS能力和能量收集功能，能同时解决通信效率和自持续性问题

Method: 设计参数化共享的多智能体混合深度强化学习(PMHRL)，结合PPO处理连续变量(功率分配、波束成形、幅度相位等)和DQN处理离散变量(MF-RIS位置)，优化多MF-RIS配置

Result: PMHRL相比其他基准方法(无参数化共享、纯PPO、纯DQN)获得最高能效；多MF-RIS辅助的NOMA下行网络相比无EH/放大、传统RIS、无RIS/MF-RIS部署等场景，在不同多址接入下都达到最高能效

Conclusion: 提出的PMHRL方法和多MF-RIS架构能有效提升NOMA下行网络的能效，同时解决通信覆盖和自持续性问题，为未来智能反射表面系统设计提供了新思路

Abstract: Multi-functional reconfigurable intelligent surface (MF-RIS) is conceived to address the communication efficiency thanks to its extended signal coverage from its active RIS capability and self-sustainability from energy harvesting (EH). We investigate the architecture of multi-MF-RISs to assist non-orthogonal multiple access (NOMA) downlink networks. We formulate an energy efficiency (EE) maximization problem by optimizing power allocation, transmit beamforming and MF-RIS configurations of amplitudes, phase-shifts and EH ratios, as well as the position of MF-RISs, while satisfying constraints of available power, user rate requirements, and self-sustainability property. We design a parametrized sharing scheme for multi-agent hybrid deep reinforcement learning (PMHRL), where the multi-agent proximal policy optimization (PPO) and deep-Q network (DQN) handle continuous and discrete variables, respectively. The simulation results have demonstrated that proposed PMHRL has the highest EE compared to other benchmarks, including cases without parametrized sharing, pure PPO and DQN. Moreover, the proposed multi-MF-RISs-aided downlink NOMA achieves the highest EE compared to scenarios of no-EH/amplification, traditional RISs, and deployment without RISs/MF-RISs under different multiple access.

</details>


### [9] [Fractional Programming for Kullback-Leibler Divergence in Hypothesis Testing](https://arxiv.org/abs/2601.00564)
*Jeongwoo Park,Seongkyu Jung,Kaiming Shen,Jeonghun Park*

Main category: eess.SP

TL;DR: 提出基于分数规划的计算高效优化框架，用于最大化Kullback-Leibler散度，显著降低计算复杂度并加速收敛。


<details>
  <summary>Details</summary>
Motivation: 在主动感知和假设检验中，最大化KLD散度对检测概率至关重要，但现有方法计算复杂度高，需要每次迭代进行矩阵求逆，限制了实际应用。

Method: 1) 使用矩阵分数规划将KLD最大化问题转化为一系列可处理的二次子问题；2) 引入非齐次松弛技术，用闭式更新替代昂贵的线性系统求解；3) 采用STEM加速方法，将迭代方案解释为定点映射以提升收敛速度。

Result: 所提算法将每次迭代复杂度降至二次阶，总运行时间比最先进基准方法减少数个数量级，在多个随机接入和联合感知通信场景中验证了有效性。

Conclusion: 该框架为KLD最大化问题提供了高效计算解决方案，显著降低了计算负担，适用于实际应用场景，为主动感知和假设检验提供了实用工具。

Abstract: Maximizing the Kullback-Leibler divergence (KLD) is a fundamental problem in waveform design for active sensing and hypothesis testing, as it directly relates to the error exponent of detection probability. However, the associated optimization problem is highly nonconvex due to the intricate coupling of log-determinant and matrix trace terms. Existing solutions often suffer from high computational complexity, typically requiring matrix inversion at every iteration. In this paper, we propose a computationally efficient optimization framework based on fractional programming (FP). Our key idea is to reformulate the KLD maximization problem into a sequence of tractable quadratic subproblems using matrix FP. To further reduce complexity, we introduce a nonhomogeneous relaxation technique that replaces the costly linear system solver with a simple closed-form update, thereby reducing the per-iteration complexity to quadratic order. To compensate for the convergence speed trade-off caused by relaxation, we employ an acceleration method called STEM by interpreting the iterative scheme as a fixed-point mapping. The resulting algorithm achieves significantly faster convergence rates with low per-iteration cost. Numerical results demonstrate that our approach reduces the total runtime by orders of magnitude compared to a state-of-the-art benchmark. Finally, we apply the proposed framework to a multiple random access scenario and a joint integrated sensing and communication scenario, validating the efficacy of our framework in such applications.

</details>


### [10] [WiFo-MUD: Wireless Foundation Model for Heterogeneous Multi-User Demodulator](https://arxiv.org/abs/2601.00612)
*Zonghui Yang,Shijian Gao,Xuesong Cai,Xiang Cheng,Liuqing Yang*

Main category: eess.SP

TL;DR: 提出WiFo-MUD，一种基于扩散模型的通用多用户解调基础模型，通过条件去噪和通信感知一致性蒸馏，在大规模异构数据集上实现最先进性能


<details>
  <summary>Details</summary>
Motivation: 现有解调器在通用多用户环境中表现不佳：经典方法难以平衡准确性和复杂度，深度学习方法缺乏异构配置下的适应性，现有扩散模型灵活性有限

Method: 提出WiFo-MUD模型，对齐用户间信噪比不平衡，通过定制化骨干网络进行条件去噪，设计通信感知一致性蒸馏方法和动态用户分组策略以增强推理

Result: 在大规模异构数据集上取得最先进结果，展示了高效推理能力和在不同系统配置下的强泛化性能

Conclusion: WiFo-MUD作为通用扩散基础模型，有效解决了多用户解调中的准确性与适应性挑战，为无线通信系统提供了可靠的解调解决方案

Abstract: Multi-user signal demodulation is critical to wireless communications, directly impacting transmission reliability and efficiency. However, existing demodulators underperform in generic multi-user environments: classical demodulators struggle to balance accuracy and complexity, while deep learning-based methods lack adaptability under heterogeneous configurations. Although diffusion models have been introduced for demodulation, their flexibility remains limited for practical use. To address these issues, this work proposes WiFo-MUD, a universal diffusion-based foundation model for multi-user demodulation. The model aligns inter-user signal-to-noise ratio imbalance and performs conditional denoising via a customized backbone. Furthermore, a communication-aware consistency distillation method and a dynamic user-grouping strategy are devised to enhance inference. WiFo-MUD achieves state-of-the-art results on large-scale heterogeneous datasets, demonstrating efficient inference and strong generalization across varying system configurations.

</details>


### [11] [Splitting Precoding with Subspace Selection and Quantized Refinement for Massive MIMO](https://arxiv.org/abs/2601.00616)
*Yasaman Khorsandmanesh,Emil Bjornson,Joakim Jalden*

Main category: eess.SP

TL;DR: 提出一种分裂预编码架构，将预编码设计分离到AAS和BBU之间，通过本地子空间选择降低信道维度，提高大规模MIMO系统的频谱效率


<details>
  <summary>Details</summary>
Motivation: 有限的前传容量是大规模MIMO 5G架构的实际瓶颈，传统下行设计将所有预编码计算放在BBU，并通过前传传输高维预编码矩阵，导致显著的量化损失和信令开销

Method: 提出分裂预编码架构：AAS执行本地子空间选择以降低信道维度，BBU基于得到的有效信道计算优化的量化细化预编码

Result: 数值结果显示，所提出的分裂预编码策略比传统单级预编码实现了更高的总频谱效率

Conclusion: 分裂预编码架构通过在前传链路上分离预编码设计，有效解决了大规模MIMO系统中的前传容量限制问题，提高了系统性能

Abstract: Limited fronthaul capacity is a practical bottleneck in massive multiple-input multiple-output (MIMO) 5G architectures, where a base station (BS) consists of an advanced antenna system (AAS) connected to a baseband unit (BBU). Conventional downlink designs place the entire precoding computation at the BBU and transmit a high-dimensional precoding matrix over the fronthaul, resulting in substantial quantization losses and signaling overhead. This letter proposes a splitting precoding architecture that separates the design between the AAS and BBU. The AAS performs a local subspace selection to reduce the channel dimensionality, while the BBU computes an optimized quantized refinement precoding based on the resulting effective channel. The numerical results show that the proposed splitting precoding strategy achieves higher sum spectral efficiency than conventional one-stage precoding.

</details>


### [12] [Conformal Reconfigurable Intelligent Surfaces: A Cylindrical Geometry Perspective](https://arxiv.org/abs/2601.00734)
*Filippo Pepe,Ivan Iudice,Giuseppe Castaldi,Marco Di Renzo,Vincenzo Galdi*

Main category: eess.SP

TL;DR: 该论文系统研究了圆柱形可重构智能表面，从理想表面阻抗合成到基于简单1比特超原子的实际实现，建立了分析模型并验证了1比特RIS可实现定向散射。


<details>
  <summary>Details</summary>
Motivation: 曲面可重构智能表面是下一代无线通信的前沿技术，可在无人机和城市基础设施等非平面平台上实现自适应波前控制。圆柱形RIS具有实际应用潜力，但需要系统研究其设计限制和实际实现方法。

Method: 首先开发精确的解析模型和几何光学模型探索基本设计限制，然后提出适用于离散可重构架构的半解析公式。使用进化优化和低复杂度策略（如最小功率无失真响应方法）进行波束合成，并通过全波仿真验证。

Result: 结果表明，1比特RIS能够实现定向散射，具有可管理的旁瓣水平和最小的硬件复杂度。验证了圆柱形RIS的可行性。

Conclusion: 圆柱形RIS是可行的，这些发现为其集成到实际通信场景中的双用途无线平台打开了大门。

Abstract: Curved reconfigurable intelligent surfaces (RISs) represent a promising frontier for next-generation wireless communication, enabling adaptive wavefront control on nonplanar platforms such as unmanned aerial vehicles and urban infrastructure. This work presents a systematic investigation of cylindrical RISs, progressing from idealized surface-impedance synthesis to practical implementations based on simple one-bit meta-atoms. Exact analytical and geometrical-optics-based models are first developed to explore fundamental design limits, followed by a semi-analytical formulation tailored to discrete, reconfigurable architectures. This model enables efficient beam synthesis using both evolutionary optimization and low-complexity strategies, including the minimum power distortionless response method, and is validated through full-wave simulations. Results confirm that one-bit RISs can achieve directive scattering with manageable sidelobe levels and minimal hardware complexity. These findings establish the viability of cylindrical RISs and open the door to their integration into dual-use wireless platforms for real-world communication scenarios.

</details>


### [13] [Energy Efficiency Maximization of MIMO Systems through Reconfigurable Holographic Beamforming](https://arxiv.org/abs/2601.00780)
*Robert Kuku Fotock,Alessio Zappone,Agbotiname Lucky Imoize,Marco Di Renzo*

Main category: eess.SP

TL;DR: 该研究提出了一种在点对点多天线无线链路中部署可重构超表面的全息波束赋形架构，通过优化发射协方差矩阵和超表面反射矩阵来最大化系统能效，并开发了低复杂度算法。


<details>
  <summary>Details</summary>
Motivation: 传统全数字波束赋形架构虽然能实现显著的多路复用增益，但在能效方面存在不足。研究者希望探索通过部署可重构超表面实现全息波束赋形，以在保持性能的同时显著提升系统能效。

Method: 在发射和接收天线阵列附近各部署一个可重构超表面，构建全息波束赋形架构。优化问题涉及发射协方差矩阵和两个超表面的反射矩阵，开发了保证收敛到一阶最优点的低复杂度算法。针对单天线或单流传输的特殊情况，推导了超表面矩阵的闭式解。

Result: 数值性能分析表明，与全数字波束赋形架构相比，基于超表面的全息波束赋形能提供显著的能效增益，即使后者实现了可观的多路复用增益。算法能有效收敛到最优解。

Conclusion: 在无线通信系统中部署可重构超表面实现全息波束赋形是一种有前景的技术，能在保持系统性能的同时显著提升能效，为未来绿色通信系统设计提供了新思路。

Abstract: This study considers a point-to-point wireless link, in which both the transmitter and receiver are equipped with multiple antennas. In addition, two reconfigurable metasurfaces are deployed, one in the immediate vicinity of the transmit antenna array, and one in the immediate vicinity of the receive antenna array. The resulting architecture implements a holographic beamforming structure at both the transmitter and receiver. In this scenario, the system energy efficiency is optimized with respect to the transmit covariance matrix, and the reflection matrices of the two metasurfaces. A low-complexity algorithm is developed, which is guaranteed to converge to a first-order optimal point of the energy efficiency maximization problem. Moreover, closed-form expressions are derived for the metasurface matrices in the special case of single-antenna or single-stream transmission. The two metasurfaces are considered to be nearly-passive and subject to global reflection constraints. A numerical performance analysis is conducted to assess the performance of the proposed optimization methods, showing, in particular, that the use of holographic beamforming by metasurfaces can provide significant energy efficiency gains compared to fully digital beamforming architectures, even when the latter achieve substantial multiplexing gains.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [14] [A repair scheme for a distributed storage system based on multivariate polynomials](https://arxiv.org/abs/2601.00120)
*Hiram H. López,Gretchen L. Matthews,Daniel Valvo*

Main category: cs.IT

TL;DR: 将基于Reed-Solomon码的精确修复方案扩展到基于Reed-Muller码的分布式存储系统，支持单节点和多节点故障修复


<details>
  <summary>Details</summary>
Motivation: 分布式存储系统需要高效的数据恢复机制。现有基于Reed-Solomon码的精确修复方案仅适用于单变量多项式，需要扩展到基于多变量多项式的Reed-Muller码系统

Method: 将GW论文中的精确修复方案扩展到Reed-Muller码家族，利用多变量多项式的特性设计修复方案，支持单节点故障和满足特定条件的多节点故障修复

Result: 提出了适用于Reed-Muller码分布式存储系统的修复方案，能够修复任意单节点故障和满足特定位置条件的多节点故障

Conclusion: 成功将精确修复方案从Reed-Solomon码扩展到Reed-Muller码，为基于多变量多项式的分布式存储系统提供了有效的故障恢复机制

Abstract: A distributed storage system stores data across multiple nodes, with the primary objective of enabling efficient data recovery even in the event of node failures. The main goal of an exact repair scheme is to recover the data from a failed node by accessing and downloading information from the rest of the nodes. In a groundbreaking paper, ~\cite{GW} developed an exact repair scheme for a distributed storage system that is based on Reed-Solomon codes, which depend on single-variable polynomials. In these notes, we extend the repair scheme to the family of distributed storage systems based on Reed-Muller codes, which are linear codes based on multivariate polynomials. The repair scheme we propose repairs any single node failure and multiple node failures, provided the positions satisfy certain conditions.

</details>


### [15] [The permutation group of Reed-Solomon codes over arbitrary points](https://arxiv.org/abs/2601.00122)
*Eduardo Camps-Moreno,Jun Bo Lau,Hiram H. López,Welington Santos*

Main category: cs.IT

TL;DR: 证明了Reed-Solomon码的置换群由保持评估点集不变的一次多项式构成，为已知特殊情况提供了简洁证明


<details>
  <summary>Details</summary>
Motivation: 研究Reed-Solomon码的置换群结构，为理解这类重要纠错码的对称性提供理论依据

Method: 通过数学证明方法，建立Reed-Solomon码置换群与保持评估点集不变的一次多项式之间的等价关系

Result: 成功证明了Reed-Solomon码的置换群恰好由那些保持评估点集不变的一次多项式构成

Conclusion: 该结果为Reed-Solomon码置换群提供了完整描述，并为评估点集为整个有限域或乘法群的已知特例提供了简洁证明

Abstract: In this work, we prove that the permutation group of a Reed-Solomon code is given by the polynomials of degree one that leave the set of evaluation points invariant. Our results provide a straightforward proof of the well-known cases of the permutation group of the Reed-Solomon code when the set of evaluation points is the whole finite field or the multiplicative group.

</details>


### [16] [Evolution of UE in Massive MIMO Systems for 6G: From Passive to Active](https://arxiv.org/abs/2601.00251)
*Kwonyeol Park,Hyuckjin Choi,Geonho Han,Gyoseung Lee,Yeonjoon Choi,Sunwoo Park,Junil Choi*

Main category: cs.IT

TL;DR: 本文探讨了从5G到6G演进过程中，用户设备(UE)在mMIMO系统中的角色转变——从被动收发器转变为主动参与系统性能优化的智能实体，分析了3GPP标准演进、设备实现挑战和架构创新。


<details>
  <summary>Details</summary>
Motivation: 随着无线网络发展，严格的延迟和可靠性要求以及高度动态的信道暴露了gNB中心化mMIMO架构的局限性，需要重新思考UE的角色，使其从被动接收者转变为主动贡献系统性能的智能实体。

Method: 通过回顾3GPP Release 15-19的标准演进，分析UE功能从基本CSI报告到AI/ML增强CSI和UE发起波束管理的进展；研究MPUE架构、设备端智能处理和能效操作等实现挑战；基于数字孪生评估验证UE中心化功能的影响。

Result: 数字孪生评估显示：UE发起的波束报告在真实移动场景中提高了吞吐量；多面板架构相比单面板UE增强了链路鲁棒性；UE智能化功能显著改善了系统性能。

Conclusion: UE正从被动收发器演变为主动智能实体，通过AI/ML增强、多面板架构和UE发起的管理功能，能够更好地应对6G网络的严格要求和动态信道条件，这代表了mMIMO架构的重要范式转变。

Abstract: As wireless networks continue to evolve, stringent latency and reliability requirements and highly dynamic channels expose fundamental limitations of gNB-centric massive multiple-input multiple-output (mMIMO) architectures, motivating a rethinking of the user equipment (UE) role. In response, the UE is transitioning from a passive transceiver into an active entity that directly contributes to system-level performance. In this context, this article examines the evolving role of the UE in mMIMO systems during the transition from fifth-generation (5G) to sixth-generation (6G), bridging third generation partnership project (3GPP) standardization, device implementation, and architectural innovation. Through a chronological review of 3GPP Releases 15 to 19, we highlight the progression of UE functionalities from basic channel state information (CSI) reporting to artificial intelligence (AI) and machine learning (ML)-based CSI enhancement and UE-initiated beam management. We further examine key implementation challenges, including multi-panel UE (MPUE) architectures, on-device intelligent processing, and energy-efficient operation, and then discuss corresponding architectural innovations under practical constraints. Using digital-twin-based evaluations, we validate the impact of emerging UE-centric functionalities, illustrating that UE-initiated beam reporting improves throughput in realistic mobility scenarios, while a multi-panel architecture enhances link robustness compared with a single-panel UE.

</details>


### [17] [Semantic Transmission Framework in Direct Satellite Communications](https://arxiv.org/abs/2601.00381)
*Chong Huang,Xuyang Chen,Jingfu Li,Pei Xiao,Gaojie Chen,Rahim Tafazolli*

Main category: cs.IT

TL;DR: 提出卫星通信语义传输框架，引入语义效率指标，通过强化学习算法优化传输模式选择、卫星-用户关联等决策，提升链路预算不足下的通信性能。


<details>
  <summary>Details</summary>
Motivation: 当前卫星通信中链路预算不足已成为直接接入的瓶颈问题，需要有效解决方案来提升通信效率。

Method: 开发卫星通信语义传输框架，引入带优化权重的语义效率指标，提出决策辅助的REINFORCE++算法，优化传输模式选择、卫星-用户关联、ISL任务迁移、去噪步骤和自适应权重。

Result: 数值结果表明，所提算法比基线方法获得更高的语义效率。

Conclusion: 语义传输框架是解决卫星通信链路预算不足问题的有效可行方案，提出的优化算法能够显著提升语义效率。

Abstract: Insufficient link budget has become a bottleneck problem for direct access in current satellite communications. In this paper, we develop a semantic transmission framework for direct satellite communications as an effective and viable solution to tackle this problem. To measure the tradeoffs between communication, computation, and generation quality, we introduce a semantic efficiency metric with optimized weights. The optimization aims to maximize the average semantic efficiency metric by jointly optimizing transmission mode selection, satellite-user association, ISL task migration, denoising steps, and adaptive weights, which is a complex nonlinear integer programming problem. To maximize the average semantic efficiency metric, we propose a decision-assisted REINFORCE++ algorithm that utilizes feasibility-aware action space and a critic-free stabilized policy update. Numerical results show that the proposed algorithm achieves higher semantic efficiency than baselines.

</details>


### [18] [On the burst-covering radius of binary cyclic codes](https://arxiv.org/abs/2601.00435)
*Gabriel Sac Himelfarb,Moshe Schwartz*

Main category: cs.IT

TL;DR: 该论文定义了突发覆盖码，研究了其参数与突发覆盖半径的关系，对循环码提供了更强的界限，对BCH码证明了LFSR序列中模式频率的新界限，并提出了高效的突发覆盖循环码算法。


<details>
  <summary>Details</summary>
Motivation: 研究突发覆盖码是为了解决数据传输中突发错误的覆盖问题，特别是在循环码和BCH码等实际应用中，需要有效的编码方案来应对突发错误模式。

Method: 1. 定义突发覆盖码并建立一般参数界限；2. 利用线性反馈移位寄存器(LFSR)序列分析循环码的突发覆盖半径；3. 对BCH码证明LFSR序列中模式频率的新界限；4. 开发高效的突发覆盖循环码算法。

Result: 1. 建立了突发覆盖码参数与覆盖半径的一般关系；2. 获得了循环码突发覆盖半径的更强界限；3. 证明了BCH码LFSR序列模式频率的新界限；4. 推导了二进制原始BCH码和Melas码的覆盖半径界限；5. 提出了高效的突发覆盖循环码算法。

Conclusion: 该论文系统研究了突发覆盖码的理论性质，通过LFSR序列分析获得了循环码和BCH码的改进界限，并提供了实用的算法工具，对编码理论和实际应用都有重要价值。

Abstract: We define and study burst-covering codes. We provide some general bounds connecting the code parameters with its burst-covering radius. We then provide stronger bounds on the burst-covering radius of cyclic codes, by employing linear-feedback shift-register (LFSR) sequences. For the case of BCH codes we prove a new bound on pattern frequencies in LFSR sequences, which is of independent interest. Using this tool, we can bound the covering-radius of binary primitive BCH codes and Melas codes. We conclude with an efficient algorithm for burst-covering cyclic codes.

</details>


### [19] [CoCo-Fed: A Unified Framework for Memory- and Communication-Efficient Federated Learning at the Wireless Edge](https://arxiv.org/abs/2601.00549)
*Zhiheng Guo,Zhaoyang Liu,Zihan Cen,Chenyuan Feng,Xinghua Sun,Xiang Chen,Tony Q. S. Quek,Xijun Wang*

Main category: cs.IT

TL;DR: CoCo-Fed：一种面向O-RAN的压缩与组合联邦学习框架，通过双重维度降维投影解决本地内存瓶颈，通过正交子空间叠加协议减少全局通信开销，在无线感知任务中保持高效收敛。


<details>
  <summary>Details</summary>
Motivation: 在O-RAN架构中部署大规模神经网络面临两大瓶颈：1) 资源受限的gNB本地训练所需的内存占用过大；2) 高维模型更新在带宽受限的回传链路上进行全局聚合时导致带宽饱和。

Method: 提出CoCo-Fed框架：本地采用双重维度降维投影技术，将梯度投影到低维结构，使优化器能在低秩结构上运行而不增加推理参数/延迟；全局采用基于正交子空间叠加的传输协议，将层间更新投影并叠加为每个gNB的单个整合矩阵，大幅减少回传流量。

Result: 在到达角估计任务上的大量仿真表明，CoCo-Fed在内存和通信效率方面显著优于现有基线方法，同时在非独立同分布设置下保持稳健收敛。

Conclusion: CoCo-Fed为O-RAN中的边缘智能提供了统一的本地内存效率和全局通信减少解决方案，建立了严格的理论基础，证明了即使在适用于无线感知任务的无监督学习条件下也能收敛。

Abstract: The deployment of large-scale neural networks within the Open Radio Access Network (O-RAN) architecture is pivotal for enabling native edge intelligence. However, this paradigm faces two critical bottlenecks: the prohibitive memory footprint required for local training on resource-constrained gNBs, and the saturation of bandwidth-limited backhaul links during the global aggregation of high-dimensional model updates. To address these challenges, we propose CoCo-Fed, a novel Compression and Combination-based Federated learning framework that unifies local memory efficiency and global communication reduction. Locally, CoCo-Fed breaks the memory wall by performing a double-dimension down-projection of gradients, adapting the optimizer to operate on low-rank structures without introducing additional inference parameters/latency. Globally, we introduce a transmission protocol based on orthogonal subspace superposition, where layer-wise updates are projected and superimposed into a single consolidated matrix per gNB, drastically reducing the backhaul traffic. Beyond empirical designs, we establish a rigorous theoretical foundation, proving the convergence of CoCo-Fed even under unsupervised learning conditions suitable for wireless sensing tasks. Extensive simulations on an angle-of-arrival estimation task demonstrate that CoCo-Fed significantly outperforms state-of-the-art baselines in both memory and communication efficiency while maintaining robust convergence under non-IID settings.

</details>


### [20] [Universal Outlier Hypothesis Testing via Mean- and Median-Based Tests](https://arxiv.org/abs/2601.00712)
*Bernhard C. Geiger,Tobias Koch,Josipa Mihaljević,Maximilian Toller*

Main category: cs.IT

TL;DR: 论文研究了通用离群值假设检验问题，提出两种测试方法：当离群序列数量相对于总序列数量为亚线性时，基于均值的测试能达到最优错误指数；当离群序列数量与总序列数量成比例时，基于中位数的测试能以概率趋近于1达到最优错误指数。


<details>
  <summary>Details</summary>
Motivation: 研究通用离群值假设检验问题，其中观测到大量序列，大多数服从典型分布π，少数服从离群分布μ。与先前工作不同，本文假设观测序列数量和离群序列数量都随序列长度增长，需要在不了解π和μ的情况下识别离群序列。

Method: 提出两种测试方法：1）当离群序列数量相对于总序列数量为亚线性时，使用基于均值的测试，通过计算所有观测序列的均值来估计π；2）当离群序列数量与总序列数量成比例时，使用基于中位数的测试，通过所有观测序列的中位数来估计π。引入典型错误指数概念来形式化分析。

Result: 基于均值的测试在离群序列数量亚线性时能达到最大似然测试（已知π和μ）的错误指数；基于中位数的测试在离群序列数量成比例时能以概率趋近于1达到最大似然测试的错误指数。

Conclusion: 论文表明，在离群序列数量不同增长模式下，通过适当的统计量（均值或中位数）估计典型分布π，可以实现接近最优的离群检测性能，即使不知道π和μ的具体分布。

Abstract: Universal outlier hypothesis testing refers to a hypothesis testing problem where one observes a large number of length-$n$ sequences -- the majority of which are distributed according to the typical distribution $π$ and a small number are distributed according to the outlier distribution $μ$ -- and one wishes to decide, which of these sequences are outliers without having knowledge of $π$ and $μ$. In contrast to previous works, in this paper it is assumed that both the number of observation sequences and the number of outlier sequences grow with the sequence length. In this case, the typical distribution $π$ can be estimated by computing the mean over all observation sequences, provided that the number of outlier sequences is sublinear in the total number of sequences. It is demonstrated that, in this case, one can achieve the error exponent of the maximum likelihood test that has access to both $π$ and $μ$. However, this mean-based test performs poorly when the number of outlier sequences is proportional to the total number of sequences. For this case, a median-based test is proposed that estimates $π$ as the median of all observation sequences. It is demonstrated that the median-based test achieves again the error exponent of the maximum likelihood test that has access to both $π$ and $μ$, but only with probability approaching one. To formalize this case, the typical error exponent -- similar to the typical random coding exponent introduced in the context of random coding for channel coding -- is proposed.

</details>
