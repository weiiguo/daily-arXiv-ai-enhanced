{"id": "2601.06059", "categories": ["cs.IT", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.06059", "abs": "https://arxiv.org/abs/2601.06059", "authors": ["Bingyan Xie", "Yongpeng Wu", "Wenjun Zhang", "Derrick Wing Kwan Ng", "Merouane Debbah"], "title": "Context Video Semantic Transmission with Variable Length and Rate Coding over MIMO Channels", "comment": null, "summary": "The evolution of semantic communications has profoundly impacted wireless video transmission, whose applications dominate driver of modern bandwidth consumption. However, most existing schemes are predominantly optimized for simple additive white Gaussian noise or Rayleigh fading channels, neglecting the ubiquitous multiple-input multiple-output (MIMO) environments that critically hinder practical deployment. To bridge this gap, we propose the context video semantic transmission (CVST) framework under MIMO channels. Building upon an efficient contextual video transmission backbone, CVST effectively learns a context-channel correlation map to explicitly formulate the relationships between feature groups and MIMO subchannels. Leveraging these channel-aware features, we design a multi-reference entropy coding mechanism, enabling channel state-aware variable length coding. Furthermore, CVST incorporates a checkerboard-based feature modulation strategy to achieve multiple rate points within a single trained model, thereby enhancing deployment flexibility. These innovations constitute our multi-reference variable length and rate coding (MR-VLRC) scheme. By integrating contextual transmission with MR-VLRC, CVST demonstrates substantial performance gains over various standardized separated coding methods and recent wireless video semantic communication approaches. The code is available at https://github.com/xie233333/CVST."}
{"id": "2601.06075", "categories": ["cs.IT", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.06075", "abs": "https://arxiv.org/abs/2601.06075", "authors": ["Ali Hossary", "Laura Crosara", "Stefano Tomasin"], "title": "Jamming Detection in Cell-Free MIMO with Dynamic Graphs", "comment": null, "summary": "Jamming attacks pose a critical threat to wireless networks, particularly in cell-free massive MIMO systems, where distributed access points and user equipment (UE) create complex, time-varying topologies. This paper proposes a novel jamming detection framework leveraging dynamic graphs and graph convolutional neural networks (GCN) to address this challenge. By modeling the network as a dynamic graph, we capture evolving communication links and detect jamming attacks as anomalies in the graph evolution. A GCN-Transformer-based model, trained with supervised learning, learns graph embeddings to identify malicious interference. Performance evaluation in simulated scenarios with moving UEs, varying jamming conditions and channel fadings, demonstrates the method's effectiveness, which is assessed through accuracy and F1 score metrics, achieving promising results for effective jamming detection."}
{"id": "2601.06077", "categories": ["cs.IT", "cs.AI", "cs.LG", "math.OC"], "pdf": "https://arxiv.org/pdf/2601.06077", "abs": "https://arxiv.org/abs/2601.06077", "authors": ["Aolin Xu"], "title": "One if by Land, Two if by Sea, Three if by Four Seas, and More to Come -- Values of Perception, Prediction, Communication, and Common Sense in Decision Making", "comment": null, "summary": "This work aims to rigorously define the values of perception, prediction, communication, and common sense in decision making. The defined quantities are decision-theoretic, but have information-theoretic analogues, e.g., they share some simple but key mathematical properties with Shannon entropy and mutual information, and can reduce to these quantities in particular settings. One interesting observation is that, the value of perception without prediction can be negative, while the value of perception together with prediction and the value of prediction alone are always nonnegative. The defined quantities suggest answers to practical questions arising in the design of autonomous decision-making systems. Example questions include: Do we need to observe and predict the behavior of a particular agent? How important is it? What is the best order to observe and predict the agents? The defined quantities may also provide insights to cognitive science and neural science, toward the understanding of how natural decision makers make use of information gained from different sources and operations."}
{"id": "2601.06095", "categories": ["cs.IT", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.06095", "abs": "https://arxiv.org/abs/2601.06095", "authors": ["Andrii Grekhov", "Volodymyr Kharchenko", "Vasyl Kondratiuk"], "title": "Deep Q-Network Based Resilient Drone Communication:Neutralizing First-Order Markov Jammers", "comment": "13 pages, 6 figures", "summary": "Deep Reinforcement Learning based solution for jamming communications using Frequency Hopping Spread Spectrum technology in a 16 channel radio environment is presented. Deep Q Network based transmitter continuously selects the next frequency hopping channel while facing first order reactive jamming, which uses observed transition statistics to predict and interrupt transmissions. Through self training, the proposed agent learns a uniform random frequency hopping policy that effectively neutralizes the predictive advantage of the jamming. In the presence of Rayleigh fading and additive noise, the impact of forward error correction Bose Chaudhuri Hocquenghem type codes is systematically evaluated, demonstrating that even moderate redundancy significantly reduces packet loss. Extensive visualization of the learning dynamics, channel utilization distribution, epsilon greedy decay, cumulative reward, BER and SNR evolution, and detailed packet loss tables confirms convergence to a near optimal jamming strategy. The results provide a practical framework for autonomous resilient communications in modern electronic warfare scenarios."}
{"id": "2601.06068", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.06068", "abs": "https://arxiv.org/abs/2601.06068", "authors": ["Yuan Gao", "Xinyu Wang", "Yifan Ren", "Yuning Zhou", "Ziwei Wang"], "title": "Dual radar-guided glide path error correction based on the Izhikevich neuron model", "comment": null, "summary": "Aiming at the ranging and angle measurement errors caused by target reflection characteristics and system noise in dual radar tracking, this paper proposes a dual radar track error correction method based on the Izhikevich neural model. The network uses the dynamic differential equation of the Izhikevich model to simulate the discharge characteristics of biological neurons. Its input layer integrates the coordinate measurement data of the dual radar, and the output layer represents the error compensation amount through the pulse emission frequency. The spike-timing-dependent plasticity (STDP) is used to adjust the neuron connection weights dynamically, and the trajectory distortion caused by system noise and radar ranging and angle measurement errors can be effectively suppressed."}
{"id": "2601.06110", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.06110", "abs": "https://arxiv.org/abs/2601.06110", "authors": ["Zewei Guo", "Ranran Sun", "Yulong Shen", "Xiaohong Jiang"], "title": "Optimal Beamforming for Uplink Covert Communication in MIMO GEO Satellite-Terrestrial Systems", "comment": null, "summary": "This paper investigates the uplink covert communication in a multiple-input multiple-output (MIMO) satellite-terrestrial system consisting of an Earth station transmitter Alice, a geosynchronous Earth orbit (GEO) satellite receiver Bob, and multiple GEO satellite wardens around Bob, where each node in the system is equipped with an array of directional antennas. Based on beamforming and the default antenna orientation setting, we first propose a scheme for covert Alice-Bob uplink transmission. Under the perfect channel estimation scenario, we provide theoretical modeling for the system performance in terms of detection error probability (DEP), transmission outage probability (TOP) and covert rate (CR), and then explore the optimal beamforming (OB) design as well as the joint optimal beamforming and antenna orientation (JO-BA) design for CR maximization. We then extend our study to the imperfect channel estimation scenario, and conduct related performance modeling and OB/JO-BA designs for CR maximization. We also apply the techniques of semidefinite relaxation, alternating optimization, Rodrigues' rotation formula and 1-D search algorithm to develop efficient algorithms to solve the above optimization problems. Finally, extensive numerical results are presented to verify our theoretical results and to illustrate the efficiency of beamforming and antenna orientation design for supporting the uplink covert communication in MIMO GEO satellite-terrestrial systems."}
{"id": "2601.06076", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.06076", "abs": "https://arxiv.org/abs/2601.06076", "authors": ["Desire Guel", "Justin Pegd-Windé Kouraogo", "Kouka Kouakou Nakoulma"], "title": "Optimizing the 4G--5G Migration: A Simulation-Driven Roadmap for Emerging Markets", "comment": "17 pages, 7 figures, 14 Tables", "summary": "Deploying fifth-generation (5G) networks in emerging markets demands a balance between performance targets and constraints in budget, spectrum, and infrastructure. We use MATLAB simulations to quantify how radio and architectural levers - MIMO (beamforming, diversity, spatial multiplexing), carrier aggregation (CA), targeted spectrum refarming to New Radio (NR), mmWave propagation with blockage/rain, and Non-Standalone (NSA) versus Standalone (SA) cores - affect capacity, coverage, latency, and interference robustness, with D2D and M2M as complements to wide-area access. Beamforming improves cell-edge SNR by about 3-6 dB, while spatial multiplexing dominates at moderate/high SNR via multi-stream gains. Throughput scales strongly with CA: increasing from 1 to 5x20-MHz carriers raises peak rate from about 200 Mb/s to about 1 Gb/s at 30 dB SNR; water-filling adds 5-12% over equal power at mid-SNR. Targeted mid-band refarming to NR increases median throughput by 60-90% in urban and 40-70% in rural scenarios when sub-1-GHz layers preserve coverage. At 28 GHz, rain and human blockage add about 8-30 dB excess loss, so viable mmWave deployment concentrates in LOS hot zones with narrow-beam arrays and short inter-site distances. NSA delivers broader initial coverage than SA by reusing LTE/EPC, while SA becomes attractive as transport improves (e.g., >= 10 Gb/s and < 5 ms RTT) and site density grows. We synthesize these results into a practical roadmap: start NR on NSA, prioritize CA-centric spectrum strategies with focused refarming, densify selectively in demand hotspots, and migrate to SA as backhaul and device ecosystems mature."}
{"id": "2601.06120", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.06120", "abs": "https://arxiv.org/abs/2601.06120", "authors": ["Tilo Strutz", "Roman Rischke"], "title": "Range-Coder with fast Adaptation and Table-Based Decoding", "comment": null, "summary": "The transmission or storage of signals typically involves data compression. The final processing step in compression systems is generally an entropy coding stage, which converts symbols into a bit stream based on their probability distribution. A distinct class of entropy coding methods operates not by mapping input symbols to discrete codewords but by operating on intervals or ranges. This approach enables a more accurate approximation of the source entropy, particularly for sources with highly skewed or varying symbol distributions. Representative techniques in this category include traditional arithmetic coding, range coding, and methods based on asymmetric numeral systems (ANS). The complexity of these methods depends mainly on three processing steps: the core routines of encoding and decoding doing the calculations, the interval-based determination of the correct symbol at decoder, and the efforts of keeping updated with respect to the varying symbol distribution.\n  The interval-based symbol determination at decoder typically demands for a searching procedure. In previous literature, it could be shown that the search can be replaced by a table-based approach with only O(1)-complexity but having the side-effect that the adaptation of the symbols statistic becomes infeasible because of the high time-consumption of adapting the table.\n  We propose an adaptation process using a ring-buffer technique enabling the adaptive table-based decoding procedure as well as the replacement of a division by a bit-shift operation at encoder and decoder core routines. This accelerates the coding process significantly. In static (non-adaptive) mode, the coding time can be reduced by about 40 percent. In adaptive mode, the proposed technique is faster than alternative approaches for alphabets from about 12 to 64 different symbol when comparing the overall encoder+decoder time."}
{"id": "2601.06308", "categories": ["eess.SP", "cs.AR", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.06308", "abs": "https://arxiv.org/abs/2601.06308", "authors": ["Mostafa Darvishi"], "title": "Timing Fragility Aware Selective Hardening of RISCV Soft Processors on SRAM Based FPGAs", "comment": "14 pages, 2 tables, 13 figures", "summary": "Selective hardening is widely employed to improve the reliability of FPGA based soft processors while limiting the overhead of full redundancy. However, existing approaches primarily rely on architectural criticality or functional fault analysis, overlooking the impact of routing dependent timing sensitivity on processor robustness. This paper introduces a timing fragility aware selective hardening methodology for RISCV soft processors implemented on SRAM based FPGAs. Building on recent advances in in situ timing observability, the proposed approach quantifies the statistical timing sensitivity of pipeline components under controlled routing perturbations and uses this information to guide hardening decisions. Experimental results on a RISCV processor implemented on a commercial FPGA platform show that components exhibiting higher timing fragility also demonstrate increased vulnerability to routing induced delay effects. Leveraging this correlation, the proposed selective hardening strategy achieves robustness comparable to full hardening while significantly reducing area and timing overhead. These results demonstrate that timing fragility provides a practical and effective metric for reliability aware design optimization in FPGA based processor architectures."}
{"id": "2601.06125", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.06125", "abs": "https://arxiv.org/abs/2601.06125", "authors": ["Shengcai Zhou", "Luping Xiang", "Yi Wang", "Kun Yang", "Kai Kit Wong", "Chan-Byoung Chae"], "title": "Extended Target Adaptive Beamforming for ISAC:A Perspective of Predictive Error Ellipse", "comment": null, "summary": "Utilizing communication signals to extract motion parameters has emerged as a key direction in Vehicle-to- Everything (V2X) networks. Accurately modeling the relationship between communication signals and sensing performance is critical for the advancement of such systems. Unlike prior work that relies primarily on qualitative analysis, this paper derives the Cramér-Rao Bound (CRB) for radar parameter estimation in the context of Orthogonal Frequency Division Multiplexing (OFDM) waveforms and Uniform Planar Array (UPA) configurations. Recognizing that vehicles may act as extended targets, we propose two New Radio (NR)-V2X-compatible beamforming schemes tailored to different phases of the communication process. During the initial beam establishment phase, we develop a beamforming approach based on the union of predictive error ellipses, which enhances scatterer localization through temporally assisted beam training. In the beam adjustment phase, we introduce an adaptive narrowest-beam strategy that leverages the positions of scatterers and the communication receiver (CR), enabling effective tracking with reduced complexity. The beam design problem is addressed using the minimum enclosing ellipse algorithm and tailored antenna control methods. Simulation results validate the proposed approach, showing up to a 32.4% improvement in achievable rate with a 32*32 transmit antenna array and a 5.2% gain with an 8*8 array, compared to conventional beam sweeping under identical SNR conditions."}
{"id": "2601.06333", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.06333", "abs": "https://arxiv.org/abs/2601.06333", "authors": ["Ahmed Nirjhar Alam", "Wesley Reinhart", "Rebecca Napolitano"], "title": "Building Envelope Inversion by Data-driven Interpretation of Ground Penetrating Radar", "comment": null, "summary": "Ground-penetrating radar (GPR) combines depth resolution, non-destructive operation, and broad material sensitivity, yet it has seen limited use in diagnosing building envelopes. The compact geometry of wall assemblies, where reflections from closely spaced studs, sheathing, and cladding strongly overlap, has made systematic inversion difficult. Recent advances in data-driven interpretation provide an opportunity to revisit this challenge and assess whether machine learning can reliably extract structural information from such complex signals. Here, we develop a GPR-based inversion framework that decomposes wall diagnostics into classification tasks addressing vertical (stud presence) and lateral (wall-type) variations. Alongside model development, we implement multiple feature minimization strategies - including recursive elimination, agglomerative clustering, and L0-based sparsity - to promote fidelity and interpretability. Among these approaches, the L0-based sparse neural network (SparseNN) emerges as particularly effective: it exceeds Random Forest accuracy while relying on only a fraction of the input features, each linked to identifiable dielectric interfaces. SHAP analysis further confirms that the SparseNN learns reflection patterns consistent with physical layer boundaries. In summary, this framework establishes a foundation for physically interpretable and data-efficient inversion of wall assemblies using GPR radargrams. Although defect detection is not addressed here, the ability to reconstruct intact envelope structure and isolate features tied to key elements provides a necessary baseline for future inversion and anomaly-analysis tasks."}
{"id": "2601.06156", "categories": ["cs.IT", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.06156", "abs": "https://arxiv.org/abs/2601.06156", "authors": ["Ziyu Huang", "Yong Zeng", "Shen Fu", "Xiaoli Xu", "Hongyang Du"], "title": "Channel Knowledge Map Construction via Guided Flow Matching", "comment": null, "summary": "The efficient construction of accurate channel knowledge maps (CKMs) is crucial for unleashing the full potential of environment-aware wireless networks, yet it remains a difficult ill-posed problem due to the sparsity of available location-specific channel knowledge data. Although diffusion-based methods such as denoising diffusion probabilistic models (DDPMs) have been exploited for CKM construction, they rely on iterative stochastic sampling, rendering them too slow for real-time wireless applications. To bridge the gap between high fidelity and efficient CKM construction, this letter introduces a novel framework based on linear transport guided flow matching (LT-GFM). Deviating from the noise-removal paradigm of diffusion models, our approach models the CKM generation process as a deterministic ordinary differential equation (ODE) that follows linear optimal transport paths, thereby drastically reducing the number of required inference steps. We propose a unified architecture that is applicable to not only the conventional channel gain map (CGM) construction, but also the more challenging spatial correlation map (SCM) construction. To achieve physics-informed CKM constructions, we integrate environmental semantics (e.g., building masks) for edge recovery and enforce Hermitian symmetry for property of the SCM. Simulation results verify that LT-GFM achieves superior distributional fidelity with significantly lower Fréchet Inception Distance (FID) and accelerates inference speed by a factor of 25 compared to DDPMs."}
{"id": "2601.06396", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.06396", "abs": "https://arxiv.org/abs/2601.06396", "authors": ["Mengqi Ma", "Aihua Xia"], "title": "Performance Analysis for Wireless Localization with Random Sensor Network", "comment": null, "summary": "Accurate wireless localization underpins applications from autonomous systems to smart infrastructure. We study the mean-squared error (MSE) and conditional MSE (CMSE) of a practical fusion-based estimator in d-dimensional, stationary isotropic (translation- and rotation-invariant) random sensor networks, where a central processor combines received-signal-strength (RSS) and angle-of-arrival (AOA) measurements to infer a target's position. Our contributions are twofold. First, we establish an approximation theorem: when measurement noise is sufficiently large, the joint law of RSS and AOA observations under a broad class of stationary isotropic deployments is, in distribution, indistinguishable from that induced by a homogeneous Poisson point process (PPP). Second, leveraging this equivalence, we investigate a homogeneous PPP-based sensor network. We propose a fusion-based estimator in which a central processor aggregates RSS and AOA measurements from a set of spatially distributed sensors to infer the target position. For this PPP deployment within a finite observation region, we derive tractable analytical upper bounds for both the MSE and CMSE, establishing explicit scaling laws with respect to sensor density, observation radius, and noise variance. The approximation theorem then certifies these PPP-based bounds as reasonable proxies for non-Poisson deployments in noisy regimes. Overall, the results translate deployment and sensing parameters into achievable accuracy targets and provide robust, cost-aware guidance for the design of next-generation location-aware wireless networks."}
{"id": "2601.06211", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.06211", "abs": "https://arxiv.org/abs/2601.06211", "authors": ["Sunwoo Kim", "Byonghyo Shim"], "title": "Large Multimodal Model-Aided Scheduling for 6G Autonomous Communications", "comment": "16 pages", "summary": "Recently, large language models (LLMs) have gained significant attention for their ability to generate fast and accurate answer to the given query. These models have evolved into large multimodal models (LMMs), which can interpret and analyze multimodal inputs such as images and text. With the exponential growth of AI functionalities in autonomous devices, the central unit (CU), a digital processing unit performing AI inference, needs to handle LMMs to effectively control these devices. To ensure seamless command delivery to devices, the CU must perform the scheduling, which involves resource block (RB) allocation for data transmission and modulation and coding scheme (MCS) index selection based on the channel conditions. This task is challenging in many practical environments in 6G, where even small user movement can cause abrupt channel changes. In this paper, we propose a novel LMM-based scheduling technique to address this challenge. Our key idea is to leverage LMM to predict future channel parameters (e.g., distance, angles, and path gain) by analyzing the visual sensing information as well as pilot signals. By exploiting LMMs to predict the presence of reliable path and geometric information of users from the visual sensing information, and then combining these with past channel states from pilot signals, we can accurately predict future channel parameters. Using these predictions, we can preemptively make channel-aware scheduling decisions. From the numerical evaluations, we show that the proposed technique achieves more than 30% throughput gain over the conventional scheduling techniques."}
{"id": "2601.06467", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.06467", "abs": "https://arxiv.org/abs/2601.06467", "authors": ["Sijie Ji", "Weiying Hou", "Chenshu Wu"], "title": "Neuro-Wideband WiFi Sensing via Self-Conditioned CSI Extrapolation", "comment": "In Submission", "summary": "WiFi sensing has suffered from the limited bandwidths designated for its original communication purpose, leading to fundamental limits in multipath resolution and thus multi-user sensing. Unfortunately, it is practically prohibitive to obtain large bandwidths on commercial WiFi, considering the conflict between the limited spectrum and the crowded networks. In this paper, we present Neuro-Wideband (NWB), a completely different paradigm that enables wideband WiFi sensing without specialized hardware or extra channel measurements. Our key insight is that any physical measurement of channel state information (CSI) inherently encapsulates multipath parameters, which, while unsolvable in isolation, can be transformed into an expanded form of CSI (eCSI) approximating measurements over a broader bandwidth. To ground this insight, we propose WUKONG to address NWB as a unique self-conditioned learning problem that can be trained by using any existing CSI data as self-labeled samples. WUKONG introduces a novel deep learning framework by integrating Transformer and Diffusion models, which captures sample-specific multipath parameters and transfers this sample-level knowledge to the outcome eCSI. We conduct real-world experiments to evaluate WUKONG on diverse WiFi signals across protocols and bandwidths. The results show the promising effectiveness of NWB, which is further demonstrated through case studies on localization and multi-person breathing monitoring using eCSI. Overall, the proposed NWB promises a practical pathway toward realizing wideband WiFi sensing on commodity hardware, expanding the design space of wireless sensing systems."}
{"id": "2601.06430", "categories": ["cs.IT", "eess.SP"], "pdf": "https://arxiv.org/pdf/2601.06430", "abs": "https://arxiv.org/abs/2601.06430", "authors": ["Ruotong Zhao", "Shaokang Hu", "Deepak Mishra", "Derrick Wing Kwan Ng"], "title": "Robust and Secure Blockage-Aware Pinching Antenna-assisted Wireless Communication", "comment": "This work has been submitted to IEEE TMC", "summary": "In this work, we investigate a blockage-aware pinching antenna (PA) system designed for secure and robust wireless communication. The considered system comprises a base station equipped with multiple waveguides, each hosting multiple PAs, and serves multiple single-antenna legitimate users in the presence of multi-antenna eavesdroppers under imperfect channel state information (CSI). To safeguard confidential transmissions, artificial noise (AN) is deliberately injected to degrade the eavesdropping channels. Recognizing that conventional linear CSI-error bounds become overly conservative for spatially distributed PA architectures, we develop new geometry-aware uncertainty sets that jointly characterize eavesdroppers position and array-orientation errors. Building upon these sets, we formulate a robust joint optimization problem that determines per-waveguide beamforming and AN covariance, individual PA power-ratio allocation, and PA positions to maximize the system sum rate subject to secrecy constraints. The highly non-convex design problem is efficiently addressed via a low computational complexity iterative algorithm that capitalizes on block coordinate descent, penalty-based methods, majorization-minimization, the S-procedure, and Lipschitz-based surrogate functions. Simulation results demonstrate that sum rates for the proposed algorithm outperforms conventional fixed antenna systems by 4.7 dB, offering substantially improved rate and secrecy performance. In particular, (i) adaptive PA positioning preserves LoS to legitimate users while effectively exploiting waveguide geometry to disrupt eavesdropper channels, and (ii) neglecting blockage effects in the PA system significantly impacts the system design, leading to performance degradation and inadequate secrecy guarantees."}
{"id": "2601.06483", "categories": ["eess.SP", "cs.IT"], "pdf": "https://arxiv.org/pdf/2601.06483", "abs": "https://arxiv.org/abs/2601.06483", "authors": ["Özlem Tuğfe Demir", "Emil Björnson"], "title": "Joint Impact of ADC and Fronthaul Quantization in Cell-Free Massive MIMO-OFDM Uplink", "comment": "Presented at Asilomar Conference on Signals, Systems, and Computers, 2025, 5 pages, 2 figures", "summary": "In the uplink of a cell-free massive MIMO system, quantization affects performance in two key domains: the time-domain distortion introduced by finite-resolution analog-to-digital converters (ADCs) at the access points (APs), and the fronthaul quantization of signals sent to the central processing unit (CPU). Although quantizing twice may seem redundant, the ADC quantization in orthogonal frequency-division duplex (OFDM) systems appears in the time domain, and one must then convert to the frequency domain, where quantization can be applied only to the signals at active subcarriers. This reduces fronthaul load and avoids unnecessary distortion, since the ADC output spans all OFDM samples while only a subset of subcarriers carries useful information.\n  While both quantization effects have been extensively studied in narrowband systems, their joint impact in practical wideband OFDM-based cell-free massive MIMO remains largely unexplored. This paper addresses the gap by modeling the joint distortion and proposing a fronthaul strategy in which each AP processes the received signal to reduce quantization artifacts before transmission. We develop an efficient estimation algorithm that reconstructs the unquantized time-domain signal prior to fronthaul transmission and evaluate its effectiveness. The proposed design offers new insights for implementing efficient, quantization-aware uplink transmission in wideband cell-free architectures."}
{"id": "2601.06447", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.06447", "abs": "https://arxiv.org/abs/2601.06447", "authors": ["Boris Ryabko"], "title": "Error correction methods based on two-faced processes", "comment": null, "summary": "A new approach to the problem of error correction in communication channels is proposed, in which the input sequence is transformed in such a way that the interdependence of symbols is significantly increased. Then, after the sequence is transmitted over the channel, this property is used for error correction so that the remaining error rate is significantly reduced. The complexity of encoding and decoding is linear."}
{"id": "2601.06486", "categories": ["eess.SP", "cs.IT"], "pdf": "https://arxiv.org/pdf/2601.06486", "abs": "https://arxiv.org/abs/2601.06486", "authors": ["Özlem Tuğfe Demir", "Emil Björnson"], "title": "Cell-Free Massive MIMO with Hardware-Impaired Wireless Fronthaul", "comment": "Presented at Asilomar Conference on Signals, Systems, and Computers, 2025, 5 pages, 4 figures", "summary": "Cell-free massive MIMO (multiple-input multiple-output) enhances spectral and energy efficiency compared to conventional cellular networks by enabling joint transmission and reception across a large number of distributed access points (APs). Since these APs are envisioned to be low-cost and densely deployed, hardware impairments, stemming from non-ideal radio-frequency (RF) chains, are unavoidable. While existing studies primarily address hardware impairments on the access side, the impact of hardware impairments on the wireless fronthaul link has remained largely unexplored. In this work, we fill this important gap by introducing a novel amplify-and-forward (AF) based wireless fronthauling scheme tailored for cell-free massive MIMO. Focusing on the uplink, we develop an analytical framework that jointly models the hardware impairments at both the APs and the fronthaul transceivers, derives the resulting end-to-end distorted signal expression, and quantifies the individual contribution of each impairment to the spectral efficiency. Furthermore, we design distortion-aware linear combiners that optimally mitigate these effects. Numerical results demonstrate significant performance gains from distortion-aware processing and illustrate the potential of the proposed AF fronthauling scheme as a cost-effective enabler for future cell-free architectures."}
{"id": "2601.06450", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.06450", "abs": "https://arxiv.org/abs/2601.06450", "authors": ["Charul Rajput", "B. Sundar Rajan", "Ragnar Freij-Hollanti", "Camilla Hollanti"], "title": "Function-Correcting Partition codes", "comment": null, "summary": "We introduce function-correcting partition codes (FCPCs) that are a natural generalization of function-correcting codes (FCCs). A $t$-error function-correcting partition code is an $(\\mathcal{P},t)$-encoding defined directly on a partition $\\mathcal{P}$ of $\\mathbb{F}_q^k$. For a partition $\\mathcal{P}=\\{P_1,P_2,\\ldots,P_E\\}$ a systematic mapping $\\mathcal{C}_{\\mathcal{P}} : \\mathbb{F}_q^k \\rightarrow \\mathbb{F}_q^{k+r}$ is called a \\emph{$(\\mathcal{P},t)$-encoding} if for all $u\\in P_i$ and $v\\in P_j$ with $i\\neq j$, $d\\big(\\mathcal{C}_{\\mathcal{P}}(u), \\mathcal{C}_{\\mathcal{P}}(v)\\big)\\ge 2t+1.$ We show that any $t$-error correcting code for a function $f$, denoted by $(f,t)$-FCC is exactly an FCPC with respect to the domain partition induced by $f$, which makes these codes a natural generalization of FCCs. We use the join of domain partitions to construct a single code that protects multiple functions simultaneously. We define the notion of partition redundancy gain and partition rate gain to measure the bandwidth saved by using a single FCPC for multiple functions instead of constructing separate FCCs for each function. We specialize this to linear functions via coset partition of the intersection of their kernels. Then, we associate a partition graph to any given partition of $\\mathbb{F}_q^k$, and show that the existence of a suitable clique in this graph yields a set of representative information vectors that achieves the optimal redundancy. We showed the existence of a full-size clique in the partition graphs of weight partition and support partition. Finally, we introduce the notion of a block-preserving contraction for a partition, which helps reduce the problem of finding optimal redundancy for an FCPC. We observe that FCPCs naturally provide a form of partial privacy, in the sense that only the domain partition of the function needs to be revealed to the transmitter."}
{"id": "2601.06645", "categories": ["eess.SP", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.06645", "abs": "https://arxiv.org/abs/2601.06645", "authors": ["Juan Miguel López Alcaraz", "Xicoténcatl López Moran", "Erick Dávila Zaragoza", "Claas Händel", "Richard Koebe", "Wilhelm Haverkamp", "Nils Strodthoff"], "title": "A Multimodal Deep Learning Framework for Predicting ICU Deterioration: Integrating ECG Waveforms with Clinical Data and Clinician Benchmarking", "comment": "23 pages, 8 figures, source code under https://github.com/AI4HealthUOL/MDS-ICU", "summary": "Artificial intelligence holds strong potential to support clinical decision making in intensive care units where timely and accurate risk assessment is critical. However, many existing models focus on isolated outcomes or limited data types, while clinicians integrate longitudinal history, real time physiology, and heterogeneous clinical information. To address this gap, we developed MDS ICU, a unified multimodal machine learning framework that fuses routinely collected data including demographics, biometrics, vital signs, laboratory values, ECG waveforms, surgical procedures, and medical device usage to provide continuous predictive support during ICU stays. Using 63001 samples from 27062 patients in MIMIC IV, we trained a deep learning architecture that combines structured state space S4 encoders for ECG waveforms with multilayer perceptron RealMLP encoders for tabular data to jointly predict 33 clinically relevant outcomes spanning mortality, organ dysfunction, medication needs, and acute deterioration. The model achieved strong discrimination with AUROCs of 0.90 for 24 hour mortality, 0.92 for sedative administration, 0.97 for invasive mechanical ventilation, and 0.93 for coagulation dysfunction. Calibration analysis showed close agreement between predicted and observed risks, with consistent gains from ECG waveform integration. Comparisons with clinicians and large language models showed that model predictions alone outperformed both, and that providing model outputs as decision support further improved their performance. These results demonstrate that multimodal AI can deliver clinically meaningful risk stratification across diverse ICU outcomes while augmenting rather than replacing clinical expertise, establishing a scalable foundation for precision critical care decision support."}
{"id": "2601.06492", "categories": ["cs.IT", "math.OC", "quant-ph"], "pdf": "https://arxiv.org/pdf/2601.06492", "abs": "https://arxiv.org/abs/2601.06492", "authors": ["Chun-Neng Chu", "Wei-Fu Tseng", "Yen-Huan Li"], "title": "Algorithms for Computing the Petz-Augustin Capacity", "comment": null, "summary": "We propose the first algorithms with non-asymptotic convergence guarantees for computing the Petz-Augustin capacity, which generalizes the channel capacity and characterizes the optimal error exponent in classical-quantum channel coding. This capacity can be equivalently expressed as the maximization of two generalizations of mutual information: the Petz-Rényi information and the Petz-Augustin information. To maximize the Petz-Rényi information, we show that it corresponds to a convex Hölder-smooth optimization problem, and hence the universal fast gradient method of Nesterov (2015), along with its convergence guarantees, readily applies. Regarding the maximization of the Petz-Augustin information, we adopt a two-layered approach: we show that the objective function is smooth relative to the negative Shannon entropy and can be efficiently optimized by entropic mirror descent; each iteration of entropic mirror descent requires computing the Petz-Augustin information, for which we propose a novel fixed-point algorithm and establish its contractivity with respect to the Thompson metric. Notably, this two-layered approach can be viewed as a generalization of the mirror-descent interpretation of the Blahut-Arimoto algorithm due to He et al. (2024)."}
{"id": "2601.06796", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.06796", "abs": "https://arxiv.org/abs/2601.06796", "authors": ["Yasir Ali", "Tayyab Manzoor", "Huan Yang", "Chenhang Yan", "Yuanqing Xia"], "title": "Artificial Intelligence Driven Channel Coding and Resource Optimization for Wireless Networks", "comment": "50 Pages", "summary": "The ongoing evolution of 5G and its enhanced version, 5G+, has significantly transformed the telecommunications landscape, driving an unprecedented demand for ultra-high-speed data transmission, ultra-low latency, and resilient connectivity. These capabilities are essential for enabling mission-critical applications such as the Internet of Things, autonomous vehicles, and smart city infrastructures. This paper investigates the important role of Artificial Intelligence (AI) in addressing the key challenges faced by 5G/5G+ networks, including interference mitigation, dynamic resource allocation, and maintaining seamless network operation. The study particularly focuses on AI-driven innovations in coding theory, which offer advanced solutions to the limitations of conventional error correction and modulation techniques. By employing deep learning, reinforcement learning, and neural network-based approaches, this research demonstrates significant advancements in error correction performance, decoding efficiency, and adaptive transmission strategies. Additionally, the integration of AI with emerging technologies, such as massive multiple-input and multiple-output, intelligent reflecting surfaces, and privacy-enhancing mechanisms, is discussed, highlighting their potential to propel the next generation of wireless networks. This paper also provides insights into the transformative impact of AI on modern wireless communication, establishing a foundation for scalable, adaptive, and more efficient network architectures."}
{"id": "2601.06493", "categories": ["cs.IT", "math.CO"], "pdf": "https://arxiv.org/pdf/2601.06493", "abs": "https://arxiv.org/abs/2601.06493", "authors": ["Han Li", "Xiang Wang", "Fang-Wei Fu"], "title": "On the Number of Subsequences in the Nonbinary Deletion Channel", "comment": null, "summary": "In the deletion channel, an important problem is to determine the number of subsequences derived from a string $U$ of length $n$ when subjected to $t$ deletions. It is well-known that the number of subsequences in the setting exhibits a strong dependence on the number of runs in the string $U$, where a run is defined as a maximal substring of identical characters. In this paper we study the number of subsequences of a non-binary string in this scenario, and propose some improved bounds on the number of subsequences of $r$-run non-binary strings. Specifically, we characterize a family of $r$-run non-binary strings with the maximum number of subsequences under any $t$ deletions, and show that this number can be computed in polynomial time."}
{"id": "2601.06809", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.06809", "abs": "https://arxiv.org/abs/2601.06809", "authors": ["Hong-Bae Jeon", "Chan-Byoung Chae"], "title": "RIS-aided ISAC with $K$-Rydberg Atomic Receivers", "comment": "13 pages, 5 figures", "summary": "In this paper, we investigate a reconfigurable intelligent surface (RIS)-assisted integrated sensing and communications (ISAC) framework equipped with multiple Rydberg atomic receiver (RAR)-aided users. By leveraging the reference-assisted reception mechanism of RARs, we develop a unified signal model that jointly captures downlink multi-user communication with RARs and monostatic radar sensing. To explicitly balance communication performance and sensing accuracy, we formulate a Cramer-Rao bound (CRB)-constrained utility maximization problem. To address these challenges, we propose a joint optimization framework that combines fractional programming (FP), majorization-minimization (MM), and the alternating direction method of multipliers (ADMM). Simulation results demonstrate that the proposed framework consistently outperforms the conventional approach over a wide range of system environments, thereby highlighting the importance of the proposed framework in unlocking the potential of RARs for 6G."}
{"id": "2601.06501", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.06501", "abs": "https://arxiv.org/abs/2601.06501", "authors": ["Yuhan Yang", "Haoheng Yuan", "Chao Qi", "Fan Cheng", "Bin Dai"], "title": "Coding for Fading Channels with Imperfect CSI at the Transmitter and Quantized Feedback", "comment": "16 pages, 9 figures", "summary": "The classical Schalkwijk-Kailath (SK) scheme for the additive Gaussian noise channel with noiseless feedback is highly efficient since its coding complexity is extremely low and the decoding error doubly exponentially decays as the coding blocklength tends to infinity. However, how to extend the SK scheme to channel models with memory has yet to be solved. In this paper, we first investigate how to design SK-type scheme for the 2-path quasi-static fading channel with noiseless feedback. By viewing the signal of the second path as a relay and adopting an amplify-and-forward (AF) relay strategy, we show that the interference path signal can help to enhance the transmission rate. Besides this, for arbitrary multi-path fading channel with feedback, we also present an SK-type scheme for such a model, which\n  transforms the time domain channel into a frequency domain MIMO channel."}
{"id": "2601.06824", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.06824", "abs": "https://arxiv.org/abs/2601.06824", "authors": ["Haruto Kobayashi", "Takuya Sakamoto"], "title": "Radar-Based Identification of Individuals Using Heartbeat Features Extracted from Signal Amplitude and Phase", "comment": "5 pages, 5 figures, and 2 tables. This work is going to be submitted to the IEEE for possible publication", "summary": "This study proposes a non-contact method for identifying individuals through the use of heartbeat features measured with millimeter-wave radar. Although complex-valued radar signal spectrograms are commonly used for this task, little attention has been paid to the choice of signal components, namely, whether to use amplitude, phase, or the complex signal itself. Although spectrograms can be constructed independently from amplitude or phase information, their respective contributions to identification accuracy remain unclear. To address this issue, we first evaluate identification performance using spectrograms derived separately from amplitude, phase, and complex signals. We then propose a feature fusion method that integrates these three representations to enhance identification accuracy. Experiments conducted with a 79-GHz radar system and involving six participants achieved an identification accuracy of 97.67%, demonstrating the effectiveness of the proposed component-wise analysis and integration approach."}
{"id": "2601.06503", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.06503", "abs": "https://arxiv.org/abs/2601.06503", "authors": ["Xiang Wang", "Weijun Fang", "Han Li", "Fang-Wei Fu"], "title": "Some New Results on Sequence Reconstruction Problem for Deletion Channels", "comment": null, "summary": "Levenshtein first introduced the sequence reconstruction problem in $2001$. In the realm of combinatorics, the sequence reconstruction problem is equivalent to determining the value of $N(n,d,t)$, which represents the maximum size of the intersection of two metric balls of radius $t$, given that the distance between their centers is at least $d$ and the sequence length is $n$. In this paper, We present a lower bound on $N(n,3,t)$ for $n\\geq 13$ and $t \\geq 4$. For $t=4$, we prove that this lower bound is tight. This settles an open question posed by Pham, Goyal, and Kiah, confirming that $N(n,3,4)=20n-166$ for all $n \\geq 13$."}
{"id": "2601.06837", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.06837", "abs": "https://arxiv.org/abs/2601.06837", "authors": ["Shuyue Xu", "Matteo Nerini", "Bruno Clerckx"], "title": "Movable Beyond-Diagonal Reconfigurable Intelligent Surfaces: Moving, Interconnecting, or Both?", "comment": null, "summary": "This letter proposes a movable beyond-diagonal reconfigurable intelligent surfaces (MA-BD-RIS) design, combining inter-element connectivity and movability for channel enhancement. We study a MA-BD-RIS assisted multi-user multiple input single output system where beamforming, BD-RIS configuration, and elements positions are jointly optimized to maximize the sum-rate. An efficient algorithm is developed, incorporating closed-form beamforming, a low-complexity partially proximal alternating direction method of multipliers for BD-RIS design, and successive convex approximation for element placement. Simulations show that the high-movability structure yields superior performance in small-scale RIS and rich scattering scenarios, while the high-connectivity structure dominates in large-scale RIS and massive transmit array configurations."}
{"id": "2601.06527", "categories": ["cs.IT", "cs.RO", "eess.IV"], "pdf": "https://arxiv.org/pdf/2601.06527", "abs": "https://arxiv.org/abs/2601.06527", "authors": ["Wataru Uemura", "Shogo Kawasaki"], "title": "Visible Light Communication using Led-Based AR Markers for Robot Localization", "comment": null, "summary": "A method of information transmission using visual markers has been widely studied. In this approach, information or identifiers (IDs) are encoded in the black-and-white pattern of each marker. By analyzing the geometric properties of the marker frame - such as its size, distortion, and coordinates - the relative position and orientation between the camera and the marker can be estimated. Furthermore, by associating the positional information of each marker with its corresponding ID, the position of the camera that takes the image picture can be calculated. In the field of mobile robotics, such markers are commonly utilized for robot localization. As mobile robots become more widely used in everyday environments, such visual markers are expected to be utilized across various contexts. In environments where robots collaborate with humans - such as in cell-based manufacturing systems in factories or in domestic settings with partner robots - it is desirable for such markers to be designed in a manner that appears natural and unobtrusive to humans. In this paper, we propose a method for implementing an ArUco marker in the form of illumination. In the proposed method, LEDs are arranged in accordance with the grid pattern of the marker, and the blinking frequency of each LED is determined based on the corresponding black or white cell. As a result, the illumination appears uniformly bright to the human eye, while the camera can capture variations in the blinking frequency. From these differences, the black-and-white pattern can be reconstructed, enabling the identification of the marker's tag information. We develop a prototype system, and conduct experiments which are conducted to evaluate its performance in terms of recognition accuracy under varying distances and viewing angles with respect to the ArUco marker."}
{"id": "2601.06858", "categories": ["eess.SP", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.06858", "abs": "https://arxiv.org/abs/2601.06858", "authors": ["Qikai Xiao", "Kehui Li", "Binggui Zhou", "Shaodan Ma"], "title": "Deep Learning Based Channel Extrapolation for Dual-Band Massive MIMO Systems", "comment": null, "summary": "Future wireless communication systems will increasingly rely on the integration of millimeter wave (mmWave) and sub-6 GHz bands to meet heterogeneous demands on high-speed data transmission and extensive coverage. To fully exploit the benefits of mmWave bands in massive multiple-input multiple-output (MIMO) systems, highly accurate channel state information (CSI) is required. However, directly estimating the mmWave channel demands substantial pilot overhead due to the large CSI dimension and low signal-to-noise ratio (SNR) led by severe path loss and blockage attenuation. In this paper, we propose an efficient \\textbf{M}ulti-\\textbf{D}omain \\textbf{F}usion \\textbf{C}hannel \\textbf{E}xtrapolator (MDFCE) to extrapolate sub-6 GHz band CSI to mmWave band CSI, so as to reduce the pilot overhead for mmWave CSI acquisition in dual band massive MIMO systems. Unlike traditional channel extrapolation methods based on mathematical modeling, the proposed MDFCE combines the mixture-of-experts framework and the multi-head self-attention mechanism to fuse multi-domain features of sub-6 GHz CSI, aiming to characterize the mapping from sub-6 GHz CSI to mmWave CSI effectively and efficiently. The simulation results demonstrate that MDFCE can achieve superior performance with less training pilots compared with existing methods across various antenna array scales and signal-to-noise ratio levels while showing a much higher computational efficiency."}
{"id": "2601.06558", "categories": ["cs.IT", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.06558", "abs": "https://arxiv.org/abs/2601.06558", "authors": ["Jiao Xu", "Peng Li", "Bing Zheng"], "title": "Hard Thresholding Pursuit Algorithms for Least Absolute Deviations Problem", "comment": null, "summary": "Least absolute deviations (LAD) is a statistical optimality criterion widely utilized in scenarios where a minority of measurements are contaminated by outliers of arbitrary magnitudes. In this paper, we delve into the robustness of the variant of adaptive iterative hard thresholding to outliers, known as graded fast hard thresholding pursuit (GFHTP$_1$) algorithm. Unlike the majority of the state-of-the-art algorithms in this field, GFHTP$_1$ does not require prior information about the signal's sparsity. Moreover, its design is parameterless, which not only simplifies the implementation process but also removes the intricacies of parameter optimization. Numerical experiments reveal that the GFHTP$_1$ algorithm consistently outperforms competing algorithms in terms of both robustness and computational efficiency."}
{"id": "2601.06991", "categories": ["eess.SP", "q-bio.NC"], "pdf": "https://arxiv.org/pdf/2601.06991", "abs": "https://arxiv.org/abs/2601.06991", "authors": ["Triet M. Tran", "Seyed Majid Razavi", "Dee H. Wu", "Sina Khanmohammadi"], "title": "Continuous Energy Landscape Model for Analyzing Brain State Transitions", "comment": null, "summary": "Energy landscape models characterize neural dynamics by assigning energy values to each brain state that reflect their stability or probability of occurrence. The conventional energy landscape models rely on binary brain state representation, where each region is considered either active or inactive based on some signal threshold. However, this binarization leads to significant information loss and an exponential increase in the number of possible brain states, making the calculation of energy values infeasible for large numbers of brain regions. To overcome these limitations, we propose a novel continuous energy landscape framework that employs Graph Neural Networks (GNNs) to learn a continuous precision matrix directly from functional MRI (fMRI) signals, preserving the full range of signal values during energy landscape computation. We validated our approach using both synthetic data and real-world fMRI datasets from brain tumor patients. Our results on synthetic data generated from a switching linear dynamical system (SLDS) and a Kuramoto model show that the continuous energy model achieved higher likelihood and more accurate recovery of basin geometry, state occupancy, and transition dynamics than conventional binary energy landscape models. In addition, results from the fMRI dataset indicate a 0.27 increase in AUC for predicting working memory and executive function, along with a 0.35 improvement in explained variance (R2) for predicting reaction time. These findings highlight the advantages of utilizing the full signal values in energy landscape models for capturing neuronal dynamics, with strong implications for diagnosing and monitoring neurological disorders."}
{"id": "2601.06588", "categories": ["cs.IT", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2601.06588", "abs": "https://arxiv.org/abs/2601.06588", "authors": ["Zijiu Yang", "Qianqian Yang", "Shunpu Tang", "Tingting Yang", "Zhiguo Shi"], "title": "TCLNet: A Hybrid Transformer-CNN Framework Leveraging Language Models as Lossless Compressors for CSI Feedback", "comment": null, "summary": "In frequency division duplexing (FDD) massive multiple-input multiple-output (MIMO) systems, downlink channel state information (CSI) plays a crucial role in achieving high spectrum and energy efficiency. However, the CSI feedback overhead becomes a major bottleneck as the number of antennas increases. Although existing deep learning-based CSI compression methods have shown great potential, they still face limitations in capturing both local and global features of CSI, thereby limiting achievable compression efficiency. To address these issues, we propose TCLNet, a unified CSI compression framework that integrates a hybrid Transformer-CNN architecture for lossy compression with a hybrid language model (LM) and factorized model (FM) design for lossless compression. The lossy module jointly exploits local features and global context, while the lossless module adaptively switches between context-aware coding and parallel coding to optimize the rate-distortion-complexity (RDC) trade-off. Extensive experiments on both real-world and simulated datasets demonstrate that the proposed TCLNet outperforms existing approaches in terms of reconstruction accuracy and transmission efficiency, achieving up to a 5 dB performance gain across diverse scenarios. Moreover, we show that large language models (LLMs) can be leveraged as zero-shot CSI lossless compressors via carefully designed prompts."}
{"id": "2601.07099", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.07099", "abs": "https://arxiv.org/abs/2601.07099", "authors": ["Masaya Kato", "Takuya Sakamoto"], "title": "Autofocus Method for Human-Body Imaging under Respiratory Motion Using Synthetic Aperture Radar", "comment": "8 pages, 7 figures, and 3 tables. This work is going to be submitted to the IEEE for possible publication", "summary": "This study presents an effective autofocusing approach for synthetic aperture radar imaging of the human body under conditions of respiratory motion. The proposed method suppresses respiratory-motion-induced phase errors by separating radar echoes in the spatial- and time-frequency domains and estimating phase errors individually for each separated echo. By compensating for the estimated phase errors, synthetic aperture radar images focused on all scattering points are generated, even when multiple body parts exhibit different motions due to respiration. The performance of the proposed method is evaluated through experiments with four participants in the supine position. Compared with a conventional method, the proposed approach improves image quality by a factor of 5.1 in terms of Muller-Buffington sharpness, and reduces the root-mean-square error with respect to a reference point cloud from 34 mm to 20 mm."}
{"id": "2601.06609", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.06609", "abs": "https://arxiv.org/abs/2601.06609", "authors": ["Anup Kushwaha", "Om Prakash"], "title": "Symplectic Hulls over a Non-Unital Ring", "comment": "24", "summary": "This paper presents the study of the symplectic hulls over a non-unital ring $ E= \\langle κ,τ\\mid 2 κ=2 τ=0,~ κ^2=κ,~ τ^2=τ,~ κτ=κ,~ τκ=τ\\rangle$. We first identify the residue and torsion codes of the left, right, and two-sided symplectic hulls, and characterize the generator matrix of the two-sided symplectic hull of a free $E$-linear code. Then, we explore the symplectic hull of the sum of two free $E$-linear codes. Subsequently, we provide two build-up techniques that extend a free $E$-linear code of smaller length and symplectic hull-rank to one of larger length and symplectic hull-rank. Further, for free $E$-linear codes, we discuss the permutation equivalence and investigate the symplectic hull-variation problem. An application of this study is given by classifying the free $E$-linear optimal codes for smaller lengths."}
{"id": "2601.07324", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.07324", "abs": "https://arxiv.org/abs/2601.07324", "authors": ["Yijun Chen", "Shanpu Shen", "Tianrui Qiao", "Hongyu Li", "Kai-Kit Wong", "Ross Murch"], "title": "Antenna Coding Optimization for Pixel Antenna Empowered MIMO Wireless Power Transfer", "comment": null, "summary": "We investigate antenna coding utilizing pixel antennas as a new degree of freedom for enhancing multiple-input multiple-output (MIMO) wireless power transfer (WPT) systems. The objective is to enhance the output direct current (DC) power under RF combining and DC combining schemes by jointly exploiting gains from antenna coding, beamforming, and rectenna nonlinearity. We first propose the MIMO WPT system model with binary and continuous antenna coding using the beamspace channel model and formulate the joint antenna coding and beamforming optimization using a nonlinear rectenna model. We propose two efficient closed-form successive convex approximation algorithms to efficiently optimize the beamforming. To further reduce the computational complexity, we propose codebook-based antenna coding designs for output DC power maximization based on K-means clustering. Results show that the proposed pixel antenna empowered MIMO WPT system with binary antenna coding increases output DC power by more than 15 dB compared with conventional systems with fixed antenna configuration. With continuous antenna coding, the performance improves another 6 dB. Moreover, the proposed codebook design outperforms previous designs by up to 40% and shows good performance with reduced computational complexity. Overall, the significant improvement in output DC power verifies the potential of leveraging antenna coding utilizing pixel antennas to enhance WPT systems."}
{"id": "2601.06688", "categories": ["cs.IT", "math.ST"], "pdf": "https://arxiv.org/pdf/2601.06688", "abs": "https://arxiv.org/abs/2601.06688", "authors": ["Terence Viaud", "Ioannis Kontoyiannis"], "title": "The Sample Complexity of Lossless Data Compression", "comment": null, "summary": "A new framework is introduced for examining and evaluating the fundamental limits of lossless data compression, that emphasizes genuinely non-asymptotic results. The {\\em sample complexity} of compressing a given source is defined as the smallest blocklength at which it is possible to compress that source at a specified rate and to within a specified excess-rate probability. This formulation parallels corresponding developments in statistics and computer science, and it facilitates the use of existing results on the sample complexity of various hypothesis testing problems. For arbitrary sources, the sample complexity of general variable-length compressors is shown to be tightly coupled with the sample complexity of prefix-free codes and fixed-length codes. For memoryless sources, it is shown that the sample complexity is characterized not by the source entropy, but by its Rényi entropy of order~$1/2$. Nonasymptotic bounds on the sample complexity are obtained, with explicit constants. Generalizations to Markov sources are established, showing that the sample complexity is determined by the source's Rényi entropy rate of order~$1/2$. Finally, bounds on the sample complexity of universal data compression are developed for arbitrary families of memoryless sources. There, the sample complexity is characterized by the minimum Rényi divergence of order~$1/2$ between elements of the family and the uniform distribution. The connection of this problem with identity testing and with the associated separation rates is explored and discussed."}
{"id": "2601.07436", "categories": ["eess.SP", "cs.LG", "physics.optics"], "pdf": "https://arxiv.org/pdf/2601.07436", "abs": "https://arxiv.org/abs/2601.07436", "authors": ["Zicong Jiang", "Magnus Karlsson", "Erik Agrell", "Christian Häger"], "title": "PIDT: Physics-Informed Digital Twin for Optical Fiber Parameter Estimation", "comment": "The paper will be appeared in Optical Fiber Communications Conference and Exhibition (OFC) 2026", "summary": "We propose physics-informed digital twin (PIDT): a fiber parameter estimation approach that combines a parameterized split-step method with a physics-informed loss. PIDT improves accuracy and convergence speed with lower complexity compared to previous neural operators."}
{"id": "2601.06732", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.06732", "abs": "https://arxiv.org/abs/2601.06732", "authors": ["Hassan Touati", "Rodrigo C. de Lamare"], "title": "Study of Adaptive Reliability-Driven Conditional Innovation Decoding for LDPC Codes", "comment": "12 pages, 7 figures", "summary": "In this work, we present an adaptive reliability-driven conditional innovation (AR-CID) decoding algorithm for low-density parity check (LDPC) codes. The proposed AR-CID decoding algorithm consists of one stage of message quality checking and another stage of message passing refinement, which are incorporated into a residual belief propagation decoding strategy. An analysis of the AR-CID decoding algorithm is carried out along with a study of its computational complexity and latency characteristics. Simulation results for several examples of LDPC codes, including short and medium-length codes over an extended range of channel conditions, indicate that the proposed AR-CID decoding algorithm outperforms competing decoding techniques and has an extremely fast convergence, making it particularly suitable for low-delay applications."}
{"id": "2601.07584", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.07584", "abs": "https://arxiv.org/abs/2601.07584", "authors": ["Yuhang Ma", "Nan Ma", "Jianqiao Chen", "Wenkai Liu"], "title": "Vector Quantized-Aided XL-MIMO CSI Feedback with Channel Adaptive Transmission", "comment": "5 pages, 4 figures", "summary": "Efficient channel state information (CSI) feedback is critical for 6G extremely large-scale multiple-input multiple-output (XL-MIMO) systems to mitigate channel interference. However, the massive antenna scale imposes a severe burden on feedback overhead. Meanwhile, existing quantized feedback methods face dual challenges of limited quantization precision and insufficient channel robustness when compressing high-dimensional channel features into discrete symbols. To reduce these gaps, guided by the deep joint source-channel coding (DJSCC) framework, we propose a vector quantized (VQ)-aided scheme for CSI feedback in XL-MIMO systems considering the near-field effect, named VQ-DJSCC-F. Firstly, taking advantage of the sparsity of near-field channels in the polar-delay domain, we extract energy-concentrated features to reduce dimensionality. Then, we simultaneously design the Transformer and CNN (convolutional neural network) architectures as the backbones to hierarchically extract CSI features, followed by VQ modules projecting features into a discrete latent space. The entropy loss regularization in synergy with an exponential moving average (EMA) update strategy is introduced to maximize quantization precision. Furthermore, we develop an attention mechanism-driven channel adaptation module to mitigate the impact of wireless channel fading on the transmission of index sequences. Simulation results demonstrate that the proposed scheme achieves superior CSI reconstruction accuracy with lower feedback overheads under varying channel conditions."}
{"id": "2601.06836", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.06836", "abs": "https://arxiv.org/abs/2601.06836", "authors": ["Zhou Li", "Xiang Zhang", "Kai Wan", "Hua Sun", "Mingyue Ji", "Giuseppe Caire"], "title": "Optimal Rate Region for Multi-server Secure Aggregation with User Collusion", "comment": "29 pages, 1 figures", "summary": "Secure aggregation is a fundamental primitive in privacy-preserving distributed learning systems, where an aggregator aims to compute the sum of users' inputs without revealing individual data. In this paper, we study a multi-server secure aggregation problem in a two-hop network consisting of multiple aggregation servers and multiple users per server, under the presence of user collusion. Each user communicates only with its associated server, while the servers exchange messages to jointly recover the global sum. We adopt an information-theoretic security framework, allowing up to $T$ users to collude with any server.\n  We characterize the complete optimal rate region in terms of user-to-server communication rate, server-to-server communication rate, individual key rate, and source key rate. Our main result shows that the minimum communication and individual key rates are all one symbol per input symbol, while the optimal source key rate is given by $\\min\\{U+V+T-2,\\, UV-1\\}$, where $U$ denotes the number of servers and $V$ the number of users per server. The achievability is established via a linear key construction that ensures correctness and security against colluding users, while the converse proof relies on tight entropy bounds derived from correctness and security constraints.\n  The results reveal a fundamental tradeoff between security and key efficiency and demonstrate that the multi-server architecture can significantly reduce the required key randomness compared to single-server secure aggregation. Our findings provide a complete information-theoretic characterization of secure aggregation in multi-server systems with user collusion."}
{"id": "2601.07630", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.07630", "abs": "https://arxiv.org/abs/2601.07630", "authors": ["Zihan Jiao", "Xinping Yi", "Shi Jin"], "title": "Learning to Unfold Fractional Programming for Multi-Cell MU-MIMO Beamforming with Graph Neural Networks", "comment": null, "summary": "In the multi-cell multiuser multi-input multi-output (MU-MIMO) systems, fractional programming (FP) has demonstrated considerable effectiveness in optimizing beamforming vectors, yet it suffers from high computational complexity. Recent improvements demonstrate reduced complexity by avoiding large-dimension matrix inversions (i.e., FastFP) and faster convergence by learning to unfold the FastFP algorithm (i.e., DeepFP)."}
{"id": "2601.06906", "categories": ["cs.IT", "eess.SP"], "pdf": "https://arxiv.org/pdf/2601.06906", "abs": "https://arxiv.org/abs/2601.06906", "authors": ["Chong Huang", "Gaojie Chen", "Pei Xiao", "Zhu Han", "Rahim Tafazolli"], "title": "Large Artificial Intelligence Models for Future Wireless Communications", "comment": "8 Pages", "summary": "The anticipated integration of large artificial intelligence (AI) models with wireless communications is estimated to usher a transformative wave in the forthcoming information age. As wireless networks grow in complexity, the traditional methodologies employed for optimization and management face increasingly challenges. Large AI models have extensive parameter spaces and enhanced learning capabilities and can offer innovative solutions to these challenges. They are also capable of learning, adapting and optimizing in real-time. We introduce the potential and challenges of integrating large AI models into wireless communications, highlighting existing AIdriven applications and inherent challenges for future large AI models. In this paper, we propose the architecture of large AI models for future wireless communications, introduce their advantages in data analysis, resource allocation and real-time adaptation, discuss the potential challenges and corresponding solutions of energy, architecture design, privacy, security, ethical and regulatory. In addition, we explore the potential future directions of large AI models in wireless communications, laying the groundwork for forthcoming research in this area."}
{"id": "2601.07721", "categories": ["eess.SP", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.07721", "abs": "https://arxiv.org/abs/2601.07721", "authors": ["Jindřich Duník", "Jan Krejčí", "Jakub Matoušek", "Marek Brandner", "Yeongkwon Choe"], "title": "Lagrangian Grid-based Estimation of Nonlinear Systems with Invertible Dynamics", "comment": "Under review for IFAC WC 2026 with IFAC Journal of Systems and Control option", "summary": "This paper deals with the state estimation of non-linear and non-Gaussian systems with an emphasis on the numerical solution to the Bayesian recursive relations. In particular, this paper builds upon the Lagrangian grid-based filter (GbF) recently-developed for linear systems and extends it for systems with nonlinear dynamics that are invertible. The proposed nonlinear Lagrangian GbF reduces the computational complexity of the standard GbFs from quadratic to log-linear, while preserving all the strengths of the original GbF such as robustness, accuracy, and deterministic behaviour. The proposed filter is compared with the particle filter in several numerical studies using the publicly available MATLAB\\textregistered\\ implementation\\footnote{https://github.com/pesslovany/Matlab-LagrangianPMF}."}
{"id": "2601.06925", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.06925", "abs": "https://arxiv.org/abs/2601.06925", "authors": ["Hui Zhao", "Dirk Slock", "Petros Elia"], "title": "Caching Yields up to 5x Spectral Efficiency in Multi-Beam Satellite Communications", "comment": "11 pages, 6 figures", "summary": "This paper examines the integration of vector coded caching (VCC) into multi-beam satellite communications (SATCOM) systems and demonstrates that even limited receiver-side caching can substantially enhance spectral efficiency. By leveraging cached content to suppress interference, VCC enables the concurrent transmission of multiple precoded signal vectors that would otherwise require separate transmission resources. This leads to a multiplicative improvement in resource utilization in SATCOM. To characterize this performance, we model the satellite-to-ground channel using Rician-shadowed fading and after incorporating practical considerations such as matched-filter precoding, channel state information (CSI) acquisition overhead as well as CSI imperfections at the transmitter, we here derive closed-form expressions for the average sum rate and spectral efficiency gain of VCC in SATCOM. Our analysis, tightly validated through numerical simulations, reveals that VCC can yield spectral efficiency gains of 300% to 550% over traditional multi-user MISO SATCOM with the same resources. These gains -- which have nothing to do with multicasting, prefetching gains nor file popularity -- highlight VCC as a pure physical-layer solution for future high-throughput SATCOM systems, significantly narrowing the performance gap between satellite and wired networks."}
{"id": "2601.07728", "categories": ["eess.SP", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.07728", "abs": "https://arxiv.org/abs/2601.07728", "authors": ["J. Matoušek", "J. Krejčí", "J. Duník", "R. Zanetti"], "title": "Tensor Decompositions for Online Grid-Based Terrain-Aided Navigation", "comment": "In review for FUSION 2026", "summary": "This paper presents a practical and scalable grid-based state estimation method for high-dimensional models with invertible linear dynamics and with highly non-linear measurements, such as the nearly constant velocity model with measurements of e.g. altitude, bearing, and/or range. Unlike previous tensor decomposition-based approaches, which have largely remained at the proof-of-concept stage, the proposed method delivers an efficient and practical solution by exploiting decomposable model structure-specifically, block-diagonal dynamics and sparsely coupled measurement dimensions. The algorithm integrates a Lagrangian formulation for the time update and leverages low-rank tensor decompositions to compactly represent and effectively propagate state densities. This enables real-time estimation for models with large state dimension, significantly extending the practical reach of grid-based filters beyond their traditional low-dimensional use. Although demonstrated in the context of terrain-aided navigation, the method is applicable to a wide range of models with decomposable structure. The computational complexity and estimation accuracy depend on the specific structure of the model. All experiments are fully reproducible, with source code provided alongside this paper (GitHub link: https://github.com/pesslovany/Matlab-LagrangianPMF)."}
{"id": "2601.06969", "categories": ["cs.IT", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.06969", "abs": "https://arxiv.org/abs/2601.06969", "authors": ["Qinshan Zhang", "Bin Chen", "Yong Jiang", "Shu-Tao Xia"], "title": "Generalization Bounds for Transformer Channel Decoders", "comment": "18 pages, 3 figures", "summary": "Transformer channel decoders, such as the Error Correction Code Transformer (ECCT), have shown strong empirical performance in channel decoding, yet their generalization behavior remains theoretically unclear. This paper studies the generalization performance of ECCT from a learning-theoretic perspective. By establishing a connection between multiplicative noise estimation errors and bit-error-rate (BER), we derive an upper bound on the generalization gap via bit-wise Rademacher complexity. The resulting bound characterizes the dependence on code length, model parameters, and training set size, and applies to both single-layer and multi-layer ECCTs. We further show that parity-check-based masked attention induces sparsity that reduces the covering number, leading to a tighter generalization bound. To the best of our knowledge, this work provides the first theoretical generalization guarantees for this class of decoders."}
{"id": "2601.06430", "categories": ["cs.IT", "eess.SP"], "pdf": "https://arxiv.org/pdf/2601.06430", "abs": "https://arxiv.org/abs/2601.06430", "authors": ["Ruotong Zhao", "Shaokang Hu", "Deepak Mishra", "Derrick Wing Kwan Ng"], "title": "Robust and Secure Blockage-Aware Pinching Antenna-assisted Wireless Communication", "comment": "This work has been submitted to IEEE TMC", "summary": "In this work, we investigate a blockage-aware pinching antenna (PA) system designed for secure and robust wireless communication. The considered system comprises a base station equipped with multiple waveguides, each hosting multiple PAs, and serves multiple single-antenna legitimate users in the presence of multi-antenna eavesdroppers under imperfect channel state information (CSI). To safeguard confidential transmissions, artificial noise (AN) is deliberately injected to degrade the eavesdropping channels. Recognizing that conventional linear CSI-error bounds become overly conservative for spatially distributed PA architectures, we develop new geometry-aware uncertainty sets that jointly characterize eavesdroppers position and array-orientation errors. Building upon these sets, we formulate a robust joint optimization problem that determines per-waveguide beamforming and AN covariance, individual PA power-ratio allocation, and PA positions to maximize the system sum rate subject to secrecy constraints. The highly non-convex design problem is efficiently addressed via a low computational complexity iterative algorithm that capitalizes on block coordinate descent, penalty-based methods, majorization-minimization, the S-procedure, and Lipschitz-based surrogate functions. Simulation results demonstrate that sum rates for the proposed algorithm outperforms conventional fixed antenna systems by 4.7 dB, offering substantially improved rate and secrecy performance. In particular, (i) adaptive PA positioning preserves LoS to legitimate users while effectively exploiting waveguide geometry to disrupt eavesdropper channels, and (ii) neglecting blockage effects in the PA system significantly impacts the system design, leading to performance degradation and inadequate secrecy guarantees."}
{"id": "2601.07034", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.07034", "abs": "https://arxiv.org/abs/2601.07034", "authors": ["Ioannis Krikidis"], "title": "Quantum Optical Integrated Sensing and Communication with Homodyne BPSK Detection", "comment": "IEEE Wireless Communications Letters, 2026", "summary": "In this letter, we propose a quantum integrated sensing and communication scheme for a quantum optical link using binary phase-shift keying modulation and homodyne detection. The link operates over a phase-insensitive Gaussian channel with an unknown deterministic phase rotation, where the homodyne receiver jointly carries out symbol detection and phase estimation. We formulate a design problem that minimizes the bit-error rate subject to a Fisher information-based constraint on estimation accuracy. To solve it, we develop an iterative algorithm composed of an inner expectation-maximization loop for joint detection and estimation and an outer loop that adaptively retunes the local oscillator phase. Numerical results confirm the effectiveness of the proposed approach and demonstrate a fundamental trade-off between communication reliability and sensing accuracy."}
{"id": "2601.06906", "categories": ["cs.IT", "eess.SP"], "pdf": "https://arxiv.org/pdf/2601.06906", "abs": "https://arxiv.org/abs/2601.06906", "authors": ["Chong Huang", "Gaojie Chen", "Pei Xiao", "Zhu Han", "Rahim Tafazolli"], "title": "Large Artificial Intelligence Models for Future Wireless Communications", "comment": "8 Pages", "summary": "The anticipated integration of large artificial intelligence (AI) models with wireless communications is estimated to usher a transformative wave in the forthcoming information age. As wireless networks grow in complexity, the traditional methodologies employed for optimization and management face increasingly challenges. Large AI models have extensive parameter spaces and enhanced learning capabilities and can offer innovative solutions to these challenges. They are also capable of learning, adapting and optimizing in real-time. We introduce the potential and challenges of integrating large AI models into wireless communications, highlighting existing AIdriven applications and inherent challenges for future large AI models. In this paper, we propose the architecture of large AI models for future wireless communications, introduce their advantages in data analysis, resource allocation and real-time adaptation, discuss the potential challenges and corresponding solutions of energy, architecture design, privacy, security, ethical and regulatory. In addition, we explore the potential future directions of large AI models in wireless communications, laying the groundwork for forthcoming research in this area."}
{"id": "2601.07053", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.07053", "abs": "https://arxiv.org/abs/2601.07053", "authors": ["Chen Wang", "Eitan Yaakobi"], "title": "Random Access in DNA Storage: Algorithms, Constructions, and Bounds", "comment": null, "summary": "As DNA data storage moves closer to practical deployment, minimizing sequencing coverage depth is essential to reduce both operational costs and retrieval latency. This paper addresses the recently studied Random Access Problem, which evaluates the expected number of read samples required to recover a specific information strand from $n$ encoded strands. We propose a novel algorithm to compute the exact expected number of reads, achieving a computational complexity of $O(n)$ for fixed field size $q$ and information length $k$. Furthermore, we derive explicit formulas for the average and maximum expected number of reads, enabling an efficient search for optimal generator matrices under small parameters. Beyond theoretical analysis, we present new code constructions that improve the best-known upper bound from $0.8815k$ to $0.8811k$ for $k=3$, and achieve an upper bound of $0.8629k$ for $k=4$ for sufficiently large $q$. We also establish a tighter theoretical lower bound on the expected number of reads that improves upon state-of-the-art bounds. In particular, this bound establishes the optimality of the simple parity code for the case of $n=k+1$ across any alphabet $q$."}
{"id": "2601.07095", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.07095", "abs": "https://arxiv.org/abs/2601.07095", "authors": ["Tadashi Wadayama", "Takumi Takahashi"], "title": "Score-Based VAMP with Fisher-Information-Based Onsager Correction", "comment": null, "summary": "We propose score-based VAMP (SC-VAMP), a variant of vector approximate message passing (VAMP) in which the Onsager correction is expressed and computed via conditional Fisher information, thereby enabling a Jacobian-free implementation. Using learned score functions, SC-VAMP constructs nonlinear MMSE estimators through Tweedie's formula and derives the corresponding Onsager terms from the score-norm statistics, avoiding the need for analytical derivatives of the prior or likelihood. When combined with random orthogonal/unitary mixing to mitigate non-ideal, structured or correlated sensing settings, the proposed framework extends VAMP to complex black-box inference problems where explicit modeling is intractable. Finally, by leveraging the entropic CLT, we provide an information-theoretic perspective on the Gaussian approximation underlying SE, offering insight into the decoupling principle beyond idealized i.i.d. settings, including nonlinear regimes."}
{"id": "2601.07147", "categories": ["cs.IT", "cs.CR"], "pdf": "https://arxiv.org/pdf/2601.07147", "abs": "https://arxiv.org/abs/2601.07147", "authors": ["Ji He"], "title": "PASS-Enabled Covert Communications With Distributed Cooperative Wardens", "comment": null, "summary": "This paper investigates PASS-enabled downlink covert communication in the presence of distributed surveillance, where multiple wardens perform signal detection and fuse their local binary decisions via majority-voting rule. We consider a dual-waveguide architecture that simultaneously delivers covert information and randomized jamming to hide the transmission footprint, incorporating three representative PASS power-radiation laws-general, proportional, and equal. To characterize the system-level detectability, we derive closed-form expressions for local false-alarm and miss-detection probabilities. By leveraging a probability-generating-function (PGF) and elementary-symmetric-polynomial (ESP) framework, combined with a breakpoint-based partition of the threshold domain, we obtain explicit closed-form characterizations of the system-level detection error probability (DEP) under non-i.i.d. majority-voting fusion. Building on this analytical framework, we formulate a robust optimization problem to maximize the average covert rate subject to covertness constraint. To solve the resulting nonconvex design, we develop an MM-BCD-SCA algorithm that produces tractable alternating updates for power/radiation variables and PA positions via convex surrogates and inner approximations of the DEP value function. Numerical results validate the theoretical analysis and demonstrate the impact of cooperative monitoring and PASS radiation laws on the covertness-rate tradeoff."}
{"id": "2601.07235", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.07235", "abs": "https://arxiv.org/abs/2601.07235", "authors": ["Agnivo Gosai", "Shuvodeep De", "Karun Thankachan"], "title": "Sentiment Analysis on Movie Reviews: A Deep Dive into Modern Techniques and Open Challenges", "comment": "31 Pages; 1 figure; 108 references; ongoing paper that would be submitted to suitable Wiley journal", "summary": "This paper presents a comprehensive survey of sentiment analysis methods for movie reviews, a benchmark task that has played a central role in advancing natural language processing. We review the evolution of techniques from early lexicon-based and classical machine learning approaches to modern deep learning architectures and large language models, covering widely used datasets such as IMDb, Rotten Tomatoes, and SST-2, and models ranging from Naive Bayes and support vector machines to LSTM networks, BERT, and attention-based transformers. Beyond summarizing prior work, this survey differentiates itself by offering a comparative, challenge-driven analysis of how these modeling paradigms address domain-specific issues such as sarcasm, negation, contextual ambiguity, and domain shift, which remain open problems in existing literature. Unlike earlier reviews that focus primarily on text-only pipelines, we also synthesize recent advances in multimodal sentiment analysis that integrate textual, audio, and visual cues from movie trailers and clips. In addition, we examine emerging concerns related to interpretability, fairness, and robustness that are often underexplored in prior surveys, and we outline future research directions including zero-shot and few-shot learning, hybrid symbolic--neural models, and real-time deployment considerations. Overall, this abstract provides a domain-focused roadmap that highlights both established solutions and unresolved challenges toward building more accurate, generalizable, and explainable sentiment analysis systems for movie review data."}
{"id": "2601.07240", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.07240", "abs": "https://arxiv.org/abs/2601.07240", "authors": ["Mohammad Rowshan"], "title": "Bias-Aware BP Decoding of Quantum Codes via Directional Degeneracy", "comment": null, "summary": "We study directionally informed belief propagation (BP) decoding for quantum CSS codes, where anisotropic Tanner-graph structure and biased noise concentrate degeneracy along preferred directions. We formalize this by placing orientation weights on Tanner-graph edges, aggregating them into per-qubit directional weights, and defining a \\emph{directional degeneracy enumerator} that summarizes how degeneracy concentrates along those directions. A single bias parameter~$β$ maps these weights into site-dependent log-likelihood ratios (LLRs), yielding anisotropic priors that plug directly into standard BP$\\rightarrow$OSD decoders without changing the code construction. We derive bounds relating directional and Hamming distances, upper bound the number of degenerate error classes per syndrome as a function of distance, rate, and directional bias, and give a MacWilliams-type expression for the directional enumerator. Finite-length simulations under code-capacity noise show significant logical error-rate reductions -- often an order of magnitude at moderate physical error rates -- confirming that modest anisotropy is a simple and effective route to hardware-aware decoding gains."}
{"id": "2601.07246", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.07246", "abs": "https://arxiv.org/abs/2601.07246", "authors": ["Jiayang Zou", "Luyao Fan", "Jiayang Gao", "Jia Wang"], "title": "Rate-distortion Theory on Non-compact Spaces: A Concentration-compactness Approach", "comment": null, "summary": "In this paper, we study rate-distortion theory for general sources with an emphasis on the existence of optimal reconstruction distributions. Classical existence results rely on compactness assumptions that are often violated in non-compact settings. By introducing the concentration-compactness principle into the analysis of the rate-distortion functional, we establish the existence of optimal reconstructions under mild coercivity conditions on the distortion function. Our results provide a unified and transparent existence theorem for rate-distortion problems on general non-compact spaces."}
{"id": "2601.07317", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.07317", "abs": "https://arxiv.org/abs/2601.07317", "authors": ["Yuxuan Chen", "Qingqing Wu", "Guangji Chen", "Qiaoyan Peng", "Wen Chen"], "title": "Engineering Favorable Propagation: Near-Field IRS Deployment for Spatial Multiplexing", "comment": null, "summary": "In intelligent reflecting surface IRS assisted multiple input multiple output MIMO systems, a strong line of sight LoS link is required to compensate for the severe cascaded path loss. However, such a link renders the effective channel highly rank deficient and fundamentally limits spatial multiplexing. To overcome this limitation, this paper leverages the large aperture of sparse arrays to harness near field spherical wavefronts, and establishes a deterministic deployment criterion that strategically positions the IRS in the near field of a base station BS. This placement exploits the spherical wavefronts of the BS IRS link to engineer decorrelated channels, thereby fundamentally overcoming the rank deficiency issue in far field cascaded channels. Based on a physical channel model for the sparse BS array and the IRS, we characterize the rank properties and inter user correlation of the cascaded BS IRS user channel. We further derive a closed form favorable propagation metric that reveals how the sparse array geometry and the IRS position can be tuned to reduce inter user channel correlation. The resulting geometry driven deployment rule provides a simple guideline for creating a favorable propagation environment with enhanced effective degrees of freedom. The favorable channel statistics induced by our deployment criterion enable a low complexity maximum ratio transmission MRT precoding scheme. This serves as the foundation for an efficient algorithm that jointly optimizes the IRS phase shifts and power allocation based solely on long term statistical channel state information CSI. Simulation results validate the effectiveness of our deployment criterion and demonstrate that our optimization framework achieves significant performance gains over benchmark schemes."}
{"id": "2601.07322", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.07322", "abs": "https://arxiv.org/abs/2601.07322", "authors": ["Jinnan Piao", "Dong Li", "Zhibo Li", "Ming Yang", "Xueting Yu", "Jincheng Dai"], "title": "Performance Bounds of Joint Detection with Kalman Filtering and Channel Decoding for Wireless Networked Control Systems", "comment": null, "summary": "The joint detection uses Kalman filtering (KF) to estimate the prior probability of control outputs to assist channel decoding. In this paper, we regard the joint detection as maximum a posteriori (MAP) decoding and derive the lower and upper bounds based on the pairwise error probability considering system interference, quantization interval, and weight distribution. We first derive the limiting bounds as the signal-to-noise ratio (SNR) goes to infinity and the system interference goes to zero. Then, we construct an infinite-state Markov chain to describe the consecutive packet losses of the control systems to derive the MAP bounds. Finally, the MAP bounds are approximated as the bounds of the transition probability from the state with no packet loss to the state with consecutive single packet loss. The simulation results show that the MAP performance of $\\left(64,16\\right)$ polar code and 16-bit CRC coincides with the limiting upper bound as the SNR increases and has $3.0$dB performance gain compared with the normal approximation of the finite block rate at block error rate $10^{-3}$."}
{"id": "2601.07340", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.07340", "abs": "https://arxiv.org/abs/2601.07340", "authors": ["Zhou Li"], "title": "On the Extremal Source Key Rates for Secure Storage over Graphs", "comment": "13 pages, 7 figures", "summary": "This paper investigates secure storage codes over graphs, where multiple independent source symbols are encoded and stored at graph nodes subject to edge-wise correctness and security constraints. For each edge, a specified subset of source symbols must be recoverable from its two incident nodes, while no information about the remaining sources is revealed. To meet the security requirement, a shared source key may be employed. The ratio between the source symbol size and the source key size defines the source key rate, and the supremum of all achievable rates is referred to as the source key capacity.\n  We study extremal values of the source key capacity in secure storage systems and provide complete graph characterizations for several fundamental settings. For the case where each edge is associated with a single source symbol, we characterize all graphs whose source key capacity equals one. We then generalize this result to the case where each edge is associated with multiple source symbols and identify a broad class of graphs that achieve the corresponding extremal capacity under a mild structural condition. In addition, we characterize all graphs for which secure storage can be achieved without using any source key."}
{"id": "2601.07355", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.07355", "abs": "https://arxiv.org/abs/2601.07355", "authors": ["Yichen Fu", "Tianming Wang", "Ke Wei"], "title": "Fast and Provable Nonconvex Robust Matrix Completion", "comment": null, "summary": "This paper studies the robust matrix completion problem and a computationally efficient non-convex method called ARMC has been proposed. This method is developed by introducing subspace projection to a singular value thresholding based method when updating the low rank part. Numerical experiments on synthetic and real data show that ARMC is superior to existing non-convex RMC methods. Through a refined analysis based on the leave-one-out technique, we have established the theoretical guarantee for ARMC subject to both sparse outliers and stochastic noise. The established bounds for the sample complexity and outlier sparsity are better than those established for a convex approach that also considers both outliers and stochastic noise."}
{"id": "2601.07388", "categories": ["cs.IT", "math.PR"], "pdf": "https://arxiv.org/pdf/2601.07388", "abs": "https://arxiv.org/abs/2601.07388", "authors": ["Manuel Franco-Vivo"], "title": "Novel Decoding Algorithm for Noiseless Non-Adaptive Group Testing", "comment": null, "summary": "Group testing enables the identification of a small subset of defective items within a larger population by performing tests on pools of items rather than on each item individually. Over the years, it has not only attracted attention from the academic community, but has also demonstrated its potential in addressing real-world problems such as infectious disease screening, drug discovery and manufacturing quality control. With the emergence of the COVID-19 pandemic, interest in group testing has grown further, particularly in non-adaptive testing, due to its time efficiency compared to adaptive approaches. This highlights the importance of improving the performance currently achievable in such a scheme. This article focuses on advancing the field of noiseless non-adaptive group testing. The main objective of this work is to study and maximize the probability of successfully identifying the subset of defective items while performing as few tests as possible. To this end, we first note current well-known decoding algorithms, as well as established test design strategies for assigning items to pools. From this review, we identify key opportunities for improvement that inform the development of new decoding algorithms. Specifically, we propose a novel method, Weighted Sequential Combinatorial Orthogonal Matching Pursuit (W-SCOMP), to enhance the efficiency of existing detection procedures. Theoretical results demonstrate that W-SCOMP outperforms other algorithms in noiseless non-adaptive group testing. Furthermore, we develop a simulation framework to model the group testing process and conduct comparative evaluations between the proposed and existing algorithms. The empirical results are consistent with the theoretical findings. Overall, our work expands the range of available decoding algorithms and contributes to the broader understanding of noiseless non-adaptive group testing."}
{"id": "2601.07424", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.07424", "abs": "https://arxiv.org/abs/2601.07424", "authors": ["Xu Gan", "Yuanwei Liu"], "title": "Center-Fed Pinching Antenna System (C-PASS) Aided Wireless Communications", "comment": null, "summary": "The novel architecture of the center-fed pinching antenna system (C-PASS) is investigated, where the waveguide-fed signal is divided into two propagation directions through controllable power splitting. By doing so, a doubled degree of freedom (DoF) is achieved compared to conventional PASS. Based on the new designed basic signal model of C-PASS, three practical operating protocols for C-PASS are proposed, namely power splitting (PS), direction switching (DS), and time switching (TS). Then, the sum-rate maximization problem for the joint optimization of transmit and pinching beamforming is formulated for each of the proposed protocols. 1) For PS, the highly coupled non-convex problem is first transformed into a tractable form via the weighted minimum mean square error reformulation and solved using the alternating optimization framework; 2) For DS, the above approach is subsequently extended to solve the mixed-integer constraints inherent for DS via the penalty-based algorithm; 3) For TS, the optimization problem can be decomposed into two subproblems and solved using the similar iterative techniques, while its optimal time allocation ratio is derived in closed form. Finally, numerical results reveal that TS is superior in the low-power regime, while PS and DS achieve significantly higher rates in the high-power regime due to the enhanced DoF."}
{"id": "2601.07472", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.07472", "abs": "https://arxiv.org/abs/2601.07472", "authors": ["Sheng Su", "Yuhan Yang", "Chao Qi", "Xuan He", "Bin Dai", "Xiaohu Tang"], "title": "Secure Joint Source-Channel Coding for the AWGN Channel with Feedback: A Finite Blocklength Analysis", "comment": null, "summary": "In the literature, it has been shown that the secrecy capacity of the additive white Gaussian noise (AWGN) wiretap channel with noise-free feedback equals the capacity of the same model without secrecy constraint, and the classical Schalkwijk-Kailath (SK) scheme achieves the secrecy capacity. In this paper, we show that in finite blocklength regime, the SK scheme is not optimal, and propose a modified SK scheme which may perform better than the classical one. Besides this, this paper establishes a finite blocklength converse for the AWGN wiretap channel with feedback, which can also be viewed as a converse for the same model without secrecy constraint. To the best of the authors' knowledge, this is the first paper to address such a problem, and the results of this paper are further explained via numerical examples."}
{"id": "2601.07489", "categories": ["cs.IT", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.07489", "abs": "https://arxiv.org/abs/2601.07489", "authors": ["Emiel Vanspranghels", "Zhuangzhuang Cui", "Sofie Pollin"], "title": "Frequency-Adaptive Multi-Band Architecture for Upper Mid-Band MIMO Systems", "comment": "5 pages, 5 figures, submitted to DySPAN 2026", "summary": "FR3 ($\\approx$7-24 GHz), also referred to as the upper mid-band, has recently emerged as promising spectrum for 6G; however, its propagation and MIMO characteristics vary significantly with frequency and environment, and spectrum availability may be intermittent due to incumbents. Using site-specific ray tracing (Sionna RT) in representative indoor and outdoor scenarios, we evaluate 7, 10, 14, 20, and 24 GHz under SISO and MIMO configurations. The results show that FR3 exhibits propagation characteristics intermediate between sub-6 GHz and mmWave bands while supporting meaningful spatial multiplexing, albeit with strong site dependence. Motivated by these findings, we propose a fully digital frequency-adaptive multi-band MIMO architecture that repurposes ADCs/DACs and baseband processing resources across FR3 subbands via switching, enabling dynamic trade-offs between bandwidth (spectrum gain) and antenna consolidation (MIMO gain) under availability and channel constraints. Simulation results demonstrate that exploiting additional spectrum is often optimal, while adaptive resource repurposing becomes beneficial when subbands are unavailable or when multiplexing gains are concentrated at specific frequencies."}
{"id": "2601.07515", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.07515", "abs": "https://arxiv.org/abs/2601.07515", "authors": ["Yang Liu", "Bolin Wu", "Yuxin Han", "Kai Niu"], "title": "A Parity-Consistent Decomposition Method for the Weight Distribution of Pre-Transformed Polar Codes", "comment": null, "summary": "This paper introduces an efficient algorithm based on the Parity-Consistent Decomposition (PCD) method to determine the WD of pre-transformed polar codes. First, to address the bit dependencies introduced by the pre-transformation matrix, we propose an iterative algorithm to construct an \\emph{Expanded Information Set}. By expanding the information bits within this set into 0s and 1s, we eliminate the correlations among information bits, thereby enabling the recursive calculation of the Hamming weight distribution using the \\emph{PCD method}. Second, to further reduce computational complexity, we establish the theory of equivalence classes for pre-transformed polar codes. Codes within the same equivalence class share an identical weight distribution but correspond to different \\emph{Expanded Information Set} sizes. By selecting the pre-transformation matrix that minimizes the \\emph{Expanded Information Set} size within an equivalence class, we optimize the computation process. Numerical results demonstrate that the proposed method significantly reduces computational complexity compared to existing deterministic algorithms."}
{"id": "2601.07523", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.07523", "abs": "https://arxiv.org/abs/2601.07523", "authors": ["Amirreza Zamani", "Sajad Daei", "Parastoo Sadeghi", "Mikael Skoglund"], "title": "Sparse Point-wise Privacy Leakage: Mechanism Design and Fundamental Limits", "comment": null, "summary": "We study an information-theoretic privacy mechanism design problem, where an agent observes useful data $Y$ that is arbitrarily correlated with sensitive data $X$, and design disclosed data $U$ generated from $Y$ (the agent has no direct access to $X$). We introduce \\emph{sparse point-wise privacy leakage}, a worst-case privacy criterion that enforces two simultaneous constraints for every disclosed symbol $u\\in\\mathcal{U}$: (i) $u$ may be correlated with at most $N$ realizations of $X$, and (ii) the total leakage toward those realizations is bounded. In the high-privacy regime, we use concepts from information geometry to obtain a local quadratic approximation of mutual information which measures utility between $U$ and $Y$. When the leakage matrix $P_{X|Y}$ is invertible, this approximation reduces the design problem to a sparse quadratic maximization, known as the Rayleigh-quotient problem, with an $\\ell_0$ constraint. We further show that, for the approximated problem, one can without loss of optimality restrict attention to a binary released variable $U$ with a uniform distribution. For small alphabet sizes, the exact sparsity-constrained optimum can be computed via combinatorial support enumeration, which quickly becomes intractable as the dimension grows. For general dimensions, the resulting sparse Rayleigh-quotient maximization is NP-hard and closely related to sparse principal component analysis (PCA). We propose a convex semidefinite programming (SDP) relaxation that is solvable in polynomial time and provides a tractable surrogate for the NP-hard design, together with a simple rounding procedure to recover a feasible leakage direction. We also identify a sparsity threshold beyond which the sparse optimum saturates at the unconstrained spectral value and the SDP relaxation becomes tight."}
{"id": "2601.07546", "categories": ["cs.IT", "q-bio.GN"], "pdf": "https://arxiv.org/pdf/2601.07546", "abs": "https://arxiv.org/abs/2601.07546", "authors": ["Shiv Pratap Singh Rathore", "Navin Kashyap"], "title": "Estimators for Substitution Rates in Genomes from Read Data", "comment": null, "summary": "We study the problem of estimating the mutation rate between two sequences from noisy sequencing reads. Existing alignment-free methods typically assume direct access to the full sequences. We extend these methods to the sequencing framework, where only noisy reads from the sequences are observed. We use a simple model in which both mutations and sequencing errors are substitutions. We propose multiple estimators, provide theoretical guarantees for one of them, and evaluate the others through simulations."}
{"id": "2601.07547", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.07547", "abs": "https://arxiv.org/abs/2601.07547", "authors": ["Wentu Song", "Kui Cai", "Tony Q. S. Quek"], "title": "On the Sequence Reconstruction Problem for the Single-Deletion Two-Substitution Channel", "comment": null, "summary": "The Levenshtein sequence reconstruction problem studies the reconstruction of a transmitted sequence from multiple erroneous copies of it. A fundamental question in this field is to determine the minimum number of erroneous copies required to guarantee correct reconstruction of the original sequence. This problem is equivalent to determining the maximum possible intersection size of two error balls associated with the underlying channel. Existing research on the sequence reconstruction problem has largely focused on channels with a single type of error, such as insertions, deletions, or substitutions alone. However, relatively little is known for channels that involve a mixture of error types, for instance, channels allowing both deletions and substitutions. In this work, we study the sequence reconstruction problem for the single-deletion two-substitution channel, which allows one deletion and at most two substitutions applied to the transmitted sequence. Specifically, we prove that if two $q$-ary length-$n$ sequences have the Hamming distance $d\\geq 2$, where $q\\geq 2$ is any fixed integer, then the intersection size of their error balls under the single-deletion two-substitution channel is upper bounded by $(q^2-1)n^2-(3q^2+5q-5)n+O_q(1)$, where $O_q(1)$ is a constant independent from $n$ but dependent on $q$. Moreover, we show that this upper bound is tight up to an additive constant."}
{"id": "2601.07567", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.07567", "abs": "https://arxiv.org/abs/2601.07567", "authors": ["Eimear Byrne", "Johan Vester Dinesen", "Ragnar Freij-Hollanti", "Camilla Hollanti"], "title": "A $q$-Polymatroid Framework for Information Leakage in Secure Linear Network Coding", "comment": null, "summary": "We study information leakage in secure linear network coding schemes based on nested rank-metric codes. We show that the amount of information leaked to an adversary that observes a subset of network links is characterized by the conditional rank function of a representable $q$-polymatroid associated with the underlying rank-metric code pair. Building on this connection, we introduce the notions of $q$-polymatroid ports and $q$-access structures and describe their structural properties. Moreover, we extend Massey's correspondence between minimal codewords and minimal access sets to the rank-metric setting and prove a $q$-analogue of the Brickell--Davenport theorem."}
{"id": "2601.07622", "categories": ["cs.IT", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.07622", "abs": "https://arxiv.org/abs/2601.07622", "authors": ["Hao Wu", "Shengtian Yang", "Huiguo Gao", "Diao Wang", "Jun Chen", "Guanding Yu"], "title": "Clipped Affine Policy: Low-Complexity Near-Optimal Online Power Control for Energy Harvesting Communications over Fading Channels", "comment": "14 pages, 5 figures, v0.8", "summary": "This paper investigates online power control for point-to-point energy harvesting communications over wireless fading channels. A linear-policy-based approximation is derived for the relative-value function in the Bellman equation of the power control problem. This approximation leads to two fundamental power control policies: optimistic and robust clipped affine policies, both taking the form of a clipped affine function of the battery level and the reciprocal of channel signal-to-noise ratio coefficient. They are essentially battery-limited weighted directional waterfilling policies operating between adjacent time slots. By leveraging the relative-value approximation and derived policies, a domain-knowledge-enhanced reinforcement learning (RL) algorithm is proposed for online power control. The proposed approach is further extended to scenarios with energy and/or channel lookahead. Comprehensive simulation results demonstrate that the proposed methods achieve a good balance between computational complexity and optimality. In particular, the robust clipped affine policy (combined with RL, using at most five parameters) outperforms all existing approaches across various scenarios, with less than 2\\% performance loss relative to the optimal policy."}
{"id": "2601.07676", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.07676", "abs": "https://arxiv.org/abs/2601.07676", "authors": ["Yuan Gao", "Weijun Fang", "Jingke Xu", "Jiejing Wen"], "title": "New $X$-Secure $T$-Private Information Retrieval Schemes via Rational Curves and Hermitian Curves", "comment": "18 pages, 1 figure", "summary": "$X$-secure and $T$-private information retrieval (XSTPIR) is a variant of private information retrieval where data security is guaranteed against collusion among up to $X$ servers and the user's retrieval privacy is guaranteed against collusion among up to $T$ servers. Recently, researchers have constructed XSTPIR schemes through the theory of algebraic geometry codes and algebraic curves, with the aim of obtaining XSTPIR schemes that have higher maximum PIR rates for fixed field size and $X,T$ (the number of servers $N$ is not restricted). The mainstream approach is to employ curves of higher genus that have more rational points, evolving from rational curves to elliptic curves to hyperelliptic curves and, most recently, to Hermitian curves.\n  In this paper, we propose a different perspective: with the shared goal of constructing XSTPIR schemes with higher maximum PIR rates, we move beyond the mainstream approach of seeking curves with higher genus and more rational points. Instead, we aim to achieve this goal by enhancing the utilization efficiency of rational points on curves that have already been considered in previous work. By introducing a family of bases for the polynomial space $\\text{span}_{\\mathbb{F}_q}\\{1,x,\\dots,x^{k-1}\\}$ as an alternative to the Lagrange interpolation basis, we develop two new families of XSTPIR schemes based on rational curves and Hermitian curves, respectively. Parameter comparisons demonstrate that our schemes achieve superior performance. Specifically, our Hermitian-curve-based XSTPIR scheme provides the largest known maximum PIR rates when the field size $q^2\\geq 14^2$ and $X+T\\geq 4q$. Moreover, for any field size $q^2\\geq 28^2$ and $X+T\\geq 4$, our two XSTPIR schemes collectively provide the largest known maximum PIR rates."}
{"id": "2601.07725", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.07725", "abs": "https://arxiv.org/abs/2601.07725", "authors": ["Jessica Bariffi", "Drisana Bhatia", "Giuseppe Cotardo", "Violetta Weger"], "title": "Weak Composition Lattices and Ring-Linear Anticodes", "comment": null, "summary": "Lattices and partially ordered sets have played an increasingly important role in coding theory, providing combinatorial frameworks for studying structural and algebraic properties of error-correcting codes. Motivated by recent works connecting lattice theory, anticodes, and coding-theoretic invariants, we investigate ring-linear codes endowed with the Lee metric. We introduce and characterize optimal Lee-metric anticodes over the ring $\\mathbb{Z}/p^s\\mathbb{Z}$. We show that the family of such anticodes admits a natural partition into subtypes and forms a lattice under inclusion. We establish a bijection between this lattice and a lattice of weak compositions ordered by dominance. As an application, we use this correspondence to introduce new invariants for Lee-metric codes via an anticode approach."}
{"id": "2601.07797", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.07797", "abs": "https://arxiv.org/abs/2601.07797", "authors": ["Yiqi Chen", "Holger Boche", "Marc Geitz"], "title": "Lossy Source Coding with Broadcast Side Information", "comment": null, "summary": "This paper considers the source coding problem with broadcast side information. The side information is sent to two receivers through a noisy broadcast channel. We provide an outer bound of the rate--distortion--bandwidth (RDB) quadruples and achievable RDB quadruples when the helper uses a separation-based scheme. Some special cases with full characterization are also provided. We then compare the separation-based scheme with the uncoded scheme in the quadratic Gaussian case."}
{"id": "2601.06483", "categories": ["eess.SP", "cs.IT"], "pdf": "https://arxiv.org/pdf/2601.06483", "abs": "https://arxiv.org/abs/2601.06483", "authors": ["Özlem Tuğfe Demir", "Emil Björnson"], "title": "Joint Impact of ADC and Fronthaul Quantization in Cell-Free Massive MIMO-OFDM Uplink", "comment": "Presented at Asilomar Conference on Signals, Systems, and Computers, 2025, 5 pages, 2 figures", "summary": "In the uplink of a cell-free massive MIMO system, quantization affects performance in two key domains: the time-domain distortion introduced by finite-resolution analog-to-digital converters (ADCs) at the access points (APs), and the fronthaul quantization of signals sent to the central processing unit (CPU). Although quantizing twice may seem redundant, the ADC quantization in orthogonal frequency-division duplex (OFDM) systems appears in the time domain, and one must then convert to the frequency domain, where quantization can be applied only to the signals at active subcarriers. This reduces fronthaul load and avoids unnecessary distortion, since the ADC output spans all OFDM samples while only a subset of subcarriers carries useful information.\n  While both quantization effects have been extensively studied in narrowband systems, their joint impact in practical wideband OFDM-based cell-free massive MIMO remains largely unexplored. This paper addresses the gap by modeling the joint distortion and proposing a fronthaul strategy in which each AP processes the received signal to reduce quantization artifacts before transmission. We develop an efficient estimation algorithm that reconstructs the unquantized time-domain signal prior to fronthaul transmission and evaluate its effectiveness. The proposed design offers new insights for implementing efficient, quantization-aware uplink transmission in wideband cell-free architectures."}
{"id": "2601.06486", "categories": ["eess.SP", "cs.IT"], "pdf": "https://arxiv.org/pdf/2601.06486", "abs": "https://arxiv.org/abs/2601.06486", "authors": ["Özlem Tuğfe Demir", "Emil Björnson"], "title": "Cell-Free Massive MIMO with Hardware-Impaired Wireless Fronthaul", "comment": "Presented at Asilomar Conference on Signals, Systems, and Computers, 2025, 5 pages, 4 figures", "summary": "Cell-free massive MIMO (multiple-input multiple-output) enhances spectral and energy efficiency compared to conventional cellular networks by enabling joint transmission and reception across a large number of distributed access points (APs). Since these APs are envisioned to be low-cost and densely deployed, hardware impairments, stemming from non-ideal radio-frequency (RF) chains, are unavoidable. While existing studies primarily address hardware impairments on the access side, the impact of hardware impairments on the wireless fronthaul link has remained largely unexplored. In this work, we fill this important gap by introducing a novel amplify-and-forward (AF) based wireless fronthauling scheme tailored for cell-free massive MIMO. Focusing on the uplink, we develop an analytical framework that jointly models the hardware impairments at both the APs and the fronthaul transceivers, derives the resulting end-to-end distorted signal expression, and quantifies the individual contribution of each impairment to the spectral efficiency. Furthermore, we design distortion-aware linear combiners that optimally mitigate these effects. Numerical results demonstrate significant performance gains from distortion-aware processing and illustrate the potential of the proposed AF fronthauling scheme as a cost-effective enabler for future cell-free architectures."}
