<div id=toc></div>

# Table of Contents

- [cs.IT](#cs.IT) [Total: 3]
- [eess.SP](#eess.SP) [Total: 22]


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [1] [Information Capacity of EEG: Theoretical and Computational Limits of Recoverable Neural Information](https://arxiv.org/abs/2510.17841)
*Ishir Rao*

Main category: cs.IT

TL;DR: EEG的信息容量有限，每个样本仅能传递数十比特关于低维神经活动的信息，信息量在64-128个电极时达到饱和，且与信噪比呈对数关系增长。


<details>
  <summary>Details</summary>
Motivation: 量化脑电图(EEG)的信息容量，了解其从皮层源到头皮记录的信息传递能力，以确定EEG在推断大脑状态或思维内容方面的内在限制。

Method: 结合信息论和合成前向建模，使用高斯信道理论和经验模拟来估计皮层源与EEG记录之间的互信息。

Result: 头皮EEG每个样本仅传递数十比特关于低维神经活动的信息；信息在64-128个电极时饱和；线性解码器几乎能捕获所有可线性恢复的方差，但恢复的互信息远低于分析信道容量。

Conclusion: 测量物理特性（而非算法复杂性）是EEG信息容量的主要限制因素，这为从EEG推断大脑状态或思维内容的结构设定了内在上限。

Abstract: Electroencephalography (EEG) is widely used to study human brain dynamics,
yet its quantitative information capacity remains unclear. Here, we combine
information theory and synthetic forward modeling to estimate the mutual
information between latent cortical sources and EEG recordings. Using
Gaussian-channel theory and empirical simulations, we find that scalp EEG
conveys only tens of bits per sample about low-dimensional neural activity.
Information saturates with approximately 64-128 electrodes and scales
logarithmically with signal-to-noise ratio (SNR). Linear decoders capture
nearly all variance that is linearly recoverable, but the mutual information
they recover remains far below the analytic channel capacity, indicating that
measurement physics - not algorithmic complexity - is the dominant limitation.
These results outline the intrinsic ceiling on how much structure about brain
state or thought content can be inferred from EEG.

</details>


### [2] [Performance of Modified Fractional Frequency Reuse Algorithm in Random Ultra Dense Networks](https://arxiv.org/abs/2510.18440)
*Bach Hung Luu,Samuel Harry Gardner,Sinh Cong Lam,Trong Minh Hoang*

Main category: cs.IT

TL;DR: 提出了一种改进的分数频率复用算法，使用服务基站与第二近基站信号功率比来分类小区边缘用户和中心用户，通过提高边缘用户发射功率来改善其性能。


<details>
  <summary>Details</summary>
Motivation: 在5G及B5G高密度基站网络中，传统基于SINR或距离的频率复用算法存在局限，需要更有效的用户分类方法来缓解小区间干扰。

Method: 使用服务基站与第二近基站的信号功率比作为用户分类标准，当功率比低于预设阈值时，将用户分类为小区边缘用户并分配更高发射功率。

Result: 仿真结果表明，提高发射功率能改善小区边缘用户性能，但会降低典型用户性能；在障碍物密集环境中，频率复用算法能有效抑制小区间干扰。

Conclusion: 基于功率比的用户分类方法在密集障碍物环境中特别有效，能够通过频率复用算法显著抑制小区间干扰，提升网络性能。

Abstract: Mitigating intercell interference by employing fractional frequency reuse
algorithms is one of the important approaches to improving user performance in
5G and Beyond 5G cellular network systems, which typically have a high density
of Base Stations (BSs). While most frequency reuse algorithms are based on the
downlink Signal-to-Interference-plus-Noise Ratio (SINR) or the distance between
the user and its serving BS to classify Cell-Edge Users (CEUs) and Cell-Center
Users (CCUs), this paper discusses a modified algorithm that uses the power
ratio between the signal strengths from the serving BS and the second nearest
BS for user classification. Specifically, if the power ratio is below a
predefined threshold, the user is classified as a CEU and is served with higher
transmission power. Simulation results show that increasing transmission power
is necessary to enhance CEU performance, but it also degrades the performance
of typical users. The use of frequency reuse algorithms is particularly
feasible in environments with a high density of obstacles, where intercell
interference can be effectively suppressed.

</details>


### [3] [A Markov-Chain Characterization of Finite-State Dimension and a Generalization of Agafonov's Theorem](https://arxiv.org/abs/2510.18736)
*Laurent Bienvenu,Hugo Gimbert,Subin Pulari*

Main category: cs.IT

TL;DR: 本文扩展了有限状态维度的信息论特征，通过马尔可夫链模拟中的Kullback-Leibler散度来量化序列的信息率，并推广了Agafonov定理。


<details>
  <summary>Details</summary>
Motivation: 有限状态维度量化了无限序列中有限自动机感知的信息渐近率。传统上，Borel正规数具有最大有限状态维度，但需要将这一对应关系扩展到非正规数。

Method: 使用马尔可夫链模拟序列，通过条件Kullback-Leibler散度比较极限分布与平稳分布，从而特征化有限状态维度。

Result: 建立了有限状态维度与马尔可夫链模拟中条件Kullback-Leibler散度的定量关系，推广了Schnorr-Stimm定理。

Conclusion: 提供了有限状态维度的新信息论特征化，并证明了Agafonov定理的推广版本，建立了序列与其自动子序列有限状态维度之间的紧密定量关系。

Abstract: Finite-state dimension quantifies the asymptotic rate of information in an
infinite sequence as perceived by finite automata. For a fixed alphabet, the
infinite sequences that have maximal finite-state dimension are exactly those
that are Borel normal, i.e., in which all words of any given length appear with
the same frequency. A theorem of Schnorr and Stimm (1972) shows that a real
number is Borel normal if and only if, for every finite-state irreducible
Markov chain with fair transitions, when the chain is simulated using the
binary expansion of the given number, the empirical distribution of states
converges to its stationary distribution. In this paper we extend this
correspondence beyond normal numbers. We show that the finite-state dimension
of a sequence can be characterized in terms of the conditional Kullback-Leibler
divergence between the limiting distributions arising from the simulation of
Markov chains using the given sequence and their stationary distributions. This
provides a new information-theoretic characterization of finite-state dimension
which generalizes the Schnorr-Stimm result.
  As an application, we prove a generalization of Agafonov's theorem for normal
numbers. Agafonov's theorem states that a sequence is normal if and only if
every subsequence selected by a finite automaton is also normal. We extend this
to arbitrary sequences by establishing a tight quantitative relationship
between the finite-state dimension of a sequence and the finite-state
dimensions of its automatic subsequences.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [4] [Machine Learning-Based Performance Evaluation of a Solar-Powered Hydrogen Fuel Cell Hybrid in a Radio-Controlled Electric Vehicle](https://arxiv.org/abs/2510.17808)
*Amirhesam Aghanouri,Mohamed Sabry,Joshua Cherian Varughese,Cristina Olaverri-Monreal*

Main category: eess.SP

TL;DR: 该论文研究了镍氢电池与质子交换膜燃料电池混合动力系统在遥控车上的性能表现，通过机器学习方法分析运行数据，发现混合系统比纯电池系统具有更好的电压稳定性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 研究混合动力系统在小电动车上的应用潜力，评估其在真实工况下的性能表现，探索可再生能源在交通领域的应用可能性。

Method: 采用实验测试和数据分析相结合的方法，使用信号处理和机器学习技术（包括时间卷积网络）进行数据建模、异常检测和电压行为预测。

Result: 混合系统比纯电池系统电压稳定性更好，故障更少；机器学习能高精度识别油门等级；系统展示了离网可再生氢能应用的潜力。

Conclusion: 质子交换膜燃料电池与镍氢电池的集成显著提升了小型电动车的电气性能和可靠性，为扩展到大型车辆提供了基准参考。

Abstract: This paper presents an experimental investigation and performance evaluation
of a hybrid electric radio-controlled car powered by a Nickel-Metal Hydride
battery combined with a renewable Proton Exchange Membrane Fuel Cell system.
The study evaluates the performance of the system under various load-carrying
scenarios and varying environmental conditions, simulating real-world operating
conditions including throttle operation. In order to build a predictive model,
gather operational insights, and detect anomalies, data-driven analyses using
signal processing and modern machine learning techniques were employed.
Specifically, machine learning techniques were used to distinguish throttle
levels with high precision based on the operational data. Anomaly and change
point detection methods enhanced voltage stability, resulting in fewer critical
faults in the hybrid system compared to battery-only operation. Temporal
Convolutional Networks were effectively employed to predict voltage behavior,
demonstrating potential for use in planning the locations of fueling or
charging stations. Moreover, integration with a solar-powered electrolyzer
confirmed the system's potential for off-grid, renewable hydrogen use. The
results indicate that integrating a Proton Exchange Membrane Fuel Cell with
Nickel-Metal Hydride batteries significantly improves electrical performance
and reliability for small electric vehicles, and these findings can be a
potential baseline for scaling up to larger vehicles.

</details>


### [5] [In-Process Monitoring of Gear Power Honing Using Vibration Signal Analysis and Machine Learning](https://arxiv.org/abs/2510.17809)
*Massimo Capurso,Luciano Afferrante*

Main category: eess.SP

TL;DR: 提出基于振动信号分析和机器学习的齿轮强力珩磨过程监控框架，使用三种子空间学习方法进行特征提取，结合SVM分类器实现高达100%的分类准确率。


<details>
  <summary>Details</summary>
Motivation: 传统质量控制方法无法捕捉瞬态加工异常和实时缺陷检测，无法满足现代齿轮制造对NVH性能的严格要求。

Method: 通过加速度计连续采集数据，使用时频信号分析，比较三种子空间学习方法（PCA、PCA+LDA、R-UMLDA）进行特征提取，然后使用SVM分类器预测四个齿轮质量类别。

Result: 在工业环境中实现高达100%的分类准确率，提供可解释的频谱特征与工艺动态相关。

Conclusion: 该框架能够实现实时监控和预测性维护，为齿轮制造过程质量控制提供了有效的解决方案。

Abstract: In modern gear manufacturing, stringent Noise, Vibration, and Harshness (NVH)
requirements demand high-precision finishing operations such as power honing.
Conventional quality control strategies rely on post-process inspections and
Statistical Process Control (SPC), which fail to capture transient machining
anomalies and cannot ensure real-time defect detection. This study proposes a
novel, data-driven framework for in-process monitoring of gear power honing
using vibration signal analysis and machine learning. Our proposed methodology
involves continuous data acquisition via accelerometers, followed by
time-frequency signal analysis. We investigate and compare the efficacy of
three subspace learning methods for features extraction: (1) Principal
Component Analysis (PCA) for dimensionality reduction; (2) a two-stage
framework combining PCA with Linear Discriminant Analysis (LDA) for enhanced
class separation; and (3) Uncorrelated Multilinear Discriminant Analysis with
Regularization (R-UMLDA), adapted for tensor data, which enforces feature
decorrelation and includes regularization for small sample sizes. These
extracted features are then fed into a Support Vector Machine (SVM) classifier
to predict four distinct gear quality categories, established through rigorous
geometrical inspections and test bench results of assembled gearboxes. The
models are trained and validated on an experimental dataset collected in an
industrial context during gear power-honing operations, with gears classified
into four different quality categories. The proposed framework achieves high
classification accuracy (up to 100%) in an industrial setting. The approach
offers interpretable spectral features that correlate with process dynamics,
enabling practical integration into real-time monitoring and predictive
maintenance systems.

</details>


### [6] [Exploring Complexity Changes in Diseased ECG Signals for Enhanced Classification](https://arxiv.org/abs/2510.17810)
*Camilo Quiceno Quintero,Sandip Varkey George*

Main category: eess.SP

TL;DR: 使用非线性时间序列分析研究心电图复杂性如何随心脏病理变化，通过PTB-XL数据集提取非线性指标，发现疾病与健康个体间存在显著差异，并将这些复杂性量化指标整合到机器学习模型中提高了分类准确性。


<details>
  <summary>Details</summary>
Motivation: 心脏的复杂动态反映在其电活动中，通过心电图捕捉。本研究旨在理解心电图复杂性如何随心脏病理变化，探索非线性指标在心脏疾病诊断中的价值。

Method: 使用PTB-XL数据集，从导联II心电图提取非线性指标，并使用斯皮尔曼相关性和互信息计算跨通道指标（导联II、V2、AVL）。

Result: 几乎所有指标在疾病与健康个体间以及5个诊断超类间均发现显著差异（p<0.001）。将复杂性量化指标整合到机器学习模型中，AUC从基线0.86提高到非线性指标0.87，包含跨时间序列指标后达到0.90。

Conclusion: 非线性时间序列分析能够有效捕捉心电图复杂性变化，这些复杂性指标显著提高了心脏疾病分类的准确性，为心脏病理诊断提供了有价值的工具。

Abstract: The complex dynamics of the heart are reflected in its electrical activity,
captured through electrocardiograms (ECGs). In this study we use nonlinear time
series analysis to understand how ECG complexity varies with cardiac pathology.
Using the large PTB-XL dataset, we extracted nonlinear measures from lead II
ECGs, and cross-channel metrics (leads II, V2, AVL) using Spearman correlations
and mutual information. Significant differences between diseased and healthy
individuals were found in almost all measures between healthy and diseased
classes, and between 5 diagnostic superclasses ($p<.001$). Moreover,
incorporating these complexity quantifiers into machine learning models
substantially improved classification accuracy measured using area under the
ROC curve (AUC) from 0.86 (baseline) to 0.87 (nonlinear measures) and 0.90
(including cross-time series metrics).

</details>


### [7] [Channel Modeling of Satellite-to-Underwater Laser Communication Links: An Analytical-Monte Carlo Hybrid Approach](https://arxiv.org/abs/2510.17811)
*Zhixing Wang,Renzhi Yuan,Haifeng Yao,Chuang Yang,Mugen Peng*

Main category: eess.SP

TL;DR: 提出了一种综合的卫星到水下激光通信信道模型，采用解析-蒙特卡洛混合方法，同时考虑粒子和湍流效应，分析了不同环境条件下的通信性能。


<details>
  <summary>Details</summary>
Motivation: 现有卫星到水下激光通信信道模型要么关注分离信道，要么忽略了粒子和湍流对激光传播的联合影响，需要建立更全面的信道模型。

Method: 采用解析-蒙特卡洛混合方法：基于扩展惠更斯-菲涅耳原理获得激光束通过湍流大气后的强度分布；推导光子通过水-气界面后传播方向的闭式概率密度函数；使用蒙特卡洛方法模拟水下链路并获取接收平面功率分布。

Result: 数值结果表明，水下粒子浓度对通信性能的影响远大于大气湍流和水下湍流；增加水-气界面风速不会显著恶化通信性能。

Conclusion: 建立了综合考虑粒子和湍流效应的综合StULC信道模型，发现水下粒子浓度是影响通信性能的主要因素，而界面风速影响较小。

Abstract: Channel modeling for satellite-to-underwater laser communication (StULC)
links remains challenging due to long distances and the diversity of the
channel constituents. The StULC channel is typically segmented into three
isolated channels: the atmospheric channel, the air-water interface channel,
and the underwater channel. Previous studies involving StULC channel modeling
either focused on separated channels or neglected the combined effects of
particles and turbulence on laser propagation. In this paper, we established a
comprehensive StULC channel model by an analytical-Monte Carlo hybrid approach,
taking into account the effects of both particles and turbulence. We first
obtained the intensity distribution of the transmitted laser beam after passing
through the turbulent atmosphere based on the extended Huygens-Fresnel
principle. Then we derived a closed-form probability density function of the
photon propagating direction after passing through the air-water interface,
which greatly simplified the modeling of StULC links. At last, we employed a
Monte Carlo method to model the underwater links and obtained the power
distribution at the receiving plane. Based on the proposed StULC channel model,
we analyzed the bit error rate and the outage probability under different
environmental conditions. Numerical results demonstrated that, the influence of
underwater particle concentration on the communication performance is much
pronounced than those of both the atmospheric turbulence and the underwater
turbulence. Notably, increasing the wind speed at the air-water interface does
not significantly worsen the communication performance of the StULC links.

</details>


### [8] [Cross-Domain Multi-Person Human Activity Recognition via Near-Field Wi-Fi Sensing](https://arxiv.org/abs/2510.17816)
*Xin Li,Jingzhi Hu,Yinghui He,Hongbo Wang,Jin Gan,Jun Luo*

Main category: eess.SP

TL;DR: WiAnchor是一个用于Wi-Fi多用户活动识别的跨域适应训练框架，通过锚点匹配机制处理不完整活动类别，在缺少某些类别的情况下仍能实现超过90%的跨域准确率。


<details>
  <summary>Details</summary>
Motivation: Wi-Fi活动识别在多用户场景下受限于空间分辨率，而利用近场效应建立专用感知链路时，由于用户特定特征和信号不规则模式，神经网络模型需要跨域微调，这在某些类别不可用时尤其困难。

Method: 三阶段框架：预训练阶段扩大类间特征边界增强活动可分性；微调阶段创新锚点匹配机制进行跨域适应，基于不完整活动类别过滤用户特定干扰；最后基于输入样本与锚点的特征相似性进一步改进识别。

Result: 构建了综合数据集进行彻底评估，在活动类别缺失的情况下实现了超过90%的跨域准确率。

Conclusion: WiAnchor框架有效解决了Wi-Fi多用户活动识别中跨域适应和不完整类别的问题，通过锚点匹配机制显著提升了识别性能。

Abstract: Wi-Fi-based human activity recognition (HAR) provides substantial convenience
and has emerged as a thriving research field, yet the coarse spatial resolution
inherent to Wi-Fi significantly hinders its ability to distinguish multiple
subjects. By exploiting the near-field domination effect, establishing a
dedicated sensing link for each subject through their personal Wi-Fi device
offers a promising solution for multi-person HAR under native traffic. However,
due to the subject-specific characteristics and irregular patterns of
near-field signals, HAR neural network models require fine-tuning (FT) for
cross-domain adaptation, which becomes particularly challenging with certain
categories unavailable. In this paper, we propose WiAnchor, a novel training
framework for efficient cross-domain adaptation in the presence of incomplete
activity categories. This framework processes Wi-Fi signals embedded with
irregular time information in three steps: during pre-training, we enlarge
inter-class feature margins to enhance the separability of activities; in the
FT stage, we innovate an anchor matching mechanism for cross-domain adaptation,
filtering subject-specific interference informed by incomplete activity
categories, rather than attempting to extract complete features from them;
finally, the recognition of input samples is further improved based on their
feature-level similarity with anchors. We construct a comprehensive dataset to
thoroughly evaluate WiAnchor, achieving over 90% cross-domain accuracy with
absent activity categories.

</details>


### [9] [Single-Snapshot Gridless 2D-DoA Estimation for UCAs: A Joint Optimization Approach](https://arxiv.org/abs/2510.17818)
*Salar Nouri*

Main category: eess.SP

TL;DR: 提出了一种用于均匀圆形阵列单快照数据的无网格二维波达方向估计算法，通过联合估计流形变换矩阵和源方位-仰角对，避免了半定规划的计算负担。


<details>
  <summary>Details</summary>
Motivation: 传统无网格方法在单快照场景下由于计算成本过高或缺乏鲁棒性而失效，需要一种能够克服这些限制的新方法。

Method: 使用不精确增广拉格朗日方法(iALM)在统一优化问题中联合估计流形变换矩阵和源方位-仰角对，避免半定规划。

Result: 仿真结果表明该iALM框架能够提供鲁棒且高分辨率的无网格2D-DOA估计。

Conclusion: 该方法特别适用于具有挑战性的单快照阵列信号处理应用，证明了其有效性。

Abstract: This paper tackles the challenging problem of gridless two-dimensional (2D)
direction-of-arrival (DOA) estimation for a uniform circular array (UCA) from a
single snapshot of data. Conventional gridless methods often fail in this
scenario due to prohibitive computational costs or a lack of robustness. We
propose a novel framework that overcomes these limitations by jointly
estimating a manifold transformation matrix and the source azimuth-elevation
pairs within a single, unified optimization problem. This problem is solved
efficiently using an inexact Augmented Lagrangian Method (iALM), which
completely circumvents the need for semidefinite programming. By unifying the
objectives of data fidelity and transformation robustness, our approach is
uniquely suited for the demanding single-snapshot case. Simulation results
confirm that the proposed iALM framework provides robust and high-resolution,
gridless 2D-DOA estimates, establishing its efficacy for challenging array
signal processing applications.

</details>


### [10] [CLARAE: Clarity Preserving Reconstruction AutoEncoder for Denoising and Rhythm Classification of Intracardiac Electrograms](https://arxiv.org/abs/2510.17821)
*Long Lin,Pablo Peiro-Corbacho,Pablo Ávila,Alejandro Carta-Bergaz,Ángel Arenal,Gonzalo R. Ríos-Muñoz,Carlos Sevilla-Salcedo*

Main category: eess.SP

TL;DR: CLARAE是一种用于心房电图的一维编码器-解码器，能够实现高保真重建和紧凑的64维潜在表示，在心律分类和去噪任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 心房电图常受噪声污染且维度高，限制了实时分析能力，需要开发既能降噪又能生成紧凑表示的模型。

Method: 采用一维编码器-解码器架构，通过池化下采样、混合插值-卷积上采样路径和有界潜在空间三个原则来保护波形形态。

Result: 在49.5万多个EGM片段上测试，所有心律类型的F1分数均超过0.97，潜在空间按心律清晰聚类，去噪性能始终位居前列。

Conclusion: CLARAE结合了稳健的去噪能力和紧凑的判别性表示，为心律鉴别、信号质量评估和实时映射等临床工作流程提供了实用基础。

Abstract: Intracavitary atrial electrograms (EGMs) provide high-resolution insights
into cardiac electrophysiology but are often contaminated by noise and remain
high-dimensional, limiting real-time analysis. We introduce CLARAE
(CLArity-preserving Reconstruction AutoEncoder), a one-dimensional
encoder--decoder designed for atrial EGMs, which achieves both high-fidelity
reconstruction and a compact 64-dimensional latent representation. CLARAE is
designed to preserve waveform morphology, mitigate reconstruction artifacts,
and produce interpretable embeddings through three principles: downsampling
with pooling, a hybrid interpolation--convolution upsampling path, and a
bounded latent space.
  We evaluated CLARAE on 495,731 EGM segments (unipolar and bipolar) from 29
patients across three rhythm types (AF, SR300, SR600). Performance was
benchmarked against six state-of-the-art autoencoders using reconstruction
metrics, rhythm classification, and robustness across signal-to-noise ratios
from -5 to 15 dB. In downstream rhythm classification, CLARAE achieved
F1-scores above 0.97 for all rhythm types, and its latent space showed clear
clustering by rhythm. In denoising tasks, it consistently ranked among the top
performers for both unipolar and bipolar signals.
  In order to promote reproducibility and enhance accessibility, we offer an
interactive web-based application. This platform enables users to explore
pre-trained CLARAE models, visualize the reconstructions, and compute metrics
in real time. Overall, CLARAE combines robust denoising with compact,
discriminative representations, offering a practical foundation for clinical
workflows such as rhythm discrimination, signal quality assessment, and
real-time mapping.

</details>


### [11] [Covariance Matrix Construction with Preprocessing-Based Spatial Sampling for Robust Adaptive Beamforming](https://arxiv.org/abs/2510.17823)
*Saeed Mohammadzadeh,Rodrigo C. de Lamare,Yuriy Zakharov*

Main category: eess.SP

TL;DR: 提出一种高效的鲁棒自适应波束形成技术，通过方向估计和协方差矩阵重构来处理导向向量失配和数据协方差矩阵重建问题。


<details>
  <summary>Details</summary>
Motivation: 解决导向向量估计失配和数据协方差矩阵重建问题，提高波束形成在干扰环境下的性能。

Method: 使用广义线性组合算法重构干扰加噪声协方差矩阵，基于预处理空间采样策略，用样本协方差矩阵替代预处理矩阵，并采用功率谱采样策略。

Result: 仿真结果表明该方法相比现有方法具有更好的性能表现。

Conclusion: 提出的PPBSS技术能有效处理导向向量失配和协方差矩阵重建问题，在计算成本和性能方面均优于现有方法。

Abstract: This work proposes an efficient, robust adaptive beamforming technique to
deal with steering vector (SV) estimation mismatches and data covariance matrix
reconstruction problems. In particular, the direction-of-arrival(DoA) of
interfering sources is estimated with available snapshots in which the angular
sectors of the interfering signals are computed adaptively. Then, we utilize
the well-known general linear combination algorithm to reconstruct the
interference-plus-noise covariance (IPNC) matrix using preprocessing-based
spatial sampling (PPBSS). We demonstrate that the preprocessing matrix can be
replaced by the sample covariance matrix (SCM) in the shrinkage method. A power
spectrum sampling strategy is then devised based on a preprocessing matrix
computed with the estimated angular sectors' information. Moreover, the
covariance matrix for the signal is formed for the angular sector of the
signal-of-interest (SOI), which allows for calculating an SV for the SOI using
the power method. An analysis of the array beampattern in the proposed PPBSS
technique is carried out, and a study of the computational cost of competing
approaches is conducted. Simulation results show the proposed method's
effectiveness compared to existing approaches.

</details>


### [12] [Carbon-Aware Orchestration of Integrated Satellite Aerial Terrestrial Networks via Digital Twin](https://arxiv.org/abs/2510.17825)
*Shumaila Javaid,Nasir Saeed*

Main category: eess.SP

TL;DR: 提出了一种基于数字孪生技术的碳感知编排框架，用于集成卫星-航空-地面网络，通过多时间尺度的PDCA循环和特定控制策略，显著降低了碳排放。


<details>
  <summary>Details</summary>
Motivation: 随着6G网络中ISATN的大规模部署，传统网络面临着不可持续的能源消耗和碳排放问题，需要开发碳感知的编排框架来应对这一挑战。

Method: 采用数字孪生技术，建立以gCO₂/bit为主要可持续性指标的多时间尺度PDCA循环，结合日前预测和实时自适应优化，利用碳感知切换、UAV占空比控制和可再生能源感知边缘放置等控制策略。

Result: 使用真实碳强度数据的仿真结果显示，相比仅考虑QoS的编排，gCO₂/bit降低了29%，同时提高了可再生能源利用率和在不利事件下的弹性。

Conclusion: 该碳感知编排框架有效解决了ISATN的可持续性问题，在保证服务质量的同时显著降低了碳排放，为6G网络的绿色部署提供了可行方案。

Abstract: Integrated Satellite Aerial Terrestrial Networks (ISATNs) are envisioned as
key enablers of 6G, providing global connectivity for applications such as
autonomous transportation, Industrial IoT, and disaster response. Their
large-scale deployment, however, risks unsustainable energy use and carbon
emissions. This work advances prior energy-aware studies by proposing a
carbon-aware orchestration framework for ISATNs that leverages Digital Twin
(DT) technology. The framework adopts grams of CO$_2$-equivalent per bit
(gCO$_2$/bit) as a primary sustainability metric and implements a multi
timescale Plan Do Check Act (PDCA) loop that combines day-ahead forecasting
with real-time adaptive optimization. ISATN-specific control knobs, including
carbon-aware handovers, UAV duty cycling, and renewable-aware edge placement,
are exploited to reduce emissions. Simulation results with real carbon
intensity data show up to 29\% lower gCO$_2$/bit than QoS-only orchestration,
while improving renewable utilization and resilience under adverse events.

</details>


### [13] [Synthetic EEG Generation using Diffusion Models for Motor Imagery Tasks](https://arxiv.org/abs/2510.17832)
*Henrique de Lima Alexandre,Clodoaldo Aparecido de Moraes Lima*

Main category: eess.SP

TL;DR: 使用扩散概率模型生成合成EEG信号，以解决脑机接口中EEG数据稀缺问题，生成的数据在分类任务中达到95%以上准确率。


<details>
  <summary>Details</summary>
Motivation: EEG数据采集面临传感器成本高、采集时间长和个体间差异大的挑战，需要解决数据稀缺问题来改善脑机接口应用。

Method: 预处理真实EEG数据，训练扩散模型从噪声中重建EEG通道，使用KNN、CNN和U-Net分类器评估生成信号质量。

Result: 生成数据在分类任务中准确率超过95%，与真实信号具有低均方误差和高相关性。

Conclusion: 扩散模型生成的合成EEG信号能有效补充数据集，改善脑机接口中的分类性能，解决数据稀缺问题。

Abstract: Electroencephalography (EEG) is a widely used, non-invasive method for
capturing brain activity, and is particularly relevant for applications in
Brain-Computer Interfaces (BCI). However, collecting high-quality EEG data
remains a major challenge due to sensor costs, acquisition time, and
inter-subject variability. To address these limitations, this study proposes a
methodology for generating synthetic EEG signals associated with motor imagery
brain tasks using Diffusion Probabilistic Models (DDPM). The approach involves
preprocessing real EEG data, training a diffusion model to reconstruct EEG
channels from noise, and evaluating the quality of the generated signals
through both signal-level and task-level metrics. For validation, we employed
classifiers such as K-Nearest Neighbors (KNN), Convolutional Neural Networks
(CNN), and U-Net to compare the performance of synthetic data against real data
in classification tasks. The generated data achieved classification accuracies
above 95%, with low mean squared error and high correlation with real signals.
  Our results demonstrate that synthetic EEG signals produced by diffusion
models can effectively complement datasets, improving classification
performance in EEG-based BCIs and addressing data scarcity.

</details>


### [14] [Two Phases Leakage Detection Strategy Supported by DMAs](https://arxiv.org/abs/2510.17836)
*G. Messa,G. Acconciaioco,S. Ripani,L. Bozzelli,A. Simone,O. Giustolisi*

Main category: eess.SP

TL;DR: 提出了一种基于模型的两阶段漏水检测策略，包括DMA识别和管道预定位阶段，使用AMSI指标减少误报，并通过压力计优化布置提高检测性能。


<details>
  <summary>Details</summary>
Motivation: 为水务公司提供一种能够识别DMA级别异常并以最小检查成本定位漏水的有效策略，解决传统方法中误报率高和定位效率低的问题。

Method: 采用两阶段模型：第一阶段识别发生漏水的DMA区域，第二阶段在识别出的DMA内预定位漏水管道序列。使用AMSI指标检测异常，并提出压力计位置优化策略。

Result: 该策略在阿普利亚地区两个真实供水管网中进行了验证，能够有效限制DMA识别阶段的误报，并提供需检查的管道序列，降低检查成本。

Conclusion: 提出的两阶段漏水检测策略结合AMSI指标和压力计优化布置，为水务公司提供了一种高效、低成本的漏水检测和定位解决方案。

Abstract: The present work proposes a novel two phases model-based strategy for leakage
detection. The two phases are: the identification of the district metering area
(DMA) and the pipe pre-localization into the identified DMA. The strategy is
based on detecting and pre-localizing the punctual leakage as anomaly with
respect to the normal working conditions. A further novelty is the fact that
the pre-localization phase returns the sequence of pipes to inspect, which
makes the strategy attractive for water utilities, whose aim is to identify the
anomaly at DMA level and, successively, to localize it with the minimum
inspection cost. Furthermore, a random database is useful to test the
performance of the strategy with respect to the configuration of DMAs and the
pressure metering system. Consequently, a novel strategy to design the location
of pressure meters is also proposed. It is demonstrated that the entire
strategy limits false positives during the DMA identification phase by using
the recently proposed index named Asset Management Support Indicator (AMSI).
AMSI is invariant with respect to the deterioration, i.e., it is sensitive to
its increase causing punctual leakage. The strategy is studied and discussed
using two real Apulian WDNs managed by Acquedotto Pugliese.

</details>


### [15] [Majority Vote Compressed Sensing](https://arxiv.org/abs/2510.18008)
*Henrik Hellström,Jiwon Jeong,Ayfer Özgür,Viktoria Fodor,Carlo Fischione*

Main category: eess.SP

TL;DR: 提出了一种基于多数投票空中计算和1位压缩感知的非相干空中计算方案，利用数据稀疏性在更少信道使用次数下实现高维数据向量聚合。


<details>
  <summary>Details</summary>
Motivation: 传统非相干空中计算需要超过d次信道使用来计算函数，而如果数据向量是稀疏的，可以利用稀疏性显著降低通信成本。

Method: 使用随机变换传输数据向量的低维投影，通过多数投票AirComp方案估计聚合投影的符号位向量，然后在接收端利用1位压缩感知恢复原始高维聚合数据。

Result: 提出的MVCS方案在T=O(knlog(d)/ε²)次信道使用下能以ℓ₂范数误差ε估计聚合数据向量∑ᵢxᵢ。

Conclusion: MVCS方案相比现有技术具有显著优势，可应用于直方图估计和分布式机器学习等场景。

Abstract: We consider the problem of non-coherent over-the-air computation (AirComp),
where $n$ devices carry high-dimensional data vectors
$\mathbf{x}_i\in\mathbb{R}^d$ of sparsity $\lVert\mathbf{x}_i\rVert_0\leq k$
whose sum has to be computed at a receiver. Previous results on non-coherent
AirComp require more than $d$ channel uses to compute functions of
$\mathbf{x}_i$, where the extra redundancy is used to combat non-coherent
signal aggregation. However, if the data vectors are sparse, sparsity can be
exploited to offer significantly cheaper communication. In this paper, we
propose to use random transforms to transmit lower-dimensional projections
$\mathbf{s}_i\in\mathbb{R}^T$ of the data vectors. These projected vectors are
communicated to the receiver using a majority vote (MV)-AirComp scheme, which
estimates the bit-vector corresponding to the signs of the aggregated
projections, i.e., $\mathbf{y} = \text{sign}(\sum_i\mathbf{s}_i)$. By
leveraging 1-bit compressed sensing (1bCS) at the receiver, the real-valued and
high-dimensional aggregate $\sum_i\mathbf{x}_i$ can be recovered from
$\mathbf{y}$. We prove analytically that the proposed MVCS scheme estimates the
aggregated data vector $\sum_i \mathbf{x}_i$ with $\ell_2$-norm error
$\epsilon$ in $T=\mathcal{O}(kn\log(d)/\epsilon^2)$ channel uses. Moreover, we
specify algorithms that leverage MVCS for histogram estimation and distributed
machine learning. Finally, we provide numerical evaluations that reveal the
advantage of MVCS compared to the state-of-the-art.

</details>


### [16] [MCANet: A Coherent Multimodal Collaborative Attention Network for Advanced Modulation Recognition in Adverse Noisy Environments](https://arxiv.org/abs/2510.18336)
*Wangye Jiang,Haoming Yang,Xinyu Lu,Mingyuan Wang,Huimei Sun,Jingya Zhang*

Main category: eess.SP

TL;DR: 提出MCANet多模态深度学习框架，通过精细化特征提取和全局建模，在低信噪比条件下实现优于主流AMR模型的自动调制识别性能。


<details>
  <summary>Details</summary>
Motivation: 传统自动调制识别方法在复杂噪声环境特别是低信噪比条件下表现不佳，需要更鲁棒的解决方案来提高频谱效率。

Method: 采用多模态协作注意力网络(MCANet)，结合精细化特征提取和全局建模来支持融合策略。

Result: 在多个基准数据集上的实验结果表明，MCANet优于主流AMR模型，在低信噪比条件下具有更好的鲁棒性。

Conclusion: MCANet通过多模态深度学习框架有效解决了复杂噪声环境下的自动调制识别挑战，特别是在低信噪比条件下表现出色。

Abstract: As wireless communication systems evolve, automatic modulation recognition
(AMR) plays a key role in improving spectrum efficiency, especially in
cognitive radio systems. Traditional AMR methods face challenges in complex,
noisy environments, particularly in low signal-to-noise ratio (SNR) conditions.
This paper introduces MCANet (Multimodal Collaborative Attention Network), a
multimodal deep learning framework designed to address these challenges. MCANet
employs refined feature extraction and global modeling to support its fusion
strategy.Experimental results across multiple benchmark datasets show that
MCANet outperforms mainstream AMR models, offering better robustness in low-SNR
conditions.

</details>


### [17] [AWSPNet: Attention-based Dual-Tree Wavelet Scattering Prototypical Network for MIMO Radar Target Recognition and Jamming Suppression](https://arxiv.org/abs/2510.18422)
*Yizhen Jia,Siyao Xiao,Wenkai Jia,Hui Chen,Wen-Qin Wang*

Main category: eess.SP

TL;DR: 提出基于注意力机制的双树小波散射原型网络(AWSPNet)，用于雷达目标识别和干扰抑制，在低信噪比环境下实现90.45%的准确率。


<details>
  <summary>Details</summary>
Motivation: 数字射频存储器电子对抗技术的威胁日益增加，产生大量欺骗性虚假目标，淹没雷达处理能力并掩盖真实目标，需要在低信噪比环境下鲁棒地区分真实目标和复杂干扰信号。

Method: 使用双树复小波变换提取对噪声和信号平移具有鲁棒性的特征，通过注意力机制和预训练骨干网络进一步精炼特征，采用监督对比学习策略解决标记数据有限的问题，原型网络进行分类。

Result: 在-6dB信噪比下达到90.45%的准确率，通过t-SNE可视化提供网络内部工作机制的物理解释，结合时域滑动窗口方法实现完整的干扰识别和抑制算法。

Conclusion: AWSPNet在复杂电磁环境中具有实际应用潜力，能够有效识别并抑制各种类型的干扰信号。

Abstract: The increasing of digital radio frequency memory based electronic
countermeasures poses a significant threat to the survivability and
effectiveness of radar systems. These jammers can generate a multitude of
deceptive false targets, overwhelming the radar's processing capabilities and
masking targets. Consequently, the ability to robustly discriminate between
true targets and complex jamming signals, especially in low signal-to-noise
ratio (SNR) environments, is of importance. This paper introduces the
attention-based dual-tree wavelet scattering prototypical network (AWSPNet), a
deep learning framework designed for simultaneous radar target recognition and
jamming suppression. The core of AWSPNet is the encoder that leverages the
dual-tree complex wavelet transform to extract features that are inherently
robust to noise and signal translations. These features are further refined by
an attention mechanism and a pre-trained backbone network. To address the
challenge of limited labeled data and enhance generalization, we employ a
supervised contrastive learning strategy during the training phase. The
classification is performed by a prototypical network, which is particularly
effective in few-shot learning scenarios, enabling rapid adaptation to new
signal types. We demonstrate the efficacy of our approach through extensive
experiments. The results show that AWSPNet achieves 90.45\% accuracy at -6 dB
SNR. Furthermore, we provide a physical interpretation of the network's inner
workings through t-SNE visualizations, which analyze the feature separability
at different stages of the model. Finally, by integrating AWSPNet with a
time-domain sliding window approach, we present a complete algorithm capable of
not only identifying but also effectively suppressing various types of jamming,
thereby validating its potential for practical application in complex
electromagnetic environments.

</details>


### [18] [Microsecond Federated SVD on Grassmann Manifold for Real-time IoT Intrusion Detection](https://arxiv.org/abs/2510.18501)
*Tung-Anh Nguyen,Van-Phuc Bui,Shashi Raj Pandey,Kim Hue Ta,Nguyen H. Tran,Petar Popovski*

Main category: eess.SP

TL;DR: FedSVD是一个用于物联网网络实时异常检测的无监督联邦学习框架，使用奇异值分解和Grassmann流形优化，能在低功耗设备上高效运行。


<details>
  <summary>Details</summary>
Motivation: 物联网网络需要实时异常检测，但传统方法依赖标记数据或集中式数据共享，不适合资源受限的设备和隐私保护需求。

Method: 基于奇异值分解和Grassmann流形优化的无监督联邦学习，不依赖标记数据或集中数据共享，专为低功耗设备设计。

Result: FedSVD性能与深度学习基线相当，同时推理延迟降低10倍以上，通信开销和计算成本显著减少。

Conclusion: FedSVD是适用于延迟敏感物联网应用的高效异常检测解决方案，在保持准确性的同时大幅提升效率。

Abstract: This paper introduces FedSVD, a novel unsupervised federated learning
framework for real-time anomaly detection in IoT networks. By leveraging
Singular Value Decomposition (SVD) and optimization on the Grassmann manifolds,
FedSVD enables accurate detection of both known and unknown intrusions without
relying on labeled data or centralized data sharing. Tailored for deployment on
low-power devices like the NVIDIA Jetson AGX Orin, the proposed method
significantly reduces communication overhead and computational cost.
Experimental results show that FedSVD achieves performance comparable to deep
learning baselines while reducing inference latency by over 10x, making it
suitable for latency-sensitive IoT applications.

</details>


### [19] [Channel-Aware Vector Quantization for Robust Semantic Communication on Discrete Channels](https://arxiv.org/abs/2510.18604)
*Zian Meng,Qiang Li,Wenqian Tang,Mingdie Yan,Xiaohu Ge*

Main category: eess.SP

TL;DR: 提出了一种通道感知向量量化算法(CAVQ)，在联合源信道编码框架(VQJSCC)中实现离散语义传输，通过集成信道状态信息到量化过程来提升鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的基于深度学习的语义通信大多依赖模拟或半数字传输，与现代数字通信基础设施不兼容。虽然最近研究使用向量量化实现离散语义传输，但现有方法在码本优化时忽略了信道状态信息，导致鲁棒性不足。

Method: 在离散无记忆信道中建立VQJSCC框架，语义特征被离散化并直接映射到调制星座符号。CAVQ将信道转移概率集成到量化过程中，使易混淆符号与语义相似的码字对齐。引入多码本对齐机制处理码本顺序与调制顺序不匹配问题。

Result: 实验结果表明VQJSCC有效缓解了数字悬崖效应，在各种调制方案下实现了优越的重建质量，在鲁棒性和效率方面均优于最先进的数字语义通信基线方法。

Conclusion: 所提出的通道感知向量量化方法能够显著提升离散语义通信系统的性能，为与现代数字通信基础设施兼容的语义通信提供了有效解决方案。

Abstract: Deep learning-based semantic communication has largely relied on analog or
semi-digital transmission, which limits compatibility with modern digital
communication infrastructures. Recent studies have employed vector quantization
(VQ) to enable discrete semantic transmission, yet existing methods neglect
channel state information during codebook optimization, leading to suboptimal
robustness. To bridge this gap, we propose a channel-aware vector quantization
(CAVQ) algorithm within a joint source-channel coding (JSCC) framework, termed
VQJSCC, established on a discrete memoryless channel. In this framework,
semantic features are discretized and directly mapped to modulation
constellation symbols, while CAVQ integrates channel transition probabilities
into the quantization process, aligning easily confused symbols with
semantically similar codewords. A multi-codebook alignment mechanism is further
introduced to handle mismatches between codebook order and modulation order by
decomposing the transmission stream into multiple independently optimized
subchannels. Experimental results demonstrate that VQJSCC effectively mitigates
the digital cliff effect, achieves superior reconstruction quality across
various modulation schemes, and outperforms state-of-the-art digital semantic
communication baselines in both robustness and efficiency.

</details>


### [20] [Delay Management Using Packet Fragmentation in Wireless Industrial Automation Systems](https://arxiv.org/abs/2510.18646)
*Anwar Ahmed Khan,Shama Siddiqui,Indrakshi Dey*

Main category: eess.SP

TL;DR: 比较FROG-MAC与FPS-MAC在工业自动化无线网络中的性能，FROG-MAC在能效和延迟方面表现更优。


<details>
  <summary>Details</summary>
Motivation: 工业自动化应用对延迟管理有严格要求，需要高效的MAC方案来保证关键数据的及时传输，特别是在异构数据环境中。

Method: 使用Contiki作为仿真平台，采用单跳星型拓扑模拟工业环境，比较FROG-MAC和FPS-MAC两种MAC方案。

Result: FROG-MAC在能效和延迟方面都优于FPS-MAC，这得益于其能够中断信道中正在进行的低优先级传输的特性。

Conclusion: FROG-MAC具有在异构无线网络中优化性能的潜力，特别是在工业自动化应用中需要管理延迟的场景。

Abstract: Managing delay is one of the core requirements of industrial automation
applications due to the high risk associated for equipment and human lives.
Using efficient Media Access Control (MAC) schemes guarantees the timely
transmission of critical data, particularly in the industrial environments
where heterogeneous data is inherently expected. This paper compares the
performance of Fragmentation based MAC (FROG-MAC) against Fuzzy Priority
Scheduling based MAC (FPS-MAC), both of which have been designed to optimize
the performance of heterogenous wireless networks. Contiki has been used as a
simulation platform and a single hop star topology has been assumed to resemble
the industrial environment. It has been shown that FROG-MAC has the potential
to outperform FPS-MAC in terms of energy efficiency and delay both, due to its
inherent feature of interrupting ongoing lower priority transmission on the
channel.

</details>


### [21] [A Comparative Analysis of High-Level vs. Low-Level Simulations for Dynamic MAC Protocols in Wireless Sensor Networks](https://arxiv.org/abs/2510.18662)
*Shama Siddiqui,Anwar Ahmed Khan,Indrakshi Dey*

Main category: eess.SP

TL;DR: 比较了ADP-MAC协议在高层理论模拟和详细实现两种仿真级别下的性能差异，发现能耗和延迟趋势存在显著不同


<details>
  <summary>Details</summary>
Motivation: 评估无线传感器网络中MAC协议性能时，需要比较高层理论模拟与详细实现结果，以确保协议在真实场景部署前的质量评估准确性

Method: 使用MATLAB进行高层理论模拟，使用TinyOS在Mica2平台上开发详细实现，基于能耗和延迟进行性能评估

Result: 高层实现中能耗随轮询间隔增加而减少，延迟增加；详细实现中能耗和延迟都随轮询间隔增加而增加，两种仿真趋势显著不同

Conclusion: ADP-MAC的高层和低层仿真趋势存在显著差异，这主要是由于高层研究中缺乏现实假设所致

Abstract: Simulation studies are conducted at different levels of details for assessing
the performance of Media Access Control (MAC) protocols in Wireless Sensor
Networks (WSN). In the present-day scenario where hundreds of MAC protocols
have been proposed, it is important to assess the quality of performance
evaluation being conducted for each of the proposed protocols. It therefore
becomes crucial to compare the results of high-level theoretical simulations
with the detailed implementation results before any network protocol could be
deployed for a real-world scenario. In this work, we present a comparison of
high-level theoretical and detailed implementation results for Adaptive and
Dynamic Polling-MAC (ADP-MAC). MATLAB has been used for conducting initial
theoretical simulations and TinyOS has been used to develop the detailed
implementation of protocol for Mica2 platform. Performance evaluation of
ADP-MAC using the two levels of simulation has been conducted based on energy
and delay. In the high-level implementation, energy consumption was found to be
decreasing whereas delay was found to be increasing for increasing channel
polling intervals. On the other hand, when detailed implementation was
developed, it was observed that both energy consumption and delay revealed an
increasing trend with the increasing polling intervals. Therefore, it has been
shown that the trends for high- and low-level simulations for ADP-MAC are
significantly different, due to the lack of realistic assumptions in the
higher-level study.

</details>


### [22] [mSQUID: Model-Based Leanred Modulo Recovery at Low Sampling Rates](https://arxiv.org/abs/2510.18729)
*Yhonatan Kvich,Rotem Arie,Hana Hasan,Shaik Basheeruddin Shah,Yonina C. Eldar*

Main category: eess.SP

TL;DR: 提出了一种基于模型深度展开网络的模数软量化迭代解码器(mSQUID)，用于解决模数采样中的信号恢复问题，在低采样率和高斯噪声下实现优越的重建性能。


<details>
  <summary>Details</summary>
Motivation: 模数采样通过将输入信号折叠到有限区间来避免信号削波，但非线性失真给信号恢复带来挑战，特别是在噪声和量化条件下。

Method: 结合压缩感知求解器的可解释性和学习的灵活性，引入软量化模块，以可微分和可学习的方式将解引导至折叠范围的离散倍数。

Result: 在低采样率和高斯噪声下获得优越的重建性能，能够同时恢复幅度差异大且频带不重叠的信号，显著减少运行时间。

Conclusion: 该方法适用于实时、资源受限系统，解决了传统采样方法在弱信号失真或强信号削波情况下的困难。

Abstract: Modulo sampling enables acquisition of signals with unlimited dynamic range
by folding the input into a bounded interval prior to sampling, thus
eliminating the risk of signal clipping and preserving information without
requiring highresolution ADCs. While this enables low-cost hardware, the
nonlinear distortion introduced by folding presents recovery challenges,
particularly under noise and quantization. We propose a model-based deep
unfolding network tailored to this setting, combining the interpretability of
classical compress sensing (CS) solvers with the flexibility of learning. A key
innovation is a soft-quantization module that encodes the modulo prior by
guiding the solution toward discrete multiples of the folding range in a
differentiable and learnable way. Our method, modulo soft-quantized unfolded
iterative decoder (mSQUID), achieves superior reconstruction performance at low
sampling rates under additive Gaussian noise. We further demonstrate its
utility in a challenging case where signals with vastly different amplitudes
and disjoint frequency bands are acquired simultaneously and quantized. In this
scenario, classical sampling often struggles due to weak signal distortion or
strong signal clipping, while our approach is able to recover the input
signals. Our method also offers significantly reduced runtimes, making it
suitable for real-time, resource-limited systems.

</details>


### [23] [Wireless-Fed Pinching-Antenna Systems (Wi-PASS) for NextG Wireless Networks](https://arxiv.org/abs/2510.18743)
*Kasun R. Wijewardhana,Animesh Yadav,Ming Zeng,Mohamed Elsayed,Octavia A. Dobre,Zhiguo Ding*

Main category: eess.SP

TL;DR: 提出无线馈电的夹持天线系统(Wi-PASS)，通过无线馈电方式为波导供电，克服传统线缆馈电的限制，扩展毫米波和太赫兹频段的覆盖范围。


<details>
  <summary>Details</summary>
Motivation: 传统波导夹持天线系统(PASS)依赖有线馈电，部署范围受限，成本效益低，无法有效服务远距离用户或区域。

Method: 采用无线馈电技术为波导供电，实现灵活的部署和扩展覆盖范围。

Result: Wi-PASS在室内外场景中优于PASS，数值结果显示比传统固定天线系统提供更高的数据速率。

Conclusion: Wi-PASS具有优越的可行性和性能，是解决毫米波和太赫兹频段传播损耗的有效方案。

Abstract: Waveguide-based pinching-antenna systems (PASS) have recently emerged as a
promising solution to mitigate severe propagation losses in millimeter-wave and
terahertz bands by intelligently and flexibly establishing line-of-sight links.
However, their reliance on wire-based feeding confines deployment to areas near
the base station (BS), limiting installation flexibility and making them
cost-ineffective for serving distant users or regions. To overcome this
challenge, this article proposes wireless-fed pinchingantenna systems
(Wi-PASS), which employ wireless feeding to energize waveguides. Wi-PASS offer
a practical and cost-efficient means to extend coverage beyond the BS vicinity.
Several indoor and outdoor use cases demonstrate Wi-PASS advantages over PASS.
Numerical results further show that Wi-PASS deliver higher data rates than
conventional fixed-antenna systems, confirming the superior feasibility and
performance of Wi-PASS. Key future research directions are also discussed to
advance Wi-PASS deployment.

</details>


### [24] [Analyse comparative d'algorithmes de restauration en architecture dépliée pour des signaux chromatographiques parcimonieux](https://arxiv.org/abs/2510.18760)
*Mouna Gharbi,Silvia Villa,Emilie Chouzenoux,Jean-Christophe Pesquet,Laurent Duval*

Main category: eess.SP

TL;DR: 本文对三种展开式架构在参数化色谱信号数据库上进行了比较研究，特别关注适用于物理化学峰信号特征度量的性能表现。


<details>
  <summary>Details</summary>
Motivation: 数据从稀疏假设的退化观测中恢复是一个活跃的研究领域，传统迭代优化方法现在与深度学习技术相辅相成，展开式方法的发展从这两类方法中受益。

Method: 在参数化色谱信号数据库上对三种展开式架构进行对比研究，使用适用于物理化学峰信号特征度量的评估指标。

Result: 研究突出了这些方法的性能表现，特别是在采用适应物理化学峰信号特征度量的情况下。

Conclusion: 展开式方法结合了传统优化和深度学习的优势，在色谱信号恢复任务中表现出色，特别是当使用专门针对物理化学峰信号特征的度量标准时。

Abstract: Data restoration from degraded observations, of sparsity hypotheses, is an
active field of study. Traditional iterative optimization methods are now
complemented by deep learning techniques. The development of unfolded methods
benefits from both families. We carry out a comparative study of three
architectures on parameterized chromatographic signal databases, highlighting
the performance of these approaches, especially when employing metrics adapted
to physico-chemical peak signal characterization.

</details>


### [25] [SO(3)-invariant PCA with application to molecular data](https://arxiv.org/abs/2510.18827)
*Michael Fraiman,Paulina Hoyos,Tamir Bendory,Joe Kileel,Oscar Mickelin,Nir Sharon,Amit Singer*

Main category: eess.SP

TL;DR: 本文提出了一种SO(3)不变的主成分分析方法，用于处理具有未知方向的三维体积数据，避免了传统方法需要大量数据增强的高计算成本。


<details>
  <summary>Details</summary>
Motivation: PCA在三维结构生物学数据中的应用面临挑战，因为数据具有任意方向性。传统方法需要生成大量旋转副本，计算成本过高。

Method: 通过利用底层代数结构，开发了一个高效且原则性的SO(3)不变PCA框架，隐式地考虑所有旋转而不需要显式数据增强。

Result: 该方法仅需要计算协方差矩阵条目总数的平方根，显著降低了计算复杂度。在真实分子数据集上验证了有效性。

Conclusion: 该方法为大规模高维重建问题开辟了新可能性，在三维体积数据分析中具有重要应用价值。

Abstract: Principal component analysis (PCA) is a fundamental technique for
dimensionality reduction and denoising; however, its application to
three-dimensional data with arbitrary orientations -- common in structural
biology -- presents significant challenges. A naive approach requires
augmenting the dataset with many rotated copies of each sample, incurring
prohibitive computational costs. In this paper, we extend PCA to 3D volumetric
datasets with unknown orientations by developing an efficient and principled
framework for SO(3)-invariant PCA that implicitly accounts for all rotations
without explicit data augmentation. By exploiting underlying algebraic
structure, we demonstrate that the computation involves only the square root of
the total number of covariance entries, resulting in a substantial reduction in
complexity. We validate the method on real-world molecular datasets,
demonstrating its effectiveness and opening up new possibilities for
large-scale, high-dimensional reconstruction problems.

</details>
