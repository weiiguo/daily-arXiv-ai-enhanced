<div id=toc></div>

# Table of Contents

- [cs.IT](#cs.IT) [Total: 16]
- [eess.SP](#eess.SP) [Total: 15]


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [1] [Study of Switched Step-size Based Filtered-x NLMS Algorithm for Active Noise Cancellation](https://arxiv.org/abs/2601.16382)
*Zhiyuan Li,Yi Yu,Hongsen He,Yuyu Zhu,Rodrigo C. de Lamare*

Main category: cs.IT

TL;DR: 提出两种改进的FxNLMS算法：SSS-FxNLMS通过动态选择步长解决收敛速度与稳态误差的权衡问题，以及其鲁棒变体用于脉冲噪声环境


<details>
  <summary>Details</summary>
Motivation: 传统FxNLMS算法存在两个关键限制：固定步长导致收敛速度与稳态误差之间的权衡，以及在脉冲噪声环境下性能显著恶化

Method: 1) 推导FxNLMS算法的均方偏差趋势，通过比较不同步长对应的MSD趋势，为每次迭代选择最优步长，提出SSS-FxNLMS算法；2) 将鲁棒策略集成到SSS-FxNLMS中，形成鲁棒变体

Result: 通过计算机仿真在不同噪声场景下验证了所提算法的有效性和优越性

Conclusion: 提出的SSS-FxNLMS算法及其鲁棒变体成功解决了传统FxNLMS算法的步长约束问题和脉冲噪声环境下的性能恶化问题

Abstract: While the filtered-x normalized least mean square (FxNLMS) algorithm is widely applied due to its simple structure and easy implementation for active noise control system, it faces two critical limitations: the fixed step-size causes a trade-off between convergence rate and steady-state residual error, and its performance deteriorates significantly in impulsive noise environments. To address the step-size constraint issue, we propose the switched \mbox{step-size} FxNLMS (SSS-FxNLMS) algorithm. Specifically, we derive the \mbox{mean-square} deviation (MSD) trend of the FxNLMS algorithm, and then by comparing the MSD trends corresponding to different \mbox{step-sizes}, the optimal step-size for each iteration is selected. Furthermore, to enhance the algorithm's robustness in impulsive noise scenarios, we integrate a robust strategy into the SSS-FxNLMS algorithm, resulting in a robust variant of it. The effectiveness and superiority of the proposed algorithms has been confirmed through computer simulations in different noise scenarios.

</details>


### [2] [Two classes of LCD codes derived from $(\mathcal{L},\mathcal{P})$-TGRS codes](https://arxiv.org/abs/2601.16438)
*Ziwei Zhao,Xiaoni DU,Xingbin Qiao*

Main category: cs.IT

TL;DR: 本文从扭曲广义Reed-Solomon码构造了两类LCD码，并进一步得到LCD MDS码


<details>
  <summary>Details</summary>
Motivation: 扭曲广义Reed-Solomon码作为经典GRS码的灵活扩展受到广泛关注，本文旨在从这类码构造线性互补对偶码

Method: 从$(\mathcal{L},\mathcal{P})$-TGRS码$\mathcal{C}_h$出发，首先推导其校验矩阵和成为AMDS码的充要条件，然后通过适当选择评估点和对扭曲项多项式中$x^{h-1}$系数的限制，构造两类LCD码

Result: 成功构造了两类LCD码，并进一步得到两类LCD MDS码，提供了多个具体例子

Conclusion: 本文为从扭曲广义Reed-Solomon码构造LCD码提供了系统方法，特别是获得了具有最大距离可分性的LCD码

Abstract: Twisted generalized Reed-Solomon (TGRS) codes, as a flexible extension of classical generalized Reed-Solomon (GRS) codes, have attracted significant attention in recent years. In this paper, we construct two classes of LCD codes from the $(\mathcal{L},\mathcal{P})$-TGRS code $\mathcal{C}_h$ of length $n$ and dimension $k$, where $\mathcal{L}=\{0,1,\ldots,l\}$ for $l\leq n-k-1$ and $\mathcal{P}=\{h\}$ for $1\leq h\leq k-1$. First, we derive the parity check matrix of $\mathcal{C}_h$ and provide a necessary and sufficient condition for $\mathcal{C}_h$ to be an AMDS code. Then, we construct two classes of LCD codes from $\mathcal{C}_h$ by suitably choosing the evaluation points together with certain restrictions on the coefficient of $x^{h-1}$ in the polynomial associated with the twisting term. From the constructed LCD codes we further obtain two classes of LCD MDS codes. Finally, several examples are presented.

</details>


### [3] [Cramér-Rao Bound Minimization for Flexible Intelligent Metasurface-Enabled ISAC Systems](https://arxiv.org/abs/2601.16455)
*Qian Zhang,Yufei Zhao,Jiancheng An,Zheng Dong,Yong Liang Guan,Ju Liu,Chau Yuen*

Main category: cs.IT

TL;DR: 首次研究柔性智能超表面(FIM)辅助的ISAC系统中的CRB最小化问题，通过优化FIM表面形状和波束成形，显著降低感知CRB同时保持通信质量


<details>
  <summary>Details</summary>
Motivation: 集成感知与通信(ISAC)是未来无线网络的关键使能技术，CRB是量化感知精度的核心指标。目前缺乏对柔性智能超表面(FIM)辅助ISAC系统中CRB最小化的研究，而FIM的表面形状可重构性有望显著提升感知性能

Method: 1) 推导FIM表面形状相关的平均CRB表达式；2) 采用平均Fisher信息最大化作为替代目标，使用Gauss-Hermite积分法获得目标函数的显式近似；3) 将问题分解为三个子问题：波束成形优化、发射/接收FIM表面形状优化；4) 使用Schur补和惩罚基半定松弛技术优化波束成形；5) 提出定点方程法和投影梯度算法分别优化接收和发射FIM表面形状

Result: 仿真结果表明，与刚性阵列相比，发射和接收FIM的表面形状优化能显著降低平均感知CRB，同时保持通信质量，即使在多目标场景下仍然有效

Conclusion: FIM的表面形状可重构性为ISAC系统提供了新的自由度，通过联合优化波束成形和表面形状，可以显著提升感知性能，为未来ISAC系统设计提供了重要指导

Abstract: Integrated sensing and communication (ISAC) have been widely recognized as a key enabler for future wireless networks, where the Cramér-Rao bound (CRB) plays a central role in quantifying sensing accuracy.In this paper, we present the first study on CRB minimization in flexible intelligent metasurface (FIM)-enabled ISAC systems.Specifically, we first derive an average CRB expression that explicitly depends on FIM surface shape and demonstrate that array reconfigurability can substantially reduce the CRB, thereby significantly enhancing sensing performance.Moreover, to tackle the challenging CRB minimization problem, we adopt average Fisher information maximization as a surrogate objective and use the Gauss-Hermite quadrature method to obtain an explicit approximation of the objective function.The resulting problem is then decoupled into three subproblem, i.e., beamforming optimization and transmit/receive FIM surface shape optimization.For beamforming optimization, we employ the Schur complement and penalty-based semi-definite relaxation (SDR) technique to solve it.Furthermore, we propose a fixed-point equation method and a projected gradient algorithm to optimize the surface shapes of the receive and transmit FIMs, respectively.Simulation results demonstrate that, compared to rigid arrays, surface shaping of both transmit and receive FIMs can significantly reduce the average sensing CRB while maintaining communication quality, and remains effective even in multi-target scenarios.

</details>


### [4] [Log-Likelihood Loss for Semantic Compression](https://arxiv.org/abs/2601.16461)
*Anuj Kumar Yadav,Dan Song,Yanina Shkel,Ayfer Özgür*

Main category: cs.IT

TL;DR: 本文研究基于指定条件分布P_{X|U}诱导的负对数似然定义的失真度量下的有损信源编码，这种对数似然失真建模了重建是语义表示而非逐点近似的压缩场景。


<details>
  <summary>Details</summary>
Motivation: 传统有损压缩关注逐点近似，但许多应用需要重建作为语义表示，从中可以概率生成源信号。对数似然失真提供了一种建模这种语义压缩的框架。

Method: 提出对数似然失真度量，基于指定条件分布P_{X|U}的负对数似然定义。制定相应的率失真问题，分析所得率失真函数的基本性质。

Result: 建立了对数似然失真率失真函数与对数损失下的有损压缩、任意失真度量的经典率失真问题以及完美感知率失真之间的理论联系。

Conclusion: 对数似然失真为语义压缩提供了统一的数学框架，连接了多种压缩范式，为基于概率生成的重建表示建立了理论基础。

Abstract: We study lossy source coding under a distortion measure defined by the negative log-likelihood induced by a prescribed conditional distribution $P_{X|U}$. This \emph{log-likelihood distortion} models compression settings in which the reconstruction is a semantic representation from which the source can be probabilistically generated, rather than a pointwise approximation. We formulate the corresponding rate-distortion problem and characterize fundamental properties of the resulting rate-distortion function, including its connections to lossy compression under log-loss, classical rate-distortion problems with arbitrary distortion measures, and rate-distortion with perfect perception.

</details>


### [5] [Load Balanced ISAC Systems for URLLC Users](https://arxiv.org/abs/2601.16495)
*Shivani Singh,Amudheesan Nakkeeran,Prem Singh,Ekant Sharma,Jyotsna Bapat*

Main category: cs.IT

TL;DR: 提出一种用于集成感知与通信（ISAC）网络的能量高效负载均衡算法，在服务URLLC用户的同时检测目标，相比无负载均衡基线可降低约33%的功耗。


<details>
  <summary>Details</summary>
Motivation: 在集成感知与通信（ISAC）网络中，需要同时满足URLLC用户的通信QoS要求和目标检测的感知QoS要求，同时最小化网络功耗（包括发射功率、固定静态功率和流量相关前传功率）。

Method: 提出联合功率分配和AP负载均衡（JPALB）算法，解决混合整数非凸优化问题。该算法通过迭代优化功率分配和AP负载均衡来最小化总功耗，同时满足通信和感知的QoS要求。使用MRT和RZF预编码器进行仿真验证。

Result: 仿真结果显示，与无负载均衡的基线相比，JPALB算法可降低约33%的功耗，同时不损害通信和感知的QoS要求。

Conclusion: 提出的JPALB算法能有效降低ISAC网络的总功耗，在满足URLLC通信和目标检测要求的同时实现显著的节能效果。

Abstract: This paper presents an energy-efficient downlink cell-free massive multiple-input multiple-output (CF-mMIMO) integrated sensing and communication (ISAC) network that serves ultra-reliable low-latency communication (URLLC) users while simultaneously detecting a target. We propose a load-balancing algorithm that minimizes the total network power consumption; including transmit power, fixed static power, and traffic-dependent fronthaul power at the access points (APs) without degrading system performance. To this end, we formulate a mixed-integer non-convex optimization problem and introduce an iterative joint power allocation and AP load balancing (JPALB) algorithm. The algorithm aims to reduce total power usage while meeting both the communication quality-of-service (QoS) requirements of URLLC users and the sensing QoS needed for target detection. Proposed JPALB algorithm for ISAC systems was simulated with maximum-ratio transmission (MRT) and regularized zero-forcing (RZF) precoders. Simulation results show approximately 33% reduction in power consumption, using JPALB algorithm compared to a baseline with no load balancing, without compromising communication and sensing QoS requirements.

</details>


### [6] [Noise-immune and AI-enhanced DNA storage via adaptive partition mapping of digital data](https://arxiv.org/abs/2601.16518)
*Zimu Li,Bingyi Liu,Lei Zhao,Qian Zhang,Yang Liu,Jun Liu,Ke Ke,Huating Kong,Xiaolei Zuo,Chunhai Fan,Fei Wang*

Main category: cs.IT

TL;DR: PJ编码方案通过分区映射和跳转旋转策略，实现了对DNA存储中任意噪声条件的鲁棒性，即使在高链损失率下也能保持文件可解码性。


<details>
  <summary>Details</summary>
Motivation: DNA存储面临合成、保存和测序过程中的错误挑战，传统纠错码在噪声超过阈值时容易失效，需要一种能应对任意噪声条件的鲁棒编码方案。

Method: 开发了分区映射与跳转旋转（PJ）编码方案：1）分区映射消除链间信息依赖，使链损失表现为局部间隙而非灾难性失败；2）跳转旋转策略放宽序列约束，通过可调跳转长度提供可调信息密度；3）结合AI推理实现可控信息恢复。

Result: PJ编码能在任意链损失率下解码原始文件，保真度随损伤增加平滑下降：10%链损失下仍能有效恢复文件，机器学习数据集保持分类性能；极端环境扰动（加速老化和高强度X射线辐照）后仍能成功解码图像文件。

Conclusion: PJ编码消除了对先验错误概率的依赖，建立了适用于现实世界保存条件的鲁棒、长期DNA存储通用框架，为信息时代和人工智能时代的数据存储提供了有前景的解决方案。

Abstract: Encoding digital information into DNA sequences offers an attractive potential solution for storing rapidly growing data under the information age and the rise of artificial intelligence. However, practical implementations of DNA storage are constrained by errors introduced during synthesis, preservation, and sequencing processes, and traditional error-correcting codes remain vulnerable to noise levels that exceed predefined thresholds. Here, we developed a Partitioning-mapping with Jump-rotating (PJ) encoding scheme, which exhibits exceptional noise resilience. PJ removes cross-strand information dependencies so that strand loss manifests as localized gaps rather than catastrophic file failure. It prioritizes file decodability under arbitrary noise conditions and leverages AI-based inference to enable controllable recovery of digital information. For the intra-strand encoding, we develop a jump-rotating strategy that relaxes sequence constraints relative to conventional rotating codes and provides tunable information density via an adjustable jump length. Based on this encoding architecture, the original file information can always be decoded and recovered under any strand loss ratio, with fidelity degrading smoothly as damage increases. We demonstrate that original files can be effectively recovered even with 10% strand loss, and machine learning datasets stored under these conditions retain their classification performance. Experiments further confirmed that PJ successfully decodes image files after extreme environmental disturbance using accelerated aging and high-intensity X-ray irradiation. By eliminating reliance on prior error probabilities, PJ establishes a general framework for robust, archival DNA storage capable of withstanding the rigorous conditions of real-world preservation.

</details>


### [7] [Generalized Forms of the Kraft Inequality for Finite-State Encoders](https://arxiv.org/abs/2601.16594)
*Neri Merhav*

Main category: cs.IT

TL;DR: 本文扩展了Kraft不等式在有限状态无损编码器中的应用，定义了Kraft矩阵概念，并证明信息无损的必要条件是Kraft矩阵谱半径不超过1。


<details>
  <summary>Details</summary>
Motivation: 研究有限状态编码器的信息无损条件，扩展经典Kraft不等式到更一般的有限状态编码场景，为编码理论提供更严格的理论基础。

Method: 定义Kraft矩阵概念，利用谱半径理论分析有限状态编码器的性质，对不可约情况推导等价形式的Kraft不等式，并扩展到有边信息和有损压缩场景。

Result: 建立了有限状态编码器信息无损的必要条件：Kraft矩阵谱半径≤1；在不可约情况下，Kraft和有界且不随块长增长；提出了两种扩展形式。

Conclusion: Kraft不等式可扩展到有限状态编码器，谱半径条件为信息无损提供了必要判据，为编码理论建立了更完善的理论框架。

Abstract: We derive a few extended versions of the Kraft inequality for information lossless finite-state encoders. The main basic contribution is in defining a notion of a Kraft matrix and in establishing the fact that a necessary condition for information losslessness of a finite-state encoder is that none of the eigenvalues of this matrix have modulus larger than unity, or equivalently, the generalized Kraft inequality asserts that the spectral radius of the Kraft matrix cannot exceed one. For the important special case where the FS encoder is irreducible, we derive several equivalent forms of this inequality, which are based on well known formulas for spectral radius. It also turns out that in the irreducible case, Kraft sums are bounded by a constant, independent of the block length, and thus cannot grow even in any subexponential rate. Finally, two extensions are outlined - one concerns the case of side information available to both encoder and decoder, and the other is for lossy compression.

</details>


### [8] [An Explicit Upper Bound of Generalized Quadratic Gauss Sums and Its Applications for Asymptotically Optimal Aperiodic Polyphase Sequence Design](https://arxiv.org/abs/2601.16599)
*Huaning Liu,Zilong Liu*

Main category: cs.IT

TL;DR: 本文解决了设计满足Welch界的渐近最优非周期多相序列集的长期开放问题，通过提出广义二次高斯和的显式上界，并基于此构建了四种具有低非周期相关性和/或模糊特性的最优序列集。


<details>
  <summary>Details</summary>
Motivation: 解决设计满足Welch界的渐近最优非周期多相序列集的长期开放问题。虽然Mow在30多年前曾尝试解决，但对该问题的全面理解仍然缺乏。

Method: 1. 通过递归应用Paris渐近展开并利用Fibonacci zeta函数的快速收敛性，获得广义二次高斯和的显式上界。2. 基于这一关键发现，通过精心选择的Chu序列和Alltop序列，系统构建了四种具有最优非周期相关性和/或模糊特性的序列集。

Result: 首次在文献中揭示了完整的Alltop序列集对其低非周期相关旁瓣是渐近最优的。此外，引入了一个新的Alltop序列子集，在整个时间偏移窗口内同时具有最优的非周期相关性和模糊特性。

Conclusion: 本文成功解决了设计满足Welch界的渐近最优非周期多相序列集的长期开放问题，通过建立广义二次高斯和的理论上界，并构建了多种具有最优特性的实际序列集，为序列设计领域做出了重要贡献。

Abstract: This work is motivated by the long-standing open problem of designing asymptotically order-optimal aperiodic polyphase sequence sets with respect to the celebrated Welch bound. Attempts were made by Mow over 30 years ago, but a comprehensive understanding to this problem is lacking. Our first key contribution is an explicit upper bound of generalized quadratic Gauss sums which is obtained by recursively applying Paris' asymptotic expansion and then bounding it by leveraging the fast convergence property of the Fibonacci zeta function. Building upon this major finding, our second key contribution includes four systematic constructions of order-optimal sequence sets with low aperiodic correlation and/or ambiguity properties via carefully selected Chu sequences and Alltop sequences. For the first time in the literature, we reveal that the full Alltop sequence set is asymptotically optimal for its low aperiodic correlation sidelobes. Besides, we introduce a novel subset of Alltop sequences possessing both order-optimal aperiodic correlation and ambiguity properties for the entire time-shift window.

</details>


### [9] [Term Coding: An Entropic Framework for Extremal Combinatorics and the Guessing--Number Sandwich Theorem](https://arxiv.org/abs/2601.16614)
*Søren Riis*

Main category: cs.IT

TL;DR: 本文提出了一种连接项编码与图猜测数（图熵）的"猜测数三明治定理"，建立了项编码问题与图熵的定量联系，并给出了计算最大编码大小的通用方法。


<details>
  <summary>Details</summary>
Motivation: 将拟群、设计等组合结构的存在性问题转化为极值问题，研究在给定项恒等式系统下，通过自由选择函数符号解释所能获得的最大解集规模。

Method: 通过显式归一化和多样化约简，将每个项编码实例转化为具有猜测数α的规范有向依赖结构，利用熵和多拟阵方法计算α值。

Result: 证明了最大编码大小满足log_n S_n(Γ) = α + o(1)，即S_n(Γ) = n^{α+o(1)}，其中α可通过熵和多拟阵方法计算或界定。

Conclusion: 建立了一个连接项编码与图猜测数的统一框架，为极值组合学和信息流/网络编码约束提供了定量分析工具，并展示了在Steiner型恒等式、自正交拉丁方等实例中的应用。

Abstract: Term Coding asks: given a finite system of term identities $Γ$ in $v$ variables, how large can its solution set be on an $n$--element alphabet, when we are free to choose the interpretations of the function symbols? This turns familiar existence problems for quasigroups, designs, and related objects into quantitative extremal questions.
  We prove a guessing-number sandwich theorem that connects term coding to graph guessing numbers (graph entropy). After explicit normalisation and diversification reductions, every instance yields a canonical directed dependency structure with guessing number $α$ such that the maximum code size satisfies $\log_n \Sn(Γ)=α+o(1)$ (equivalently, $\Sn(Γ)=n^{α+o(1)}$), and $α$ can be bounded or computed using entropy and polymatroid methods.
  We illustrate the framework with examples from extremal combinatorics (Steiner-type identities, self-orthogonal Latin squares) and from information-flow / network-coding style constraints (including a five-cycle instance with fractional exponent and small storage/relay maps).

</details>


### [10] [Taming the Heavy Tail: Age-Optimal Preemption](https://arxiv.org/abs/2601.16624)
*Aimin Li,Yiğit İnce,Elif Uysal*

Main category: cs.IT

TL;DR: 该论文研究了一个连续时间联合采样与抢占问题，在一般服务时间分布下结合了采样和抢占惩罚。通过将系统建模为脉冲控制的分段确定性马尔可夫过程，推导出耦合积分平均成本最优性方程，避免了传统HJB-QVI所需的平滑性假设。研究发现抢占控制可简化为最优停止问题，并开发了高效的策略迭代算法。仿真显示在重尾服务时间下，相比非抢占采样和零等待基准，平均成本最多可降低30倍。


<details>
  <summary>Details</summary>
Motivation: 研究在一般服务时间分布下，结合采样和抢占惩罚的联合优化问题。传统方法通常需要平滑性假设，而本文旨在避免这些限制，同时探索抢占控制如何影响信息新鲜度（AoI）和系统性能。

Method: 将系统建模为脉冲控制的分段确定性马尔可夫过程（PDMP），通过动态规划原理推导耦合积分平均成本最优性方程。利用繁忙阶段的关键不变性将动态压缩到一维繁忙起始边界，将抢占控制简化为最优停止问题。开发了带有重尾加速的高效策略迭代算法，采用混合（均匀/对数间隔）动作网格和远场线性闭合技术。

Result: 在Pareto和对数正态服务时间分布下的仿真表明，相比AoI最优的非抢占采样和零等待基准，该方法在重尾机制下实现了高达30倍的平均成本降低。研究发现了一个反直觉的洞察：在抢占控制下，延迟方差（通常被视为不利因素）可以成为信息新鲜度的战略优势。

Conclusion: 本文提出了一种避免传统平滑性假设的连续时间联合采样与抢占优化框架，将抢占控制简化为最优停止问题，并开发了高效算法。研究不仅展示了显著的性能改进，还揭示了延迟方差在抢占策略下可能成为信息新鲜度优势的新见解。

Abstract: This paper studies a continuous-time joint sampling-and-preemption problem, incorporating sampling and preemption penalties under general service-time distributions. We formulate the system as an impulse-controlled piecewise-deterministic Markov process (PDMP) and derive coupled integral average-cost optimality equations via the dynamic programming principle, thereby avoiding the smoothness assumptions typically required for an average-cost Hamilton-Jacobi-Bellman quasi-variational inequality (HJB-QVI) characterization. A key invariance in the busy phase collapses the dynamics onto a one-dimensional busy-start boundary, reducing preemption control to an optimal stopping problem. Building on this structure, we develop an efficient policy iteration algorithm with heavy-tail acceleration, employing a hybrid (uniform/log-spaced) action grid and a far-field linear closure. Simulations under Pareto and log-normal service times demonstrate substantial improvements over AoI-optimal non-preemptive sampling and zero-wait baselines, achieving up to a 30x reduction in average cost in heavy-tailed regimes. Finally, simulations uncover a counterintuitive insight: under preemption, delay variance, despite typically being a liability, can become a strategic advantage for information freshness.

</details>


### [11] [The Oval Strikes Back](https://arxiv.org/abs/2601.16628)
*Andrea Di Giusto,Alberto Ravagnani,Emina Soljanin*

Main category: cs.IT

TL;DR: 本文研究射影平面中卵形线在分布式存储中的应用，特别是服务率区域问题，利用卵形线与直线的关联关系构造了一类具有大量小且不相交恢复集的非系统MDS矩阵，在某些参数下其服务率区域优于系统生成矩阵，并分析了PIR性质和多数逻辑解码算法。


<details>
  <summary>Details</summary>
Motivation: 研究射影平面中的经典几何对象——卵形线在现代编码理论中的新应用，特别是解决分布式存储中的服务率区域问题，探索几何结构与编码性能之间的关系。

Method: 利用射影平面中卵形线与直线的关联关系，构造一类非系统MDS矩阵，这些矩阵具有大量小且不相交的恢复集，并分析其服务率区域、PIR性质，以及设计一步多数逻辑解码算法。

Result: 对于某些参数选择，所构造的非系统MDS矩阵的服务率区域包含了相同码的系统生成矩阵的区域，表现出更好的服务性能；同时分析了PIR性质并提出了具有强纠错能力的一步多数逻辑解码算法。

Conclusion: 射影平面中的经典几何对象卵形线在现代编码理论中重新显现为有用工具，为分布式存储、服务率区域和PIR等问题提供了新的构造方法和性能改进。

Abstract: We investigate the applications of ovals in projective planes to distributed storage, with a focus on the Service Rate Region problem. Leveraging the incidence relations between lines and ovals, we describe a class of non-systematic MDS matrices with a large number of small and disjoint recovery sets. For certain parameter choices, the service-rate region of these matrices contains the region of a systematic generator matrix for the same code, yielding better service performance. We further apply our construction to analyze the PIR properties of the considered MDS matrices and present a one-step majority-logic decoding algorithm with strong error-correcting capability. These results highlight how ovals, a classical object in finite geometry, re-emerge as a useful tool in modern coding theory.

</details>


### [12] [Stable Source Coding](https://arxiv.org/abs/2601.16680)
*Zhenduo Wen,Amin Gohari*

Main category: cs.IT

TL;DR: 研究稳定无损信源编码的压缩率，推导稳定性参数下的可达速率信息论极限


<details>
  <summary>Details</summary>
Motivation: 传统随机分组编码不稳定，因为随机映射导致相似信源序列可能被分配到完全不相关的分组索引，需要研究稳定信源编码的性能

Method: 使用组合论证方法，推导稳定无损信源编码的可达速率信息论极限

Result: 得到了作为稳定性函数的可达速率信息论界限

Conclusion: 稳定信源编码在保证稳定性的同时，其压缩性能存在信息论极限，该极限与稳定性参数相关

Abstract: A source encoder is stable if a small change in the source sequence (e.g., changing a few symbols) results in a small (or bounded) change in the output codeword. By this definition, the common technique of random binning is unstable; because the mapping is random, two nearly identical source sequences can be assigned to completely unrelated bin indices. We study compression rates of stable lossless source codes. Using combinatorial arguments, we derive information-theoretic limits on the achievable rate as a function of the stability parameters.

</details>


### [13] [Adaptive Beam Alignment using Noisy Twenty Questions Estimation with Trained Questioner](https://arxiv.org/abs/2601.16799)
*Chunsong Sun,Lin Zhou*

Main category: cs.IT

TL;DR: 提出基于噪声二十问估计框架的自适应波束对准算法，通过训练提问器解决传统方法延迟高、现有方法不实用或不解释的问题


<details>
  <summary>Details</summary>
Motivation: 6G通信系统使用毫米波和MIMO技术，需要波束对准克服信号衰减。传统扇区搜索算法延迟高，现有自适应算法要么依赖理想假设不实用，要么使用黑盒神经网络缺乏解释性

Method: 提出基于噪声二十问估计框架的自适应波束对准算法，训练提问器。第一种方法通过导向向量加权求和将二十问查询映射到波束赋形向量；第二种方法使用多层全连接神经网络训练提问器，提高性能

Result: 数值仿真表明所提算法有效，性能优于所有基准算法

Conclusion: 提出的自适应波束对准算法既避免了理想假设，又保持了可解释性，解决了现有方法的可行性问题和可解释性问题

Abstract: The 6G communication systems use mmWave and MIMO technologies to achieve wide bandwidth and high throughout, leading to indispensable need for beam alignment to overcome severe signal attenuation. Traditional sector-search-based beam alignment algorithms rely on sequential sampling to identify the best sector, resulting in a significant latency burden on 6G communication systems. Recently proposed adaptive beam alignment algorithms based on the active learning framework address the problem, aiming to identify the optimal sector with the fewest possible samples under an identical sector partition. Nevertheless, these algorithms either lack feasibility (Chiu, Ronquillo and Javidi, JSAC 2019) due to ideal assumptions or lack interpretability (Sohrabi, Chen and Yu, JSAC 2021) due to the use of end-to-end black-box neural networks. To avoid ideal assumptions and maintain interpretability, we address all above problems by proposing an adaptive beam alignment algorithm using the framework of noisy twenty questions estimation with a trained questioner. Specifically, we use two methods for training the questioner to eliminate reliance on ideal assumptions. The first method maps queries of twenty questions estimation to beamforming vectors via weighted summation of steering vectors, as an initial attempt to address the feasibility problem encountered in prior pioneering study by Chiu, Ronquillo and Javidi (JSAC 2019). The second method uses multi-layer fully connected neural networks to achieve improved performance while only employing them to train the questioner, which can effectively mitigate the interpretability issues in prior study by Sohrabi, Chen and Yu (JSAC 2021). Furthermore, we provide numerical simulations to illustrate the effectiveness of our proposed adaptive beam alignment algorithms and demonstrate that our algorithms outperform all benchmark algorithms.

</details>


### [14] [Privacy-Resolution Tradeoff for Adaptive Noisy Twenty Questions Estimation](https://arxiv.org/abs/2601.16825)
*Chunsong Sun,Lin Zhou*

Main category: cs.IT

TL;DR: 本文研究带噪声的二十问题估计中的隐私-分辨率权衡，提出两阶段隐私查询方案，分析其非渐近和二阶渐近性能，并讨论隐私影响


<details>
  <summary>Details</summary>
Motivation: 自适应查询通常性能更好，但会引发隐私问题。先前研究集中在无噪声情况，本文将其扩展到更实际的带噪声场景，研究隐私与估计精度之间的权衡

Method: 提出两阶段隐私查询方案：第一阶段使用非自适应查询获取粗略估计，第二阶段基于第一阶段结果设计自适应查询。分析该方案的非渐近和二阶渐近性能

Result: 提出的隐私查询方案在带噪声情况下实现了隐私与估计精度的权衡，在无噪声特例中性能优于先前研究（COLT 2018, AISTATS 2021）

Conclusion: 本文成功将隐私-分辨率权衡研究扩展到带噪声的二十问题估计，提出的两阶段方案在保护隐私的同时保持了良好的估计性能

Abstract: We revisit noisy twenty questions estimation and study the privacy-resolution tradeoff for adaptive query procedures. Specifically, in twenty questions estimation, there are two players: an oracle and a questioner. The questioner aims to estimate target variables by posing queries to the oracle that knows the variables and using noisy responses to form reliable estimates. Typically, there are adaptive and non-adaptive query procedures. In adaptive querying, one designs the current query using previous queries and their noisy responses while in non-adaptive querying, all queries are posed simultaneously. Generally speaking, adaptive query procedures yield better performance. However, adaptive querying leads to privacy concerns, which were first studied by Tsitsiklis, Xu and Xu (COLT 2018) and by Xu, Xu and Yang (AISTATS 2021) for the noiseless case, where the oracle always provides correct answers to queries. In this paper, we generalize the above results to the more practical noisy case, by proposing a two-stage private query procedure, analyzing its non-asymptotic and second-order asymptotic achievable performance and discussing the impact of privacy concerns. Furthermore, when specialized to the noiseless case, our private query procedure achieves better performance than above-mentioned query procedures (COLT 2018, AISTATS 2021).

</details>


### [15] [Information Contraction under $(\varepsilon,δ)$-Differentially Private Mechanisms](https://arxiv.org/abs/2601.16845)
*Theshani Nuradha,Ian George,Christoph Hirche*

Main category: cs.IT

TL;DR: 本文针对(ε,δ)-局部差分隐私机制，推导了曲棍球散度和f-散度的线性和非线性强数据处理不等式，改进了现有仅适用于(ε,0)-LDP机制的界限。


<details>
  <summary>Details</summary>
Motivation: 现有的大多数信息度量收缩特征（包括全变差距离、曲棍球散度和f-散度）仅适用于(ε,0)-局部差分隐私机制，当δ≠0时缺乏有效的分析工具。需要为所有(ε,δ)-LDP机制建立更通用的数据处理不等式。

Method: 推导了适用于所有(ε,δ)-局部差分隐私机制的线性和非线性强数据处理不等式，专门针对曲棍球散度和f-散度这两种可区分性度量。

Result: 获得了比先前已知界限更优或更一般的结果，扩展了信息度量收缩分析到δ≠0的情况，为(ε,δ)-LDP机制提供了更全面的理论工具。

Conclusion: 本文填补了(ε,δ)-局部差分隐私机制下信息度量收缩分析的理论空白，为隐私保护统计任务提供了更强大的分析框架，推广并改进了现有结果。

Abstract: The distinguishability quantified by information measures after being processed by a private mechanism has been a useful tool in studying various statistical and operational tasks while ensuring privacy. To this end, standard data-processing inequalities and strong data-processing inequalities (SDPI) are employed. Most of the previously known and even tight characterizations of contraction of information measures, including total variation distance, hockey-stick divergences, and $f$-divergences, are applicable for $(\varepsilon,0)$-local differential private (LDP) mechanisms. In this work, we derive both linear and non-linear strong data-processing inequalities for hockey-stick divergence and $f$-divergences that are valid for all $(\varepsilon,δ)$-LDP mechanisms even when $δ\neq 0$. Our results either generalize or improve the previously known bounds on the contraction of these distinguishability measures.

</details>


### [16] [Perfect Privacy and Strong Stationary Times for Markovian Sources](https://arxiv.org/abs/2601.16857)
*Fangwei Ye,Zonghong Liu,Parimal Parag,Salim El Rouayheb*

Main category: cs.IT

TL;DR: 研究在完美信息论隐私约束下共享相关数据的问题，提出基于窗口的删减机制，在保护初始状态的同时实现最优失真，且平均删减数据点数量与数据长度无关。


<details>
  <summary>Details</summary>
Motivation: 在数据共享场景中，如何在保护隐私（特别是初始状态）的同时最大化共享数据量是一个重要问题。现有方法需要在隐私保护和数据效用之间权衡，本文旨在设计既能保证完美隐私又能高效共享相关数据的机制。

Method: 采用删减（擦除）机制，数据要么被保留要么被删除。研究基于马尔可夫链生成的数据，提出窗口式删减方案，证明擦除数据直到强平稳时间可以保护隐私。进一步研究最优顺序删减机制，并证明其具有等效的窗口解释。

Result: 建立了完美隐私与窗口式删减方案之间的联系，证明了两种机制都能在保护初始状态隐私的同时实现最优失真。特别重要的是，两种机制平均只删减常数数量的数据点，与数据长度N无关。

Conclusion: 对于马尔可夫链生成的相关数据，可以通过窗口式删减机制实现完美隐私保护，同时保持高数据效用。该机制具有理论保证，且在实际应用中具有可扩展性，因为删减的数据量不随数据长度增长而增加。

Abstract: We consider the problem of sharing correlated data under a perfect information-theoretic privacy constraint. We focus on redaction (erasure) mechanisms, in which data are either withheld or released unchanged, and measure utility by the average cardinality of the released set, equivalently, the expected Hamming distortion. Assuming the data are generated by a finite time-homogeneous Markov chain, we study the protection of the initial state while maximizing the amount of shared data. We establish a connection between perfect privacy and window-based redaction schemes, showing that erasing data up to a strong stationary time preserves privacy under suitable conditions. We further study an optimal sequential redaction mechanism and prove that it admits an equivalent window interpretation. Interestingly, we show that both mechanisms achieve the optimal distortion while redacting only a constant average number of data points, independent of the data length~$N$.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [17] [Gesture Recognition from body-Worn RFID under Missing Data](https://arxiv.org/abs/2601.16301)
*Sahar Golipoor,Richard T. Brophy,Ying Liu,Reza Ghazalian,Stephan Sigg*

Main category: eess.SP

TL;DR: 该论文提出了一种基于被动反射标签的手势识别系统，通过数据插补和图卷积神经网络处理缺失数据，在21种手势识别上达到98.13%的准确率。


<details>
  <summary>Details</summary>
Motivation: 解决基于被动反射标签的手势识别中数据缺失问题，提高识别准确率，并探索不同身体部位标签对识别性能的影响。

Method: 1) 提出数据处理流水线，使用线性和指数插值/外推法恢复缺失数据；2) 采用插补和邻近推理；3) 将标签表示为时序图中的节点，基于RSS和相位值相关性构建边；4) 训练基于图的自注意力图卷积神经网络。

Result: 1) 在21种手势识别上达到98.13%的准确率，优于现有方法；2) 留一人出交叉验证准确率为89.28%；3) 手臂标签比手腕标签更重要：移除手臂标签使准确率下降超10%，而移除手腕标签仅下降约2%。

Conclusion: 基于被动反射标签的手势识别系统通过有效处理缺失数据和利用图神经网络，实现了高精度识别。手臂部位的标签比手腕标签对识别性能贡献更大，为未来可穿戴手势识别系统的设计提供了指导。

Abstract: We explore hand-gesture recognition through the use of passive body-worn reflective tags. A data processing pipeline is proposed to address the issue of missing data. Specifically, missing information is recovered through linear and exponential interpolation and extrapolation. Furthermore, imputation and proximity-based inference are employed. We represent tags as nodes in a temporal graph, with edges formed based on correlations between received signal strength (RSS) and phase values across successive timestamps, and we train a graph-based convolutional neural network that exploits graph-based self-attention. The system outperforms state-of-the-art methods with an accuracy of 98.13% for the recognition of 21 gestures. We achieve 89.28% accuracy under leave-one-person-out cross-validation. We further investigate the contribution of various body locations on the recognition accuracy. Removing tags from the arms reduces accuracy by more than 10%, while removing the wrist tag only reduces accuracy by around 2%. Therefore, tag placements on the arms are more expressive for gesture recognition than on the wrist.

</details>


### [18] [Angle of Arrival Estimation for Gesture Recognition from reflective body-worn tags](https://arxiv.org/abs/2601.16303)
*Sahar Golipoor,Reza Ghazalian,Ines Lobato Mesquita,Stephan Sigg*

Main category: eess.SP

TL;DR: 利用被动反射标签进行手势识别，通过AoA追踪提升识别性能


<details>
  <summary>Details</summary>
Motivation: 传统基于RSS和相位信号的手势识别在面对大量手势时，不同手势间的信号特征相似度高，难以有效区分，需要寻找更具区分性的特征

Method: 1. 使用MUSIC算法验证AoA估计的可靠性；2. 提出基于卡尔曼平滑的AoA追踪方法；3. 将AoA特征集成到手势识别系统中

Result: AoA追踪能有效区分RSS和相位信号难以区分的手势数据，集成AoA特征后手势识别系统性能提升高达15%

Conclusion: AoA作为手势识别的特征具有显著优势，能有效提升识别性能，特别是在区分相似手势方面表现突出

Abstract: We investigate hand gesture recognition by leveraging passive reflective tags worn on the body. Considering a large set of gestures, distinct patterns are difficult to be captured by learning algorithms using backscattered received signal strength (RSS) and phase signals. This is because these features often exhibit similarities across signals from different gestures. To address this limitation, we explore the estimation of Angle of Arrival (AoA) as a distinguishing feature, since AoA characteristically varies during body motion. To ensure reliable estimation in our system, which employs Smart Antenna Switching (SAS), we first validate AoA estimation using the Multiple SIgnal Classification (MUSIC) algorithm while the tags are fixed at specific angles. Building on this, we propose an AoA tracking method based on Kalman smoothing. Our analysis demonstrates that, while RSS and phase alone are insufficient for distinguishing certain gesture data, AoA tracking can effectively differentiate them. To evaluate the effectiveness of AoA tracking, we implement gesture recognition system benchmarks and show that incorporating AoA features significantly boosts their performance. Improvements of up to 15% confirm the value of AoA-based enhancement.

</details>


### [19] [TransfoREM: Transformer aided 3D Radio Environment Mapping](https://arxiv.org/abs/2601.16421)
*Gautham Reddy,Ismail Guvenc,Mihail L. Sichitiu,Arupjyoti Bhuyan,Bryton Petersen,Jason Abrahamson*

Main category: eess.SP

TL;DR: TransfoREM：一种结合确定性信道模型和真实数据的3D无线电环境地图生成方法，使用transformer模型将无线电传播映射转化为序列预测任务，为无人机提供更好的蜂窝网络覆盖预测。


<details>
  <summary>Details</summary>
Motivation: 为无人机提供可靠的蜂窝网络连接是一个关键挑战，因为现有的地面网络主要部署在地面覆盖，无人机只能通过天线旁瓣获得有限的网络覆盖，且飞行动态会进一步恶化连接质量。

Method: 提出TransfoREM方法，结合确定性信道模型和真实世界数据生成3D无线电环境地图。核心是使用transformer模型，将无线电传播映射转化为序列预测任务来构建REM。

Result: TransfoREM在真实世界数据上展现出比传统Kriging和其他机器学习技术更好的插值能力。该方法设计用于在基站级别与蜂窝网络集成，构建的REM可用于增强资源分配、干扰管理和空间频谱利用。

Conclusion: TransfoREM为无人机蜂窝网络覆盖预测提供了一种有效的3D无线电环境地图生成方法，通过transformer模型实现了更好的插值性能，并具有与现有蜂窝网络集成的潜力。

Abstract: Providing reliable cellular connectivity to Unmanned Aerial Vehicles (UAV) is a key challenge, as existing terrestrial networks are deployed mainly for ground-level coverage. The cellular network coverage may be available for a limited range from the antenna side lobes, with poor connectivity further exacerbated by UAV flight dynamics. In this work, we propose TransfoREM, a 3D Radio Environment Map (REM) generation method that combines deterministic channel models and real-world data to map terrestrial network coverage at higher altitudes. At the core of our solution is a transformer model that translates radio propagation mapping into a sequence prediction task to construct REMs. Our results demonstrate that TransfoREM offers improved interpolation capability on real-world data compared against conventional Kriging and other machine learning (ML) techniques. Furthermore, TransfoREM is designed for holistic integration into cellular networks at the base station (BS) level, where it can build REMs, which can then be leveraged for enhanced resource allocation, interference management, and spatial spectrum utilization.

</details>


### [20] [Auditory Attention Decoding without Spatial Information: A Diotic EEG Study](https://arxiv.org/abs/2601.16442)
*Masahiro Yoshino,Haruki Yokota,Junya Hara,Yuichi Tanaka,Hiroshi Higashi*

Main category: eess.SP

TL;DR: 提出一种用于双耳相同语音混合环境（diotic）的听觉注意解码框架，通过共享潜在空间映射EEG和语音信号，消除空间线索依赖，在真实鸡尾酒会场景中实现72.70%的准确率。


<details>
  <summary>Details</summary>
Motivation: 现有听觉注意解码研究主要依赖双耳分听环境（dichotic），利用左右耳接收不同语音信号的空间线索来识别注意方向而非语音内容。这种空间依赖性限制了在真实鸡尾酒会场景中的应用，因为现实中说话者声音会重叠或动态移动。需要开发不依赖空间线索的AAD方法。

Method: 提出双耳相同语音混合环境（diotic）的AAD框架，将EEG和语音信号映射到共享潜在空间。使用wav2vec 2.0提取语音特征，通过2层1D CNN编码；使用BrainNetwork架构编码EEG信号。通过计算EEG和语音表示之间的余弦相似度来识别被注意的语音。

Result: 在双耳相同语音混合EEG数据集上评估，达到72.70%的准确率，比最先进的基于方向的AAD方法提高了22.58%。

Conclusion: 提出的框架成功消除了对空间线索的依赖，能够在更真实的鸡尾酒会场景中解码听觉注意，为智能助听器和客观听力测试系统提供了更实用的解决方案。

Abstract: Auditory attention decoding (AAD) identifies the attended speech stream in multi-speaker environments by decoding brain signals such as electroencephalography (EEG). This technology is essential for realizing smart hearing aids that address the cocktail party problem and for facilitating objective audiometry systems. Existing AAD research mainly utilizes dichotic environments where different speech signals are presented to the left and right ears, enabling models to classify directional attention rather than speech content. However, this spatial reliance limits applicability to real-world scenarios, such as the "cocktail party" situation, where speakers overlap or move dynamically. To address this challenge, we propose an AAD framework for diotic environments where identical speech mixtures are presented to both ears, eliminating spatial cues. Our approach maps EEG and speech signals into a shared latent space using independent encoders. We extract speech features using wav2vec 2.0 and encode them with a 2-layer 1D convolutional neural network (CNN), while employing the BrainNetwork architecture for EEG encoding. The model identifies the attended speech by calculating the cosine similarity between EEG and speech representations. We evaluate our method on a diotic EEG dataset and achieve 72.70% accuracy, which is 22.58% higher than the state-of-the-art direction-based AAD method.

</details>


### [21] [Cell-Free MIMO with Rotatable Antennas: When Macro-Diversity Meets Antenna Directivity](https://arxiv.org/abs/2601.16543)
*Xingxiang Peng,Qingqing Wu,Ziyuan Zheng,Yanze Zhu,Wen Chen,Penghui Huang,Ying Gao,Honghao Wang*

Main category: eess.SP

TL;DR: 论文研究了在无小区网络中使用可旋转天线优化最差用户速率的问题，通过联合优化波束成形和天线方向，提出了交替优化算法和低复杂度两阶段方案。


<details>
  <summary>Details</summary>
Motivation: 无小区网络虽然通过分布式接入点实现了宏分集，但用户几何位置和遮挡导致的信道质量差异限制了性能。可旋转天线通过调整天线主瓣方向来增强不利链路，使网络能更好地利用宏分集，实现更高且更均匀的性能。

Method: 1. 提出联合优化波束成形和天线方向的交替优化算法：使用二阶锥规划更新波束成形器，采用逐次凸逼近优化天线方向。2. 提出低复杂度两阶段方案：首先通过流形感知Frank-Wolfe更新最大化比例公平对数效用函数来设计天线方向，然后使用基于SOCP的设计计算波束成形器。

Result: 仿真结果表明，所提出的方向感知设计相比传统仅波束成形的基准方案，实现了显著更高的最差用户速率。此外，更大的天线方向性在正确调整方向时能增强公平性，但方向不当反而会降低最差用户性能。

Conclusion: 可旋转天线是无小区网络中增强宏分集利用的有效硬件自由度，通过联合优化波束成形和天线方向能够显著提升最差用户速率和网络公平性。提出的算法和两阶段方案为实际部署提供了可行的解决方案。

Abstract: Cell-free networks leverage distributed access points (APs) to achieve macro-diversity, yet their performance is often constrained by large disparities in channel quality arising from user geometry and blockages. To address this, rotatable antennas (RAs) add a lightweight hardware degree of freedom by steering the antenna boresight toward dominant propagation directions to strengthen unfavorable links, thereby enabling the network to better exploit macro-diversity for higher and more uniform performance. This paper investigates an RA-enabled cell-free downlink network and formulates a max-min rate problem that jointly optimizes transmit beamforming and antenna orientations. To tackle this challenging problem, we develop an alternating-optimization-based algorithm that iteratively updates the beamformers via a second-order cone program (SOCP) and optimizes the antenna orientations using successive convex approximation. To reduce complexity, we further propose an efficient two-stage scheme that first designs orientations by maximizing a proportional-fair log-utility using manifold-aware Frank-Wolfe updates, and then computes the beamformers using an SOCP-based design. Simulation results demonstrate that the proposed orientation-aware designs achieve a substantially higher worst-user rate than conventional beamforming-only benchmarks. Furthermore, larger antenna directivity enhances fairness with proper orientation but can degrade the worst-user performance otherwise.

</details>


### [22] [Spiking Neural Networks for Communication Systems: Encoding Schemes, Learning Algorithms, and Equalization~Techniques](https://arxiv.org/abs/2601.16550)
*Eike-Manuel Edelmann*

Main category: eess.SP

TL;DR: 该论文研究基于脉冲神经网络(SNN)的接收机设计，用于非线性时不变频率选择性信道，通过量化编码和强化学习优化，实现了比传统人工神经网络(ANN)接收机更好的性能和更低的能耗。


<details>
  <summary>Details</summary>
Motivation: 现代通信系统复杂度增加导致能耗上升，而脉冲神经网络(SNN)模仿人脑的事件驱动和高效能机制，有望实现低功耗实时信号处理，但面临学习规则和神经编码等挑战。

Method: 研究SNN接收机设计，采用基于时间的反向传播与替代梯度作为更新规则，提出量化编码(QE)作为神经编码方法，比较两种接收机架构，并引入基于策略梯度的更新(PGU)算法优化编码参数。

Result: SNN接收机显著优于ANN接收机，决策反馈与量化编码结合实现了强性能和低脉冲计数，PGU算法大幅减少运行时间、复杂度和每次推理的脉冲数，同时保持性能。

Conclusion: 该论文成功开发了SNN接收机的设计和优化框架，解决了SNN优化的关键挑战，为未来设计和部署高能效SNN接收机奠定了基础。

Abstract: Machine learning with artificial neural networks (ANNs), provides solutions for the growing complexity of modern communication systems. This complexity, however, increases power consumption, making the systems energy-intensive. Spiking neural networks (SNNs) represent a novel generation of neural networks inspired by the highly efficient human brain. By emulating its event-driven and energy-efficient mechanisms, SNNs enable low-power, real-time signal processing. They differ from ANNs in two key ways: they exhibit inherent temporal dynamics and process and transmit information as short binary signals called spikes. Despite their promise, major challenges remain, e.g., identifying optimal learning rules and effective neural encoding. This thesis investigates the design of SNN-based receivers for nonlinear time-invariant frequency-selective channels. Backpropagation through time with surrogate gradients is identified as a promising update rule and the novel quantization encoding (QE) as promising neural encoding. Given the model of the intensity modulation with direct detection link, we compare two different receiver architectures based on equalization performance and spike count. Using decision feedback and QE achieves both strong performance and low spike counts. Notably, SNN-based receivers significantly outperform ANN-based counterparts. We furthermore introduce policy gradient-based update (PGU), an reinforcement learning-based update algorithm that requires no backpropagation. Using PGU, encoding parameters are optimized, drastically reducing runtime, complexity, and spikes per inference while maintaining performance. This thesis contributes a successful design and optimization framework for SNN-based receivers. By addressing key challenges in SNN optimization, it facilitates future advances in the design and deployment of energy-efficient SNN receivers.

</details>


### [23] [Real-Time Evaluation of an Ultra-Tight GNSS/INS Integration Based on Adaptive PLL Bandwidth](https://arxiv.org/abs/2601.16577)
*Gaël Pages,Priot Benoît,Guillaume Beaugendre*

Main category: eess.SP

TL;DR: 提出一种基于矢量跟踪环架构的GNSS/INS超紧耦合系统，通过INS信息自适应调整PLL带宽，可在FPGA上实现且不增加额外资源占用


<details>
  <summary>Details</summary>
Motivation: 传统矢量跟踪方案需要并行运行标量环或存储预下载星历数据，这会增加FPGA面积和存储资源消耗。本文旨在设计一种更高效、资源友好的GNSS/INS超紧耦合架构

Method: 采用矢量跟踪环架构的GNSS接收机，利用惯性导航系统信息自适应调整锁相环带宽。在环路内解码导航电文，无需并行标量环或预存星历数据。系统基于FPGA实现，包含1个捕获模块和16个跟踪通道（8个GPS L1/C和8个Galileo E1）

Result: 提出的架构可在Zynq-Ultrascale FPGA上实现，相比传统矢量方案，不增加FPGA面积占用，也不使用额外存储资源，同时保持GPS和Galileo信号处理能力

Conclusion: 该GNSS/INS超紧耦合架构具有资源效率高、易于在现有GNSS接收机平台上实现的特点，为高性能导航系统提供了一种实用的FPGA实现方案

Abstract: In this contribution, we propose a GNSS/INS ultra-tight coupling in which the GNSS receiver architecture is based on a vector tracking loop type architecture. In the proposed approach, the phase lock loop bandwidth is adapted according to the inertial navigation system information. The latter has the advantage to be easily implementable on a System-on-Chip component such as an FPGA (Field-Programmable Gate Arrays), and can be implemented with minor modifications on an existing GNSS receiver platform. Moreover, compared to classical vector-based solutions, the proposed architecture decodes the navigation message in the loop, without the need to run scalar loops in parallel or having to store pre-downloaded ephemeris data. This architecture therefore does not increase the area occupied on the FPGA and does not use additional resources for storage. The proposed GNSS receiver architecture uses GPS L1/C and Galileo E1 signals and is composed of one acquisition module and 16 tracking channels (8 GPS and 8 Galileo) which are implemented within a FPGA (Zynq-Ultrascale).

</details>


### [24] [Learning Successive Interference Cancellation for Low-Complexity Soft-Output MIMO Detection](https://arxiv.org/abs/2601.16586)
*Benedikt Fesl,Fatih Capar*

Main category: eess.SP

TL;DR: 提出recurSIC：一种轻量级学习型MIMO检测框架，结合SIC结构和学习处理，在低复杂度下实现可靠的硬检测和软信息生成，适用于边缘设备。


<details>
  <summary>Details</summary>
Motivation: 5G RedCap和IoT设备需要低复杂度的MIMO检测方案，同时要支持高阶调制并生成可靠的软信息用于信道解码，现有方案难以平衡性能与计算资源限制。

Method: 基于连续干扰消除(SIC)结构设计轻量级学习框架，通过多路径假设跟踪生成软信息，仅需单次前向传播且参数极少，复杂度可调。

Result: 在真实无线场景中，recurSIC在极低复杂度下实现了优异的硬检测和软检测性能，适合资源受限的边缘MIMO接收器。

Conclusion: recurSIC为边缘设备提供了一种有效的低复杂度MIMO检测解决方案，平衡了机器学习部署需求与硬件约束，支持高阶调制和可靠软信息生成。

Abstract: Low-complexity multiple-input multiple-output (MIMO) detection remains a key challenge in modern wireless systems, particularly for 5G reduced capability (RedCap) and internet-of-things (IoT) devices. In this context, the growing interest in deploying machine learning on edge devices must be balanced against stringent constraints on computational complexity and memory while supporting high-order modulation. Beyond accurate hard detection, reliable soft information is equally critical, as modern receivers rely on soft-input channel decoding, imposing additional requirements on the detector design. In this work, we propose recurSIC, a lightweight learning-based MIMO detection framework that is structurally inspired by successive interference cancellation (SIC) and incorporates learned processing stages. It generates reliable soft information via multi-path hypothesis tracking with a tunable complexity parameter while requiring only a single forward pass and a minimal parameter count. Numerical results in realistic wireless scenarios show that recurSIC achieves strong hard- and soft-detection performance at very low complexity, making it well suited for edge-constrained MIMO receivers.

</details>


### [25] [Assessment of Errors of Fundamental Frequency Estimation Methods in the Presence of Voltage Fluctuations and Distortions](https://arxiv.org/abs/2601.16606)
*Antonio Bracale,Pasquale De Falco,Piotr Kuwałek,Grzegorz Wiczyński*

Main category: eess.SP

TL;DR: 该论文通过数值模拟研究评估了现代电网条件下各种基频估计方法的误差，包括IEC 61000-4-30标准方法，特别关注电压波动和畸变同时存在的情况。


<details>
  <summary>Details</summary>
Motivation: 基频是定义电能质量的关键参数之一。在现代电网条件下正确确定该参数至关重要，而诊断目的通常需要在短时间内窗口内高效估计该参数。

Method: 采用数值模拟研究方法，使用模拟现代电网状态的测试信号（包括电压波动和畸变同时发生的情况），评估各种基频估计方法的误差，包括标准IEC 61000-4-30方法。

Result: 研究得出了各种基频估计方法在不同电网条件下的误差评估结果，为方法选择提供了依据。

Conclusion: 基于研究结果提出了结论，为现代电网条件下基频估计方法的选择和应用提供了指导。

Abstract: The fundamental frequency is one of the parameters that define power quality. Correctly determining this parameter under the conditions that prevail in modern power grids is crucial. Diagnostic purposes often require an efficient estimation of this parameter within short time windows. Therefore, this article presents the results of numerical simulation studies that allow the assessment of errors in various fundamental frequency estimation methods, including the standard IEC 61000-4-30 method, when the analyzed signal has a form similar to that found in modern power grids. For the purposes of this study, a test signal was adopted recreating the states of the power grid, including the simultaneous occurrence of voltage fluctuations and distortions. Conclusions are presented based on conducted research.

</details>


### [26] [Low-Power On-Device Gesture Recognition with Einsum Networks](https://arxiv.org/abs/2601.16662)
*Sahar Golipoor,Lingyun Yao,Martin Andraud,Stephan Sigg*

Main category: eess.SP

TL;DR: 基于Einsum网络的分布式资源受限设备手势识别系统，在低功耗RFID手势识别场景中表现优于基准模型


<details>
  <summary>Details</summary>
Motivation: 为分布式、资源受限的设备网络设计高效的手势识别系统，利用Einsum网络的可追踪推理、可解释性和能效优势

Method: 使用Einsum网络构建概率电路，每个受限设备包含RSS/相位处理或AoA估计的任务特定处理单元，以及特征提取和专用Einsum硬件，最后通过决策聚合模块融合所有设备输出

Result: 在低功耗、可穿戴、被动RFID手势识别场景中验证，实验结果表明该方法优于基准模型

Conclusion: 基于Einsum网络的分布式手势识别系统在资源受限设备上有效，结合了可解释性、能效和优越性能

Abstract: We design a gesture-recognition pipeline for networks of distributed, resource constrained devices utilising Einsum Networks. Einsum Networks are probabilistic circuits that feature a tractable inference, explainability, and energy efficiency. The system is validated in a scenario of low-power, body-worn, passive Radio Frequency Identification-based gesture recognition. Each constrained device includes task-specific processing units responsible for Received Signal Strength (RSS) and phase processing or Angle of Arrival (AoA) estimation, along with feature extraction, as well as dedicated Einsum hardware that processes the extracted features. The output of all constrained devices is then fused in a decision aggregation module to predict gestures. Experimental results demonstrate that the method outperforms the benchmark models.

</details>


### [27] [OFDM-Based ISAC Imaging of Extended Targets via Inverse Virtual Aperture Processing](https://arxiv.org/abs/2601.16664)
*Michael Negosanti,Lorenzo Pucci,Andrea Giorgetti*

Main category: eess.SP

TL;DR: 该研究探讨了利用逆虚拟孔径(IVA)进行车载场景中移动扩展目标成像的集成感知与通信(ISAC)系统性能，使用MIMO-OFDM波形和运动补偿技术形成IVA距离-多普勒图像。


<details>
  <summary>Details</summary>
Motivation: 研究动机是开发下一代无线网络中有效的感知策略，解决车载场景中移动扩展目标的成像问题，同时平衡感知精度与通信效率的需求。

Method: 采用MIMO-OFDM波形，基站作为单站传感器，通过运动补偿技术处理目标反射的回波，形成IVA距离-多普勒图像。使用5G NR波形和3GPP Release 19中定义的车辆目标模型（作为空间分布散射点集），通过调整子载波分配来探索感知精度与通信效率的权衡。

Result: 研究评估了图像对比度(IC)和目标质心距离估计的均方根误差(RMSE)，结果表明通过调整子载波分配可以在感知精度和通信效率之间实现有效权衡。

Conclusion: 该研究为下一代无线网络中设计有效的感知策略提供了重要见解，证明了利用IVA进行移动扩展目标成像的可行性，并展示了感知精度与通信效率之间的可调权衡关系。

Abstract: This work investigates the performance of an integrated sensing and communication (ISAC) system exploiting inverse virtual aperture (IVA) for imaging moving extended targets in vehicular scenarios. A base station (BS) operates as a monostatic sensor using MIMO-OFDM waveforms. Echoes reflected by the target are processed through motion-compensation techniques to form an IVA range-Doppler (cross-range) image. A case study considers a 5G NR waveform in the upper mid-band, with the target model defined in 3GPP Release 19, representing a vehicle as a set of spatially distributed scatterers. Performance is evaluated in terms of image contrast (IC) and the root mean squared error (RMSE) of the estimated target-centroid range. Finally, the trade-off between sensing accuracy and communication efficiency is examined by varying the subcarrier allocation for IVA imaging. The results provide insights for designing effective sensing strategies in next-generation radio networks.

</details>


### [28] [Precise Low-Current Measurement Techniques for IoT Devices: A Case Study on MoleNet](https://arxiv.org/abs/2601.16727)
*Julian Block,Andreas Könsgen,Jens Dede,Anna Förster*

Main category: eess.SP

TL;DR: 比较专用源测量单元(SMU)在测量物联网设备微小电流方面的性能，并以MoleNet传感器板为例进行实际测量演示


<details>
  <summary>Details</summary>
Motivation: 物联网设备通常需要长时间电池供电，功耗至关重要。传统万用表和示波器难以精确测量设备休眠时的微小电流，需要更专业的测量工具。

Method: 使用专用源测量单元(SMU)进行高精度微小电流测量，并以MoleNet物联网传感器板作为应用实例进行实际测量。

Result: 专用SMU能够有效测量物联网设备的微小电流，特别是在设备休眠模式下的极低功耗状态，为设备功耗优化提供准确数据支持。

Conclusion: 专用源测量单元是测量物联网设备微小电流的理想工具，能够提供传统测量设备无法达到的精度，对于物联网设备的功耗优化和电池寿命评估至关重要。

Abstract: Power consumption is a crucial aspect of IoT devices which often have to run on a battery for an extended period of time. Therefore, supply current measurements are crucial before deploying a device in the field. Multimeters and oscilloscopes are not well suited when it comes to measuring very small currents which occur e.g. when an IoT device is in sleep mode. In this report, we compare dedicated source measurement units (SMUs) which allow to measure very small currents with high precision. As an application example, we demonstrate current measurements on our MoleNet IoT sensor board.

</details>


### [29] [A Dynamic Parametric Simulator for Fetal Heart Sounds](https://arxiv.org/abs/2601.16792)
*Yingtong Zhou,Yiang Zhou,Zhengxian Qu,Kang Liu,Ting Tan*

Main category: eess.SP

TL;DR: 开发了一个可重复的动态参数模拟器，用于生成腹部胎儿心音图信号，支持在受控条件下评估处理方法


<details>
  <summary>Details</summary>
Motivation: 胎儿心音图研究面临腹部记录数量有限、母体干扰严重、信号衰减明显等问题，缺乏可重复的基准测试

Method: 结合周期级胎儿S1/S2事件合成与卷积传输模块，加入可配置的干扰和背景噪声，参数从真实腹部记录中周期校准

Result: 生成的信号在包络时间结构和频域特性方面与真实记录验证一致，模拟器作为开源软件发布

Conclusion: 该模拟器支持在受控采集条件下快速、可重复地评估fPCG处理方法，解决了研究中的基准测试难题

Abstract: Research on fetal phonocardiogram (fPCG) is challenged by the limited number of abdominal recordings, substantial maternal interference, and marked transmissioninduced signal attenuation that complicate reproducible benchmarking. We present a reproducible dynamic parametric simulator that generates long abdominal fPCG sequences by combining cycle-level fetal S1/S2 event synthesis with a convolutional transmission module and configurable interference and background noise. Model parameters are calibrated cyclewise from real abdominal recordings to capture beat-to-beat variability and to define data-driven admissible ranges for controllable synthesis. The generated signals are validated against real recordings in terms of envelope-based temporal structure and frequency-domain characteristics. The simulator is released as open software to support rapid, reproducible evaluation of fPCG processing methods under controlled acquisition conditions.

</details>


### [30] [Hierarchical Distribution Matcher Design for Probabilistic Constellation Shaping Based on a Novel Semi-Analytical Optimization Approach](https://arxiv.org/abs/2601.16847)
*Pantea Nadimi Goki,Luca Potì*

Main category: eess.SP

TL;DR: 提出一种实用的分层分布匹配器设计方法，通过半解析优化框架联合优化速率和能量损失，在16QAM概率整形系统中实现2.8%的整形增益提升


<details>
  <summary>Details</summary>
Motivation: 为了解决概率整形星座系统中分层分布匹配器的实际设计问题，需要一种能够确定最优参数、考虑硬件实现约束（如ASIC/FPGA限制）的设计方法

Method: 提出分层分布匹配器设计流程，通过解析估计能量损失、速率损失和内存需求的下界，采用半解析优化框架联合优化速率和能量损失，选择分层数、内存大小和块长度来优化信道容量

Result: 在16QAM概率整形系统中验证了模型准确性，在200Gbps净数据速率和25%前向纠错开销下，相比先前方案实现了2.8%的整形增益提升

Conclusion: 提出的分析工具能够设计符合实际硬件约束的分层分布匹配器结构，在AWGN信道下表现出优越性能，为实际系统实现提供了有效的设计方法

Abstract: A novel design procedure for practical hierarchical distribution matchers (HiDMs) in probabilistically shaped constellation systems is presented. The proposed approach enables the determination of optimal parameters for any target distribution matcher rate. Specifically, lower bounds on energy loss, rate loss, and memory requirements are analytically estimated for HiDM architectures approximating the Maxwell Boltzmann (MB) distribution. A semi analytical optimization framework is employed to jointly optimize rate and energy loss, allowing the selection of the number of hierarchical layers, memory size, and block length required to optimize channel capacity. The accuracy of the proposed model is validated through probabilistic amplitude shaping of 16QAM (PAS 16QAM), showing good agreement between analytical predictions and simulated results. The proposed analytical tool facilitates the design of HiDM structures that are compatible with practical hardware and implementation constraints, such as those imposed by state-of-the-art application-specific integrated circuits (ASICs) and field-programmable gate arrays (FPGAs). Furthermore, the performance of the optimized HiDM structure, incorporating layer selection based on lower-bound energy loss, is evaluated over the AWGN channel in terms of normalized generalized mutual information (NGMI) as a function of the optical signal-to-noise ratio (OSNR). At a net data rate of 200 Gbps with 25% forward error correction (FEC) overhead, the proposed scheme achieves a shaping gain improvement of 2.8% compared to previously reported solutions.

</details>


### [31] [IRS Compensation of Hyper-Rayleigh Fading: How Many Elements Are Needed?](https://arxiv.org/abs/2601.16915)
*Aleksey S. Gvozdarev*

Main category: eess.SP

TL;DR: 研究确定了在严重衰落条件下补偿多径衰落信道所需的最小智能反射表面(IRS)元件数量，基于超瑞利衰落机制和逆幂洛马克斯信道模型进行分析。


<details>
  <summary>Details</summary>
Motivation: 在严重衰落条件下，需要确定智能反射表面所需的最小元件数量来补偿信道衰落，量化不同衰落严重程度下的性能需求。

Method: 使用逆幂洛马克斯(IPL)信道模型，推导单IRS元件信道的闭式信道系数包络统计，以及总IRS辅助信道的紧致近似，分析超瑞利衰落机制下的性能。

Result: 当源-IRS和IRS-目的地两个单链路都处于完全超瑞利衰落时，需要至少6个IRS元件才能使总IRS辅助链路脱离完全超瑞利衰落，需要14个元件才能达到无超瑞利衰落状态。

Conclusion: 确定了在不同衰落严重程度下补偿信道所需的最小IRS元件数量，为IRS系统设计提供了重要的理论指导。

Abstract: The letter introduces and studies the problem of defining the minimum number of Intelligent Reflecting Surface (IRS) elements needed to compensate for heavy fading conditions in multipath fading channels. The fading severity is quantified in terms of Hyper-Rayleigh Regimes (HRRs) (i.e., full-HRR (worst-case conditions), strong-, weak-, and no-HRR), and the channel model used (Inverse Power Lomax (IPL)) was chosen since it can account for all HRRs. The research presents the derived closed-form channel coefficient envelope statistics for the single IRS-element channel with IPL statistics in both subchannels and total IRS-assisted channel, as well as tight approximations for the channel coefficient and instantaneous signal-to-noise ratio (SNR) statistics for the latter. The derived expressions helped estimate channel parameters corresponding to the specific HRRs of the total channel and demonstrate that while both single links (i.e., ''source-IRS'' and ''IRS-destination'') are in full-HRR, the minimum number of IRS elements needed to bring the total IRS-assisted link (''source-IRS-destination'') out of full-HRR is no less than $6$ (for the whole range on the IPL scale parameter corresponding full-HRR). Furthermore, the minimum number of IRS elements required to bring the total IRS-assisted link into no-HRR is $14$ (under the same conditions).

</details>
