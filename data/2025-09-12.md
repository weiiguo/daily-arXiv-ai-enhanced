<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 14]
- [cs.IT](#cs.IT) [Total: 5]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [A Masked Representation Learning to Model Cardiac Functions Using Multiple Physiological Signals](https://arxiv.org/abs/2509.08830)
*Seong-A Park,Jong-Eui Chae,Sungdong Kim,Hyung-Chul Lee,Hyun-Lim Yang*

Main category: eess.SP

TL;DR: SNUPHY-M模型通过自监督学习同时分析ECG、PPG和ABP三种生理信号，在血流动力学监测任务中显著优于传统方法，为非侵入性临床诊断提供了有效支持。


<details>
  <summary>Details</summary>
Motivation: 临床实践中需要综合分析多种生理信号来监测血流动力学，但现有研究多集中于单一信号分析，缺乏适用于真实临床场景的复杂信号分析方法。

Method: 基于自监督学习的掩码表示学习方法，通过恢复三种被掩码的生理信号（ECG、PPG、ABP）来提取反映心脏周期电学、压力和流体特性的生理特征。

Result: 在低血压、心搏量、收缩压、舒张压和年龄预测等临床下游任务中，SNUPHY-M显著优于监督学习或自监督学习模型，特别是在使用非侵入性信号的预测任务中表现突出。

Conclusion: SNUPHY-M是首个将多模态自监督学习应用于心血管分析（涉及ECG、PPG和ABP信号）的模型，能有效支持临床决策和精确诊断，为非侵入性血流动力学早期诊断和管理做出重要贡献。

Abstract: In clinical settings, monitoring hemodynamics is crucial for managing patient
prognosis, necessitating the integrated analysis of multiple physiological
signals. While recent research has analyzed single signals such as
electrocardiography (ECG) or photoplethysmography (PPG), there has yet to be a
proposal for an approach that encompasses the complex signal analysis required
in actual clinical scenarios. In this study, we introduce the SNUPHY-M (Seoul
National University hospital PHYsiological signal Masked representation
learning) model extracts physiological features reflecting the electrical,
pressure, and fluid characteristics of the cardiac cycle in the process of
restoring three masked physiological signals based on self-supervised learning
(SSL): ECG, PPG, and arterial blood pressure (ABP) signals. By employing
multiple physical characteristics, the model can extract more enriched features
only using non-invasive signals. We evaluated the model's performance in
clinical downstream tasks such as hypotension, stroke volume, systolic blood
pressure, diastolic blood pressure, and age prediction. Our results showed that
the SNUPHY-M significantly outperformed supervised or SSL models, especially in
prediction tasks using non-invasive signals. To the best of our knowledge,
SNUPHY-M is the first model to apply multi-modal SSL to cardiovascular analysis
involving ECG, PPG, and ABP signals. This approach effectively supports
clinical decision-making and enables precise diagnostics, contributing
significantly to the early diagnosis and management of hemodynamics without
invasiveness.

</details>


### [2] [Deploying AI for Signal Processing education: Selected challenges and intriguing opportunities](https://arxiv.org/abs/2509.08950)
*Jarvis Haupt,Qin Lu,Yanning Shen,Jia Chen,Yue Dong,Dan McCreary,Mehmet Akçakaya,Georgios B. Giannakis*

Main category: eess.SP

TL;DR: 本文探讨AI在教育领域的应用，特别是信号处理教育，关注技术限制和实际应用，强调公平性、包容性和资源效率等问题


<details>
  <summary>Details</summary>
Motivation: AI技术虽然取得重大突破，但如何公平负责地使用AI来真正改善全球人类状况仍面临深刻挑战，特别是在教育领域的应用

Method: 提供关于AI在教育环境中使用的核心技术问题的入门知识，包括确保公平性、处理幻觉输出、资源高效使用等，并通过开发沉浸式结构化"智能教科书"来说明这些考虑因素

Result: 提出了将AI工具应用于信号处理教育的具体方法，包括技术限制识别和实际应用改进，为研究者和教育者提供了资源

Conclusion: 文章为寻求推进AI在工程教育中作用的研究者和教育者提供了有价值的资源，强调了透明度、可解释性和可信赖性等关键考虑因素

Abstract: Powerful artificial intelligence (AI) tools that have emerged in recent years
-- including large language models, automated coding assistants, and advanced
image and speech generation technologies -- are the result of monumental human
achievements. These breakthroughs reflect mastery across multiple technical
disciplines and the resolution of significant technological challenges.
However, some of the most profound challenges may still lie ahead. These
challenges are not purely technical but pertain to the fair and responsible use
of AI in ways that genuinely improve the global human condition. This article
explores one promising application aligned with that vision: the use of AI
tools to facilitate and enhance education, with a specific focus on signal
processing (SP). It presents two interrelated perspectives: identifying and
addressing technical limitations, and applying AI tools in practice to improve
educational experiences. Primers are provided on several core technical issues
that arise when using AI in educational settings, including how to ensure
fairness and inclusivity, handle hallucinated outputs, and achieve efficient
use of resources. These and other considerations -- such as transparency,
explainability, and trustworthiness -- are illustrated through the development
of an immersive, structured, and reliable "smart textbook." The article serves
as a resource for researchers and educators seeking to advance AI's role in
engineering education.

</details>


### [3] [Ultrafast Deep Learning-Based Scatter Estimation in Cone-Beam Computed Tomography](https://arxiv.org/abs/2509.08973)
*Harshit Agrawal,Ari Hietanen,Simo Särkkä*

Main category: eess.SP

TL;DR: 本研究通过下采样技术优化深度学习网络，在维持散射估计精度的同时大幅降低计算复杂度和资源消耗，为移动CBCT系统提供了可行的散射美化解决方案。


<details>
  <summary>Details</summary>
Motivation: 围绕散射估计深度学习模型在移动CBCT系统或边缘设备上部署时的资源约束问题，需要找到计算效率与准确性的最佳平衡点。

Method: 首先在六种分辨率下分析下上采样的重建误差，比较四种插值方法。然后在五种图像分辨率下训练最新的SOTA模型，评估FLOPs、推理时间和GPU内存的减少情况。

Result: 缩减输入尺寸和网络参数实现了FLOPs降低78倍，MAPE从4.42%降至3.85%，MSE从2.01×10˂²降至1.34×10˂²，推理时间和GPU内存分别减少16倍和12倍。

Conclusion: 研究强调了下采样在深度学习散射估计中的重要作用，通过资源需求的大幅降低，为移动CBCT和边缘设备上实现散射美化提供了可行性。

Abstract: Purpose: Scatter artifacts drastically degrade the image quality of cone-beam
computed tomography (CBCT) scans. Although deep learning-based methods show
promise in estimating scatter from CBCT measurements, their deployment in
mobile CBCT systems or edge devices is still limited due to the large memory
footprint of the networks. This study addresses the issue by applying networks
at varying resolutions and suggesting an optimal one, based on speed and
accuracy.
  Methods: First, the reconstruction error in down-up sampling of CBCT scatter
signal was examined at six resolutions by comparing four interpolation methods.
Next, a recent state-of-the-art method was trained across five image
resolutions and evaluated for the reductions in floating-point operations
(FLOPs), inference times, and GPU memory requirements.
  Results: Reducing the input size and network parameters achieved a 78-fold
reduction in FLOPs compared to the baseline method, while maintaining comarable
performance in terms of mean-absolute-percentage-error (MAPE) and
mean-square-error (MSE). Specifically, the MAPE decreased to 3.85% compared to
4.42%, and the MSE decreased to 1.34 \times 10^{-2} compared to 2.01 \times
10^{-2}. Inference time and GPU memory usage were reduced by factors of 16 and
12, respectively. Further experiments comparing scatter-corrected
reconstructions on a large, simulated dataset and real CBCT scans from water
and Sedentex CT phantoms clearly demonstrated the robustness of our method.
  Conclusion: This study highlights the underappreciated role of downsampling
in deep learning-based scatter estimation. The substantial reduction in FLOPs
and GPU memory requirements achieved by our method enables scatter correction
in resource-constrained environments, such as mobile CBCT and edge devices.

</details>


### [4] [6G Resilience -- White Paper](https://arxiv.org/abs/2509.09005)
*Hirley Alves,Nurul H. Mahmood,Onel L. A. López,Sumudu Samarakoon,Seppo Yrjölä,Matti Latva-Aho,Markku Juntti,Ari Pouttu,Armin Dekorsy,Arthur Sousa de Sena,Aydin Sezgin,Bho Matthiesen,Chafika Benzaid,Chathuranga Weeraddana,David Hutchison,Dileepa Marasinghe,Doganalp Ergenc,Eduard Jorswieck,Erkki Harjula,Falko Dressler,Harri Saarnisaari,Italo Atzeni,Jaap Van De Beek,Jacek Rak,Konstantin Mikhaylov,Lauri Loven,Madhusanka Liyanage,Marcos Katz,Marja Matinmikko-Blue,Mehdi Rasti,Mika Ylianttila Nhan Nguyen,Pawani Porambage,Petar Popovski,Petri Ahokangas,Premanandana Rajatheva,Robert-Jeron Reifert,Tharaka Hewa,Tommy Svensson*

Main category: eess.SP

TL;DR: 6G网络设计需要将韧性作为核心目标，通过3R框架（可靠性、鲁棒性、韧性）和四大可测量能力来应对复杂中断，采用边缘原生架构和AI驱动控制，同时考虑技术经济层面的开放平台和商业模式创新。


<details>
  <summary>Details</summary>
Motivation: 移动网络从效率优先转向可持续性导向，需要设计能够承受、适应和演进于长期复杂中断的6G网络，将韧性提升为与可持续性和效率并列的主要设计目标。

Method: 提出3R框架（可靠性、鲁棒性、韧性），转化为四大可测量能力：优雅降级、态势感知、快速重构、学习驱动的改进和恢复；采用边缘原生架构、开放接口、可编程性设计；结合AI原生控制环、零信任安全和关键流量优先的网络技术。

Result: 建立了完整的6G韧性设计框架，包括技术架构、能力定义和测量指标，提出了九种商业模式组和多种模式，为6G韧性发展提供了系统性的理论基础和实践指导。

Conclusion: 该白皮书作为6G韧性发展的初步步骤和催化剂，为研究人员、专业人士、政府官员和公众提供了理解和塑造6G韧性发展的基本组件，强调了韧性在6G设计中的核心地位及其跨领域重要性。

Abstract: 6G must be designed to withstand, adapt to, and evolve amid prolonged,
complex disruptions. Mobile networks' shift from efficiency-first to
sustainability-aware has motivated this white paper to assert that resilience
is a primary design goal, alongside sustainability and efficiency, encompassing
technology, architecture, and economics. We promote resilience by analysing
dependencies between mobile networks and other critical systems, such as
energy, transport, and emergency services, and illustrate how cascading
failures spread through infrastructures. We formalise resilience using the 3R
framework: reliability, robustness, resilience. Subsequently, we translate this
into measurable capabilities: graceful degradation, situational awareness,
rapid reconfiguration, and learning-driven improvement and recovery.
  Architecturally, we promote edge-native and locality-aware designs, open
interfaces, and programmability to enable islanded operations, fallback modes,
and multi-layer diversity (radio, compute, energy, timing). Key enablers
include AI-native control loops with verifiable behaviour, zero-trust security
rooted in hardware and supply-chain integrity, and networking techniques that
prioritise critical traffic, time-sensitive flows, and inter-domain
coordination.
  Resilience also has a techno-economic aspect: open platforms and high-quality
complementors generate ecosystem externalities that enhance resilience while
opening new markets. We identify nine business-model groups and several
patterns aligned with the 3R objectives, and we outline governance and
standardisation. This white paper serves as an initial step and catalyst for 6G
resilience. It aims to inspire researchers, professionals, government
officials, and the public, providing them with the essential components to
understand and shape the development of 6G resilience.

</details>


### [5] [Personalized Sleep Prediction via Deep Adaptive Spatiotemporal Modeling and Sparse Data](https://arxiv.org/abs/2509.09018)
*Xueyi Wang,C. J. C.,Lamoth,Elisabeth Wilhelm*

Main category: eess.SP

TL;DR: 提出了AdaST-Sleep模型，结合CNN和RNN进行睡眠评分预测，通过领域分类器实现跨用户泛化，在多个时间窗口设置下优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 睡眠预测可以帮助个人和医疗保健提供者预见并主动解决影响休息质量的因素，从而改善身心健康。

Method: 使用卷积层捕捉多特征间的空间交互，循环神经网络层处理长期时间序列健康数据，集成领域分类器实现跨用户泛化。

Result: 在5种输入窗口大小和5种预测窗口大小的实验中均优于4个基线模型，最低RMSE为0.282（7天输入窗口+1天预测窗口），在多日预测中保持强劲性能。

Conclusion: 该框架为使用商业可穿戴设备稀疏数据和领域自适应技术提供了稳健且适应性强的个性化睡眠预测解决方案。

Abstract: A sleep forecast allows individuals and healthcare providers to anticipate
and proactively address factors influencing restful rest, ultimately improving
mental and physical well-being. This work presents an adaptive spatial and
temporal model (AdaST-Sleep) for predicting sleep scores. Our proposed model
combines convolutional layers to capture spatial feature interactions between
multiple features and recurrent neural network layers to handle longer-term
temporal health-related data. A domain classifier is further integrated to
generalize across different subjects. We conducted several experiments using
five input window sizes (3, 5, 7, 9, 11 days) and five predicting window sizes
(1, 3, 5, 7, 9 days). Our approach consistently outperformed four baseline
models, achieving its lowest RMSE (0.282) with a seven-day input window and a
one-day predicting window. Moreover, the method maintained strong performance
even when forecasting multiple days into the future, demonstrating its
versatility for real-world applications. Visual comparisons reveal that the
model accurately tracks both the overall sleep score level and daily
fluctuations. These findings prove that the proposed framework provides a
robust and adaptable solution for personalized sleep forecasting using sparse
data from commercial wearable devices and domain adaptation techniques.

</details>


### [6] [Improving the Elevational Focusing of Fast Orthogonal Row-Column Electronic Scanning (FORCES) Ultrasound Imaging using Retrospective Transmit Beamforming (RTB)](https://arxiv.org/abs/2509.09056)
*Michael Caulfield,Randy Palamar,Darren Dahunsi,Mohammad Rahim Sobhani,Negar Majidi,Roger Zemp*

Main category: eess.SP

TL;DR: 基于行列数组(RCA)的FORCES成像方案存在载波方向焦点外焦聚性能差的问题，本研究通过引入载波方向还顿传输波束形技术(RTB)来改善远离焦点处的载波焦聚性能。


<details>
  <summary>Details</summary>
Motivation: 解决FORCES成像方案因固定载波焦点和大传输孔径导致的远离焦点处载波焦聚性能差的问题，提高体积成像质量。

Method: 对FORCES和uFORCES方法应用载波方向还顿传输波束形技术(RTB)，通过线阶幻像和囊性幻像实验评估性能。

Result: 实验结果显示RTB技术显著改善了远离焦点处的载波焦聚性能，在焦点处保持或改善了性能，通过半高宽度和对比度噪声比进行了量化验证。

Conclusion: 还顿传输波束形技术有效提升了FORCES方案的载波焦聚性能，特别是在远离焦点区域，为提高体积成像质量提供了有效方案。

Abstract: Recent developments in Row Column Arrays (RCAs) have presented promising
options for volumetric imaging without the need for the excessive channel
counts of fully wired 2D-arrays. Bias programmable RCAs, also known as Top
Orthogonal to Bottom Electrode (TOBE) Arrays, show further promise in that
imaging schemes, such as Fast Orthogonal Row-Column Electronic Scanning
(FORCES) allow for full transmit and receive focusing everywhere in the image
plane. However, due to its fixed elevational focus and large transmit aperture,
FORCES experiences poor elevational focusing away from the focal point. In this
study we present a modification to the FORCES imaging scheme by applying
Retrospective Transmit Beamforming (RTB) in the elevational direction to allow
for elevational transmit focusing everywhere in the imaging plane. We evaluate
FORCES and uFORCES methods, with and without RTB applied, when imaging both a
cyst and wire phantom. With experiment we show improved elevational focusing
capabilities away from the focal point when RTB is applied to both FORCES and
uFORCES. At the focal point, performance with RTB remains comparable or
improved relative to standard FORCES. This is quantified by the measurement of
Full Width Half Max when imaging the wire phantom, and by the generalized
Contrast to Noise Ratio when imaging the tubular cyst phantom. We also
demonstrate the volumetric imaging capabilities of FORCES RTB with the wire
phantom.

</details>


### [7] [Signed Graph Learning with Hidden Nodes](https://arxiv.org/abs/2509.09120)
*Rong Ye,Xue-Qin Jiang,Hui Feng,Jian Wang,Runhe Qiu*

Main category: eess.SP

TL;DR: 提出了一种考虑隐藏节点的符号图学习方法SGL-HNCS，通过列稀疏正则化约束优化问题来重构符号图拉普拉斯矩阵


<details>
  <summary>Details</summary>
Motivation: 现有符号图学习方法通常假设所有节点都可见，但在实际应用中往往只有部分节点可观测，其余节点保持隐藏状态，需要解决这一挑战

Method: 基于图信号在符号图上的平滑性假设，将拓扑推断建模为带列稀疏正则化的约束优化问题，使用定制的块坐标下降(BCD)方法求解

Result: 在合成数据和真实数据上的实验结果表明所提出的SGL-HNCS方法具有高效性

Conclusion: 该方法能够有效处理存在隐藏节点的符号图学习问题，通过正则化约束成功重构符号图结构

Abstract: Signed graphs, which are characterized by both positive and negative edge
weights, have recently attracted significant attention in the field of graph
signal processing (GSP). Existing works on signed graph learning typically
assume that all graph nodes are available. However, in some specific
applications, only a subset of nodes can be observed while the remaining nodes
stay hidden. To address this challenge, we propose a novel method for
identifying signed graph that accounts for hidden nodes, termed \textit{signed
graph learning with hidden nodes under column-sparsity regularization}
(SGL-HNCS). Our method is based on the assumption that graph signals are smooth
over signed graphs, i.e., signal values of two nodes connected by positive
(negative) edges are similar (dissimilar). Rooted in this prior assumption, the
topology inference of a signed graph is formulated as a constrained
optimization problem with column-sparsity regularization, where the goal is to
reconstruct the signed graph Laplacian matrix without disregarding the
influence of hidden nodes. We solve the constrained optimization problem using
a tailored block coordinate descent (BCD) approach. Experimental results using
synthetic data and real-world data demonstrate the efficiency of the proposed
SGL-HNCS method.

</details>


### [8] [Sequential Spectral Clustering of Data Sequences](https://arxiv.org/abs/2509.09144)
*G Dhinesh Chandran,Kota Srinivas Reddy,Srikrishna Bhashyam*

Main category: eess.SP

TL;DR: 这篇论文研究数据序列的非参数分彩问题，提出了两种新的序列谱分彩算法（SEQ-SPEC和IA-SEQ-SPEC），证明了其有限时间停止和指数一致性，并通过模拟实验验证了其优劣性能。


<details>
  <summary>Details</summary>
Motivation: 解决在真实分布未知情况下，如何通过观测最小样本量来估计数据序列的分彩，以获得超越固定样本量方法的性能。

Method: 提出了序列谱分彩算法（SEQ-SPEC）和增量近似序列谱分彩算法（IA-SEQ-SPEC），前者保证了算法性能，后者在计算效率上更高。

Result: 算法几乎必然在有限时间停止且具有指数一致性。模拟实验显示，新算法在合成和真实数据集上都超过了固定样本量SPEC、序列K-Medoids和序列单链分彩算法的性能。

Conclusion: 这是首个在序列框架下进行数据序列谱分彩的研究，IA-SEQ-SPEC算法在保持计算效率的同时性能接近SEQ-SPEC，为序列分彩领域提供了有效解决方案。

Abstract: We study the problem of nonparametric clustering of data sequences, where
each data sequence comprises i.i.d. samples generated from an unknown
distribution. The true clusters are the clusters obtained using the Spectral
clustering algorithm (SPEC) on the pairwise distance between the true
distributions corresponding to the data sequences. Since the true distributions
are unknown, the objective is to estimate the clusters by observing the minimum
number of samples from the data sequences for a given error probability. To
solve this problem, we propose the Sequential Spectral clustering algorithm
(SEQ-SPEC), and show that it stops in finite time almost surely and is
exponentially consistent. We also propose a computationally more efficient
algorithm called the Incremental Approximate Sequential Spectral clustering
algorithm (IA-SEQ-SPEC). Through simulations, we show that both our proposed
algorithms perform better than the fixed sample size SPEC, the Sequential
$K$-Medoids clustering algorithm (SEQ-KMED) and the Sequential Single Linkage
clustering algorithm (SEQ-SLINK). The IA-SEQ-SPEC, while being computationally
efficient, performs close to SEQ-SPEC on both synthetic and real-world
datasets. To the best of our knowledge, this is the first work on spectral
clustering of data sequences under a sequential framework.

</details>


### [9] [JFRFFNet: A Data-Model Co-Driven Graph Signal Denoising Model with Partial Prior Information](https://arxiv.org/abs/2509.09147)
*Ziqi Yan,Zhichao Zhang*

Main category: eess.SP

TL;DR: 提出了JFRFFNet方法，将联合时-顶点分数傅里叶变换域的维纳滤波模型嵌入神经网络，通过数据驱动方式更新变换阶数对和滤波器系数，仅需部分先验信息即可有效去噪


<details>
  <summary>Details</summary>
Motivation: 传统滤波模型需要完整的图信号先验信息，要么使用网格搜索确定变换阶数对和计算滤波器系数，要么使用梯度下降策略优化，限制了实际应用

Method: 将JFRFT域维纳滤波模型嵌入神经网络架构，通过数据驱动方式联合优化变换阶数对和滤波器系数，只需要部分先验信息

Result: 实验表明JFRFFNet在输出信噪比方面相比现有最先进方法有显著提升

Conclusion: 提出的数据-模型协同驱动去噪方法能够有效克服传统方法对完整先验信息的依赖，在时变图信号去噪方面表现出优越性能

Abstract: Wiener filtering in the joint time-vertex fractional Fourier transform
(JFRFT) domain has shown high effectiveness in denoising time-varying graph
signals. Traditional filtering models use grid search to determine the
transform-order pair and compute filter coefficients, while learnable ones
employ gradient-descent strategies to optimize them; both require complete
prior information of graph signals. To overcome this shortcoming, this letter
proposes a data-model co-driven denoising approach, termed neural-network-aided
joint time-vertex fractional Fourier filtering (JFRFFNet), which embeds the
JFRFT-domain Wiener filter model into a neural network and updates the
transform-order pair and filter coefficients through a data-driven approach.
This design enables effective denoising using only partial prior information.
Experiments demonstrate that JFRFFNet achieves significant improvements in
output signal-to-noise ratio compared with some state-of-the-art methods.

</details>


### [10] [On Sampling of Multiple Correlated Stochastic Signals](https://arxiv.org/abs/2509.09225)
*Lin Jin,Hang Sheng,Hui Feng,Bo Hu*

Main category: eess.SP

TL;DR: 该论文提出了一种利用多通道随机信号统计相关性的高效采样方法，通过建模为少量不相关潜在源的线性组合，建立了零均方误差重建的理论采样密度下界，并开发了达到该下界的多频带采样方案。


<details>
  <summary>Details</summary>
Motivation: 传统采样方法独立处理每个通道会导致数据冗余，而多通道随机信号存在内在统计相关性，需要利用这种相关性来提高采样效率。

Method: 将相关通道建模为少量不相关宽平稳潜在源的线性组合，通过潜在源的频谱分割，然后进行时空采样和插值，构建多频带采样方案。

Result: 实验证明，该方法在理论采样密度下实现了近乎无损的重建，验证了其效率。

Conclusion: 提出的采样方案能够有效利用信号相关性，达到理论最优采样效率，为多通道信号处理提供了高效解决方案。

Abstract: Multiple stochastic signals possess inherent statistical correlations, yet
conventional sampling methods that process each channel independently result in
data redundancy. To leverage this correlation for efficient sampling, we model
correlated channels as a linear combination of a smaller set of uncorrelated,
wide-sense stationary latent sources. We establish a theoretical lower bound on
the total sampling density for zero mean-square error reconstruction, proving
it equals the ratio of the joint spectral bandwidth of latent sources to the
number of correlated signal channels. We then develop a constructive multi-band
sampling scheme that attains this bound. The proposed method operates via
spectral partitioning of the latent sources, followed by spatio-temporal
sampling and interpolation. Experiments on synthetic and real datasets confirm
that our scheme achieves near-lossless reconstruction precisely at the
theoretical sampling density, validating its efficiency.

</details>


### [11] [Improved Riemannian potato field: an Automatic Artifact Rejection Method for EEG](https://arxiv.org/abs/2509.09264)
*Davoud Hajhassani,Quentin Barthélemy,Jérémie Mattout,Marco Congedo*

Main category: eess.SP

TL;DR: iRPF是一种快速全自动的EEG伪影去除方法，在多个指标上显著优于现有方法，处理速度快，适用于大规模EEG数据处理和实时应用。


<details>
  <summary>Details</summary>
Motivation: EEG信号清洁是研究领域的关键挑战，现有方法依赖人工超参数调优、对异常值敏感且计算成本高，需要自动化解决方案来替代耗时的主观人工检查。

Method: 改进的黎曼土豆场(iRPF)方法，是一种快速全自动的EEG伪影拒绝技术，基于黎曼几何原理，无需手动超参数调优。

Result: 在226个EEG记录上测试，iRPF相比Isolation Forest、Autoreject等方法，召回率提升22%，特异性提升102%，精确度提升54%，F1分数提升24%，统计显著性p<0.001。

Conclusion: iRPF为脑机接口和临床神经影像应用提供了强大、数据驱动的伪影拒绝解决方案，具有高效处理大规模EEG数据的潜力。

Abstract: Electroencephalography (EEG) signal cleaning has long been a critical
challenge in the research community. The presence of artifacts can
significantly degrade EEG data quality, complicating analysis and potentially
leading to erroneous interpretations. While various artifact rejection methods
have been proposed, the gold standard remains manual visual inspection by human
experts-a process that is time-consuming, subjective, and impractical for
large-scale EEG studies. Existing techniques are often hindered by a strong
reliance on manual hyperparameter tuning, sensitivity to outliers, and high
computational costs. In this paper, we introduce the improved Riemannian Potato
Field (iRPF), a fast and fully automated method for EEG artifact rejection that
addresses key limitations of current approaches. We evaluate iRPF against
several state-of-the-art artifact rejection methods, using two publicly
available EEG databases, labeled for various artifact types, comprising 226 EEG
recordings. Our results demonstrate that iRPF outperforms all competitors
across multiple metrics, with gains of up to 22% in recall, 102% in
specificity, 54% in precision, and 24% in F1-score, compared to Isolation
Forest, Autoreject, Riemannian Potato, and Riemannian Potato Field,
respectively. Statistical analysis confirmed the significance of these
improvements (p < 0.001) with large effect sizes (Cohen's d > 0.8) in most
comparisons. Additionally, on a typical EEG recording iRPF performs artifact
cleaning in under 8 milliseconds per epoch using a standard laptop,
highlighting its efficiency for large-scale EEG data processing and real-time
applications. iRPF offers a robust and data-driven artifact rejection solution
for high-quality EEG pre-processing in brain-computer interfaces and clinical
neuroimaging applications.

</details>


### [12] [On the Relation of Characteristic Modes of Different Conducting Structures](https://arxiv.org/abs/2509.09282)
*Leonardo Mörlein,Dirk Manteuffel*

Main category: eess.SP

TL;DR: 推导了一种形式方法，通过基于超集结构特征模态的公共基础来分析导体结构的散射特性，并定义模态变换矩阵来描述不同结构间的映射关系。


<details>
  <summary>Details</summary>
Motivation: 为了在一个公共的特征模态基础上分析和比较不同的结构，提高设计效率和理论分析能力。

Method: 通过引入模态变换矩阵来描述两个结构特征模态之间的映射关系，并进行散射矩阵和微氧矩阵的基出变换。

Result: 证明在这种情况下散射矩阵和微氧矩阵不再是对角阵，并通过两个实例验证了形式方法的有效性。

Conclusion: 该形式方法为天线元件的渐进式设计提供了理论基础，能够在公共基础上对不同结构进行分析和比较。

Abstract: A formalism is derived to analyze the scattering of a conducting structure
based on the characteristic modes of another structure whose surface is a
superset of the first structure. This enables the analysis and comparison of
different structures using a common basis of characteristic modes.
Additionally, it is shown that the scattering matrices and perturbation
matrices are no longer diagonal in these cases. Based on this, a modal
transformation matrix is defined to describe the mapping between the
characteristic fields and the weighting coefficients of the two structures.
This matrix enables the conversion of the perturbation matrices in different
bases. Finally, two examples are provided along with a discussion of some
aspects of the theory. The first example aims to validate and illustrate the
formalism. The second example shows how the formalism can be applied in the
design process of an antenna element that is gradually modified, starting from
a base structure.

</details>


### [13] [Channel Estimation and Analog Precoding for Pixel-based Fluid-Antenna-Assisted Multiuser MIMO-OFDM Systems](https://arxiv.org/abs/2509.09373)
*Huayan Guo,Jichen Zhang,Junhui Rao,Ross Murch,Vincent K. N. Lau*

Main category: eess.SP

TL;DR: 基于浓稀通道恢复框架的流体天线多用户MIMO-OFDM系统，提出了两种低复杂度通道估计算法和模拟预编码方案，在高信噪比环境下显著优于基准方法。


<details>
  <summary>Details</summary>
Motivation: 像素基流体天线虽提供了更好的多工收益，但引入了状态非可分离通道响应问题，对通道估计和模拟预编码造成挑战。

Method: 提出了一个浓稀通道恢复框架，使用近似可分离通道响应模型和DNN基天线辐射函数，并设计了两种低复杂度算法：正交匹配追踪法和变分贝叶斯推断法。

Result: 模拟结果显示，提出的方法在高信噪比环境下显著优于多个基准方法，特别是在用户数量较多时。

Conclusion: 该研究为流体天线系统提供了高效的通道估计和预编码方案，能够准确预测不同天线状态的复合通道，从而优化天线切换状态选择。

Abstract: Pixel-based fluid antennas provide enhanced multiplexing gains and quicker
radiation pattern switching than traditional designs. However, this innovation
introduces challenges for channel estimation and analog precoding due to the
state-non-separable channel response problem. This paper explores a multiuser
MIMO-OFDM system utilizing pixel-based fluid antennas, informed by measurements
from a real-world prototype. We present a sparse channel recovery framework for
uplink channel sounding, employing an approximate separable channel response
model with DNN-based antenna radiation functions. We then propose two
low-complexity channel estimation algorithms that leverage orthogonal matching
pursuit and variational Bayesian inference to accurately recover channel
responses across various scattering cluster angles. These estimations enable
the prediction of composite channels for all fluid antenna states, leading to
an analog precoding scheme that optimally selects switching states for
different antennas. Our simulation results indicate that the proposed approach
significantly outperforms several baseline methods, especially in high
signal-to-noise ratio environments with numerous users.

</details>


### [14] [A Multi-Scale Feature Extraction and Fusion UNet for Pathloss Prediction in UAV-Assisted mmWave Radio Networks](https://arxiv.org/abs/2509.09606)
*Sajjad Hussain*

Main category: eess.SP

TL;DR: 提出基于UNet的深度学习架构，用于无人机毫米波网络路径损耗预测，结合多尺度特征提取和ASPP瓶颈，在精度和效率上优于现有方法


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法在跨环境泛化、噪声鲁棒性和无人机高度敏感性方面研究不足，需要更准确的路径损耗预测来优化无人机毫米波网络设计

Method: 使用UNet架构，结合多尺度特征提取、卷积特征融合和ASPP瓶颈进行上下文聚合，输入包括对数距离、LOS掩码和建筑掩码，并开发了向量化LOS掩码计算算法加速预处理

Result: 在内部射线追踪数据和RadioMapSeer基准测试中，该模型在准确性和效率方面均优于多个最先进的基线方法

Conclusion: 所提出的深度学习架构能够有效解决无人机毫米波网络路径损耗预测问题，具有优异的性能和泛化能力，公开源代码支持可重复性和未来研究

Abstract: Accurate pathloss prediction is essential for the design and optimization of
UAV-assisted millimeter-wave (mmWave) networks. While deep learning approaches
have shown strong potential, their generalization across diverse environments,
robustness to noisy inputs, and sensitivity to UAV altitude remain
underexplored. To address these challenges, we propose a UNet-based deep
learning architecture that combines multi-scale feature extraction,
convolution-based feature fusion, and an atrous spatial pyramid pooling (ASPP)
bottleneck for efficient context aggregation. The model predicts pathloss maps
from log-distance, line-of-sight (LOS) mask, and building mask inputs. In
addition, we develop a fully vectorized LOS mask computation algorithm that
significantly accelerates pre-processing and enables large-scale dataset
generation. Extensive evaluations on both in-house ray-tracing data and the
RadioMapSeer benchmark demonstrate that the proposed model outperforms several
state-of-the-art baselines in accuracy and efficiency. All source code is
publicly released to support reproducibility and future research.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [15] [Improved Receiver Chain Performance via Error Location Inference](https://arxiv.org/abs/2509.08869)
*Michael Greenwood,Robert Hunter*

Main category: cs.IT

TL;DR: 使用机器学习模型在解码端估计字节级错误概率，通过标记擦除来增强RS解码能力，无需改变硬件或编码标准，在信号条件恶化时提升0.3dB的数据恢复性能


<details>
  <summary>Details</summary>
Motivation: 传统航天器通信系统使用卷积码和RS码的级联纠错方案，但在信号条件恶化时纠错能力有限，需要在不改变现有硬件和编码标准的前提下提升性能

Method: 在解码端使用机器学习模型估计接收数据帧中字节级损坏的可能性，用这些估计值在RS解码前标记擦除，从而增强RS解码的纠错能力

Result: 该方法在信号条件恶化时实现了0.3分贝的性能增益，提高了数据恢复能力

Conclusion: 提出的机器学习辅助擦除标记方法有效提升了现有航天器通信系统的纠错性能，且具有向后兼容性，无需修改硬件或编码标准

Abstract: Modern spacecraft communication systems rely on concatenated error correction
schemes, typically combining convolutional and Reed-Solomon (RS) codes. This
paper presents a decoder-side method that uses a machine learning model to
estimate the likelihood of byte-level corruption in received data frames. These
estimates are used to mark erasures prior to RS decoding, enhancing its
correction capacity without requiring changes to spacecraft hardware or
encoding standards. The approach enables improved data recovery under degraded
signal conditions at a gain of 0.3 decibels.

</details>


### [16] [Gaussian Copula-Based Outage Performance Analysis of Fluid Antenna Systems: Channel Coefficient- or Envelope-Level Correlation Matrix?](https://arxiv.org/abs/2509.09411)
*Rui Xu,Yinghui Ye,Xiaoli Chu,Guangyue Lu,Farshad Rostami Ghadi,Kai-Kit Wong*

Main category: cs.IT

TL;DR: 本文探讨了在流体天线系统(FAS)中使用温度相关矩阵替代系数相关矩阵来评估故障性能的优势，并在Nakagami-m衰落下验证了其更高的准确性。


<details>
  <summary>Details</summary>
Motivation: 之前的研究使用Jake模型的通道系数相关矩阵来近似Gaussian copula中的协方差矩阵，但因为多元正态随机变量是通过变换相关通道包络生成的，所以使用温度相关矩阵可能更为准确。

Method: 在完全相关的Nakagami-m衰落环境下，研究了使用温度相关矩阵的优势，并开发了一种生成这种衰落通道的方法用于Monte Carlo模拟，作为理论结果的验证标准。

Result: 模拟结果证实了所提出的通道建模方法的有效性，并显示使用温度相关矩阵具有更高的准确性，尤其在稀疏端口部署和低故障率区域。

Conclusion: 这项研究解决了关于使用系数相关或温度相关矩阵哪个更准确的问题，证明了在FAS性能评估中使用温度相关矩阵的优势。

Abstract: Gaussian copula has been employed to evaluate the outage performance of Fluid
Antenna Systems (FAS), with the covariance matrix reflecting the dependence
among multivariate normal random variables (RVs). While prior studies
approximate this matrix using the channel coefficient correlation matrix from
Jake's model, this work instead employs the channel envelope correlation
matrix, motivated by the fact that the multivariate normal RVs are generated by
transforming correlated channel envelopes. This raises an open question of
whether using the coefficient- or envelope-level correlation matrix yields
better accuracy in accessing FAS performance. Toward this end, this paper
explores the benefits of using the envelope-level correlation matrix under
fully correlated Nakagami-m fading, and develops a method for generating such
fading channels for Monte Carlo simulations, which serve as a benchmark for
validating the theoretical results. Simulation results confirm the
effectiveness of the proposed channel modeling approach and demonstrate the
superior accuracy of using the envelope-level correlation matrix, particularly
in sparse port deployment and low-outage regime.

</details>


### [17] [Mixture of Semantics Transmission for Generative AI-Enabled Semantic Communication Systems](https://arxiv.org/abs/2509.09499)
*Junjie Ni,Tong Wu,Zhiyong Chen,Yin Xu,Meixia Tao,Wenjun Zhang*

Main category: cs.IT

TL;DR: 提出基于生成式AI的混合语义传输策略(MoS)，通过ROI和RONI分区处理实现无线语义通信中信道资源的高效利用


<details>
  <summary>Details</summary>
Motivation: 现有基于生成式AI的语义通信方法在信道资源利用效率方面存在不足，需要平衡视觉保真度和语义相关性

Method: 在发送端将图像分为感兴趣区域(ROI)和非感兴趣区域(RONI)，分别提取语义信息并分配不同带宽；在接收端使用扩散模型根据接收到的语义信息重建完整图像

Result: 实验结果表明适当的ROI-RONI分配至关重要，MoS在ROI的PSNR和RONI的CLIP分数方面取得了显著的性能提升

Conclusion: MoS策略通过语义分区传输实现了更高效的信道资源利用，在视觉保真度和语义相关性之间取得了良好平衡

Abstract: In this paper, we propose a mixture of semantics (MoS) transmission strategy
for wireless semantic communication systems based on generative artificial
intelligence (AI). At the transmitter, we divide an image into regions of
interest (ROI) and reigons of non-interest (RONI) to extract their semantic
information respectively. Semantic information of ROI can be allocated more
bandwidth, while RONI can be represented in a compact form for transmission. At
the receiver, a diffusion model reconstructs the full image using the received
semantic information of ROI and RONI. Compared to existing generative AI-based
methods, MoS enables more efficient use of channel resources by balancing
visual fidelity and semantic relevance. Experimental results demonstrate that
appropriate ROI-RONI allocation is critical. The MoS achieves notable
performance gains in peak signal-to-noise ratio (PSNR) of ROI and CLIP score of
RONI.

</details>


### [18] [Fast Polarisation-Aware Decoder for Non-Binary Polar Codes](https://arxiv.org/abs/2509.09554)
*Joseph Jabbour,Ali Chamas Al-Ghouwayel,Emmanuel Boutillon*

Main category: cs.IT

TL;DR: 提出了一种低复杂度非二进制极化码解码器FSC-PA，通过定制化每个核的解码过程，在BPSK和CCSK调制下显著降低计算复杂度，相比现有算法减少60%域加法和30%实数加法，性能损失仅0.2dB


<details>
  <summary>Details</summary>
Motivation: 非二进制极化码解码器计算复杂度高，需要开发低复杂度解码方案来提升实际应用可行性

Method: 通过离线分析定制每个极化核的解码过程，提出FSC-PA（快速连续消除-极化感知）方案，最小化具有相同输入极化水平的奇偶校验节点的计算负载

Result: 相比最先进的扩展最小和算法，FSC-PA算法实现了域加法减少60%，实数加法减少30%，性能损失仅0.2dB

Conclusion: FSC-PA方案通过核级定制化有效降低了非二进制极化码解码的计算复杂度，在保持接近最优性能的同时显著提升了计算效率

Abstract: The paper investigates the emerging field of low-complexity non-binary polar
code (NB-PC) decoders. It shows that customizing each kernel of an NB-PC
decoder through offline analysis can significantly reduce the overall decoding
complexity. The proposed decoder, referred to as the Fast Successive
Cancellation-Polarization Aware (FSC-PA) scheme, achieves this by minimizing
the computational load of parity-check nodes that share the same level of input
polarization. The NB polar decoder is developed for both BPSK and CCSK
modulations. Compared to the state-of-the-art extended min-sum algorithm, the
FSC-PA algorithm achieves an overall reduction of 60 percents in field
additions and 30 percents in real additions, while incurring only a negligible
performance loss (less than 0.2 dB degradation).

</details>


### [19] [RSMA-Enhanced Data Collection in RIS-Assisted Intelligent Consumer Transportation Systems](https://arxiv.org/abs/2509.09644)
*Chunjie Wang,Xuhui Zhang,Wenchao Liu,Jinke Ren,Shuqiang Wang,Yanyan Shen,Kejiang Ye,Kim Fung Tsang*

Main category: cs.IT

TL;DR: 提出了一种RIS赋能的智能交通系统数据收集增强框架，通过联合优化RIS相移、功率分配、计算资源和时隙分配，最大化RSU对的最小处理数据量


<details>
  <summary>Details</summary>
Motivation: 解决智能交通系统中数据收集和处理效率问题，利用RIS技术增强通信性能，提高数据处理能力

Method: 采用混合RSMA和TDMA协议，结合交替优化和顺序秩一约束松弛方法，开发高效迭代算法

Result: 大量仿真表明，所提算法在不同场景下显著优于基线方案，有效提升了智能交通应用的数据处理性能

Conclusion: 该框架和算法为RIS赋能的智能交通系统提供了有效的数据收集和处理增强解决方案

Abstract: This paper investigates the data collection enhancement problem in a
reconfigurable intelligent surface (RIS)-empowered intelligent consumer
transportation system (ICTS). We propose a novel framework where a data center
(DC) provides energy to pre-configured roadside unit (RSU) pairs during the
downlink stage. While in the uplink stage, these RSU pairs utilize a hybrid
rate-splitting multiple access (RSMA) and time-division multiple access (TDMA)
protocol to transmit the processed data to the DC, while simultaneously
performing local data processing using the harvested energy. Our objective is
to maximize the minimal processed data volume of the RSU pairs by jointly
optimizing the RIS downlink and uplink phase shifts, the transmit power of the
DC and RSUs, the RSU computation resource allocation, and the time slot
allocation. To address the formulated non-convex problem, we develop an
efficient iterative algorithm integrating alternating optimization and
sequential rank-one constraint relaxation methods. Extensive simulations
demonstrate that the proposed algorithm significantly outperforms baseline
schemes under diverse scenarios, validating its effectiveness in enhancing the
data processing performance for intelligent transportation applications.

</details>
