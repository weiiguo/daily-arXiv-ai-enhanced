<div id=toc></div>

# Table of Contents

- [cs.IT](#cs.IT) [Total: 9]
- [eess.SP](#eess.SP) [Total: 44]


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [1] [Bayesian Learning for Pilot Decontamination in Cell-Free Massive MIMO](https://arxiv.org/abs/2508.11791)
*Christian Forsch,Zilu Zhao,Dirk Slock,Laura Cottatellucci*

Main category: cs.IT

TL;DR: 提出基于期望传播的联合信道估计与数据检测算法，用于缓解无蜂窝大规模MIMO系统中的导频污染问题，该算法具有分布式、可扩展性强、对导频污染鲁棒性好等优点。


<details>
  <summary>Details</summary>
Motivation: 导频污染在用户设备使用非正交导频序列时产生，严重影响无蜂窝大规模MIMO系统的上行链路性能，需要开发有效的算法来缓解这一问题。

Method: 提出改进的双线性期望传播算法，实现分布式联合信道估计和数据检测，通过贝叶斯学习方法处理非正交导频序列。

Result: 算法在导频污染环境下表现优异，性能优于现有最先进的贝叶斯学习算法，且使用非正交导频相比共享正交序列可获得更好性能。

Conclusion: 开发了新的用户级导频污染量化指标，证明算法性能与该指标呈单调递减关系，为通过迭代联合检测算法理解和管控导频污染提供了有价值的理论工具。

Abstract: Pilot contamination (PC) arises when the pilot sequences assigned to user
equipments (UEs) are not mutually orthogonal, eventually due to their reuse. In
this work, we propose a novel expectation propagation (EP)-based joint channel
estimation and data detection (JCD) algorithm specifically designed to mitigate
the effects of PC in the uplink of cell-free massive multiple-input
multiple-output (CF-MaMIMO) systems. This modified bilinear-EP algorithm is
distributed, scalable, demonstrates strong robustness to PC, and outperforms
state-of-the-art Bayesian learning algorithms. Through a comprehensive
performance evaluation, we assess the performance of Bayesian learning
algorithms for different pilot sequences and observe that the use of
non-orthogonal pilots can lead to better performance compared to shared
orthogonal sequences. Motivated by this analysis, we introduce a new metric to
quantify PC at the UE level. We show that the performance of the considered
algorithms degrades monotonically with respect to this metric, providing a
valuable theoretical and practical tool for understanding and managing PC via
iterative JCD algorithms.

</details>


### [2] [A Law of Emergence: Maximum Causal Power at the Mesoscale](https://arxiv.org/abs/2508.12016)
*Liang Chen*

Main category: cs.IT

TL;DR: 该论文发现并验证了一个关于涌现现象的中尺度峰值定理：对于具有局部相互作用的系统，有效信息EI_ℓ在介观尺度ℓ*处出现严格最大值，揭示了噪声平均与小尺度和局域性限制与大尺度之间的基本权衡。


<details>
  <summary>Details</summary>
Motivation: 复杂系统普遍表现出涌现现象，但缺乏预测这一过程的定量规律。研究旨在建立和验证一个能够识别涌现自然尺度的可证伪的第一性原理定律。

Method: 定义系统在空间尺度ℓ上的因果力为有效信息EI_ℓ，通过最大熵干预与其结果之间的互信息来测量。推导并证明了中尺度峰值定理，并在2D伊辛模型和基于agent的集体行为模型中提供定量、可重复的证据。

Result: 在两个不同领域中均明确确认了预测的单峰峰值：临界点附近的2D伊辛模型和基于agent的集体行为模型。统计模型选择有力地证实了这一规律。

Conclusion: 该工作建立了一个可证伪的第一性原理定律，能够识别涌现的自然尺度，为有效理论的发现提供了定量基础。

Abstract: Complex systems universally exhibit emergence, where macroscopic dynamics
arise from local interactions, but a predictive law governing this process has
been absent. We establish and verify such a law. We define a system's causal
power at a spatial scale, $\ell$, as its Effective Information (EI$_\ell$),
measured by the mutual information between a targeted, maximum-entropy
intervention and its outcome. From this, we derive and prove a Middle-Scale
Peak Theorem: for a broad class of systems with local interactions, EI$_\ell$
is not monotonic but exhibits a strict maximum at a mesoscopic scale $\ell^*$.
This peak is a necessary consequence of a fundamental trade-off between
noise-averaging at small scales and locality-limited response at large scales.
We provide quantitative, reproducible evidence for this law in two distinct
domains: a 2D Ising model near criticality and a model of agent-based
collective behavior. In both systems, the predicted unimodal peak is decisively
confirmed by statistical model selection. Our work establishes a falsifiable,
first-principles law that identifies the natural scale of emergence, providing
a quantitative foundation for the discovery of effective theories.

</details>


### [3] [Cylindrical RIS-Assisted Low-Complexity Transmission with Differentiated Visible Regions Exploiting Statistical CSI](https://arxiv.org/abs/2508.12229)
*Wenjun Teng,Weicong Chen,Yiping Zuo,Wankai Tang,Shi Jin*

Main category: cs.IT

TL;DR: 本文提出一种基于均匀圆柱数组结构的RIS阶段移位设计方法，通过分类优化用户专用单元咄多用户共享单元，大幅降低了多用户场景下的优化复杂度。


<details>
  <summary>Details</summary>
Motivation: 解决RIS在多用户场景下面临的两大挑战：大规模RIS元素导致的高维优化问题，以及共享RIS反射造成的多用户信号持续耦合问题。

Method: 利用均匀圆柱数组结构的可见区域特性，将RIS元素分为用户专用单元咄多用户共享单元两类。通过迭代优化多用户共享单元的阶段移位，并基于式解直接配置用户专用单元的阶段移位。

Result: 所提方法显著降低了优化复杂度，数值模拟结果证明了该方法在系统性能咄计算效率方面都对传统均匀平面数组RIS有显著改善。

Conclusion: 基于均匀圆柱数组结构的RIS阶段移位设计方法能够有效解决多用户场景下的高维优化咄信号耦合问题，为6G网络的可持续发展提供了有效的解决方案。

Abstract: Reconfigurable intelligent surfaces (RIS), recognized as a critical enabler
for 6G networks, exhibit unprecedented capabilities in electromagnetic wave
manipulation and wireless channel reconfiguration. By leveraging existing
network infrastructure, RIS can cost-effectively create signal hotspots in
low-altitude environments, ensuring robust connectivity to support the
sustainable development of the low-altitude economy. However, achieving optimal
phase shift design in multi-user scenarios faces two major challenges: the
high-dimensional optimization introduced by massive RIS elements, and the
persistent coupling of multi-user signals caused by shared RIS reflections.
This paper utilize the visible region of an RIS arranged as the uniform
cylindrical array (UCA) to reduce the complexity of phase shift design. Under
the UCA architecture, RIS elements are categorized into two types:
user-specific units and multi-user shared units. We then determine the optimal
phase shifts by iteratively optimizing the phase shifts of multi-user shared
units while directly configuring those of user-specific units based on a
derived closed-form solution. The proposed approach significantly reduces
optimization complexity, which is further corroborated by numerical simulation
results demonstrating its substantial impact on both system performance and
computational efficiency compared to the conventional RIS with uniform planar
array.

</details>


### [4] [Age of Semantic Information-Aware Wireless Transmission for Remote Monitoring Systems](https://arxiv.org/abs/2508.12248)
*Xue Han,Biqian Feng,Yongpeng Wu,Xiang-Gen Xia,Wenjun Zhang,Shengli Sun*

Main category: cs.IT

TL;DR: 这篇论文提出了一种新的语义通信指标AoIS，通过优化语义触发、收发梯度和语义符号设计，在MIMO通信中实现低时延高信息保真度的视频传输。


<details>
  <summary>Details</summary>
Motivation: 传统的信息新鲜度指标没有考虑语义重要性，需要一种能同时考虑信息时效性和语义意义的新指标来支持下一代智能化通信系统。

Method: 提出AoIS指标并构建时间平均最小化问题，通过Lyapunov优化和替代优化算法，使用SCA算法和低复杂度ZF算法优化收发梯度，采用突然搜索法解决语义触发策略和符号设计问题。

Result: 实验结果显示，在相同的AoIS条件下，该方案能够保留比基准方案多50%以上的原始信息。

Conclusion: AoIS作为一种新的语义通信评估指标，能够有效地结合信息时效性和语义重要性，为下一代智能通信系统提供了有效的解决方案。

Abstract: Semantic communication is emerging as an effective means of facilitating
intelligent and context-aware communication for next-generation communication
systems. In this paper, we propose a novel metric called Age of Incorrect
Semantics (AoIS) for the transmission of video frames over multiple-input
multiple-output (MIMO) channels in a monitoring system. Different from the
conventional age-based approaches, we jointly consider the information
freshness and the semantic importance, and then formulate a time-averaged AoIS
minimization problem by jointly optimizing the semantic actuation indicator,
transceiver beamformer, and the semantic symbol design. We first transform the
original problem into a low-complexity problem via the Lyapunov optimization.
Then, we decompose the transformed problem into multiple subproblems and adopt
the alternative optimization (AO) method to solve each subproblem.
Specifically, we propose two efficient algorithms, i.e., the successive convex
approximation (SCA) algorithm and the low-complexity zero-forcing (ZF)
algorithm for optimizing transceiver beamformer. We adopt exhaustive search
methods to solve the semantic actuation policy indicator optimization problem
and the transmitted semantic symbol design problem. Experimental results
demonstrate that our scheme can preserve more than 50\% of the original
information under the same AoIS compared to the constrained baselines.

</details>


### [5] [The extended code for a class of generalized Roth-Lempel codes and their properties](https://arxiv.org/abs/2508.12302)
*Zhonghao Liang,Qunying Liao*

Main category: cs.IT

TL;DR: 通过扩展GRL码定义了EGRL码，给出特殊类的检验矩阵，并完全确定了NMDS EGRL码的权重分布


<details>
  <summary>Details</summary>
Motivation: 许多重要的码都是通过修改或组合现有码得到的，需要研究扩展的GRL码类以获得更好的性能

Method: 定义EGRL码类，给出特殊类的检验矩阵，建立了EGRL码或对偶码为MDS或AMDS的充要条件，构造了NMDS EGRL码

Result: 构造了一类NMDS EGRL码，这是Han等人2023年构造的推广，并完全确定了其权重分布

Conclusion: EGRL码类提供了一种有效的码构造方法，对于获得具有良好性能的编码方案具有重要意义

Abstract: As we all know, many interesting and important codes are obtained by
modifying or combining existing codes. In this paper, we focus on generalized
Roth-Lempel (in short, GRL) codes and define a class of extended codes, i.e.,
the extended generalized Roth-Lempel (in short, EGRL) code. And then for a
special class of EGRL codes, we give a parity-check matrix and establish a
necessary and sufficient condition for the EGRL code or its dual code to be MDS
or AMDS, respectively. Finally, we construct a class of NMDS EGRL codes which
is the generalization of the constructions given by Han et al. in 2023, and
then completely determine its weight distribution.

</details>


### [6] [Algorithmic Improvements to List Decoding of Folded Reed-Solomon Codes](https://arxiv.org/abs/2508.12548)
*Vikrant Ashvinkumar,Mursalin Habib,Shashank Srivastava*

Main category: cs.IT

TL;DR: 本文改进了折叠Reed-Solomon码的列表解码算法，提出了确定性和随机性两种方法，在解码时间和复杂度方面都有显著提升


<details>
  <summary>Details</summary>
Motivation: 折叠Reed-Solomon码虽然能够达到列表解码容量，但现有的解码算法时间复杂度较高，需要开发更高效的解码算法

Method: 提出了新的确定性解码器，运行时间为近线性时间Õ_ε(n)；以及随机性解码器，运行时间为多项式时间poly(1/ε)·Õ(n)

Result: 确定性解码器将时间复杂度从n^Ω(1/ε)改进到Õ_ε(n)；随机性解码器将时间复杂度从exp(1/ε)·Õ(n)改进到poly(1/ε)·Õ(n)

Conclusion: 这是首次实现容量达到码的确定性解码能在Õ_ε(n)时间内完成，也是首次实现解码时间对1/ε呈多项式依赖的容量达到码

Abstract: Folded Reed-Solomon (FRS) codes are a well-studied family of codes, known for
achieving list decoding capacity. In this work, we give improved deterministic
and randomized algorithms for list decoding FRS codes of rate $R$ up to radius
$1-R-\varepsilon$.
  We present a deterministic decoder that runs in near-linear time
$\widetilde{O}_{\varepsilon}(n)$, improving upon the best-known runtime
$n^{\Omega(1/\varepsilon)}$ for decoding FRS codes. Prior to our work, no
capacity achieving code was known whose deterministic decoding could be done in
time $\widetilde{O}_{\varepsilon}(n)$.
  We also present a randomized decoder that runs in fully polynomial time
$\mathrm{poly}(1/\varepsilon) \cdot \widetilde{O}(n)$, improving the best-known
runtime $\mathrm{exp}(1/\varepsilon)\cdot \widetilde{O}(n)$ for decoding FRS
codes. Again, prior to our work, no capacity achieving code was known whose
decoding time depended polynomially on $1/\varepsilon$.

</details>


### [7] [Deep Semantic Inference over the Air: An Efficient Task-Oriented Communication System](https://arxiv.org/abs/2508.12748)
*Chenyang Wang,Roger Olsson,Stefan Forsström,Qing He*

Main category: cs.IT

TL;DR: 深度学习基于ResNet的任务导向语义通信框架，通过模型分割和语义特征压缩，在保持85%+ 准确性的同时显著降低计算和通信开销


<details>
  <summary>Details</summary>
Motivation: 优化语义通信系统的任务准确性、计算延迟和通信成本之间的交易关系，提高无线系统效率和智能化水平

Method: 采用ResNets模型，在CIFAR-10和CIFAR-100数据集上进行分类任务模拟，通过不同模型分割点和语义特征向量大小来系统分析性能与资源效率的交易关系

Result: 通过适当的模型分割和语义特征压缩，系统可以保持超过85%的基准准确性，同时显著降低计算负载和通信开销

Conclusion: 该深度学习基于任务导向的语义通信框架能够有效平衡任务性能与资源消耗，为高效智能无线系统提供了可行的解决方案

Abstract: Empowered by deep learning, semantic communication marks a paradigm shift
from transmitting raw data to conveying task-relevant meaning, enabling more
efficient and intelligent wireless systems. In this study, we explore a deep
learning-based task-oriented communication framework that jointly considers
classification performance, computational latency, and communication cost. We
adopt ResNets-based models and evaluate them on the CIFAR-10 and CIFAR-100
datasets to simulate real-world classification tasks in wireless environments.
We partition the model at various points to simulate split inference across a
wireless channel. By varying the split location and the size of the transmitted
semantic feature vector, we systematically analyze the trade-offs between task
accuracy and resource efficiency. Experimental results show that, with
appropriate model partitioning and semantic feature compression, the system can
retain over 85\% of baseline accuracy while significantly reducing both
computational load and communication overhead.

</details>


### [8] [Information-Theoretic Fairness with A Bounded Statistical Parity Constraint](https://arxiv.org/abs/2508.12847)
*Amirreza Zamani,Abolfazl Changizi,Ragnar Thobaben,Mikael Skoglund*

Main category: cs.IT

TL;DR: 本文研究设计满足有界统计公平性的表示学习问题，通过信息论方法在保证隐私泄露约束和压缩率约束下最大化任务相关信息。


<details>
  <summary>Details</summary>
Motivation: 解决在保护敏感属性隐私的同时，保持对目标任务有用信息的问题，放松完美统计公平性约束为有界约束，提高实用性。

Method: 使用功能表示引理的扩展版本和强功能表示引理，基于随机化技术，在特殊情况下研究边界的紧致性。

Result: 改进了完美统计公平性下的现有下界结果，提出了新的上界，证明了允许非零泄露可以提高获得的效用。

Conclusion: 提出的有界统计公平性框架在隐私保护和任务效用之间提供了更好的权衡，数值实验验证了边界的有效性。

Abstract: In this paper, we study an information-theoretic problem of designing a fair
representation that attains bounded statistical (demographic) parity. More
specifically, an agent uses some useful data $X$ to solve a task $T$. Since
both $X$ and $T$ are correlated with some sensitive attribute or secret $S$,
the agent designs a representation $Y$ that satisfies a bounded statistical
parity and/or privacy leakage constraint, that is, such that $I(Y;S) \leq
\epsilon$. Here, we relax the perfect demographic (statistical) parity and
consider a bounded-parity constraint. In this work, we design the
representation $Y$ that maximizes the mutual information $I(Y;T)$ about the
task while satisfying a bounded compression (or encoding rate) constraint, that
is, ensuring that $I(Y;X) \leq r$. Simultaneously, $Y$ satisfies the bounded
statistical parity constraint $I(Y;S) \leq \epsilon$. To design $Y$, we use
extended versions of the Functional Representation Lemma and the Strong
Functional Representation Lemma which are based on randomization techniques and
study the tightness of the obtained bounds in special cases. The main idea to
derive the lower bounds is to use randomization over useful data $X$ or
sensitive data $S$. Considering perfect demographic parity, i.e., $\epsilon=0$,
we improve the existing results (lower bounds) by using a tighter version of
the Strong Functional Representation Lemma and propose new upper bounds. We
then propose upper and lower bounds for the main problem and show that allowing
non-zero leakage can improve the attained utility. Finally, we study the bounds
and compare them in a numerical example. The problem studied in this paper can
also be interpreted as one of code design with bounded leakage and bounded rate
privacy considering the sensitive attribute as a secret.

</details>


### [9] [Research on GEO SA-Bi SAR Imaging based on Joint Radar-Communications Waveform](https://arxiv.org/abs/2508.12890)
*Meng Lian,Xu Zhu*

Main category: cs.IT

TL;DR: 本文提出了一种联合雷达-通信波形，用于同时执行GEO SA-Bi SAR成像和无线通信，并设计了相应的联合接收机来验证该系统的可行性。


<details>
  <summary>Details</summary>
Motivation: 随着频谱资源日益紧张和硬件平台共享需求的增长，需要开发能够同时执行感知和通信功能的联合系统，以有效利用频谱资源并实现雷达与通信系统的协同工作。

Method: 采用联合雷达-通信波形设计，开发了适用于GEO SA-Bi SAR系统的联合接收机，实现了同时进行SAR成像和无线通信的功能。

Result: 成功验证了在GEO SA-Bi SAR系统中同时实现感知和信令传输的可行性，证明了联合波形设计的有效性。

Conclusion: 联合雷达-通信波形设计不仅减少了频谱影响，而且能够相互提升两个系统的性能，为未来雷达通信一体化系统的发展提供了重要技术支撑。

Abstract: Joint radar-communications (JRC) technology has attracted massive attention
for decades, since it can effectively utilize allocated spectral resources by
sharing frequency bands in increasingly crowded environments. In addition, the
growing demand for hardware platform sharing which benefits both
functionalities motivates more cooperation between radar and communication
systems. In order to achieve the coexistence of sensing and communicating
operations, joint systems should be designed to perform both tasks
simultaneously. Developing a joint radar-communications waveform which is
suitable for both functions is extremely crucial for this type of co-design, as
it not only decreases spectral impact, but also benefits performances of both
systems mutually. In this paper, a joint radar-communications waveform is
utilized to perform GEO SA-Bi SAR imaging and wireless communication
simultaneously. We also design a joint radar-communications receiver in this
context to demonstrate feasibility of achieving both sensing and signaling with
GEO SA-Bi SAR system.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [10] [Vibe2Spike: Batteryless Wireless Tags for Vibration Sensing with Event Cameras and Spiking Networks](https://arxiv.org/abs/2508.11640)
*Danny Scott,William LaForest,Hritom Das,Ioannis Polykretis,Catherine D. Schuman,Charles Rizzo,James Plank,Sai Swaminathan*

Main category: eess.SP

TL;DR: Vibe2Spike是一个无电池无线传感框架，利用振动能量采集、可见光通信和脉冲神经网络实现振动活动识别，无需电池和射频模块。


<details>
  <summary>Details</summary>
Motivation: 现有传感解决方案在电池维护、无线传输开销和数据处理复杂性方面存在能量、可扩展性和可靠性之间的权衡问题，需要更高效的无电池传感方案。

Method: 使用仅包含压电盘、齐纳二极管和LED的超低成本标签采集振动能量并发射稀疏可见光脉冲，通过事件相机捕获光脉冲，并使用EONS框架优化的SNN模型进行分类。

Result: 在五个设备类别上实现了94.9%的平均分类准确率，并分析了不同时间分箱策略的延迟-准确性权衡。

Conclusion: Vibe2Spike展示了一种可扩展、高能效的无电池智能环境实现方法。

Abstract: The deployment of dense, low-cost sensors is critical for realizing
ubiquitous smart environments. However, existing sensing solutions struggle
with the energy, scalability, and reliability trade-offs imposed by battery
maintenance, wireless transmission overhead, and data processing complexity. In
this work, we present Vibe2Spike, a novel battery-free, wireless sensing
framework that enables vibration-based activity recognition using visible light
communication (VLC) and spiking neural networks (SNNs). Our system uses
ultra-low-cost tags composed only of a piezoelectric disc, a Zener diode, and
an LED, which harvest vibration energy and emit sparse visible light spikes
without requiring batteries or RF radios. These optical spikes are captured by
event cameras and classified using optimized SNN models evolved via the EONS
framework. We evaluate Vibe2Spike across five device classes, achieving 94.9\%
average classification fitness while analyzing the latency-accuracy trade-offs
of different temporal binning strategies. Vibe2Spike demonstrates a scalable,
and energy-efficient approach for enabling intelligent environments in a
batteryless manner.

</details>


### [11] [Data-driven RF Tomography via Cross-modal Sensing and Continual Learning](https://arxiv.org/abs/2508.11654)
*Yang Zhao,Tao Wang,Said Elhadi*

Main category: eess.SP

TL;DR: 数据驱动的无线电频成像技术DRIFT，通过跨模态感知和持续学习方法，在动态环境中实现了高精度的地下根块藕重建检测，比现有方法提升23.2%。


<details>
  <summary>Details</summary>
Motivation: 虽然数据驱动的RF成像技术在地下目标检测方面展现了强大潜力，但在动态环境中实现准确和稳健的性能仍面临挑战。需要开发能够适应RF信号显著变化的地下根块藕截面图像重建方法。

Method: 1）设计跨模态感知系统（RF和视觉传感器）
2）采用跨模态学习方法训练RF成像深度神经网络模型
3）应用持续学习技术，在检测到环境变化时自动更新DNN模型

Result: 实验结果显示，该方法平均相当直径误差仅2.29cm，比现有最优方法提升23.2%的性能改善。代码和数据集已在GitHub上公开。

Conclusion: DRIFT框架通过跨模态感知和持续学习的结合，有效解决了动态环境下RF成像的挑战，为地下目标检测提供了一种准确且稳健的解决方案，具有重要的应用价值。

Abstract: Data-driven radio frequency (RF) tomography has demonstrated significant
potential for underground target detection, due to the penetrative nature of RF
signals through soil. However, it is still challenging to achieve accurate and
robust performance in dynamic environments. In this work, we propose a
data-driven radio frequency tomography (DRIFT) framework with the following key
components to reconstruct cross section images of underground root tubers, even
with significant changes in RF signals. First, we design a cross-modal sensing
system with RF and visual sensors, and propose to train an RF tomography deep
neural network (DNN) model following the cross-modal learning approach. Then we
propose to apply continual learning to automatically update the DNN model, once
environment changes are detected in a dynamic environment. Experimental results
show that our approach achieves an average equivalent diameter error of 2.29
cm, 23.2% improvement upon the state-of-the-art approach. Our DRIFT code and
dataset are publicly available on https://github.com/Data-driven-RTI/DRIFT.

</details>


### [12] [Inductive transfer learning from regression to classification in ECG analysis](https://arxiv.org/abs/2508.11656)
*Ridma Jayasundara,Ishan Fernando,Adeepa Fernando,Roshan Ragel,Vajira Thambawita,Isuru Nawinne*

Main category: eess.SP

TL;DR: 本研究探讨了从回归到分类的迁移学习在ECG信号分析中的应用，证明这种方法可以提高分类性能，并有效利用合成ECG数据来保护患者隐私。


<details>
  <summary>Details</summary>
Motivation: 心血管疾病是全球主要死因，ECG是重要诊断工具，但患者数据隐私问题限制了研究。合成ECG数据可解决隐私问题，但需要验证其在深度学习中的有效性。

Method: 使用流行的深度学习模型预测四个关键心脏参数（心率、PR间期、QT间期、QRS复合波），然后利用这些回归模型进行迁移学习，执行5类ECG信号分类。

Result: 实验结果表明，从回归到分类的迁移学习能够提高分类性能，证明了该方法在充分利用可用数据和推进深度学习应用方面的潜力。

Conclusion: 从回归到分类的迁移学习是可行的，能够更好地利用多样化的开放获取和合成ECG数据集，为心血管疾病诊断的深度学习应用提供了有效途径。

Abstract: Cardiovascular diseases (CVDs) are the leading cause of mortality worldwide,
accounting for over 30% of global deaths according to the World Health
Organization (WHO). Importantly, one-third of these deaths are preventable with
timely and accurate diagnosis. The electrocardiogram (ECG), a non-invasive
method for recording the electrical activity of the heart, is crucial for
diagnosing CVDs. However, privacy concerns surrounding the use of patient ECG
data in research have spurred interest in synthetic data, which preserves the
statistical properties of real data without compromising patient
confidentiality. This study explores the potential of synthetic ECG data for
training deep learning models from regression to classification tasks and
evaluates the feasibility of transfer learning to enhance classification
performance on real ECG data. We experimented with popular deep learning models
to predict four key cardiac parameters, namely, Heart Rate (HR), PR interval,
QT interval, and QRS complex-using separate regression models. Subsequently, we
leveraged these regression models for transfer learning to perform 5-class ECG
signal classification. Our experiments systematically investigate whether
transfer learning from regression to classification is viable, enabling better
utilization of diverse open-access and synthetic ECG datasets. Our findings
demonstrate that transfer learning from regression to classification improves
classification performance, highlighting its potential to maximize the utility
of available data and advance deep learning applications in this domain.

</details>


### [13] [Robust Sparse Bayesian Learning Based on Minimum Error Entropy for Noisy High-Dimensional Brain Activity Decoding](https://arxiv.org/abs/2508.11657)
*Yuanhao Li,Badong Chen,Wenjun Bai,Yasuharu Koike,Okito Yamashita*

Main category: eess.SP

TL;DR: 提出基于最小误差熵(MEE)的稀疏贝叶斯学习框架，用于处理高维脑信号解码中的噪声问题，在回归和分类任务中均优于传统方法


<details>
  <summary>Details</summary>
Motivation: 传统基于高斯和二项分布的稀疏贝叶斯学习在处理脑信号噪声时存在不足，需要更鲁棒的框架来处理复杂数据分布

Method: 采用最小误差熵(MEE)准则构建似然函数，增强稀疏贝叶斯学习对噪声脑数据的推理能力

Result: 在两个高维脑解码任务(回归和分类)中，该方法在解码指标和生理模式识别方面均优于传统和最先进方法

Conclusion: MEE似然模型使稀疏贝叶斯学习能够同时解决脑解码任务中的噪声和高维性挑战，为脑机接口等生物医学工程应用提供强大工具

Abstract: Objective: Sparse Bayesian learning provides an effective scheme to solve the
high-dimensional problem in brain signal decoding. However, traditional
assumptions regarding data distributions such as Gaussian and binomial are
potentially inadequate to characterize the noisy signals of brain activity.
Hence, this study aims to propose a robust sparse Bayesian learning framework
to address noisy highdimensional brain activity decoding. Methods: Motivated by
the commendable robustness of the minimum error entropy (MEE) criterion for
handling complex data distributions, we proposed an MEE-based likelihood
function to facilitate the accurate inference of sparse Bayesian learning in
analyzing noisy brain datasets. Results: Our proposed approach was evaluated
using two high-dimensional brain decoding tasks in regression and
classification contexts, respectively. The experimental results showed that,
our approach can realize superior decoding metrics and physiological patterns
than the conventional and state-of-the-art methods. Conclusion: Utilizing the
proposed MEE-based likelihood model, sparse Bayesian learning is empowered to
simultaneously address the challenges of noise and high dimensionality in the
brain decoding task. Significance: This work provides a powerful tool to
realize robust brain decoding, advancing biomedical engineering applications
such as brain-computer interface.

</details>


### [14] [CECGSR: Circular ECG Super-Resolution](https://arxiv.org/abs/2508.11658)
*Honggui Li,Zhengyang Zhang,Dingtai Li,Sinan Chen,Nahid Md Lokman Hossain,Xinfeng Xu,Yuting Feng,Hantao Lu,Yinlu Qin,Ruobing Wang,Maria Trocan,Dimitri Galayko,Amara Amara,Mohamad Sawan*

Main category: eess.SP

TL;DR: 闭环循环ECG超分辨率方法CECGSR，通过建模降级过程和负反馈机制，在PTB-XL数据集上超越现有开环方法的重建性能


<details>
  <summary>Details</summary>
Motivation: ECG信号因便携式采集设备、噪声和人工故障导致分辨率低，现有开环ECGSR方法性能有限，根据自动控制理论闭环结构具有更优的动态和静态性能

Method: 提出CECGSR闭环方法，建模从高分辨率到低分辨率ECG的降级过程，通过LR信号差异实现负反馈机制，构建数学循环方程，使用Taylor级数展开证明近零稳态误差，采用Plug-and-Play策略集成现有开环ECGSR方法

Result: 在PTB-XL数据集的无噪和有噪子集上进行模拟实验，结果显示CECGSR在ECG信号重建性能方面超过了现有最先进的开环ECGSR算法

Conclusion: 闭环CECGSR方法通过循环结构和负反馈机制，显著提升了ECG超分辨率的性能，为心电图信号处理提供了更有效的解决方案

Abstract: The electrocardiogram (ECG) plays a crucial role in the diagnosis and
treatment of various cardiac diseases. ECG signals suffer from low-resolution
(LR) due to the use of convenient acquisition devices, as well as internal and
external noises and artifacts. Classical ECG super-resolution (ECGSR) methods
adopt an open-loop architecture that converts LR ECG signals to
super-resolution (SR) ones. According to the theory of automatic control, a
closed-loop framework exhibits superior dynamic and static performance compared
with its open-loop counterpart. This paper proposes a closed-loop approach,
termed circular ECGSR (CECGSR), which models the degradation process from SR
ECG signals to LR ones. The negative feedback mechanism of the closed-loop
system is based on the differences between the LR ECG signals. A mathematical
loop equation is constructed to characterize the closed-loop infrastructure.
The Taylor series expansion is employed to demonstrate the near-zero
steady-state error of the proposed method. A Plug-and-Play strategy is
considered to establish the SR unit of the proposed architecture, leveraging
any existing advanced open-loop ECGSR methods. Simulation experiments on both
noiseless and noisy subsets of the PTB-XL datasets demonstrate that the
proposed CECGSR outperforms state-of-the-art open-loop ECGSR algorithms in the
reconstruction performance of ECG signals.

</details>


### [15] [Unsupervised Pairwise Learning Optimization Framework for Cross-Corpus EEG-Based Emotion Recognition Based on Prototype Representation](https://arxiv.org/abs/2508.11663)
*Guangli Li,Canbiao Wu,Zhen Liang*

Main category: eess.SP

TL;DR: 提出McdPL框架，通过双对抗分类器和三阶段对抗训练实现跨语料库情感识别，在SEED数据集上准确率提升4.76%和3.97%


<details>
  <summary>Details</summary>
Motivation: 解决跨语料库情感识别中由于被试生理差异、实验环境和设备变化导致的决策边界附近样本分类困难的问题

Method: 基于领域对抗迁移学习的优化方法，设计双对抗分类器（Ada和RMS分类器），采用三阶段对抗训练最大化分类差异并最小化特征分布，结合成对学习将分类问题转化为样本相似性问题

Result: 在SEED、SEED-IV和SEED-V公开数据库上的实验表明，McdPL模型在跨语料库情感识别任务中优于其他基线模型，平均准确率分别提升4.76%和3.97%

Conclusion: McdPL框架为跨语料库情感识别提供了有效的解决方案，通过精确的特征对齐缓解了标签噪声的影响

Abstract: Affective computing is a rapidly developing interdisciplinary research
direction in the field of brain-computer interface. In recent years, the
introduction of deep learning technology has greatly promoted the development
of the field of emotion recognition. However, due to physiological differences
between subjects, as well as the variations in experimental environments and
equipment, cross-corpus emotion recognition faces serious challenges,
especially for samples near the decision boundary. To solve the above problems,
we propose an optimization method based on domain adversarial transfer learning
to fine-grained alignment of affective features, named Maximum classifier
discrepancy with Pairwise Learning (McdPL) framework. In McdPL, we design a
dual adversarial classifier (Ada classifier and RMS classifier), and apply a
three-stage adversarial training to maximize classification discrepancy and
minimize feature distribution to align controversy samples near the decision
boundary. In the process of domain adversarial training, the two classifiers
also maintain an adversarial relationship, ultimately enabling precise
cross-corpus feature alignment. In addition, the introduction of pairwise
learning transforms the classification problem of samples into a similarity
problem between samples, alleviating the influence of label noise. We conducted
systematic experimental evaluation of the model using publicly available SEED,
SEED-IV and SEED-V databases. The results show that the McdPL model is superior
to other baseline models in the cross-corpus emotion recognition task, and the
average accuracy improvements of 4.76\% and 3.97\%, respectively. Our work
provides a promising solution for emotion recognition cross-corpus. The source
code is available at https://github.com/WuCB-BCI/Mcd_PL.

</details>


### [16] [Energy-Efficient Real-Time 4-Stage Sleep Classification at 10-Second Resolution: A Comprehensive Study](https://arxiv.org/abs/2508.11664)
*Zahra Mohammadi,Parnian Fazel,Siamak Mohammadi*

Main category: eess.SP

TL;DR: 基于单导联电心图的能源效率督睡眠分期系统，通过轻量级深度学习模型实现高准确度和低能耗


<details>
  <summary>Details</summary>
Motivation: 传统多导联睡眠监测方法成本高且不方便长期家庭使用，需要发展能源效率高的可穿戴睡眠监测方案

Method: 提出两种窗口切分策略：5分钟窗口用于机器学习模型，30秒窗口用于深度学习模型。设计了轻量级自定义CNN模型SleepLiteCNN，并应用8位量化技术

Result: SleepLiteCNN模型达到89%准确率和89% F1分数，每次推理能耗仅45.48微焦耳，量化后保持准确性同时进一步降低功耗

Conclusion: 该系统为可续续可穿戴的基于ECG的睡眠监测提供了实用解决方案，在保持高分类性能的同时实现了极低的能源消耗

Abstract: Sleep stage classification is crucial for diagnosing and managing disorders
such as sleep apnea and insomnia. Conventional clinical methods like
polysomnography are costly and impractical for long-term home use. We present
an energy-efficient pipeline that detects four sleep stages (wake, REM, light,
and deep) from a single-lead ECG. Two windowing strategies are introduced: (1)
a 5-minute window with 30-second steps for machine-learning models that use
handcrafted features, and (2) a 30-second window with 10-second steps for
deep-learning models, enabling near-real-time 10-second resolution. Lightweight
networks such as MobileNet-v1 reach 92 percent accuracy and 91 percent F1-score
but still draw significant energy. We therefore design SleepLiteCNN, a custom
model that achieves 89 percent accuracy and 89 percent F1-score while lowering
energy use to 5.48 microjoules per inference at 45 nm. Applying eight-bit
quantization preserves accuracy and further reduces power, and FPGA deployment
confirms low resource usage. The proposed system offers a practical solution
for continuous, wearable ECG-based sleep monitoring.

</details>


### [17] [Explainable Deep Neural Network for Multimodal ECG Signals: Intermediate vs Late Fusion](https://arxiv.org/abs/2508.11666)
*Timothy Oladunni,Ehimen Aneni*

Main category: eess.SP

TL;DR: 本文研究在心血管疾病ECG分类任务中比较了多模态融合策略，发现中间融合（特征层面）比后期融合（决策层面）更有效，达到97%的最高准确率。


<details>
  <summary>Details</summary>
Motivation: 单模态深度学习模型存在过拟合和通用性局限的问题，而多模态融合策略中中间融合与后期融合的最优选择在高风险临床情境中仍不充分明确。

Method: 使用ECG信号的时域、频域和时频域三个域进行多模态融合，设计了一系列实验来比较中间融合和后期融合策略的性能。使用显著性地图进行可解释性分析，并通过相互信息验证了模型的可靠性。

Result: 中间融合策略在所有实验中都表现更优，达到峰值准确率97%，相比单模态模型有显著收益（Cohen's d > 0.8），且比后期融合更好（d = 0.40）。

Conclusion: 本文提出的基于ECG域的多模态模型具有更优的预测能力和更好的可解释性，超越了现有最先进模型，对医学AI应用具有重要意义。

Abstract: The limitations of unimodal deep learning models, particularly their tendency
to overfit and limited generalizability, have renewed interest in multimodal
fusion strategies. Multimodal deep neural networks (MDNN) have the capability
of integrating diverse data domains and offer a promising solution for robust
and accurate predictions. However, the optimal fusion strategy, intermediate
fusion (feature-level) versus late fusion (decision-level) remains
insufficiently examined, especially in high-stakes clinical contexts such as
ECG-based cardiovascular disease (CVD) classification. This study investigates
the comparative effectiveness of intermediate and late fusion strategies using
ECG signals across three domains: time, frequency, and time-frequency. A series
of experiments were conducted to identify the highest-performing fusion
architecture. Results demonstrate that intermediate fusion consistently
outperformed late fusion, achieving a peak accuracy of 97 percent, with Cohen's
d > 0.8 relative to standalone models and d = 0.40 compared to late fusion.
Interpretability analyses using saliency maps reveal that both models align
with the discretized ECG signals. Statistical dependency between the
discretized ECG signals and corresponding saliency maps for each class was
confirmed using Mutual Information (MI). The proposed ECG domain-based
multimodal model offers superior predictive capability and enhanced
explainability, crucial attributes in medical AI applications, surpassing
state-of-the-art models.

</details>


### [18] [Neural Gaussian Radio Fields for Channel Estimation](https://arxiv.org/abs/2508.11668)
*Muhammad Umer,Muhammad Ahmed Mohsin,Ahsan Bilal,John M. Cioffi*

Main category: eess.SP

TL;DR: nGRF是一种基于3D高斯原语的无线信道估计新框架，相比传统方法在精度、速度和数据效率方面有显著提升，解决了移动环境下CSI获取的关键瓶颈问题。


<details>
  <summary>Details</summary>
Motivation: 传统信道状态信息(CSI)估计方法在移动环境下表现不佳，导频开销大、延迟高、频谱效率低，需要新的高效准确的信道估计解决方案。

Method: 使用显式3D高斯原语进行直接电磁场聚合，每个高斯作为局部无线电调制器，避免了基于NeRF的慢速隐式表示或非物理2D投影方法。

Result: 室内场景预测SNR比现有方法高10.9倍，推理延迟从242ms降至1.1ms；室外场景达到26.2dB SNR；数据收集负担减少18倍，训练时间从小时级降至分钟级。

Conclusion: nGRF框架在信道估计方面实现了突破性进展，大幅提升了精度、速度和效率，为动态无线环境下的实时信道估计提供了可行解决方案。

Abstract: Accurate channel state information (CSI) remains the most critical bottleneck
in modern wireless networks, with pilot overhead consuming up to 11-21% of
transmission bandwidth, increasing latency by 20-40% in massive MIMO systems,
and reducing potential spectral efficiency by over 53%. Traditional estimation
techniques fundamentally fail under mobility, with feedback delays as small as
4 ms causing 50% throughput degradation at even modest speeds (30 km/h). We
present neural Gaussian radio fields (nGRF), a novel framework that leverages
explicit 3D Gaussian primitives to synthesize complex channel matrices
accurately and efficiently. Unlike NeRF-based approaches that rely on slow
implicit representations or existing Gaussian splatting methods that use
non-physical 2D projections, nGRF performs direct 3D electromagnetic field
aggregation, with each Gaussian acting as a localized radio modulator. nGRF
demonstrates superior performance across diverse environments: in indoor
scenarios, it achieves a 10.9$\times$ higher prediction SNR than state of the
art methods while reducing inference latency from 242 ms to just 1.1 ms (a
220$\times$ speedup). For large-scale outdoor environments, where existing
approaches fail to function, nGRF achieves an SNR of 26.2 dB. Moreover, nGRF
requires only 0.011 measurements per cubic foot compared to 0.2-178.1 for
existing methods, thereby reducing data collection burden by 18$\times$.
Training time is similarly reduced from hours to minutes (a 180$\times$
reduction), enabling rapid adaptation to dynamic environments. The code and
datasets are available at: https://github.com/anonym-auth/n-grf

</details>


### [19] [Direction of Arrival Estimation: A Tutorial Survey of Classical and Modern Methods](https://arxiv.org/abs/2508.11675)
*Amgad A. Salama*

Main category: eess.SP

TL;DR: 本文是一个关于到达角度估计的综述性教程，为初学者和研究人员提供了从经典到现代方法的全面介绍，包括数学推导、Python实现和实践指南。


<details>
  <summary>Details</summary>
Motivation: 到达角度估计是数组信号处理领域的基础问题，在雷达、声纳、无线通信等领域有广泛应用。本文旨在为初学者提供一个系统的入门教程，缩小理论与实践之间的差距。

Method: 采用统一线性数组进行窄带信号处理，逐步推导数学公式并配合几何直观。包括经典波束形成方法、子空间技术（MUSIC、ESPRIT）、最大似然方法和稀疏信号处理方法。

Result: 提供了完整的Python实现代码库，支持可复现研究和实践学习。通过系统性能对比分析，提供了方法选择和参数调整的实用指南。

Conclusion: 本教程成功建立了理论基础与实际应用之间的桥梁，既适合初学者入门学习，也作为领域研究人员的完整参考资料。开源代码库为进一步研究提供了实践支持。

Abstract: Direction of arrival (DOA) estimation is a fundamental problem in array
signal processing with applications spanning radar, sonar, wireless
communications, and acoustic signal processing. This tutorial survey provides a
comprehensive introduction to classical and modern DOA estimation methods,
specifically designed for students and researchers new to the field. We focus
on narrowband signal processing using uniform linear arrays, presenting
step-by-step mathematical derivations with geometric intuition. The survey
covers classical beamforming methods, subspace-based techniques (MUSIC,
ESPRIT), maximum likelihood approaches, and sparse signal processing methods.
Each method is accompanied by Python implementations available in an
open-source repository, enabling reproducible research and hands-on learning.
Through systematic performance comparisons across various scenarios, we provide
practical guidelines for method selection and parameter tuning. This work aims
to bridge the gap between theoretical foundations and practical implementation,
making DOA estimation accessible to beginners while serving as a comprehensive
reference for the field. See https://github.com/AmgadSalama/DOA for detail
implementation of the methods.

</details>


### [20] [Age-Normalized HRV Features for Non-Invasive Glucose Prediction: A Pilot Sleep-Aware Machine Learning Study](https://arxiv.org/abs/2508.11682)
*Md Basit Azam,Sarangthem Ibotombi Singh*

Main category: eess.SP

TL;DR: 通过年龄正则化HRV特征提高了睡眠期间血糖预测的准确度，在43名受试者中实现R2=0.161，比非正则化方法提升25.6%


<details>
  <summary>Details</summary>
Motivation: 非侵入性血糖监测是糖尿病管理的关键挑战，但年龄相关的自主神经变化影响了传统HRV分析的准确性

Method: 收集43名受试者的多模态数据，包括睡眠阶段特异心电图、HRV特征和临床测量。采用新的年龄正则化技术，将HRV原始值除以年龄缩放因子。使用贝叶斯岭回归和5折交叉验证进行log血糖预测

Result: 年龄正则化HRV特征在log血糖预测中达到R2=0.161（MAE=0.182），比非正则化特征提高25.6%（R2=0.132）。最佳预测特征包括年龄正则化的REM期心率变异特征和放松期心率变异特征，以及旋式血压

Conclusion: 年龄正则化HRV特征显著提高了血糖预测准确性，这种睡眠感知方法解决了自主功能评估中的基本限制，为非侵入性血糖监测应用提供了初步可行性。但需要在更大群体中验证结果

Abstract: Non-invasive glucose monitoring remains a critical challenge in the
management of diabetes. HRV during sleep shows promise for glucose prediction
however, age-related autonomic changes significantly confound traditional HRV
analyses. We analyzed 43 subjects with multi-modal data including sleep-stage
specific ECG, HRV features, and clinical measurements. A novel
age-normalization technique was applied to the HRV features by, dividing the
raw values by age-scaled factors. BayesianRidge regression with 5-fold
cross-validation was employed for log-glucose prediction. Age-normalized HRV
features achieved R2 = 0.161 (MAE = 0.182) for log-glucose prediction,
representing a 25.6% improvement over non-normalized features (R2 = 0.132). The
top predictive features were hrv rem mean rr age normalized (r = 0.443, p =
0.004), hrv ds mean rr age normalized (r = 0.438, p = 0.005), and diastolic
blood pressure (r = 0.437, p = 0.005). Systematic ablation studies confirmed
age-normalization as the critical component, with sleep-stage specific features
providing additional predictive value. Age-normalized HRV features
significantly enhance glucose prediction accuracy compared with traditional
approaches. This sleep-aware methodology addresses fundamental limitations in
autonomic function assessment and suggests a preliminary feasibility for
non-invasive glucose monitoring applications. However, these results require
validation in larger cohorts before clinical consideration.

</details>


### [21] [A Graph Neural Network based on a Functional Topology Model: Unveiling the Dynamic Mechanisms of Non-Suicidal Self-Injury in Single-Channel EEG](https://arxiv.org/abs/2508.11684)
*BG Tong*

Main category: eess.SP

TL;DR: 这项研究提出了一种新的功能-能量拓扑模型，利用图神经网络从单通道EEG解码非自杀性自伤的神经动力学机制，发现了关键的反馈循环失调现象。


<details>
  <summary>Details</summary>
Motivation: 研究非自杀性自伤（NSSI）的神经机制，开发一种能够在真实环境下从单通道EEG数据中解码复杂心理状态的方法，为对象化生物标记物和数字疗法提供基础。

Method: 使用智能手机应用和便携式Fp1 EEG头带收集三名青少年NSSI患者的EEG数据，构建理论驱动的七节点图神经网络模型，通过内部分割和留一受试者交叉验证评估性能，使用GNNExplainer进行可解释性分析。

Result: 模型在内部验证中达到高准确率（>85%），跨主体验证也显著超过随机水平（约73.7%）。解释性分析发现NSSI状态下调节体感觉的关键反馈循环出现功能障碍和方向性反转，大脑失去了通过负面身体反馈进行自我纠正的能力。

Conclusion: 这项研究证明了理论引导的GNN模型在稀疏单通道EEG数据上解码复杂心理状态的可行性，所识别的"反馈循环反转"机制为NSSI提供了一种新题、动态且可计算的模型，为对象化生物标记物和下一代数字疗法开启了新路径。

Abstract: Objective: This study proposes and preliminarily validates a novel
"Functional-Energetic Topology Model" to uncover neurodynamic mechanisms of
Non-Suicidal Self-Injury (NSSI), using Graph Neural Networks (GNNs) to decode
brain network patterns from single-channel EEG in real-world settings.Methods:
EEG data were collected over ~1 month from three adolescents with NSSI using a
smartphone app and a portable Fp1 EEG headband during impulsive and
non-impulsive states. A theory-driven GNN with seven functional nodes was
built. Performance was evaluated via intra-subject (80/20 split) and
leave-one-subject-out cross-validation (LOSOCV). GNNExplainer was used for
interpretability.Results: The model achieved high intra-subject accuracy (>85%)
and significantly above-chance cross-subject performance (approximately73.7%).
Explainability analysis revealed a key finding: during NSSI states, a critical
feedback loop regulating somatic sensation exhibits dysfunction and directional
reversal. Specifically, the brain loses its ability to self-correct via
negative bodily feedback, and the regulatory mechanism enters an "ineffective
idling" state.Conclusion: This work demonstrates the feasibility of applying
theory-guided GNNs to sparse, single-channel EEG for decoding complex mental
states. The identified "feedback loop reversal" offers a novel, dynamic, and
computable model of NSSI mechanisms, paving the way for objective biomarkers
and next-generation Digital Therapeutics (DTx).

</details>


### [22] [Enhancing Corrosion Resistance of Aluminum Alloys Through AI and ML Modeling](https://arxiv.org/abs/2508.11685)
*Farnaz Kaboudvand,Maham Khalid,Nydia Assaf,Vardaan Sahgal,Jon P. Ruffley,Brian J. McDermott*

Main category: eess.SP

TL;DR: 机器学习预测铝合金海水腐蚀速率，高斯过程回归表现最优


<details>
  <summary>Details</summary>
Motivation: 铝合金在海洋环境中面临严重腐蚀挑战，需要有效的预测和优化方法

Method: 使用开源数据集，采用直接和逆向两种方法，比较随机森林、神经网络和高斯过程回归三种机器学习算法

Result: 高斯过程回归表现最优，混合内核函数和对数变换进一步提升了预测精度

Conclusion: 机器学习特别是GPR在腐蚀速率预测和材料性能优化方面具有高效性

Abstract: Corrosion poses a significant challenge to the performance of aluminum
alloys, particularly in marine environments. This study investigates the
application of machine learning (ML) algorithms to predict and optimize
corrosion resistance, utilizing a comprehensive open-source dataset compiled
from various sources. The dataset encompasses corrosion rate data and
environmental conditions, preprocessed to standardize units and formats. We
explored two different approaches, a direct approach, where the material's
composition and environmental conditions were used as inputs to predict
corrosion rates; and an inverse approach, where corrosion rate served as the
input to identify suitable material compositions as output. We employed and
compared three distinct ML methodologies for forward predictions: Random Forest
regression, optimized via grid search; a feed-forward neural network, utilizing
ReLU activation and Adam optimization; and Gaussian Process Regression (GPR),
implemented with GPyTorch and employing various kernel functions. The Random
Forest and neural network models provided predictive capabilities based on
elemental compositions and environmental conditions. Notably, Gaussian Process
Regression demonstrated superior performance, particularly with hybrid kernel
functions. Log-transformed GPR further refined predictions. This study
highlights the efficacy of ML, particularly GPR, in predicting corrosion rates
and material properties.

</details>


### [23] [The Lost-K and Shorter-J Phenomenon in Non-Standard Ballistocardiography Data](https://arxiv.org/abs/2508.11686)
*Shuai Jiao,Jian Fang,Tianshu Zhou,Jinsong Li,Yanhong Liu,Ye Liu,Ming Ju*

Main category: eess.SP

TL;DR: 这篇论文研究了非标准心冲图(BCG)数据中J峰不显著的问题，识别了两种导致J峰不显著的现象，并提出了三种信号变换方法来改善这些问题。


<details>
  <summary>Details</summary>
Motivation: 非标准BCG数据中J峰不显著，影响了心冲图信号的分析和循环提取的准确性，需要找到有效的方法来改善这一问题。

Method: 提出了三种信号变换方法，专门用于改善失K现象和短J现象。在40名受试者的时间对齐ECG-BCG数据集上进行了评估。

Result: 结果显示，基于变换后的信号，仅使用局部极大值或极小值检测的简单J峰基础方法在定位J峰和提取BCG循环方面表现更好，尤其是对非标准BCG数据。

Conclusion: 该研究提出的信号变换方法能够有效地改善非标准BCG信号中的J峰不显著问题，为心冲图信号处理提供了新的解决方案。

Abstract: Non-standard ballistocardiogram(BCG) data generally do not have prominent J
peaks. This paper introduces two phenomena that reduce the prominence of
Jpeaks: the shorter-J phenomenon and the lost-K phenomenon, both of which are
commonly observed in non-standard BCG signals . This paper also proposes three
signal transformation methods that effectively improve the lost-K and shorter-J
phenomena. The methods were evaluated on a time-aligned ECG-BCG dataset with 40
subjects. The results show that based on the transformed signal, simple
J-peak-based methods using only the detection of local maxima or minima show
better performance in locating J-peaks and extracting BCG cycles, especially
for non-standard BCG data.

</details>


### [24] [Agent-Based Anti-Jamming Techniques for UAV Communications in Adversarial Environments: A Comprehensive Survey](https://arxiv.org/abs/2508.11687)
*Jingpu Yang,Mingxuan Cui,Hang Zhang,Fengxian Ji,Zhengzhao Lai,Yufeng Wang*

Main category: eess.SP

TL;DR: 这是一份关于无人机通信智能抗干扰技术的综述性论文，通过"感知-决策-行动"框架系统分析了游戏论和强化学习在适应性抗干扰策略中的应用。


<details>
  <summary>Details</summary>
Motivation: 解决动态对抗环境中无人机通信遇到的多源干扰挑战，提高通信的可靠性和弹性。

Method: 建立以"感知-决策-行动"为核心的闭环决策框架，系统分析每个阶段的关键技术，重点使用游戏论建模无人机与干扰器互动，结合强化学习算法推导适应性抗干扰策略。

Result: 论文对现有技术进行了系统性的总结和分析，为无人机通信抗干扰领域提供了理论框架和技术参考。

Conclusion: 本文为开发更智能、更稳健的无人机抗干扰通信系统指明了研究方向，并识别了现有方法的局限性和关键工程挑战。

Abstract: Unmanned Aerial Vehicle communications are encountering increasingly severe
multi-source interference challenges in dynamic adversarial environments, which
impose higher demands on their reliability and resilience. To address these
challenges, agent-based autonomous anti-jamming techniques have emerged as a
crucial research direction. This paper presents a comprehensive survey that
first formalizes the concept of intelligent anti-jamming agents for UAV
communications and establishes a closed-loop decision-making framework centered
on the "Perception-Decision-Action" (P-D-A) paradigm. Within this framework, we
systematically review key technologies at each stage, with particular emphasis
on employing game theory to model UAV-jammer interactions and integrating
reinforcement learning-based intelligent algorithms to derive adaptive
anti-jamming strategies. Furthermore, we discuss potential limitations of
current approaches, identify critical engineering challenges, and outline
promising future research directions, aiming to provide valuable references for
developing more intelligent and robust anti-jamming communication systems for
UAVs.

</details>


### [25] [Towards Generalizable Learning Models for EEG-Based Identification of Pain Perception](https://arxiv.org/abs/2508.11691)
*Mathis Rezzouk,Fabrice Gagnon,Alyson Champagne,Mathieu Roy,Philippe Albouy,Michel-Pierre Coll,Cem Subakan*

Main category: eess.SP

TL;DR: 本研究系统评估了多种机器学习模型在跨被试疼痛感知识别中的泛化性能，发现深度学习模型相比传统模型在跨被试场景下表现更稳健，图神经网络模型展现出捕获被试不变EEG信号结构的潜力。


<details>
  <summary>Details</summary>
Motivation: 当前基于EEG的疼痛感知研究面临跨被试泛化的重大挑战，由于EEG信号的高个体差异性和现有研究对直接疼痛感知识别的有限关注，需要系统评估模型在跨被试场景下的性能。

Method: 使用108名参与者的EEG数据集，系统评估包括传统分类器和深度神经网络在内的多种模型在热痛和厌恶听觉刺激感知识别任务中的表现，比较了被试内和跨被试两种评估设置下的性能。

Result: 传统模型在跨被试场景下性能下降最严重，深度学习模型表现出更强的鲁棒性，图神经网络模型在捕获被试不变EEG信号结构方面展现出突出潜力，尽管性能变异性仍然较高。

Conclusion: 深度学习模型特别是图神经网络在跨被试EEG解码中具有重要价值，研究还提供了预处理数据集作为标准化基准，为未来算法在相同泛化约束下的评估提供支持。

Abstract: EEG-based analysis of pain perception, enhanced by machine learning, reveals
how the brain encodes pain by identifying neural patterns evoked by noxious
stimulation. However, a major challenge that remains is the generalization of
machine learning models across individuals, given the high cross-participant
variability inherent to EEG signals and the limited focus on direct pain
perception identification in current research. In this study, we systematically
evaluate the performance of cross-participant generalization of a wide range of
models, including traditional classifiers and deep neural classifiers for
identifying the sensory modality of thermal pain and aversive auditory
stimulation from EEG recordings. Using a novel dataset of EEG recordings from
108 participants, we benchmark model performance under both within- and
cross-participant evaluation settings. Our findings show that traditional
models suffered the largest drop from within- to cross-participant performance,
while deep learning models proved more resilient, underscoring their potential
for subject-invariant EEG decoding. Even though performance variability
remained high, the strong results of the graph-based model highlight its
potential to capture subject-invariant structure in EEG signals. On the other
hand, we also share the preprocessed dataset used in this study, providing a
standardized benchmark for evaluating future algorithms under the same
generalization constraints.

</details>


### [26] [Scalable, Technology-Agnostic Diagnosis and Predictive Maintenance for Point Machine using Deep Learning](https://arxiv.org/abs/2508.11692)
*Eduardo Di Santi,Ruixiang Ci,Clément Lefebvre,Nenad Mijatovic,Michele Pugnaloni,Jonathan Brown,Victor Martín,Kenza Saiah*

Main category: eess.SP

TL;DR: 这篇论文提出了一种只需单一电力信号输入的深度学习方法，用于预测路达转转机的故障，达到了极高的准确率和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 路达转转机作为关键路达设备，故障会导致服务中断。现有方法需要多种输入和特定信号处理，缺乏可扩展性。

Method: 使用深度学习模型分析单一的电力信号模式，识别转转机的健康状态和故障类型，并采用遵循预测技术提供信心度指标。

Result: 方法达到了>99.99%的精确度，<0.01%的假正率，以及可忽略的假负率，并在多种电机械转转机类型上验证了可扩展性。

Conclusion: 该方法不仅效果优异，而且通用性强，符合ISO-17359标准要求，为路达转转机预测性维护提供了可靠的解决方案。

Abstract: The Point Machine (PM) is a critical piece of railway equipment that switches
train routes by diverting tracks through a switchblade. As with any critical
safety equipment, a failure will halt operations leading to service
disruptions; therefore, pre-emptive maintenance may avoid unnecessary
interruptions by detecting anomalies before they become failures. Previous work
relies on several inputs and crafting custom features by segmenting the signal.
This not only adds additional requirements for data collection and processing,
but it is also specific to the PM technology, the installed locations and
operational conditions limiting scalability. Based on the available maintenance
records, the main failure causes for PM are obstacles, friction, power source
issues and misalignment. Those failures affect the energy consumption pattern
of PMs, altering the usual (or healthy) shape of the power signal during the PM
movement. In contrast to the current state-of-the-art, our method requires only
one input. We apply a deep learning model to the power signal pattern to
classify if the PM is nominal or associated with any failure type, achieving
>99.99\% precision, <0.01\% false positives and negligible false negatives. Our
methodology is generic and technology-agnostic, proven to be scalable on
several electromechanical PM types deployed in both real-world and test bench
environments. Finally, by using conformal prediction the maintainer gets a
clear indication of the certainty of the system outputs, adding a confidence
layer to operations and making the method compliant with the ISO-17359
standard.

</details>


### [27] [Track Component Failure Detection Using Data Analytics over existing STDS Track Circuit data](https://arxiv.org/abs/2508.11693)
*Francisco López,Eduardo Di Santi,Clément Lefebvre,Nenad Mijatovic,Michele Pugnaloni,Victor Martín,Kenza Saiah*

Main category: eess.SP

TL;DR: 使用SVM分类器分析STDS轨道电路电流数据，自动识别15种故障类型，提高维护效率


<details>
  <summary>Details</summary>
Motivation: 传统轨道电路故障检测需要人工分析，效率低下。需要自动化方法来准确识别具体故障组件，提升维护效果

Method: 采用支持向量机(SVM)分类器，利用智能列车检测系统(STDS)的高低频电流数据，训练模型识别15种不同故障类型

Result: 在10个不同轨道电路的现场数据测试中，所有用例都被正确分类，得到了STDS专家和维护人员的验证

Conclusion: 该方法能够有效自动识别轨道电路的具体故障组件，显著提高了维护行动的准确性和效率

Abstract: Track Circuits (TC) are the main signalling devices used to detect the
presence of a train on a rail track. It has been used since the 19th century
and nowadays there are many types depending on the technology. As a general
classification, Track Circuits can be divided into 2 main groups, DC (Direct
Current) and AC (Alternating Current) circuits. This work is focused on a
particular AC track circuit, called "Smart Train Detection System" (STDS),
designed with both high and low-frequency bands. This approach uses STDS
current data applied to an SVM (support vector machine) classifier as a type of
failure identifier. The main purpose of this work consists on determine
automatically which is the component of the track that is failing to improve
the maintenance action. Model was trained to classify 15 different failures
that belong to 3 more general categories. The method was tested with field data
from 10 different track circuits and validated by the STDS track circuit expert
and maintainers. All use cases were correctly classified by the method.

</details>


### [28] [Operational machine learning for park-scale irrigation to support urban cooling](https://arxiv.org/abs/2508.11700)
*Mesut Koçyiğit,Bahman Javadi,Russell Thomson,Sebastian Pfautsch,Oliver Obst*

Main category: eess.SP

TL;DR: SIMPaCT是一个智能灌溉系统，通过土壤湿度预测优化公园灌溉，实现城市降温而非仅节水，使用kNN预测和异常检测确保系统稳健运行。


<details>
  <summary>Details</summary>
Motivation: 传统公园灌溉系统主要关注节水，但忽略了灌溉对城市热岛效应的降温潜力。需要开发既能节水又能优化降温效果的智能灌溉方案。

Method: 使用202个土壤湿度传感器、50个温湿度节点和13个气象站数据，采用kNN预测模型，配合异常检测管道（Isolation Forest和ARIMA）和虚拟传感器机制处理设备故障。

Result: 平均绝对误差0.78%，优于SARIMA等复杂基线方法（P75误差0.71% vs 0.93%），系统已投入日常运行。

Conclusion: SIMPaCT提供了一个可操作的、稳健的城市公园规模冷却导向灌溉方案，成功平衡了节水和降温双重目标。

Abstract: Urban parks can mitigate local heat, yet irrigation control is usually tuned
for water savings rather than cooling. We report on SIMPaCT (Smart Irrigation
Management for Parks and Cool Towns), a park-scale deployment that links
per-zone soil-moisture forecasts to overnight irrigation set-points in support
of urban cooling. SIMPaCT ingests data from 202 soil-moisture sensors, 50
temperature-relative humidity (TRH) nodes, and 13 weather stations, and trains
a per-sensor k-nearest neighbours (kNN) predictor on short rolling windows
(200-900h). A rule-first anomaly pipeline screens missing and stuck-at signals,
with model-based checks (Isolation Forest and ARIMA). When a device fails, a
mutual-information neighbourhood selects the most informative neighbour and a
small multilayer perceptron supplies a "virtual sensor" until restoration.
Across sensors the mean absolute error was 0.78%, comparable to more complex
baselines; the upper-quartile error (P75) was lower for kNN than SARIMA (0.71%
vs 0.93%). SIMPaCT runs daily and writes proposed set-points to the existing
controller for operator review. This short communication reports an operational
recipe for robust, cooling-oriented irrigation at city-park scale.

</details>


### [29] [Scaling Wideband Massive MIMO Radar via Beamspace Dimension Reduction](https://arxiv.org/abs/2508.11790)
*Oveys Delafrooz Noroozi,Jiyoon Han,Wei Tang,Zhengya Zhang,Upamanyu Madhow*

Main category: eess.SP

TL;DR: 提出了一种基于窗口化材旷空间MVDR材旷形成的广带大规模MIMO雷达数字材旷形成扩展架构，通过空间FFT变换将复杂度从O(N^3)降低到O(NlogN)，在保持检测性能的同时显著减少计算和训练开销。


<details>
  <summary>Details</summary>
Motivation: 传统的空间处理在大规模天线阵列中计算复杂度过高（MVDR材旷形成复杂度为O(N^3)），需要找到一种能够降低计算复杂度同时保持检测性能的方案。

Method: 利用材旷空间中的能量聚集特性，通过空间FFT变换（复杂度O(NlogN)）将数据转换到材旷空间，提出窗口化材旷空间MVDR材旷形成架构，并在目标咄子带上并行化处理。

Result: 在DARPA SOAP项目的政府提供广带雷达数据上评估，该方法在检测性能上可以与全维度基准相比，同时显著减少了计算咄训练开销，并揭示了材旷空间窗口大小咄FFT分辨率在平衡复杂度、检测准确性咄干扰压制方面的牺换关系。

Conclusion: 该研究提出的窗口化材旷空间MVDR架构为大规模广带MIMO雷达数字材旷形成提供了一种高效的解决方案，能够在显著降低计算复杂度的同时保持优异的检测咄干扰压制性能。

Abstract: We present an architecture for scaling digital beamforming for wideband
massive MIMO radar. Conventional spatial processing becomes computationally
prohibitive as array size grows; for example, the computational complexity of
MVDR beamforming scales as O(N^3) for an N-element array. In this paper, we
show that energy concentration in beamspace provides the basis for drastic
complexity reduction, with array scaling governed by the O(NlogN) complexity of
the spatial FFT used for beamspace transformation. Specifically, we propose an
architecture for windowed beamspace MVDR beamforming, parallelized across
targets and subbands, and evaluate its efficacy for beamforming and
interference suppression for government-supplied wideband radar data from the
DARPA SOAP (Scalable On-Array Processing) program. We demonstrate that our
approach achieves detection performance comparable to full-dimensional
benchmarks while significantly reducing computational and training overhead,
and provide insight into tradeoffs between beamspace window size and FFT
resolution in balancing complexity, detection accuracy, and interference
suppression.

</details>


### [30] [Digital Post-Distortion Architectures for Nonlinear Power Amplifiers: Volterra and Kernel Methods](https://arxiv.org/abs/2508.11792)
*Daniel Schäufele,Jochen Fink,Renato L. G. Cavalcante,Sławomir Stańczak*

Main category: eess.SP

TL;DR: 本文探讨在基站端实施数字后置扭曲(DPoD)技术来补偿5G用户设备功放的非线性扭曲，在时域实现并配合频域通道均衡可在低计算复杂度下获得良好性能。


<details>
  <summary>Details</summary>
Motivation: 减少5G用户设备的功耗，特别是功放的能耗，同时避免复杂的反馈机制带来的额外复杂性和能耗增加。

Method: 采用数字后置扭曲(DPoD)技术，在基站端进行扭曲补偿，研究了时域、频域和DFT-s域的实现方案，提出在实希尔伯空间中构建复数问题的方法，以及使用核方法代替传统Volterra级数来降低算法复杂度。

Result: 模拟实验验证了分析结果，显示所提算法能够显著提高性能，超越现有最优算法。时域DPoD配合频域通道均衡能在低计算复杂度下实现高效的非线性补偿。

Conclusion: 在基站端实施DPoD是一种有效的解决方案，能够在不增加用户设备复杂性的前提下，利用基站的计算资源来补偿功放的非线性扭曲，提高系统性能。

Abstract: In modern 5G user equipments (UEs), the power amplifier (PA) contributes
significantly to power consumption during uplink transmissions, especially in
cell-edge scenarios. While reducing power backoff can enhance PA efficiency, it
introduces nonlinear distortions that degrade signal quality. Existing
solutions, such as digital pre-distortion, require complex feedback mechanisms
for optimal performance, leading to increased UE complexity and power
consumption. Instead, in this study we explore digital post-distortion (DPoD)
techniques, which compensate for these distortions at the base station,
leveraging its superior computational resources. In this study, we conduct an
comprehensive study concerning the challenges and advantages associated with
applying DPoD in time-domain, frequency-domain, and DFT-s-domain. Our findings
suggest that implementing DPoD in the time-domain, complemented by
frequency-domain channel equalization, strikes a good balance between low
computational complexity and efficient nonlinearity compensation. In addition,
we demonstrate that memory has to be taken into account regardless of the
memory of the PA. Subsequently, we show how to pose the complex-valued problem
of nonlinearity compensation in a real Hilbert space, emphasizing the potential
performance enhancements as a result. We then discuss the traditional Volterra
series and show an equivalent kernel method that can reduce algorithmic
complexity. Simulations validate the results of our analysis and show that our
proposed algorithm can significantly improve performance compared to
state-of-the-art algorithms.

</details>


### [31] [Autonomous Driving with RSMA-Enabled Finite Blocklength Transmissions: Ergodic Performance Analysis and Optimization](https://arxiv.org/abs/2508.12012)
*Yi Wang,Yingyang Chen,Li Wang,Donghong Cai,Xiaofan Li,Pingzhi Fan*

Main category: eess.SP

TL;DR: RSMA在FBL传输下的性能分析与优化，通过联合优化功率分配和速率分割，显著提升遍历和速率并降低时延和误码率


<details>
  <summary>Details</summary>
Motivation: 针对自动驾驶等高移动性场景中URLLC的严格需求，RSMA对不完美CSI具有鲁棒性，但需要研究其在有限块长传输下的性能

Method: 推导RSMA遍历和速率的闭式下界，基于梯度下降联合优化全局功率系数、私有功率分布和公共速率分割，采用序列二次规划进行优化

Result: 仿真结果表明该方案显著提升遍历性能，减少块长度和BLER，优于平均私有功率的RSMA和SDMA，同时保证最差信道用户的速率公平性

Conclusion: 提出的RSMA FBL传输方案有效满足URLLC要求，在高速移动场景中提供可靠的通信性能并增强网络公平性

Abstract: Rate-splitting multiple access (RSMA) is a key technology for next-generation
multiple access systems due to its robustness against imperfect channel state
information (CSI). This makes RSMA particularly suitable for high-mobility
autonomous driving, where ultra-reliable and low-latency communication (URLLC)
is essential. To address the stringent requirements, this study enables RSMA
finite blocklength (FBL) transmissions and explicitly evaluates the ergodic
performance. We derive the closed-form lower bound for the ergodic sum-rate of
RSMA, considering vital factors such as the vehicle velocities, vehicle
positions, power allocation of each stream, blocklengths, and block error rates
(BLERs). To further enhance the ergodic sum-rate while complying with quality
of service (QoS) rate constraints, we jointly optimize the global power
coefficient, private power distribution, and common rate splitting. Guided by
gradient descent, we first adjust the global power coefficient based on its
sum-rate solution. This parameter regulates the power state of the common
stream, allowing for dynamic activation or deactivation: if active, we optimize
the private power distribution and adjust the common rate splitting to meet
minimum transmission constraints; if inactive, we use the sequential quadratic
programming for private power distribution optimization. Simulation results
confirm that our RSMA scheme significantly improves the ergodic performance,
reduces blocklength and BLER, surpassing the RSMA counterpart with average
private power and space division multiple access (SDMA). Furthermore, our
approach is validated to guarantee the rates for users with the poorest channel
conditions, thereby enhancing fairness across the network.

</details>


### [32] [A Generalized Multidimensional Chinese Remainder Theorem (MD-CRT) for Multiple Integer Vectors](https://arxiv.org/abs/2508.12099)
*Guangpu Guo,Xiang-Gen Xia*

Main category: eess.SP

TL;DR: 本文研究多维中国剩余定理的广义形式，重点解决多个整数向量从多个向量余数集恢复的两个核心问题：唯一可确定范围和最大动态范围的达成条件。


<details>
  <summary>Details</summary>
Motivation: 多维CRT在加密、编码和信号处理领域有广泛应用，但现有方法主要处理单向量情况，需要扩展到多个整数向量的恢复问题。由于模矩阵的非交换性和多维包含关系的复杂性，这个问题拥有重大挑战性。

Method: 首先求解无先验信息下的唯一可确定范围，并提出相应算法。然后重点研究两个整数向量的特殊情况，探索达到最大动态范围的条件。当维度降为1时，这些条件较现有标量整数的广义CRT条件更优。

Result: 推导出了无先验信息下的唯一可确定范围，并设计了实现该范围的算法。在两个整数向量的情况下，得到了达到最大动态范围的新条件，该条件在维度降为1时显示出比现有标量整数广义CRT更好的性能。

Conclusion: 本文在多维中国剩余定理的广义化方面取得了重要进展，不仅解决了多个整数向量恢复的基础理论问题，而且在特殊情况下得到了更优的条件。这些结果对于多维信号处理中的频率检测等应用具有重要意义。

Abstract: Chinese remainder theorem (CRT) is widely applied in cryptography, coding
theory, and signal processing. It has been extended to the multidimensional CRT
(MD-CRT), which reconstructs an integer vector from its vector remainders
modulo multiple integer matrices. This paper investigates a generalized MD-CRT
for multiple integer vectors, where the goal is to determine multiple integer
vectors from multiple vector residue sets modulo multiple integer
matrices.Comparing to the existing generalized CRT for multiple scalar
integers, the challenge is that the moduli in MD-CRT are matrices that do not
commute and the corresponding uniquely determinable range is multidimensional
and the inclusion relationship is much more complicated. In this paper,we
address two fundamental questions regarding the generalized MD-CRT. The first
question concerns the uniquely determinable range of multiple integer vectors
when no prior information about them is available. The second question is about
the conditions under which the maximal possible dynamic range can be
achieved.To answer these two questions, we first derive a uniquely determinable
range without prior information and accordingly propose an algorithm to achieve
it. A special case involving only two integer vectors is investigated for the
second question, leading to a new condition for achieving the maximal possible
dynamic range. Interestingly, this newly obtained condition, when the dimension
is reduced to $1$, is even better than the existing ones for the conventional
generalized CRT for scalar integers.These results may have applications for
frequency detection in multidimensional signal processing.

</details>


### [33] [RFSS: A Comprehensive Multi-Standard RF Signal Source Separation Dataset with Advanced Channel Modeling](https://arxiv.org/abs/2508.12106)
*Hao Chen,Rui Jin,Dayuan Tan*

Main category: eess.SP

TL;DR: 基于3GPP标准的开源多标准RF信号数据集RFSS，包含52,847个实际信号样本，支持CNN-LSTM模型在信号源分离任务中获得26.7dB SINR改善


<details>
  <summary>Details</summary>
Motivation: 无线通信系统快速发展导致多种细胞标准(2G/3G/4G/5G)共存的复杂电磁环境，需要先进的信号源分离技术

Method: 开发RFSS开源数据集，包含GSM、UMTS、LTE和5G NR的真实基带信号，集成多路弱衰、MIMO处理(最高8发8天线)和实际干扰场景

Result: CNN-LSTM结构在信号源分离任务中实现了26.7dB SINR改善，显著超过传统ICA(15.2dB)和NMF(18.3dB)方法

Conclusion: RFSS数据集为RF信号源分离、认知无线电和机器学习应用提供了可复现的研究基础，并保持完全开源访问性

Abstract: The rapid evolution of wireless communication systems has created complex
electromagnetic environments where multiple cellular standards (2G/3G/4G/5G)
coexist, necessitating advanced signal source separation techniques. We present
RFSS (RF Signal Source Separation), a comprehensive open-source dataset
containing 52,847 realistic multi-standard RF signal samples with complete 3GPP
standards compliance. Our framework generates authentic baseband signals for
GSM, UMTS, LTE, and 5G NR with advanced channel modeling including multipath
fading, MIMO processing up to 8 by 8 antennas, and realistic interference
scenarios. Experimental validation demonstrates superior performance of
CNN-LSTM architectures achieving 26.7 dB SINR improvement in source separation
tasks, significantly outperforming traditional ICA (15.2 dB) and NMF (18.3 dB)
approaches. The RFSS dataset enables reproducible research in RF source
separation, cognitive radio, and machine learning applications while
maintaining complete open-source accessibility

</details>


### [34] [Effect of Phase Shift Errors on the Security of UAV-assisted STAR-RIS IoT Networks](https://arxiv.org/abs/2508.12114)
*Mustafa Gusaibat,Mohammed Hnaish,Abdelhamid Salem,Khaled Rabie,Zubair Md Fadlullah,Wali Ullah Khan,Mohamad A. Alawad,Yazeed Alkhrijah*

Main category: eess.SP

TL;DR: 这篇论文研究了UAV搭载STAR-RIS系统中相位偏移错误对网络安全性能的影响，通过建模分析得到了秘密速率的闭式表达式，并提出了优化UAV位置的算法来最大化加权秘密速率。


<details>
  <summary>Details</summary>
Motivation: UAV搭载STAR-RIS系统虽然能提供全方位覆盖和灵活部署，但实际中UAV的振动和气流等弊除会影响STAR-RIS的相位偏移，从而降低网络安全性能。需要研究这种实际弊除对秘密性能的影响。

Method: 采用von Mises分布模型化相位估计错误，在UAV搭载STAR-RIS辅助的NOMA系统中，推导出不完全相位调整下的秘密速率的分析闭式表达式，并通过线性网格算法优化UAV位置来最大化加权秘密速率。

Result: 得到了秘密速率的分析闭式表达式，Monte Carlo模拟验证了分析结果的正确性，分析了相位估计错误对系统秘密性能的影响。

Conclusion: 论文为STAR-RIS在安全UAV启动的IoT网络中的实际部署提供了关键见解，证明了考虑实际弊除对系统安全性能的重要性。

Abstract: Unmanned aerial vehicles (UAV)-mounted simultaneous transmitting and
reflecting reconfigurable intelligent surface (STAR-RIS) systems can provide
full-dimensional coverage and flexible deployment opportunities in future
6G-enabled IoT networks. However, practical imperfections such as jittering and
airflow of UAV could affect the phase shift of STAR-RIS, and consequently
degrade network security. In this respect, this paper investigates the impact
of phase shift errors on the secrecy performance of UAV-mounted
STAR-RIS-assisted IoT systems. More specifically, we consider a UAV-mounted
STAR-RIS-assisted non-orthogonal multiple access (NOMA) system where IoT
devices are grouped into two groups: one group on each side of the STAR-RIS.
The nodes in each group are considered as potential Malicious nodes for the
ones on the other side. By modeling phase estimation errors using a von Mises
distribution, analytical closed-form expressions for the ergodic secrecy rates
under imperfect phase adjustment are derived. An optimization problem to
maximize the weighted sum secrecy rate (WSSR) by optimizing the UAV placement
is formulated and is then solved using a linear grid-based algorithm. Monte
Carlo simulations are provided to validate the analytical derivations. The
impact of phase estimation errors on system's secrecy performance is analyzed,
providing critical insights for the practical realisation of STAR-RIS
deployments for secure UAV-enabled IoT networks.

</details>


### [35] [ATLAS: AI-Native Receiver Test-and-Measurement by Leveraging AI-Guided Search](https://arxiv.org/abs/2508.12204)
*Mauro Belgiovine,Suyash Pradhan,Johannes Lange,Michael Löhning,Kaushik Chowdhury*

Main category: eess.SP

TL;DR: ATLAS是一种AI引导的测试生成方法，专门用于测试AI原生无线接收器模型，通过梯度优化高效发现模型故障配置，相比网格搜索减少19%的测试需求。


<details>
  <summary>Details</summary>
Motivation: AI原生无线接收器在工业应用进展缓慢，主要原因是训练好的ML模型缺乏可解释性，且无法在所有可能情况下进行详尽测试，存在网络功能故障的显著风险。

Method: 使用基于梯度的优化方法，在线生成下一个测试配置来探测最高故障风险的特定环境条件，避免穷举所有信道和环境条件。在NVIDIA Sionna环境中实现和验证。

Result: ATLAS发现了AI原生DeepRx接收器在特定移动性、信道延迟扩展和噪声组合下性能不如传统接收器。相比网格搜索，每发现一个故障所需的测试数量减少19%。

Conclusion: ATLAS提供了一种高效测试AI原生无线接收器的方法，解决了高维参数空间中网格搜索计算成本指数级增长的问题，为AI无线系统的可靠性验证提供了实用解决方案。

Abstract: Industry adoption of Artificial Intelligence (AI)-native wireless receivers,
or even modular, Machine Learning (ML)-aided wireless signal processing blocks,
has been slow. The main concern is the lack of explainability of these trained
ML models and the significant risks posed to network functionalities in case of
failures, especially since (i) testing on every exhaustive case is infeasible
and (ii) the data used for model training may not be available. This paper
proposes ATLAS, an AI-guided approach that generates a battery of tests for
pre-trained AI-native receiver models and benchmarks the performance against a
classical receiver architecture. Using gradient-based optimization, it avoids
spanning the exhaustive set of all environment and channel conditions; instead,
it generates the next test in an online manner to further probe specific
configurations that offer the highest risk of failure. We implement and
validate our approach by adopting the well-known DeepRx AI-native receiver
model as well as a classical receiver using differentiable tensors in NVIDIA's
Sionna environment. ATLAS uncovers specific combinations of mobility, channel
delay spread, and noise, where fully and partially trained variants of
AI-native DeepRx perform suboptimally compared to the classical receivers. Our
proposed method reduces the number of tests required per failure found by 19%
compared to grid search for a 3-parameters input optimization problem,
demonstrating greater efficiency. In contrast, the computational cost of the
grid-based approach scales exponentially with the number of variables, making
it increasingly impractical for high-dimensional problems.

</details>


### [36] [Weighted Covariance Intersection for Range-based Distributed Cooperative Localization of Multi-Agent Systems](https://arxiv.org/abs/2508.12207)
*Chenxin Tu,Xiaowei Cui,Gang Liu,Mingquan Lu*

Main category: eess.SP

TL;DR: 本文提出简化的权重协方差交叉(WCI)方法，用于改善分布式协作定位在3D环境中的性能，解决了经典CI方法的标度失衡和相关性不匹配问题。


<details>
  <summary>Details</summary>
Motivation: 多机器人系统在恶劣环境不准确定位是关键挑战，分布式协作定位因其稳健性和可扩展性而受到关注。但经典CI方法在3D复杂场景中存在性能下降问题。

Method: 提出权重协方差交叉(WCI)方法，设计基于惯导导航系统错误传播规则的权重矩阵，并开发了多重距离测量的并发融合策略。

Result: 模拟结果显示，WCI方法在协作定位性能上显著超过经典CI方法，分布式方法在稳健性、可扩展性方面优于集中式方法，更适合大规模群体。

Conclusion: WCI方法有效解决了经典CI在3D协作定位中的限制，为大规模群体应用提供了更加高效精准的定位解决方案。

Abstract: Precise localization of multi-agent systems (MAS) in harsh environments is a
critical challenge for swarm applications, and cooperative localization is
considered a key solution to this issue. Among all solutions, distributed
cooperative localization (DCL) has garnered widespread attention due to its
robustness and scalability. The main challenge of DCL lies in how to fuse
relative measurements between agents under unknown correlations. To address
this, covariance intersection (CI) was introduced to DCL. However, the
classical CI optimization criteria suffer from issues such as scale imbalance
and correlation mismatch during the fusion process. These deficiencies are not
as pronounced in 2D scenarios, where the state space is relatively simple and
the observability of each state component is well. However, in 3D scenarios,
where the state space is more complex and there are significant disparities in
the scale and observability of state components, performance degradation
becomes severe. This necessitates the design of specialized mechanisms to
improve the data fusion process. In this paper, we identify three main
drawbacks of the classical CI optimization criteria in recursive filtering and
introduce a weighting mechanism, namely weighted covariance intersection (WCI),
to improve its performance. We then introduce WCI into range-based distributed
cooperative localization in 3D scenarios, developing a concurrent fusion
strategy for multiple distance measurements and designing a weighting matrix
based on the error propagation rule of the inertial navigation system (INS).
Simulation results demonstrate that the proposed WCI significantly enhances
cooperative localization performance compared to classical CI, while the
distributed approach outperforms the centralized approach in terms of
robustness, scalability, and is more suitable for large-scale swarms.

</details>


### [37] [Towards Generalizable Human Activity Recognition: A Survey](https://arxiv.org/abs/2508.12213)
*Yize Cai,Baoshen Guo,Flora Salim,Zhiqing Hong*

Main category: eess.SP

TL;DR: 这篇综述论文系统回顾了基于IMU的可泛化人体活动识别领域，涵盖了229篇研究论文和25个公开数据集，从模型中心和数据中心两个角度分类方法，并讨论了当前挑战和未来方向。


<details>
  <summary>Details</summary>
Motivation: 尽管IMU-based HAR在特定场景下性能有所提升，但其泛化能力仍然是实际应用的主要障碍。领域偏移（用户、传感器位置、环境变化）会导致性能显著下降，因此需要系统梳理该领域的研究进展。

Method: 从两个视角分类代表性方法：(i)模型中心方法：包括预训练方法、端到端方法、基于大语言模型的学习方法；(ii)数据中心方法：包括多模态学习和数据增强技术。同时总结了相关数据集、工具和基准。

Result: 提供了该领域的全面概述，包括方法分类、数据集汇总、工具和基准测试，并建立了持续更新的GitHub资源库。

Conclusion: 讨论了持续存在的挑战（数据稀缺、高效训练、可靠评估）和未来方向（基础模型和大语言模型采用、物理信息推理、上下文感知推理、生成建模、资源高效训练和推理）。

Abstract: As a critical component of Wearable AI, IMU-based Human Activity Recognition
(HAR) has attracted increasing attention from both academia and industry in
recent years. Although HAR performance has improved considerably in specific
scenarios, its generalization capability remains a key barrier to widespread
real-world adoption. For example, domain shifts caused by variations in users,
sensor positions, or environments can significantly decrease the performance in
practice. As a result, in this survey, we explore the rapidly evolving field of
IMU-based generalizable HAR, reviewing 229 research papers alongside 25
publicly available datasets to provide a broad and insightful overview. We
first present the background and overall framework of IMU-based HAR tasks, as
well as the generalization-oriented training settings. Then, we categorize
representative methodologies from two perspectives: (i) model-centric
approaches, including pre-training method, end-to-end method, and large
language model (LLM)-based learning method; and (ii) data-centric approaches,
including multi-modal learning and data augmentation techniques. In addition,
we summarize widely used datasets in this field, as well as relevant tools and
benchmarks. Building on these methodological advances, the broad applicability
of IMU-based HAR is also reviewed and discussed. Finally, we discuss persistent
challenges (e.g., data scarcity, efficient training, and reliable evaluation)
and also outline future directions for HAR, including the adoption of
foundation and large language models, physics-informed and context-aware
reasoning, generative modeling, and resource-efficient training and inference.
The complete list of this survey is available at
https://github.com/rh20624/Awesome-IMU-Sensing, which will be updated
continuously.

</details>


### [38] [A Novel Symbol Level Precoding based AFDM Transmission Framework: Offloading Equalization Burden to Transmitter Side](https://arxiv.org/abs/2508.12215)
*Shuntian Tang,Zesong Fei,Xinyi Wang,Dongkai Zhou,Zhiqiang Wei,Christos Masouros*

Main category: eess.SP

TL;DR: 提出一种基于符号级预编码的AFDM传输框架，通过将处理负担从用户端转移到基站端，降低接收端计算复杂度，同时保持了类似传统AFDM接收机的性能。


<details>
  <summary>Details</summary>
Motivation: AFDM虽然具有强大的多普勒强性，但其高的接收端计算复杂度严重限制了实际部署。需要一种方案来降低用户端的处理要求。

Method: 上行链路采用基于稀疏贝叶斯学习(SBL)的频道估计算法，利用几何频域频道的稀疏性，通过层次拉普拉斯分布建模并使用EM算法迭代更新参数。下行链路采用符号级预编码(SLP)技术，基于估计的上行频道状态信息设计发射波形，将优化问题形式化为二阶锥规划(SOCP)问题。

Result: 模拟结果显示，提出的SBL估计器在准确性和对离网格效应的强健性方面都超过传统的正交匹配追踪(OMP)算法。SLP基于的波形设计方案在显著降低接收端计算复杂度的同时，达到了与传统AFDM接收机相当的性能。

Conclusion: 该方案通过将处理负担从用户端转移到基站端，有效解决了AFDM高接收端计算复杂度的问题，为AFDM的实际部署提供了可行的解决方案。

Abstract: Affine Frequency Division Multiplexing (AFDM) has attracted considerable
attention for its robustness to Doppler effects. However, its high
receiver-side computational complexity remains a major barrier to practical
deployment. To address this, we propose a novel symbol-level precoding
(SLP)-based AFDM transmission framework, which shifts the signal processing
burden in downlink communications from user side to the base station (BS),
enabling direct symbol detection without requiring channel estimation or
equalization at the receiver. Specifically, in the uplink phase, we propose a
Sparse Bayesian Learning (SBL) based channel estimation algorithm by exploiting
the inherent sparsity of affine frequency (AF) domain channels. In particular,
the sparse prior is modeled via a hierarchical Laplace distribution, and
parameters are iteratively updated using the Expectation-Maximization (EM)
algorithm. We also derive the Bayesian Cramer-Rao Bound (BCRB) to characterize
the theoretical performance limit. In the downlink phase, the BS employs the
SLP technology to design the transmitted waveform based on the estimated uplink
channel state information (CSI) and channel reciprocity. The resulting
optimization problem is formulated as a second-order cone programming (SOCP)
problem, and its dual problem is investigated by Lagrangian function and
Karush-Kuhn-Tucker conditions. Simulation results demonstrate that the proposed
SBL estimator outperforms traditional orthogonal matching pursuit (OMP) in
accuracy and robustness to off-grid effects, while the SLP-based waveform
design scheme achieves performance comparable to conventional AFDM receivers
while significantly reducing the computational complexity at receiver,
validating the practicality of our approach.

</details>


### [39] [Polarization Reconfigurable Transmit-Receive Beam Alignment with Interpretable Transformer](https://arxiv.org/abs/2508.12298)
*Seungcheol Oh,Han Han,Joongheon Kim,Sean Kwon*

Main category: eess.SP

TL;DR: 提出基于可解释Transformer的深度学习框架，用于极化可重构大规模MIMO系统中联合优化极化配置和波束成形，显著降低导频开销并提升波束成形增益


<details>
  <summary>Details</summary>
Motivation: 极化可重构天线技术能改善无线信道条件，但与传统大规模MIMO系统结合时，由于信道维度增加而导频测量维度有限，导致严重的导频开销问题

Method: 在收发两端部署基于可解释Transformer的深度学习框架，根据累积接收的导频序列主动设计极化配置和波束成形向量，分别用于导频阶段和传输阶段

Result: 数值实验表明，所提框架相比现有的非自适应和数据驱动方法获得了显著的性能增益

Conclusion: 该框架有效解决了极化可重构大规模MIMO系统中的导频开销问题，同时通过模型可解释性分析了学习能力

Abstract: Recent advancement in next generation reconfigurable antenna and fluid
antenna technology has influenced the wireless system with polarization
reconfigurable (PR) channels to attract significant attention for promoting
beneficial channel condition. We exploit the benefit of PR antennas by
integrating such technology into massive multiple-input-multiple-output (MIMO)
system. In particular, we aim to jointly design the polarization and
beamforming vectors on both transceivers for simultaneous channel
reconfiguration and beam alignment, which remarkably enhance the beamforming
gain. However, joint optimization over polarization and beamforming vectors
without channel state information (CSI) is a challenging task, since
depolarization increases the channel dimension; whereas massive MIMO systems
typically have low-dimensional pilot measurement from limited radio frequency
(RF) chain. This leads to pilot overhead because the transceivers can only
observe low-dimensional measurement of the high-dimension channel. This paper
pursues the reduction of the pilot overhead in such systems by proposing to
employ \emph{interpretable transformer}-based deep learning framework on both
transceivers to actively design the polarization and beamforming vectors for
pilot stage and transmission stage based on the sequence of accumulated
received pilots. Numerical experiments demonstrate the significant performance
gain of our proposed framework over the existing non-adaptive and active
data-driven methods. Furthermore, we exploit the interpretability of our
proposed framework to analyze the learning capabilities of the model.

</details>


### [40] [Jamming Identification with Differential Transformer for Low-Altitude Wireless Networks](https://arxiv.org/abs/2508.12320)
*Pengyu Wang,Zhaocheng Wang,Tianqi Mao,Weijie Yuan,Haijun Zhang,George K. Karagiannidis*

Main category: eess.SP

TL;DR: 提出了一种基于差分Transformer的无线干扰识别框架，通过差分自注意力机制和随机掩码训练策略来提高对抗样本的鲁棒性


<details>
  <summary>Details</summary>
Motivation: 无人机等低空无线网络易受电磁干扰，而现有的深度学习干扰识别方案容易受到对抗样本攻击，导致鲁棒性下降

Method: 1) 差分Transformer网络进行差分自注意力操作减少注意力噪声；2) 随机掩码训练策略创建并行特征提取分支；3) 双分支正则化的一致性训练框架

Result: 仿真结果表明该方法在提升对抗样本鲁棒性方面优于现有方法

Conclusion: 提出的差分Transformer框架通过创新的差分注意力和随机掩码机制，有效提升了无线干扰识别系统对抗对抗攻击的鲁棒性

Abstract: Wireless jamming identification, which detects and classifies electromagnetic
jamming from non-cooperative devices, is crucial for emerging low-altitude
wireless networks consisting of many drone terminals that are highly
susceptible to electromagnetic jamming. However, jamming identification schemes
adopting deep learning (DL) are vulnerable to attacks involving carefully
crafted adversarial samples, resulting in inevitable robustness degradation. To
address this issue, we propose a differential transformer framework for
wireless jamming identification. Firstly, we introduce a differential
transformer network in order to distinguish jamming signals, which overcomes
the attention noise when compared with its traditional counterpart by
performing self-attention operations in a differential manner. Secondly, we
propose a randomized masking training strategy to improve network robustness,
which leverages the patch partitioning mechanism inherent to transformer
architectures in order to create parallel feature extraction branches. Each
branch operates on a distinct, randomly masked subset of patches, which
fundamentally constrains the propagation of adversarial perturbations across
the network. Additionally, the ensemble effect generated by fusing predictions
from these diverse branches demonstrates superior resilience against
adversarial attacks. Finally, we introduce a novel consistent training
framework that significantly enhances adversarial robustness through dualbranch
regularization. Simulation results demonstrate that our proposed methodology is
superior to existing methods in boosting robustness to adversarial samples.

</details>


### [41] [Coherent Compensation-Based Sensing for Long-Range Targets in Integrated Sensing and Communication System](https://arxiv.org/abs/2508.12371)
*Lin Wang,Zhiqing Wei,Xu Chen,Zhiyong Feng*

Main category: eess.SP

TL;DR: 基于MUSIC和LS的空间信号分离方法，解决OFDM体制ISAC系统中远程目标检测的干扰问题，显著提升相干强化后的识别性能


<details>
  <summary>Details</summary>
Motivation: 解决OFDM体制ISAC系统中，循环前缀限制导致的远程目标检测困难，以及近距离目标强回波对远程目标的干扰问题

Method: 提出MUSIC和最小二乘基于的空间信号分离方法，分离不同目标的回波信号；采用相干补偿基于的感知信号处理方法，提升OFDM块的SINR

Result: 在500米远程目标检测中，方法比传统2D-FFT方法显著提升RDM的SINR 10dB，检测概率也显著提高

Conclusion: 该方法有效解决了ISAC系统中远近程目标回波干扰问题，显著提升了远程目标的检测性能，为6G ISAC系统提供了有效的感知处理方案

Abstract: Integrated sensing and communication (ISAC) is a promising candidate
technology for 6G due to its improvement in spectral efficiency and energy
efficiency. Orthogonal frequency division multiplexing (OFDM) signal is a
mainstream candidate ISAC waveform. However, there are inter-symbol
interference (ISI) and inter-carrier interference (ICI) when the round-trip
delay exceeds the cyclic prefix (CP) duration for OFDM signals, which limits
the maximum sensing range of ISAC system. When detecting a long-range target,
the wide beam inevitably covers the close-range target, of which the echo's
power is much larger than that of the long-range target. In order to tackle the
above problem, a multiple signal classification (MUSIC) and least squares
(LS)-based spatial signal separation method is proposed to separate the echo
signals reflected from different targets. Moreover, a coherent
compensation-based sensing signal processing method at the receiver is proposed
to enhance the signal to interference plus noise power ratio (SINR) of the OFDM
block for generating the range-Doppler map (RDM) with higher SINR. Simulation
results reveal that the proposed method greatly enhances the SINR of RDM by 10
dB for a target at 500 m compared with two-dimensional fast Fourier transform
(2D-FFT) method. Besides, the detection probability is also significantly
improved compared to the benchmarking method.

</details>


### [42] [On the Extension of Differential Beamforming Theory to Arbitrary Planar Arrays of First-Order Elements](https://arxiv.org/abs/2508.12403)
*Federico Miotello,Davide Albertini,Alberto Bernardini*

Main category: eess.SP

TL;DR: 基于广义模态匹配框架的频率不变微分捕波方法，可以在任意平面数组布局和元件方向下实现精确的宽带微分捕波


<details>
  <summary>Details</summary>
Motivation: 传统微分捕波技术假设数组元件为全向性，但实际传感器具有频率相关的方向性，如果不正确建模会导致性能气化

Method: 通过将期望捕波图表示为截断的圆周调和展开，并与实际元件响应进行拟合，构建了一种适用于一阶方向性元件任意平面数组的广义框架

Result: 模拟结果证明，在设计阶段考虑传感器方向性能够在不同频率、不同数组布局和噪声条件下获得准确而稳健的性能

Conclusion: 该方法允许在不要求严格数组布局的前提下综合任意阶数和任意扩射方向的捕波图，为小型宽带数组处理提供了更灵活和可靠的解决方案

Abstract: Small-size acoustic arrays exploit spatial diversity to achieve capabilities
beyond those of single-element devices, with applications ranging from
teleconferencing to immersive multimedia. A key requirement for broadband array
processing is a frequency-invariant spatial response, which ensures consistent
directivity across wide bandwidths and prevents spectral coloration.
Differential beamforming offers an inherently frequency-invariant solution by
leveraging pressure differences between closely spaced elements of small-size
arrays. Traditional approaches, however, assume the array elements to be
omnidirectional, whereas real transducers exhibit frequency-dependent
directivity that can degrade performance if not properly modeled. To address
this limitation, we propose a generalized modal matching framework for
frequency-invariant differential beamforming, applicable to unconstrained
planar arrays of first-order directional elements. By representing the desired
beampattern as a truncated circular harmonic expansion and fitting it to the
actual element responses, our method accommodates arbitrary planar geometries
and element orientations. This approach enables the synthesis of beampatterns
of any order and steering direction without imposing rigid layout requirements.
Simulations confirm that accounting for sensor directivity at the design stage
yields accurate and robust performance across varying frequencies, geometries,
and noise conditions.

</details>


### [43] [Towards SISO Bistatic Sensing for ISAC](https://arxiv.org/abs/2508.12614)
*Zhongqin Wang,J. Andrew Zhang,Kai Wu,Min Xu,Y. Jay Guo*

Main category: eess.SP

TL;DR: WiDFS 3.0是一个轻量级双基地SISO感知框架，通过自参考互相关方法和延迟域波束成形技术，在单天线收发器设置下有效解决时钟异步导致的相位偏移和多普勒镜像模糊问题，实现精确的延迟和多普勒估计。


<details>
  <summary>Details</summary>
Motivation: 下一代无线系统中的集成感知与通信(ISAC)在现实部署中往往受限于低成本单天线收发器。在这种双基地SISO设置下，时钟异步会在信道状态信息(CSI)中引入随机相位偏移，传统多天线方法无法解决这一问题。

Method: 提出自参考互相关(SRCC)方法用于SISO随机相位去除，并采用延迟域波束成形技术来解决多普勒模糊问题。生成的明确延迟-多普勒-时间特征使紧凑神经网络能够实现鲁棒感知。

Result: 广泛实验表明，WiDFS 3.0实现了准确的参数估计，性能与甚至超过先前的多天线方法，特别是在延迟估计方面。在单目标和多目标场景下验证，提取的模糊解决特征显示出强大的感知准确性和泛化能力。

Conclusion: WiDFS 3.0框架在仅使用单天线收发器的低成本部署中，通过创新的相位去除和多普勒模糊解决技术，实现了与多天线系统相媲美甚至更优的感知性能，为下一代ISAC系统的实际部署提供了可行的解决方案。

Abstract: Integrated Sensing and Communication (ISAC) is a key enabler for
next-generation wireless systems. However, real-world deployment is often
limited to low-cost, single-antenna transceivers. In such bistatic Single-Input
Single-Output (SISO) setup, clock asynchrony introduces random phase offsets in
Channel State Information (CSI), which cannot be mitigated using conventional
multi-antenna methods. This work proposes WiDFS 3.0, a lightweight bistatic
SISO sensing framework that enables accurate delay and Doppler estimation from
distorted CSI by effectively suppressing Doppler mirroring ambiguity. It
operates with only a single antenna at both the transmitter and receiver,
making it suitable for low-complexity deployments. We propose a
self-referencing cross-correlation (SRCC) method for SISO random phase removal
and employ delay-domain beamforming to resolve Doppler ambiguity. The resulting
unambiguous delay-Doppler-time features enable robust sensing with compact
neural networks. Extensive experiments show that WiDFS 3.0 achieves accurate
parameter estimation, with performance comparable to or even surpassing that of
prior multi-antenna methods, especially in delay estimation. Validated under
single- and multi-target scenarios, the extracted ambiguity-resolved features
show strong sensing accuracy and generalization. For example, when deployed on
the embedded-friendly MobileViT-XXS with only 1.3M parameters, WiDFS 3.0
consistently outperforms conventional features such as CSI amplitude, mirrored
Doppler, and multi-receiver aggregated Doppler.

</details>


### [44] [Factorized Disentangled Representation Learning for Interpretable Radio Frequency Fingerprint](https://arxiv.org/abs/2508.12660)
*Yezhuo Zhang,Zinan Zhou,Guangyu Li,Xuanpeng Li*

Main category: eess.SP

TL;DR: 提出了一种解耦表示学习框架，通过学习明确独立的多因素表示来提高无线电频指纹识别的稳健性和可控性


<details>
  <summary>Details</summary>
Motivation: 应对IoT设备快速增长和安全风险，无线电频指纹(RFF)成为关键识别技术。但现有方法缺乏明确的因素表示，导致稳健性不足和下游任务可控性有限

Method: 设计了解耦表示学习框架，包含因素分类和信号重构专门模块，使用特制损失函数促进解耦和支持下游任务

Result: 在公开数据集和自收集数据集上表现优异，在多个DRL指标上取得突出成绩，分类准确率提高，并能够实现精确的条件信号生成控制

Conclusion: 该DRL框架为可解释和明确的无线电频指纹提供了强大潜力，通过解耦多重因素表示显著提升了RFF识别的稳健性和可控性

Abstract: In response to the rapid growth of Internet of Things (IoT) devices and
rising security risks, Radio Frequency Fingerprint (RFF) has become key for
device identification and authentication. However, various changing factors -
beyond the RFF itself - can be entangled from signal transmission to reception,
reducing the effectiveness of RFF Identification (RFFI). Existing RFFI methods
mainly rely on domain adaptation techniques, which often lack explicit factor
representations, resulting in less robustness and limited controllability for
downstream tasks. To tackle this problem, we propose a novel Disentangled
Representation Learning (DRL) framework that learns explicit and independent
representations of multiple factors, including the RFF. Our framework
introduces modules for disentanglement, guided by the principles of
explicitness, modularity, and compactness. We design two dedicated modules for
factor classification and signal reconstruction, each with tailored loss
functions that encourage effective disentanglement and enhance support for
downstream tasks. Thus, the framework can extract a set of interpretable
vectors that explicitly represent corresponding factors. We evaluate our
approach on two public benchmark datasets and a self-collected dataset. Our
method achieves impressive performance on multiple DRL metrics. We also analyze
the effectiveness of our method on downstream RFFI task and conditional signal
generation task. All modules of the framework contribute to improved
classification accuracy, and enable precise control over conditional generated
signals. These results highlight the potential of our DRL framework for
interpretable and explicit RFFs.

</details>


### [45] [Multi-Domain Supervised Contrastive Learning for UAV Radio-Frequency Open-Set Recognition](https://arxiv.org/abs/2508.12689)
*Ning Gao,Tianrui Zeng,Bowen Chen,Donghong Cai,Shi Jin,Michail Matthaiou*

Main category: eess.SP

TL;DR: 基于多域监督对比学习和改进生成OpenMax的Open-RFNet模型，用于无人机开放集识别，在封闭集和开放集识别中分别达到95.12%和96.08%的准确率


<details>
  <summary>Details</summary>
Motivation: 对凝回网络中非法无人机的监控需求，解决传统行业监管规范滞后导致的非法飞行问题

Method: 提出MD-SupContrast框架，融合ResNet的纹理特征和TransformerEncoder的时频位置特征，并通过监督对比学习优化特征表征；提出IG-OpenMax算法构建Open-RFNet模型，冻结特征提取层后重新训练分类层

Result: 在25种无人机类型下，封闭集识别准确率达到95.12%，开放集识别准确率达到96.08%，超过现有基准方法

Conclusion: 所提方法能够有效监控凝回网络中的非合作无人机，为LA-ISAC网络安全提供了可靠的技术支撑

Abstract: 5G-Advanced (5G-A) has enabled the vibrant development of low altitude
integrated sensing and communication (LA-ISAC) networks. As a core component of
these networks, unmanned aerial vehicles (UAVs) have witnessed rapid growth in
recent years. However, due to the lag in traditional industry regulatory norms,
unauthorized flight incidents occur frequently, posing a severe security threat
to LA-ISAC networks. To surveil the non-cooperative UAVs, in this paper, we
propose a multi-domain supervised contrastive learning (MD-SupContrast)
framework for UAV radio frequency (RF) open-set recognition. Specifically,
first, the texture features and the time-frequency position features from the
ResNet and the TransformerEncoder are fused, and then the supervised
contrastive learning is applied to optimize the feature representation of the
closed-set samples. Next, to surveil the invasive UAVs that appear in real
life, we propose an improved generative OpenMax (IG-OpenMax) algorithm and
construct an open-set recognition model, namely Open-RFNet. According to the
unknown samples, we first freeze the feature extraction layers and then only
retrain the classification layer, which achieves excellent recognition
performance both in closed-set and open-set recognitions. We analyze the
computational complexity of the proposed model. Experiments are conducted with
a large-scale UAV open dataset. The results show that the proposed Open-RFNet
outperforms the existing benchmark methods in terms of recognition accuracy
between the known and the unknown UAVs, as it achieves 95.12% in closed-set and
96.08% in open-set under 25 UAV types, respectively.

</details>


### [46] [LLM-RIMSA: Large Language Models driven Reconfigurable Intelligent Metasurface Antenna Systems](https://arxiv.org/abs/2508.12728)
*Yunsong Huang,Hui-Ming Wang,Qingli Yan,Zhaowei Wang*

Main category: eess.SP

TL;DR: LLM-RIMSA结合大语言模型和新型可重构智能超表面天线架构，解决了6G网络中传统RIS技术的硬件效率、动态控制和可扩展性限制问题。


<details>
  <summary>Details</summary>
Motivation: 6G网络需要超大规模连接和智能无线电环境，但现有可重构智能表面(RIS)技术在硬件效率、动态控制和可扩展性方面存在严重限制。

Method: 提出LLM-RIMSA框架，集成大语言模型(LLMs)与新型可重构智能超表面天线(RIMSA)架构。RIMSA采用并行同轴馈电和2D超表面集成，使每个超材料单元能独立调节幅度和相位。利用预训练LLMs的跨模态推理和少样本学习能力动态优化RIMSA配置。

Result: 仿真显示LLM-RIMSA实现了最先进的性能，在总速率方面优于传统基于深度学习方法，同时减少了训练开销。

Conclusion: 该框架为LLM驱动的智能无线电环境开辟了新途径。

Abstract: The evolution of 6G networks demands ultra-massive connectivity and
intelligent radio environments, yet existing reconfigurable intelligent surface
(RIS) technologies face critical limitations in hardware efficiency, dynamic
control, and scalability. This paper introduces LLM-RIMSA, a transformative
framework that integrates large language models (LLMs) with a novel
reconfigurable intelligent metasurface antenna (RIMSA) architecture to address
these challenges. Unlike conventional RIS designs, RIMSA employs parallel
coaxial feeding and 2D metasurface integration, enabling each individual
metamaterial element to independently adjust both its amplitude and phase.
While traditional optimization and deep learning (DL) methods struggle with
high-dimensional state spaces and prohibitive training costs for RIMSA control,
LLM-RIMSA leverages pre-trained LLMs cross-modal reasoning and few-shot
learning capabilities to dynamically optimize RIMSA configurations. Simulations
demonstrate that LLM-RIMSA achieves state-of-the-art performance, outperforming
conventional DL-based methods in sum rate while reducing training overhead. The
proposed framework pave the way for LLM-driven intelligent radio environments.

</details>


### [47] [Range-Angle Likelihood Maps for Indoor Positioning Using Deep Neural Networks](https://arxiv.org/abs/2508.12746)
*Muhammad Ammad,Paul Schwarzbach,Michael Schultz,Oliver Michler*

Main category: eess.SP

TL;DR: 通过深度学习和超参数优化，使用ResNet模型在模拟航空船舱环境中实现厚米级室内定位精度


<details>
  <summary>Details</summary>
Motivation: 室内定位在航空船舱环境中的准确性和高精度对于可靠导航至关重要，需要提高定位的可靠性和准确性

Method: 使用模拟航空船舱环境测量数据，将标签与锚点之间的距离和角度映射为殊余地图，然后转换为可能性网格地图，使用ResNet模型进行训练和超参数优化

Result: 通过超参数优化获得最佳模型参数设置，实现了厚米级别的定位精度

Conclusion: 深度学习模型特别是ResNet在室内定位任务中能够提供高精度和可靠性，为航空船舱环境的准确定位提供了有效解决方案

Abstract: Accurate and high precision of the indoor positioning is as important as
ensuring reliable navigation in outdoor environments. Using the
state-of-the-art deep learning models provides better reliability and accuracy
to navigate and monitor the accurate positions in the aircraft cabin
environment. We utilize the simulated aircraft cabin environment measurements
and propose a residual neural network (ResNet) model to predict the accurate
positions inside the cabin. The measurements include the ranges and angles
between a tag and the anchors points which are then mapped onto a grid as range
and angle residuals. These residual maps are then transformed into the
likelihood grid maps where each cell of the grid shows the likelihood of being
a true location. These grid maps along with the true positions are then passed
as inputs to train the ResNet model. Since any deep learning model involve
numerous parameter settings, hyperparameter optimization is performed to get
the optimal parameters for training the model effectively with the highest
accuracy. Once we get the best hyperparameters settings of the model, it is
then trained to predict the positions which provides a centimeter-level
accuracy of the localization.

</details>


### [48] [A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted RAN](https://arxiv.org/abs/2508.12892)
*Mahdi Abdollahpour,Marco Bertuletti,Yichao Zhang,Yawei Li,Luca Benini,Alessandro Vanelli-Coralli*

Main category: eess.SP

TL;DR: 一种低复杂度的模型驱动神经网络基带处理方案，专为MU-MIMO系统设计，在保持高性能的同时大幅降低计算复杂度和参数量


<details>
  <summary>Details</summary>
Motivation: 现有AI基带处理方案计算和内存要求高，限制了其在RAN边缘部署和向大带宽多天线7G系统扩展的可扩展性

Method: 提出一种低复杂度模型驱动的神经网络基础接收机，专为MU-MIMO系统设计，支持多种调制方案、带宽、用户数和基站天线数，仅需单个训练模型

Result: 在PUSCH处理模拟中，该方案在TBLER性能上超过现有最优方法，同时将FLOPs减少66倍，可学习参数量减少396倍

Conclusion: 该方案为6G系统提供了一种高效、可扩展且适合边缘部署的AI基带处理解决方案，具有重要的实际部署价值

Abstract: Artificial intelligence approaches for base-band processing for radio
receivers have demonstrated significant performance gains. Most of the proposed
methods are characterized by high compute and memory requirements, hindering
their deployment at the edge of the Radio Access Networks (RAN) and limiting
their scalability to large bandwidths and many antenna 6G systems. In this
paper, we propose a low-complexity, model-driven neural network-based receiver,
designed for multi-user multiple-input multiple-output (MU-MIMO) systems and
suitable for implementation at the RAN edge. The proposed solution is compliant
with the 5G New Radio (5G NR), and supports different modulation schemes,
bandwidths, number of users, and number of base-station antennas with a single
trained model without the need for further training. Numerical simulations of
the Physical Uplink Shared Channel (PUSCH) processing show that the proposed
solution outperforms the state-of-the-art methods in terms of achievable
Transport Block Error Rate (TBLER), while reducing the Floating Point
Operations (FLOPs) by 66$\times$, and the learnable parameters by 396$\times$.

</details>


### [49] [Interference-Asymmetric UAV Remote Control Links: Measurements and Performance Evaluation](https://arxiv.org/abs/2508.12941)
*Donggu Lee,Sung Joon Maeng,Ozgur Ozdemir,Mani Bharathi Pandian,Ismail Guvenc*

Main category: eess.SP

TL;DR: 无人机遥控链路中上行干扰不对称会导致HARQ反馈丢失，严重降低下行吞吐量性能


<details>
  <summary>Details</summary>
Motivation: 无人机遥控链路需要可靠安全的连接，但无人机比地面遥控单元面临更多干扰源，导致上行链路干扰不对称问题，可能造成HARQ反馈丢失从而影响下行吞吐量

Method: 首先使用helikite平台在NC州立大学主校区进行实地测量，然后使用MATLAB LTE和5G工具箱评估HARQ指示器反馈丢失对吞吐量的影响

Result: 数值结果证实上行干扰不对称会因HARQ指示器反馈丢失而显著降低吞吐量性能

Conclusion: 上行干扰不对称是无人机遥控链路中的一个重要问题，会严重影响通信性能，需要通过相应措施来缓解

Abstract: Reliable and secure connectivity is crucial for remote control (RC) and
uncrewed aerial vehicles (UAVs) links. A major problem for UAV RC links is that
interference sources within the coverage may degrade the link quality. Such
interference problems are a higher concern for the UAV than the RC unit on the
ground due to the UAV being in line of sight (LoS) with a larger number of
interference sources. As a result, lost hybrid automatic repeat request (HARQ)
indicators (ACK/NACK) feedback in the uplink (UL, RC to UAV) may degrade the
downlink (DL, UAV to RC) throughput. To get physical evidence for our
interference asymmetry argument, we first conducted a measurement campaign
using a helikite platform at the Main Campus area of NC State University during
the 2024 Packapalooza festival. Subsequently, we evaluated the throughput
impact of the loss of HARQ indicator feedback caused by UL asymmetry using
MATLAB long-term-evolution (LTE) and fifth-generation (5G) toolboxes. Our
numerical results confirm that UL interference asymmetry substantially degrades
the throughput performance due to the loss of HARQ indicator feedback.

</details>


### [50] [A Novel CNN Based Standalone Detector for Faster-than-Nyquist Signaling](https://arxiv.org/abs/2508.12964)
*Osman Tokluoglu,Enver Cavus,Ebrahim Bedeer,Halim Yanikomeroglu*

Main category: eess.SP

TL;DR: 这篇论文提出了一种新的卷积神经网络检测器，用于更快于奈库斯特信号传输，通过结构化固定内核和领域知识掩码技术有效减少码间干扰。该方法在保持计算效率的同时实现了接近最优的比特错误率性能。


<details>
  <summary>Details</summary>
Motivation: 传统的卷积神经网络采用移动内核，无法有效地处理更快于奈库斯特信号传输中的码间干扰问题。需要一种更有效的检测方法来提高检测准确性同时降低计算复杂度。

Method: 采用结构化固定卷积内核层，在预定义位置上显式学习不同距离处的码间干扰模式。使用基于领域知识的掩码技术来提高特征提取效果。采用层次滤波器分配策略，在前期层中分配更多滤波器来处理更强的码间干扰组件。

Result: 该检测器在压缩因子τ≥0.7时实现了接近最优的比特错误率性能，与BCJR算法相当。与M-BCJR相比，在BPSK和QPSK下分别减少86%和84%的计算成本。该方法同时兼容高阶调制方式（至64-QAM），在几乎静止多路径雷利衰落频道中保持稳健性，并在LDPC编码的FTN传输中保持有效性。

Conclusion: 该结构化固定内核CNN检测器为更快于奈库斯特信号传输提供了一种高效、准确且计算效率高的解决方案。通过显式地学习码间干扰模式和优化计算资源分配，该方法在各种通信场景下都显示出了良好的性能和实用性。

Abstract: This paper presents a novel convolutional neural network (CNN)-based detector
for faster-than-Nyquist (FTN) signaling, introducing structured fixed kernel
layers with domain-informed masking to effectively mitigate intersymbol
interference (ISI). Unlike standard CNN architectures that rely on moving
kernels, the proposed approach employs fixed convolutional kernels at
predefined positions to explicitly learn ISI patterns at varying distances from
the central symbol. To enhance feature extraction, a hierarchical filter
allocation strategy is employed, assigning more filters to earlier layers for
stronger ISI components and fewer to later layers for weaker components. This
structured design improves feature representation, eliminates redundant
computations, and enhances detection accuracy while maintaining computational
efficiency. Simulation results demonstrate that the proposed detector achieves
near-optimal bit error rate (BER) performance, comparable to the BCJR algorithm
for the compression factor $\tau \geq 0.7$, while offering up to $46\%$ and
$84\%$ computational cost reduction over M-BCJR for BPSK and QPSK,
respectively. Additional evaluations confirm the method's adaptability to
high-order modulations (up to 64-QAM), resilience in quasi-static multipath
Rayleigh fading channels, and effectiveness under LDPC-coded FTN transmission,
highlighting its robustness and practicality.

</details>


### [51] [Wavefield Correlation Imaging in Arbitrary Media with Inherent Aberration Correction](https://arxiv.org/abs/2508.13017)
*Scott Schoen Jr,Brian Lause,Marko Jakovljevic,Rimon Tadross,Mike Washburn,Anthony E. Samir*

Main category: eess.SP

TL;DR: 本文提出了一种针对异质介质（如肥胖患者）的超声波场相关成像（HWCI）扩展方法，通过在成像过程中直接考虑已知的声速分布，相比传统WCI方法实现了30%以上的分辨率提升和约10%的对比度改善


<details>
  <summary>Details</summary>
Motivation: 传统超声成像算法在形态异质性对象（如超重或肥胖患者）中表现不佳，因为波束形成过程未考虑这种变化。虽然可以通过额外校正来弥补，但会增加计算复杂度

Method: 扩展波场相关成像（WCI）方法，使其能够在成像过程中直接处理任意已知的声速分布，形成异质WCI（HWCI）方法

Result: 在计算机模拟、体外实验和体内实验中验证了方法的可行性，相比传统WCI成像，分辨率提升超过30%，对比度改善约10%

Conclusion: 异质WCI（HWCI）具有很高的转化潜力，能够显著提高超声图像的客观质量，从而增强其临床实用性

Abstract: Ultrasound (US) imaging is an indispensable tool for diagnostic imaging,
particularly given its cost, safety, and portability profiles compared to other
modalities. However, US is challenged in subjects with morphological
heterogeneity (e.g., those with overweight or obesity), largely because
conventional imaging algorithms do not account for such variation in the
beamforming process. Specific knowledge of the these spatial variations enables
supplemental corrections of these algorithms, but with added computational
complexity. Wavefield correlation imaging (WCI) enables efficient image
formation in the spatial frequency domain that, in its canonical formulation,
assumes a uniform medium. In this work, we present an extension of WCI to
arbitrary known speed-of-sound distributions directly in the image formation
process, and demonstrate its feasibility in silico, in vitro, and in vivo. We
report resolution improvements of over 30% and contrast improvements of order
10% over conventional WCI imaging. Together our results suggest heterogeneous
WCI (HWCI) may have high translational potential to improve the objective
quality, and thus clinical utility, of ultrasound images.

</details>


### [52] [Low-complexity Leakage Minimization Beamforming for Large-scale Multi-user Cell-Free Massive MIMO](https://arxiv.org/abs/2508.13067)
*Iván Alexander Morales Sandoval,Getuar Rexhepi,Kengo Ando,Giuseppe Thadeu Freitas de Abreu*

Main category: eess.SP

TL;DR: 基于分数规划和凹凸凸求解算法的低复杂度秘密权值设计，在绝密速率保持相当的情况下显著降低计算复杂度和提升收敛速度


<details>
  <summary>Details</summary>
Motivation: 解决多用户细胞免大规模MIMO系统中信息泄漏问题，在保证秘密性的同时降低算法复杂度

Method: 利用分数规划(FP)将秘密速率最大化问题重构为可处理的凹凸差形式，采用凹凸凸求解算法(CCP)高效求解非凹优化问题

Result: 模拟结果显示该方案能够达到与最先进方法相当的秘密速率，同时显著降低计算复杂度并提升收敛速度

Conclusion: 该方案为细胞免大规模MIMO系统提供了一种效率高、复杂度低的秘密权值设计方案，在性能和复杂度之间取得了良好的平衡

Abstract: We propose a low-complexity beamforming (BF) design for information leakage
minimization in multi-user (MU) cell-free massive multiple-input
multiple-output (CF-mMIMO) systems. Our approach leverages fractional
programming (FP) to reformulate the secrecy rate maximization problem into a
tractable difference-of-convex form. To efficiently solve the resulting
non-convex problem, we employ the Concave-Convex Procedure (CCP), enabling fast
convergence to a local optimum. Simulation results demonstrate that the
proposed scheme achieves secrecy rates comparable to state-of-the-art (SotA)
methods, while significantly reducing computational complexity and improving
convergence speed.

</details>


### [53] [BeamSeek: Deep Learning-based DOA Estimation for Low-Complexity mmWave Phased Arrays](https://arxiv.org/abs/2508.13075)
*Arav Sharma,Lei Chi,Ari Gebhardt,Alon S. Levin,Timothy R. Hoerning,Sam Keene*

Main category: eess.SP

TL;DR: 一种结合灵活放射切换与深度学习的新方法BeamSeek，用于提高毫米波相控阵列系统的到达角估计速度和准确性，并通过实验验证在噪声环境中显著优于基准方法。


<details>
  <summary>Details</summary>
Motivation: 传统到达角估计方法需要直接访问单个天线元素，在现代毫米波模拟或混合放射系统中不实用。虽然最近的灵活放射切换技术已展示了快速的DOA估计，但其准确性和稳健性仍需通过深度学习来改善。

Method: BeamSeek采用多层感知机(MLP)和专门的数据增废技术，模拟实际传播条件。方法在NSF PAWR COSMOS测试平台上使用60 GHz频段进行了实验验证。

Result: 结果显示BeamSeek在各种信噪比(SNR)水平下都显著优于相关基准方法，平均估计误差减少8度，在噪声通道中特别具有优势。

Conclusion: 该方法特别适用于具有多径干扰和硬件约束的实际毫米波部署环境，为低复杂度硬件实现提供了高速高准确的DOA估计解决方案。

Abstract: A novel approach combining agile beam switching with deep learning to enhance
the speed and accuracy of Direction of Arrival (DOA) estimation for
millimeter-wave (mmWave) phased array systems with low-complexity hardware
implementations is proposed and evaluated. Traditional DOA methods requiring
direct access to individual antenna elements are impractical for analog or
hybrid beamforming systems prevalent in modern mmWave implementations. Recent
agile beam switching techniques have demonstrated rapid DOA estimation, but
their accuracy and robustness can be further improved via deep learning.
BeamSeek addresses these limitations by employing a Multi-Layer Perceptron
(MLP) and specialized data augmentation that emulates real-world propagation
conditions. The proposed approach was experimentally validated at 60 GHz using
the NSF PAWR COSMOS testbed, demonstrating significant improvements over a
correlation-based method across various Signal-to-Noise Ratio (SNR) levels.
Results show that BeamSeek achieves up to an 8 degree reduction in average
estimation error compared to this baseline, with particular advantages in noisy
channels. This makes it especially suitable for practical mmWave deployments in
environments characterized by multipath interference and hardware constraints.

</details>
