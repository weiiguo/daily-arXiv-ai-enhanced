<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 22]
- [cs.IT](#cs.IT) [Total: 15]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [Modeling and Analysis of VOC-based Interplant Molecular Communication Channel](https://arxiv.org/abs/2512.12035)
*Bitop Maitra,Ozgur B. Akan*

Main category: eess.SP

TL;DR: 该论文提出了一个基于挥发性有机化合物(VOC)的植物间分子通信端到端框架，将通信过程分为发射、信道传播和接收三个阶段，分析了各阶段的衰减和延迟特性。


<details>
  <summary>Details</summary>
Motivation: VOC是生物系统中最丰富多样的信号分子之一，基于VOC的分子通信有望开发长距离、生物兼容的通信系统，能够连接纳米和微米级设备。

Method: 提出了一个从ICT视角的VOC植物间通信端到端框架，将通信过程分为三个阶段：发射（VOC生物合成和叶片释放）、信道传播（湍流风中的平流扩散，应激诱导释放采用高斯烟团模型，组成型释放采用高斯烟羽模型）、接收（VOC吸收和接收植物的生理响应）。

Result: 数值结果表明VOC信道呈现低通特性，带宽和容量受距离、风速和噪声的显著影响。虽然物理信道支持中等频率，但发射端的生物限制使得端到端信道只能传输缓慢变化的信号。

Conclusion: 该研究为VOC植物间分子通信提供了一个全面的分析框架，揭示了其通信特性受物理信道和生物约束的共同影响，为开发生物兼容的长距离通信系统奠定了基础。

Abstract: Molecular communication (MC) enables information transfer using particles inspired by biological systems. Volatile Organic Compounds (VOCs) are one of the most abundant and diverse classes of signaling molecules used by living or non-living objects. VOC-based MC holds great promise in developing long-range, bio-compatible communication systems capable of interfacing nano- and micro-scale devices. In this paper, we present a comprehensive end-to-end framework for VOC-based interplant MC from an ICT perspective. The communication process is divided into three stages: transmission (VOC biosynthesis and emission from leaves), channel propagation (advection-diffusion in turbulent wind via Gaussian puff for stress-induced VOC release and Gaussian plume for constitutive VOC release), and reception (VOC uptake and physiological response in the receiver plant). Each stage is analyzed by its attenuation and delay. Numerical results demonstrate that VOC-based channels exhibit low-pass behavior, with bandwidth and capacity heavily influenced by distance, wind velocity, and noise. Though the physical channel supports moderate frequencies, biological constraints at the transmitter restrict the end-to-end channel to slow-varying signals.

</details>


### [2] [Hierarchical Deep Learning for Joint Turbulence and PE Estimation in Multi-Aperture FSO Systems](https://arxiv.org/abs/2512.12178)
*Mohammad Taghi Dabiri,Meysam Ghanbari,Rula Ammuri,Mazen Hasna,Khalid Qaraqe*

Main category: eess.SP

TL;DR: 提出一种新型多孔径FSO接收器架构和分层深度学习框架，首次实现发射器指向误差、接收器到达角波动和湍流衰落的联合估计。


<details>
  <summary>Details</summary>
Motivation: 现有研究孤立处理自由空间光通信中的多种损伤，由于接收信号中的乘性耦合效应，传统估计器无法同时恢复发射器指向误差、接收器到达角波动和湍流衰落这三个关键参数。

Method: 1) 设计多孔径FSO接收器架构，利用透镜阵列的空间分集解耦这些相互交织的效应；2) 提出分层深度学习框架，顺序估计到达角、发射器指向误差和湍流系数。

Result: 仿真结果表明，该方法达到接近最大后验概率的精度，计算成本降低数个数量级，在估计精度和泛化能力上显著优于端到端学习基线。

Conclusion: 这是首个实现这三个关键参数实用化联合估计的工作，为可靠、抗湍流的多孔径FSO系统铺平了道路。

Abstract: Accurate characterization of free-space optical (FSO) channels requires joint estimation of transmitter pointing errors, receiver angle-of-arrival (AoA) fluctuations, and turbulence-induced fading. However, existing literature addresses these impairments in isolation, since their multiplicative coupling in the received signal severely limits conventional estimators and prevents simultaneous recovery. In this paper, we introduce a novel multi-aperture FSO receiver architecture that leverages spatial diversity across a lens array to decouple these intertwined effects. Building on this hardware design, we propose a hierarchical deep learning framework that sequentially estimates AoA, transmitter pointing error, and turbulence coefficients. This decomposition significantly reduces learning complexity and enables robust inference even under strong atmospheric fading. Simulation results demonstrate that the proposed method achieves near-MAP accuracy with orders-of-magnitude lower computational cost, and substantially outperforms end-to-end learning baselines in terms of estimation accuracy and generalization. To the best of our knowledge, this is the first work to demonstrate practical joint estimation of these three key parameters, paving the way for reliable, turbulence-resilient multi-aperture FSO systems.

</details>


### [3] [A Sensing Dataset Protocol for Benchmarking and Multi-Task Wireless Sensing](https://arxiv.org/abs/2512.12180)
*Jiawei Huang,Di Zhang,Yuanhao Cui,Xiaowen Cao,Tony Xiao Han,Xiaojun Jing,Christos Masouros*

Main category: eess.SP

TL;DR: SDP是一个无线感知数据集协议和基准框架，通过统一的数据块架构和CP-ALS池化实现多模态感知任务的标准化和可复现性。


<details>
  <summary>Details</summary>
Motivation: 现有无线感知数据集和流程在不同感知模态间碎片化，阻碍了公平比较、迁移和可复现性研究。

Method: 提出SDP协议，通过轻量级同步、频时对齐和重采样将异构无线信号映射到统一感知数据块架构，使用CP-ALS池化提供任务无关表示。

Result: 跨用户分割实验显示，SDP显著减少了不同种子间的方差（约88%），同时保持竞争性的准确率和延迟。

Conclusion: SDP为多模态和多任务感知研究提供了一个可复现的基础框架，解决了现有数据集碎片化问题。

Abstract: Wireless sensing has become a fundamental enabler for intelligent environments, supporting applications such as human detection, activity recognition, localization, and vital sign monitoring. Despite rapid advances, existing datasets and pipelines remain fragmented across sensing modalities, hindering fair comparison, transfer, and reproducibility. We propose the Sensing Dataset Protocol (SDP), a protocol-level specification and benchmark framework for large-scale wireless sensing. SDP defines how heterogeneous wireless signals are mapped into a unified perception data-block schema through lightweight synchronization, frequency-time alignment, and resampling, while a Canonical Polyadic-Alternating Least Squares (CP-ALS) pooling stage provides a task-agnostic representation that preserves multipath, spectral, and temporal structures. Built upon this protocol, a unified benchmark is established for detection, recognition, and vital-sign estimation with consistent preprocessing, training, and evaluation. Experiments under the cross-user split demonstrate that SDP significantly reduces variance (approximately 88%) across seeds while maintaining competitive accuracy and latency, confirming its value as a reproducible foundation for multi-modal and multitask sensing research.

</details>


### [4] [Learning-Driven Dual-Line Laser Scanning for Fast and Accurate LEO Satellite Positioning](https://arxiv.org/abs/2512.12181)
*Mohammad Taghi Dabiri,Rula Ammuri,Mazen Hasna,Khalid Qaraqe*

Main category: eess.SP

TL;DR: 提出一种基于学习的双线激光扫描框架，用于快速精确的卫星定位，相比传统高斯光束方案，在1-2ms内实现7-10米精度


<details>
  <summary>Details</summary>
Motivation: 低地球轨道卫星光学链路需要毫秒级波束对准以实现可靠高速通信，传统高斯光束采集系统依赖多序列光束或机械转向，存在延迟问题

Method: 采用两个正交线形激光束进行结构化光学扫描，开发包含大气衰减、湍流和MRR反射的物理模型，训练数据驱动的神经估计器将接收光能模式映射到卫星二维位置

Result: 学习驱动方法实现接近MAP的精度，典型误差7-10米，确定性扫描时间1-2毫秒；传统两阶段高斯光束方案有可比误差但随机感测时间长达5毫秒

Conclusion: 该框架在定位精度、计算复杂度和感测延迟之间提供了有利的权衡，是下一代光学LEO跟踪系统的实用候选方案

Abstract: Accurate and low-latency positioning is a key enabler for optical links with Low Earth Orbit (LEO) satellites, where millisecond-level beam alignment is required to maintain reliable high-data-rate communication. This paper presents a learning-driven dual-line laser scanning framework for fast and precise satellite positioning. Unlike conventional Gaussian-beam acquisition systems that rely on multiple sequential beams or mechanical steering, the proposed approach employs two orthogonal line-shaped laser beams to perform structured optical scanning over the ambiguity region without any moving parts. A physics-based model incorporating atmospheric attenuation, turbulence, and MRR-based reflection is developed, and a data-driven neural estimator is trained to map received optical energy patterns to the satellite's two-dimensional position. Simulation results demonstrate that the learning-driven method achieves near-MAP accuracy with typical errors of 7-10 m and deterministic scanning time of 1-2 ms, while conventional two-stage Gaussian-beam schemes exhibit comparable errors but random sensing durations of up to 5 ms. The proposed framework therefore offers a favorable trade-off between positioning accuracy, computational complexity, and sensing latency, making it a practical candidate for next-generation optical LEO tracking systems.

</details>


### [5] [MRR-Based Line-Laser Scanning for Reliable Vehicular Positioning and Optical Communication](https://arxiv.org/abs/2512.12186)
*Mohammad Taghi Dabiri,Hossein Safi,Rula Ammuri,Mazen Hasna,Khalid Qaraqe,Harald Haas,Iman Tavakkolnia*

Main category: eess.SP

TL;DR: 提出一种无机械跟踪的光学联合感知、定位与通信系统，采用结构化的线激光照明和调制后向反射器阵列，通过正交线激光扫描实现高速公路环境下的连续广域覆盖。


<details>
  <summary>Details</summary>
Motivation: 高速车辆环境需要能够在没有机械跟踪的情况下实现联合感知、定位和通信的光学系统。现有的光学和集成感知通信方法通常依赖点光源发射器或基于摄像头的接收器，在高速公路动态环境下限制了空间覆盖范围和更新速率。

Method: 1. 结合结构化线激光照明和车辆上的调制后向反射器阵列；2. 使用两个正交线激光进行同步纵向和横向扫描，提供连续广域覆盖；3. 开发覆盖驱动的分析框架，建模光束发散、扫描几何和驻留时间分配之间的耦合；4. 设计优化方案，调整扫描和发散参数以实现均匀覆盖和功率效率。

Result: 仿真结果显示在固定扫描周期内，空间覆盖均匀性、链路稳定性和可靠性都有显著改善。该系统为下一代车辆JSPC网络的可扩展、抗湍流光架构提供了实用路径。

Conclusion: 该工作提出了一种新型无跟踪光学JSPC系统，通过结构化线激光扫描和MRR阵列，实现了高速车辆环境下更好的空间覆盖和通信质量，为下一代车辆网络提供了有前景的解决方案。

Abstract: High-speed vehicular environments require optical systems capable of joint sensing, positioning, and communication (JSPC) without mechanical tracking. Existing optical and integrated sensing-communication approaches often rely on point-source emitters or camera-based receivers, limiting spatial coverage and update rate under highway dynamics. This work introduces a new class of tracking-free optical JSPC systems that combine structured line-laser illumination with modulating retroreflector (MRR) arrays on vehicles. Two orthogonal line lasers perform synchronized longitudinal and transverse scanning to provide continuous, wide-area coverage across the roadway. A coverage-driven analytical framework models the coupling between beam divergence, scan geometry, and dwell-time allocation, enabling joint evaluation of sensing reliability and communication quality. An optimization scheme is developed to adapt scanning and divergence parameters for uniform coverage and power efficiency. Simulation results demonstrate significant improvements in spatial coverage uniformity, link stability, and reliability within a fixed scan period. These results establish a practical pathway toward scalable, turbulence-resilient optical architectures for next-generation vehicular JSPC networks.

</details>


### [6] [Rotatable Antenna Array-Enhanced Null Steering: Performance Analysis and Optimization](https://arxiv.org/abs/2512.12204)
*Yingqi Wen,Weidong Mei,Yike Xie,Beixiong Zheng,Zhi Chen,Boyu Ning*

Main category: eess.SP

TL;DR: 提出可旋转天线阵列(RAA)架构，通过三维旋转控制增强空间灵活性，实现更好的零陷波束成形性能。


<details>
  <summary>Details</summary>
Motivation: 传统固定方向天线阵列在零陷波束成形方面自由度有限，无法灵活控制波束方向，需要新的天线架构来增强空间灵活性。

Method: 提出可旋转天线阵列架构，联合优化三维旋转角度以最大化期望方向波束增益同时抑制多个干扰方向。采用顺序更新算法迭代优化旋转角度，结合吉布斯采样避免局部最优。

Result: 相比传统固定方向天线阵列，RAA能显著放宽实现有效零陷所需的角分离要求，仿真结果验证了RAA在零陷波束成形方面的优越性能。

Conclusion: 可旋转天线阵列架构通过三维旋转控制提供了增强的空间灵活性，能有效解决传统天线阵列在零陷波束成形方面的局限性，具有更好的性能表现。

Abstract: Conventional fixed-orientation antenna (FOA) arrays offer limited degrees of freedom (DoF) for flexible beamforming such as null steering. To address this limitation, we propose a new rotatable antenna array (RAA) architecture in this paper, which enables three-dimensional (3D) rotational control of an antenna array to provide enhanced spatial flexibility for null steering. To characterize its performance, we aim to jointly optimize the 3D rotational angles of the RAA, to maximize the beam gain over a given desired direction, while nulling those over multiple interference directions under zero-forcing (ZF) beamforming. However, this problem is non-convex and challenging to tackle due to the highly nonlinear expression of the beam gain in terms of the rotational angles. To gain insights, we first examine several special cases including both isotropic and directional antenna radiation patterns, deriving the conditions under which full beam gain can be achieved over the desired direction while meeting the nulling constraints for interference directions. These conditions clearly indicate that compared with FOA arrays, RAAs can significantly relax the angular separation requirement for achieving effective null steering. For other general cases, we propose a sequential update algorithm, that iteratively refines the 3D rotational angles by discretizing the 3D angular search space. To avoid undesired local optimum, a Gibbs sampling (GS) procedure is also employed between two consecutive rounds of sequential update for solution exploration. Simulation results verify our analytical results and show superior null-steering performance of RAAs to FOA arrays.

</details>


### [7] [Movable Access Points in Visible Light Communications: Opportunities, Challenges and Future Directions](https://arxiv.org/abs/2512.12214)
*Sylvester Aboagye,Telex M. N. Ngatched*

Main category: eess.SP

TL;DR: 本文提出了一种基于可移动接入点(MAPs)的可见光通信系统，通过动态重新定位AP来确保视距连接和对齐，在动态环境中优于RIS辅助、固定AP和纯RIS系统。


<details>
  <summary>Details</summary>
Motivation: 可见光通信(VLC)虽然具有频谱丰富、安全性高和基础设施已部署等优势，但其性能受设备方向、视距链路可用性、发射器半角和接收器视场等因素影响。现有可重构智能表面(RIS)解决方案虽然能缓解遮挡和移动性问题，但数据速率远低于直接视距链路。

Method: 提出可移动接入点(MAPs)辅助的VLC系统，通过动态重新定位接入点来提供新的自由度，确保视距连接和发射器-接收器对齐，同时为移动用户提供超高数据速率。

Result: 仿真结果表明，在动态环境中，MAPs辅助的VLC系统性能优于RIS辅助系统、固定AP系统和纯RIS系统。

Conclusion: MAPs为VLC系统提供了有前景的解决方案，能够应对遮挡、方向问题和移动性挑战，同时保持高数据速率。文章还指出了与新兴无线技术集成等关键挑战和未来研究方向。

Abstract: Visible light communication (VLC) is expected to be a key component of future wireless networks due to its abundant license-free spectrum, inherent high-level security, and the already deployed lighting infrastructure. VLC performance, however, depends on device orientation and the availability of an unobstructed line-of-sight (LoS) link, with transmitter semi-angle and receiver field-of-view (FoV) further affecting alignment, coverage, and reliability. Reconfigurable intelligent surfaces (RISs) can mitigate blockages, orientation issues, and mobility challenges, but their data rates remain far below those of direct LoS links. This article introduces the novel concept of movable access points (MAPs)-aided VLC systems, where dynamically repositioned APs provide new degrees of freedom to ensure LoS connectivity, and transmitter-receiver alignment while providing ultra-high data rates for mobile users. Simulation results show MAPs outperform RIS-aided, fixed-AP, and RIS-only VLC systems in dynamic environments. The article also outlines key challenges and future research directions, including integration with emerging wireless technologies.

</details>


### [8] [Robust Energy-Efficient Sleep-Mode Strategy for Multi-RIS-Aided Cell-Free Massive MIMO](https://arxiv.org/abs/2512.12223)
*Hongyi Luo,Wenyu Song,Daniel K. C. So,Zahra Mobini,Zhiguo Ding*

Main category: eess.SP

TL;DR: 本文提出了一种用于无小区大规模MIMO系统的节能传输方案，通过联合协调活动AP和多个无源RIS，在低负载期间动态关闭部分AP，利用RIS维持覆盖，显著提升能效。


<details>
  <summary>Details</summary>
Motivation: 随着无线网络能耗激增，现有研究通常假设持续高流量负载，忽略了用户需求的动态性，导致低需求期间AP利用率不足和能源浪费。需要解决无小区大规模MIMO系统在低负载时期的能效挑战。

Method: 提出了一种新颖的节能传输方案，联合协调活动AP和多个无源RIS。设计了动态AP睡眠模式策略，选择性关闭部分AP，同时利用附近RIS维持覆盖。将能效最大化问题建模为分数规划问题，采用Dinkelbach方法和交替优化迭代求解三个耦合子问题：1) 通过混合分支定界和贪心算法进行AP选择；2) 使用序列凸逼近方法优化发射功率，以启发式迫零策略初始化；3) 使用梯度投影优化RIS相移。

Result: 仿真结果表明，所提出的方案在低和中度用户场景下，相比现有方法实现了显著更高的能效。

Conclusion: 该方案通过动态AP睡眠模式和RIS辅助覆盖，有效解决了无小区大规模MIMO系统在低负载时期的能效问题，为6G网络的节能设计提供了有前景的解决方案。

Abstract: With the explosive growth of data traffic and the ubiquitous connectivity of wireless devices, the energy demands of wireless networks have inevitably escalated. Reconfigurable intelligent surface (RIS) has emerged as a promising solution for 6G networks due to its energy efficiency (EE) and low cost, while cell-free massive multiple-input multiple-output (CF-mMIMO) was proposed as an innovative network architecture without fixed cell boundaries to enhance these measures even further. However, existing studies often assume consistently high traffic loads, neglecting the dynamic nature of user demand. This can result in underutilized access points (APs) and unnecessary energy expenditure during low-demand periods. To tackle the challenge of EE in CF-mMIMO systems during low load periods, this paper proposes a novel energy-efficient transmission scheme that jointly coordinates active APs and multiple passive RISs. Specifically, a dynamic AP sleep-mode strategy is designed, where certain APs are selectively deactivated while nearby RISs assist in maintaining coverage. We formulate the EE maximization objective as a fractional programming problem and adopt the Dinkelbach method in conjunction with alternating optimization (AO) to iteratively solve the three coupled subproblems: (i) AP selection via a hybrid branch-and-bound (BnB) and greedy algorithm, (ii) transmit power optimization using a sequential convex approximation (SCA) method, initialized by a heuristic zero-forcing strategy, and (iii) RIS phase shift optimization using gradient projection. Simulation results show that the proposed scheme achieves significantly higher EE than existing methods in both low and moderate user scenarios.

</details>


### [9] [WATOS: Efficient LLM Training Strategies and Architecture Co-exploration for Wafer-scale Chip](https://arxiv.org/abs/2512.12279)
*Huizheng Wang,Zichuan Wang,Hongbin Wang,Jingxiang Hou,Taiquan Wei,Chao Li,Yang Hu,Shouyi Yin*

Main category: eess.SP

TL;DR: WATOS是一个针对大语言模型训练与晶圆级架构的协同探索框架，通过优化硬件架构参数和训练策略，显著提升训练吞吐量。


<details>
  <summary>Details</summary>
Motivation: 大语言模型训练对计算、内存和互连带宽需求极高，晶圆级集成虽能提供高密度集成和高带宽互连，但有限的晶圆面积需要在计算、内存和通信资源间权衡。现有方法无法有效解决这些挑战。

Method: 提出WATOS协同探索框架：1) 定义高度可配置的硬件模板来探索晶圆级芯片的最佳架构参数；2) 利用晶圆级芯片的高D2D带宽和细粒度操作优势，探索最优并行化和资源分配策略，解决LLM训练中的内存利用率不足问题。

Result: 相比最先进的Megatron训练框架和Cerebras的权重流式晶圆训练策略，WATOS在各种LLM模型上分别实现了平均2.74倍和1.53倍的整体吞吐量提升。同时揭示了晶圆级架构设计的重要见解。

Conclusion: WATOS有效解决了晶圆级架构与LLM训练策略的协同优化问题，显著提升了训练性能，并为晶圆级架构设计提供了有价值的指导。

Abstract: Training large language models (LLMs) imposes extreme demands on computation, memory capacity, and interconnect bandwidth, driven by their ever-increasing parameter scales and intensive data movement. Wafer-scale integration offers a promising solution by densely integrating multiple single-die chips with high-speed die-to-die (D2D) interconnects. However, the limited wafer area necessitates trade-offs among compute, memory, and communication resources. Fully harnessing the potential of wafer-scale integration while mitigating its architectural constraints is essential for maximizing LLM training performance. This imposes significant challenges for the co-optimization of architecture and training strategies. Unfortunately, existing approaches all fall short in addressing these challenges.
  To bridge the gap, we propose WATOS, a co-exploration framework for LLM training strategy and wafer-scale architecture. We first define a highly configurable hardware template designed to explore optimal architectural parameters for wafer-scale chips. Based on it, we capitalize on the high D2D bandwidth and fine-grained operation advantages inherent to wafer-scale chips to explore optimal parallelism and resource allocation strategies, effectively addressing the memory underutilization issues during LLM training. Compared to the state-of-the-art (SOTA) LLM training framework Megatron and Cerebras' weight streaming wafer training strategy, WATOS can achieve an average overall throughput improvement of 2.74x and 1.53x across various LLM models, respectively. In addition, we leverage WATOS to reveal intriguing insights about wafer-scale architecture design with the training of LLM workloads.

</details>


### [10] [XR Capacity Enhancement through Multi-Connected XR Tethering Groups](https://arxiv.org/abs/2512.12368)
*Muhammad Ahsen,Boyan Yanakiev,Claudio Rosa,Ramoni Adeogun*

Main category: eess.SP

TL;DR: 本文研究通过多连接XR系留组（TGr）提升5G-A网络中XR容量，采用选择合并和软合并技术，结合增强的联合OLLA算法，显著提高XR容量和eMBB吞吐量。


<details>
  <summary>Details</summary>
Motivation: 5G-A网络中XR应用面临高吞吐量、低延迟和高可靠性的挑战，现有网络容量有限，需要提升XR容量以满足需求。

Method: 提出多连接XR系留组，包含XR设备和协作的5G-A设备，研究选择合并和软合并两种协作方式，结合联合HARQ反馈处理算法和增强的联合OLLA算法，通过动态系统级仿真验证。

Result: 软合并的XR TGr在纯XR用户场景下提升23-42%容量，在XR与eMBB共存场景下提升38-173%容量；增强联合OLLA算法在仅单设备提供CSI报告时也能实现类似性能增益；同时提升eMBB吞吐量。

Conclusion: 多连接XR系留组特别是软合并技术能显著提升5G-A网络中XR容量，增强的联合OLLA算法减少了对CSI报告的依赖，为未来XR应用部署提供了有效解决方案。

Abstract: Extended Reality (XR) applications have limited capacity in 5th generation-advanced (5G-A) cellular networks due to high throughput requirements coupled with strict latency and high reliability constraints. To enhance XR capacity in the downlink (DL), this paper investigates multi-connected XR tethering groups (TGrs), comprising an XR device and a cooperating 5G-A device. This paper presents investigations for two types of cooperation within XR TGr, i.e., selection combining (SC) and soft combining and their impact on the XR capacity of the network. These investigations consider joint hybrid automatic repeat request (HARQ) feedback processing algorithm and also propose enhanced joint Outer Loop Link Adaptation (OLLA) algorithm to leverage the benefits of multi-connectivity. These enhancements aim to improve the spectral efficiency of the network by limiting HARQ retransmissions and enabling the use of higher modulation and coding scheme (MCS) indices for given signal-to-interference-plus-noise ratio (SINR), all while maintaining or operating below than the target block error rate (BLER). Dynamic system-level simulation demonstrate that XR TGrs with soft combining achieve performance improvements of 23 - 42% in XR capacity with only XR users and 38-173% in the coexistence scenarios consisting of XR users and enhanced mobile broadband (eMBB) user. Furthermore, the enhanced joint OLLA algorithm enables similar performance gains even when only one device per XR TGr provides channel state information (CSI) reports, compared to scenarios where both devices report CSI. Notably, XR TGrs with soft combining also enhance eMBB throughput in coexistence scenarios.

</details>


### [11] [Comparing Stochastic and Ray-tracing Datasets in Machine Learning for Wireless Applications](https://arxiv.org/abs/2512.12449)
*João Morais,Akshay Malhotra,Shahab Hamidi-Rad,Ahmed Alkhateeb*

Main category: eess.SP

TL;DR: 研究无线通信中机器学习时，标准随机信道模型与射线追踪数据的适用性对比，发现随机模型评估可能高估或低估实际性能，提出任务感知的使用方法


<details>
  <summary>Details</summary>
Motivation: 无线系统中机器学习研究常用标准随机信道模型（如TDL/CDL/UMa），但这些模型的结构假设可能与实际传播存在差异。需要了解何时这些模型足够，何时需要更接近真实世界的射线追踪数据

Method: 通过两个代表性任务（CSI压缩和时序信道预测）进行实证研究，采用域内训练、跨域评估和小数据微调协议，对比标准随机模型和射线追踪数据的性能

Result: 在不同设置下，仅使用随机模型评估可能相对于RT数据高估或低估性能。随机模型可用于可扩展的预训练和不需要强时空耦合的任务，但当这种耦合重要时，预训练和评估应基于空间一致或几何相似的RT场景

Conclusion: 提出任务感知的使用方法：随机模型可用于可扩展预训练和弱时空耦合任务；强时空耦合任务需要基于射线追踪数据的预训练和评估。为未来基准测试和标准化提供初步指导

Abstract: Machine learning for wireless systems is commonly studied using standardized stochastic channel models (e.g., TDL/CDL/UMa) because of their legacy in wireless communication standardization and their ability to generate data at scale. However, some of their structural assumptions may diverge from real-world propagation. This paper asks when these models are sufficient and when ray-traced (RT) data - a proxy for the real world - provides tangible benefits. To answer these questions, we conduct an empirical study on two representative tasks: CSI compression and temporal channel prediction. Models are trained and evaluated using in-domain, cross-domain, and small-data fine-tuning protocols. Across settings, we observe that stochastic-only evaluation may over- or under-estimate performance relative to RT. These findings support a task-aware recipe where stochastic models can be leveraged for scalable pre-training and for tasks that do not rely on strong spatiotemporal coupling. When that coupling matters, pre-training and evaluation should be grounded in spatially consistent or geometrically similar RT scenarios. This study provides initial guidance to inform future discussions on benchmarking and standardization.

</details>


### [12] [Wavelet-Packet-based Noise Signatures With Higher-Order Statistics for Anomaly Prediction](https://arxiv.org/abs/2512.12528)
*Indrakshi Dey,Ilias Cherkaoui,Mohamed Khalafalla Hassan*

Main category: eess.SP

TL;DR: 首个面向融合离散时间信号的噪声中心异常预测方法，利用小波包变换分离结构与残差，高阶统计量量化非高斯性，构建紧凑噪声特征，通过马氏距离检测器实现闭式决策规则。


<details>
  <summary>Details</summary>
Motivation: 现有方法缺乏针对融合离散时间信号的噪声中心异常预测，需要开发能够有效分离信号结构与噪声残差、量化非高斯特性并提供闭式检测规则的创新方法。

Method: 使用小波包变换进行时频展开，通过正交投影分离结构与残差；采用高阶统计量（特别是三阶累积量及其双谱解释）量化非高斯性和非线性耦合；构建紧凑噪声特征，设计解析校准的马氏距离检测器。

Result: 建立了正交性、能量守恒、累积量的高斯零行为等理论性质，获得了在均值偏移替代假设下具有非中心卡方性能的闭式决策规则，实现了首个噪声中心的异常预测框架。

Conclusion: 该方法为融合离散时间信号的异常预测提供了首个噪声中心框架，结合小波包变换、高阶统计量和马氏距离检测，实现了理论严谨且实用的异常检测系统。

Abstract: This note develops the first-ever noise-centric anomaly prediction method for a fused discrete-time signal. A Wavelet Packet Transform (WPT) provides a time--frequency expansion in which structure and residual can be separated via orthogonal projection. Higher-Order Statistics (HOS), particularly the third-order cumulant (and its bispectral interpretation), quantify non-Gaussianity and nonlinear coupling in the extracted residual. Compact noise signatures are constructed and an analytically calibrated Mahalanobis detector yields a closed-form decision rule with non-central chi-square performance under mean-shift alternatives. Propositions and proofs establish orthonormality, energy preservation, Gaussian-null behavior of cumulants, and the resulting test statistics.

</details>


### [13] [Power Consumption and Energy Efficiency of Mid-Band XL-MIMO: Modeling, Scaling Laws, and Performance Insights](https://arxiv.org/abs/2512.12725)
*Jiachen Tian,Yu Han,Xiao Li,Shi Jin,Chao-Kai Wen*

Main category: eess.SP

TL;DR: 论文研究了中频段超大规模MIMO系统的能效问题，提出了综合功耗模型和吞吐量分析框架，推导了能效与系统配置的缩放规律，验证了中频段XL-MIMO在能效方面的优越性。


<details>
  <summary>Details</summary>
Motivation: 中频段超大规模MIMO作为未来通信系统的关键技术，虽然能通过扩展带宽和增大天线孔径提供更高吞吐量，但系统维度增大导致功耗问题严重，需要深入研究高效系统设计和部署方案。

Method: 提出了综合功耗模型，涵盖主要硬件组件和信号处理过程的功耗，并考虑关键系统参数影响。针对典型近场传播特性推导了吞吐量的闭式近似，建立了能效评估的分析框架。基于该框架推导了能效与关键系统配置的缩放规律，并对代表性多天线技术进行了扩展和比较。

Result: 数值结果验证了吞吐量分析的紧密度和能效评估的有效性，揭示了中频段XL-MIMO系统在能效方面的潜力，证明了其在能效方面相对于其他多天线技术的优越性。

Conclusion: 中频段XL-MIMO系统在提供高吞吐量的同时，通过合理的系统设计和配置可以实现优异的能效表现，为未来通信系统的能效优化提供了有价值的见解和设计指导。

Abstract: Mid-band extra-large-scale multiple-input multiple-output (XL-MIMO), emerging as a critical enabler for future communication systems, is expected to deliver significantly higher throughput by leveraging the extended bandwidth and enlarged antenna aperture. However, power consumption remains a significant concern due to the enlarged system dimension, underscoring the need for thorough investigations into efficient system design and deployment. To this end, an in-depth study is conducted on mid-band XL-MIMO systems. Specifically, a comprehensive power consumption model is proposed, encompassing the power consumption of major hardware components and signal processing procedures, while capturing the influence of key system parameters. Considering typical near-field propagation characteristics, closed-form approximations of throughput are derived, providing an analytical framework for assessing energy efficiency (EE). Based on the proposed framework, the scaling law of EE with respect to key system configurations is derived, offering valuable insights for system design. Subsequently, extensions and comparisons are conducted among representative multi-antenna technologies, demonstrating the superiority of mid-band XL-MIMO in EE. Extensive numerical results not only verify the tightness of the throughput analysis but also validate the EE evaluations, unveiling the potential of energy-efficient mid-band XL-MIMO systems.

</details>


### [14] [Channel Estimation for Full-duplex Multi-tag Ambient Backscatter Communication Systems with I/Q Imbalance](https://arxiv.org/abs/2512.12811)
*Saeed Abdallah,Mahmoud A. Albreem,Bassel Al Homssi,Mohamed Saad,Abdulmalik Alwarafy*

Main category: eess.SP

TL;DR: 本文针对全双工多标签环境反向散射通信系统，提出了一种三阶段训练协议和导频估计方案，以及两种半盲估计器，解决了多标签、自干扰和I/Q不平衡下的信道估计问题。


<details>
  <summary>Details</summary>
Motivation: 全双工多标签环境反向散射通信系统对于下一代物联网网络至关重要，但存在多个标签、自干扰和I/Q不平衡等硬件损伤，使得准确的信道估计对于有效干扰管理变得不可或缺。大量信道参数和信号分量的镜像图像需要精心设计信道估计阶段以防止性能下降。

Method: 提出了一种新颖的三阶段训练协议和基于导频的估计方案，确保信号正交性并成功避免误差平台。还提出了两种半盲估计器：一种基于决策导向准则，另一种基于期望条件最大化框架。这些估计器通过利用导频和数据符号实现更高的估计精度。

Result: 推导了两种估计类型的克拉美罗界。基于导频的估计器和ECM估计器接近各自的CRB，而DD估计器性能介于两者之间。三种解决方案通过提供不同的性能与计算复杂度权衡来支持不同的使用场景。

Conclusion: 提出的三阶段训练协议和三种估计方案有效解决了全双工多标签AmBC系统中的信道估计挑战，为不同应用场景提供了性能与复杂度的灵活权衡。

Abstract: Ambient backscatter communication (AmBC) has emerged as a highly attractive paradigm for energy-efficient communication. Full-duplex multi-tag AmBC systems provide the scalability and efficient spectrum utilization essential for next generation Internet-of-Things (IoT) networks. However, the presence of multiple tags, self-interference and hardware impairments such as inphase/quadrature (I/Q) imbalance, makes accurate channel estimation indispensable for efficient interference management. The large number of channel parameters and the presence of mirror images of each signal component necessitate careful design of the channel estimation phase to prevent performance degradation. In this work, we propose a novel three-stage training protocol and pilot-based estimation scheme that ensure signal orthogonality and successfully avoid error floors. We also propose two semi-blind estimators, one based on decision-directed (DD) criterion and the other on the expectation conditional maximization (ECM) framework. By exploiting both pilots and data symbols, these two estimators achieve higher estimation accuracy than pilot-based estimation, at the cost of additional complexity. Cramer-Rao bounds (CRBs) for both types of estimation are also derived. The pilot-based estimator and the ECM estimator approach their respective CRBs, while the DD estimator performs mid-way between them. The three proposed solutions support different use cases by offering distinct tradeoffs between performance and computational complexity.

</details>


### [15] [A Comprehensive Survey of Channel Estimation Techniques for OTFS in 6G and Beyond Wireless Networks](https://arxiv.org/abs/2512.13032)
*Emir Aslandogan,Haci Ilhan,Burak Ahmet Ozden,Erdogan Aydin,Ertugrul Basar,Miaowen Wen,Marco Di Renzo,Vincent Poor*

Main category: eess.SP

TL;DR: 本文系统综述了OTFS调制系统中的信道估计技术，涵盖从基础方法到前沿方法的完整研究版图，包括DD域和TF域估计、多种算法框架、联合估计与检测策略，以及与下一代无线系统的集成。


<details>
  <summary>Details</summary>
Motivation: OTFS调制作为专门针对高移动性场景和多普勒效应的无线通信技术，在挑战性传播环境中具有优越的信道估计性能。然而，需要系统梳理该领域从基础到前沿的研究进展，为未来研究提供指导。

Method: 文章采用系统性综述方法，分析DD域和TF域信道估计技术，包括独立导频、嵌入式导频和叠加导频方法；涵盖贝叶斯学习、匹配追踪、消息传递算法、深度学习等多种算法框架；探讨联合信道估计与信号检测策略。

Result: 全面梳理了OTFS信道估计技术的研究现状，识别了关键实现挑战，包括泄漏抑制、多普勒间干扰缓解、脉冲噪声处理、信令开销减少、保护空间要求、PAPR管理、波束斜视效应和硬件损伤等。

Conclusion: OTFS信道估计技术已取得显著进展，但仍面临多项实现挑战。未来研究应关注与大规模MIMO、毫米波通信、可重构智能表面和集成感知通信等下一代无线系统的集成，以及解决实际部署中的关键技术问题。

Abstract: Orthogonal time-frequency space (OTFS) modulation has emerged as a powerful wireless communication technology that is specifically designed to address the challenges of high-mobility scenarios and significant Doppler effects. Unlike conventional modulation schemes that operate in the time-frequency (TF) domain, OTFS projects signals to the delay-Doppler (DD) domain, where wireless channels exhibit sparse and quasi-static characteristics. This fundamental transformation enables superior channel estimation (CE) performance in challenging propagation environments characterized by high-mobility, severe multipath effects, and rapidly time-varying channel conditions. This article provides a systematic examination of CE techniques for OTFS systems, covering the extensive research landscape from foundational methods to cutting-edge approaches. We present a detailed analysis of DD and TF domain CE techniques presented in the literature, including separate pilot, embedded pilot, and superimposed pilot approaches. The article encompasses various algorithmic frameworks including Bayesian learning, matching pursuit-based techniques, message passing algorithms, deep learning (DL)-based methods, and recent CE approaches. Additionally, we explore joint CE and signal detection (SD) strategies, the integration of OTFS with next-generation wireless systems including massive multiple-input multiple-output (MIMO), millimeter wave (mmWave) communications, reconfigurable intelligent surfaces (RISs), and integrated sensing and communication (ISAC) systems. Critical implementation challenges are presented, including leakage suppression, inter-Doppler interference mitigation, impulsive noise handling, signaling overhead reduction, guard space requirements, peak-to-average power ratio (PAPR) management, beam squint effects, and hardware impairments.

</details>


### [16] [MR Fingerprinting for Imaging Brain Hemodynamics and Oxygenation](https://arxiv.org/abs/2512.13224)
*T. Coudert,A. Delphin,A. Barrier,E L Barbier,B. Lemasson,J M Warnking,T. Christen*

Main category: eess.SP

TL;DR: 本文综述了磁共振指纹（MRF）技术在脑血流动力学、氧合和灌注定量方面的研究进展，重点介绍了血管模拟几何模型、新序列以及结合机器学习和深度学习的最新重建技术。


<details>
  <summary>Details</summary>
Motivation: 过去十年中，多项研究探索了磁共振指纹（MRF）在脑血流动力学、氧合和灌注定量方面的潜力。随着模拟模型和重建框架的进步，血管参数估计的准确性显著提高，需要对这些进展进行系统性综述。

Method: 本文是一篇综述性文章，系统回顾了血管MRF研究的关键进展，包括：1）血管模拟的几何模型改进；2）新型序列开发；3）结合机器学习和深度学习的最新重建技术；4）临床前和临床应用分析。

Result: 综述总结了血管MRF研究的重要进展，展示了模拟模型和重建框架如何显著提高血管参数估计的准确性，并讨论了该技术在临床前和临床环境中的应用情况。

Conclusion: 基于现有研究进展，本文指出了未来发展方向和需要解决的关键问题，以促进血管MRF技术的临床转化。技术效能处于第一阶段，证据水平为N/A。

Abstract: Over the past decade, several studies have explored the potential of magnetic resonance fingerprinting (MRF) for the quantification of brain hemodynamics, oxygenation, and perfusion. Recent advances in simulation models and reconstruction frameworks have also significantly enhanced the accuracy of vascular parameter estimation. This review provides an overview of key vascular MRF studies, emphasizing advancements in geometrical models for vascular simulations, novel sequences, and state-of-the-art reconstruction techniques incorporating machine learning and deep learning algorithms. Both pre-clinical and clinical applications are discussed. Based on these findings, we outline future directions and development areas that need to be addressed to facilitate their clinical translation. Evidence Level N/A. Technical Efficacy Stage 1.

</details>


### [17] [Interference-Free RIS-Aided Cell-Free Massive MIMO with Physical Layer Security](https://arxiv.org/abs/2512.13243)
*Sumeyra Hassan,Bin Li,Yalcin Sadi,Erdal Panayirci,H. Vincent Poor*

Main category: eess.SP

TL;DR: 提出了一种RIS辅助的无蜂窝大规模MIMO框架，通过CSI预编码抑制多用户干扰，并采用交替优化和黎曼流形优化最大化保密和速率


<details>
  <summary>Details</summary>
Motivation: 下一代无线网络需要增强物理层安全性和抑制多用户干扰，特别是在密集无线环境中。传统方法在安全性和干扰管理方面存在局限，需要新的框架来同时解决这两个问题。

Method: 1. 设计基于CSI的预编码器抑制多用户干扰；2. 采用交替优化框架联合优化AP的主动波束成形、用户功率分配和RIS相移矩阵；3. 使用黎曼流形优化框架和黎曼共轭梯度算法解决高度非凸的RIS相移设计问题。

Result: 仿真结果表明，所提框架有效提升了保密和速率并消除了干扰，证明了其在密集无线环境中构建安全、可扩展的无蜂窝大规模MIMO网络的潜力。

Conclusion: RIS辅助的无蜂窝大规模MIMO框架能够同时增强物理层安全性和抑制多用户干扰，为下一代无线网络提供了有效的安全解决方案。

Abstract: In this paper, a reconfigurable intelligent surface (RIS) assisted cell free massive MIMO (CFmMIMO) framework is designed to enhance physical layer security (PLS) and mitigate multi user (MU) interference in next generation wireless networks. A channel state information (CSI) based precoder is designed at the access point (AP) to suppress MU interference, enabling interference free reception for the legitimate users. To further enhance secrecy performance, we formulate a joint optimization problem that maximizes the secrecy sum rate using an alternating optimization (AO) framework, which iteratively updates the active beamforming at the AP, user power allocation, and the RIS phase shift matrix. The highly nonconvex problem is addressed under the Riemannian manifold optimization (RMO) framework and solved using a Riemannian Conjugate Gradient (RCG) algorithm for RIS phase shift design. Simulation results verify that the proposed framework effectively enhances the secrecy sum rate and eliminates interference, demonstrating its potential for secure and scalable CFmMIMO networks in dense wireless environments.

</details>


### [18] [From Nodes to Edges: Edge-Based Laplacians for Brain Signal Processing](https://arxiv.org/abs/2512.13420)
*Andrea Santoro,Marco Nurisso,Giovanni Petri*

Main category: eess.SP

TL;DR: 边缘图信号处理在脑网络分析中优于传统节点方法，能更好捕捉脑区间的协同波动信息


<details>
  <summary>Details</summary>
Motivation: 传统图信号处理方法只关注节点信号，无法捕捉边缘上的重要动态信息。脑网络分析需要能处理边缘信号的方法来理解脑区间的功能连接和协同波动。

Method: 采用边缘中心的图信号处理方法，使用一维Hodge拉普拉斯算子描述结构连接性，处理定义在边缘上的信号来捕捉脑区间的协同波动信息。

Result: 在静态和动态场景中，基于边缘的方法相比传统节点方法实现了更优的任务解码准确性，揭示了脑功能组织的独特方面。

Conclusion: 边缘聚焦的图信号处理策略有望深化我们对脑连接性和功能动态的理解，为脑网络分析提供了新的有效工具。

Abstract: Traditional graph signal processing (GSP) methods applied to brain networks focus on signals defined on the nodes. Thus, they are unable to capture potentially important dynamics occurring on the edges. In this work, we adopt an edge-centric GSP approach to analyze edge signals constructed from 100 unrelated subjects of the Human Connectome Project. Specifically, we describe structural connectivity through the lens of the 1-dimensional Hodge Laplacian, processing signals defined on edges to capture co-fluctuation information between brain regions. We demonstrate that edge-based approaches achieve superior task decoding accuracy in static and dynamic scenarios compared to conventional node-based techniques, thereby unveiling unique aspects of brain functional organization. These findings underscore the promise of edge-focused GSP strategies for deepening our understanding of brain connectivity and functional dynamics.

</details>


### [19] [Interference Mitigation Recommender System using U-Net Autoencoders](https://arxiv.org/abs/2512.13533)
*Hiten Prakash Kothari,R. Michael Buehrer*

Main category: eess.SP

TL;DR: 提出模块化推荐系统，根据干扰特征自动选择最佳干扰抑制策略，通过分类、预测和专用U-Net自编码器提升通信鲁棒性


<details>
  <summary>Details</summary>
Motivation: 在动态通信环境中，单一干扰抑制方法难以应对多样化的干扰特征，需要自适应系统根据具体干扰情况选择最优策略

Method: 构建三阶段模块化系统：SPS分类器识别干扰参数，SIR预测器评估信干比，专用U-Net自编码器库处理不同干扰条件，推荐器根据分析结果选择最佳抑制模型

Result: 在不同SIR水平和调制环境下，推荐策略相比单一方法显著降低误码率，提升系统鲁棒性

Conclusion: 自适应模型选择架构能有效增强动态通信环境中的干扰抑制能力，为智能干扰管理提供新思路

Abstract: Building on the previous work on interference mitigation, this paper introduces a modular recommender system that automatically selects the most effective interference mitigation strategy based on the interference characteristics present in the received signal. The system integrates three key stages: an SPS classifier module, a SIR predictor, and a bank of specialized U-Net autoencoders designed for different interference conditions. The classification block identifies the parameters required for cancellation. The recommender then directs the signal to the appropriate mitigation model, optionally incorporating SIR-based decisions for scenarios where successive interference cancellation may be advantageous. Experiments conducted across diverse SIR levels and modulation environments show that the recommender strategy improves robustness and reduces BER compared to using any single mitigation method alone. The results demonstrate the potential of adaptive, model-selective architectures to enhance interference resilience in dynamic communication environments.

</details>


### [20] [On the Ability of Deep Learning to Detect Signals with Unknown Parameters](https://arxiv.org/abs/2512.13542)
*Tom Anders,Hiten Prakash Kothari,R. Michael Buehrer*

Main category: eess.SP

TL;DR: 该论文研究了在AWGN背景下使用深度神经网络进行信号检测，并与统计方法和匹配滤波器进行比较，旨在最大化检测概率同时保持恒定虚警概率。


<details>
  <summary>Details</summary>
Motivation: 在通信、声纳、雷达和定位等信号处理应用中，信号检测是一个基本问题。当信号参数未知时，不存在最优检测器（Neyman-Pearson意义上），而匹配滤波器作为性能上界需要完美的信号先验知识。近年来深度神经网络在假设检验问题上表现出色，因此研究DNN在原始I/Q层面的信号检测应用。

Method: 在原始I/Q层面应用基于DNN的方法进行信号检测，并与统计方法和匹配滤波器进行比较。训练和评估了两种机器学习算法，针对三种感兴趣信号模型。还训练了一个统一数据集上的模型，并在所有感兴趣信号上进行评估。

Result: 论文评估了DNN方法在信号检测问题上的性能，与统计方法和匹配滤波器进行了比较。具体结果需要查看完整论文，但研究框架表明DNN方法在最大化检测概率同时控制虚警概率方面具有潜力。

Conclusion: 深度神经网络在原始I/Q层面的信号检测问题上具有应用价值，能够与传统的统计方法和匹配滤波器相竞争，特别是在信号参数未知的情况下，DNN方法可能提供更优的检测性能。

Abstract: In many signal processing applications, including communications, sonar, radar, and localization, a fundamental problem is the detection of a signal of interest in background noise, known as signal detection [1] [2]. A simple version of this problem is the detection of a signal of interest with unknown parameters in Additive White Gaussian Noise (AWGN). When the parameters defining the signal are not known, an optimal detector (in the Neyman-Pearson sense) does not exist. An upper bound on the performance of any detector is the matched filter, which implies perfect sample by sample knowledge of the signal of interest. In recent years Deep Neural Networks (DNNs) have proven to be very effective at hypothesis testing problems such as object detection and image classification. This paper examines the application of DNN-based approaches to the signal detection problem at the raw I/Q level and compares them to statistically based approaches as well as the Matched Filter. These methods aim to maximize the Probability of Detection Pd while maintaining a constant Probability of False Alarm PF A. Two Machine Learning (ML) algorithms are trained and assessed on this signal detection problem, across three signal of interest models. A model was also trained on a unified dataset and assessed across all signals of interest.

</details>


### [21] [A new data weighted averaging algorithm to reduce tones in the signal band](https://arxiv.org/abs/2512.13605)
*Marta Laguna,Juana M. Martínez-Heredia,Manuel G. Satué*

Main category: eess.SP

TL;DR: 本文分析了基于sigma-delta调制的数模转换器中DWA方法产生杂散音调的机制，并提出了一种改进的DWA方法来消除这些杂散音调。


<details>
  <summary>Details</summary>
Motivation: 多比特sigma-delta调制器通过降低时钟频率和增加量化器电平数来平衡复杂性和速度，但多位数模转换块(DAC)可能降低系统性能。现有的数据加权平均(DWA)方法虽然能减少DAC误差的敏感性，但会在信号带内产生杂散音调。

Method: 分析DWA方法产生杂散音调的机制，并提出一种改进的DWA算法来消除这些杂散音调。

Result: 通过分析揭示了DWA方法产生杂散音调的具体机制，并提出了能够有效消除这些杂散音调的改进DWA方法。

Conclusion: 改进的DWA方法能够在保持减少DAC误差敏感性的同时，消除传统DWA方法产生的杂散音调，从而提升基于sigma-delta调制的数模转换器的整体性能。

Abstract: Digital/Analog converters based on sigma-delta modulation are simple and unexpensive circuits featuring a signal bandwidth limited by speed constraints. Multi-bit modulators allow balancing complexity and speed by reducing the clock frequency and increasing the number of levels in the quantizer. In this case, the multi-bit digital to analog block (DAC) can reduce the performance of the entire system. Data Weighted Averaging (DWA) methods have been proposed to reduce the vulnerability to DAC errors at the cost of spurious tones in the signal band. This work analyzes the tone producing mechanism and proposes a modification of the DWA to remove spurious tones.

</details>


### [22] [Performance Limits of Hardware-Constrained THz Inter-Satellite MIMO-ISAC Systems](https://arxiv.org/abs/2512.13652)
*Haofan Dong,Ozgur B. Akan*

Main category: eess.SP

TL;DR: 该论文建立了太赫兹卫星间链路MIMO ISAC系统在恒定包络约束下的理论性能极限，揭示了硬件失真导致的容量天花板，并提出了统一的链路预算框架。


<details>
  <summary>Details</summary>
Motivation: 太赫兹卫星间链路虽然提供巨大带宽，但受限于星载功率和热预算。硬件失真（功率放大器非线性、ADC量化、振荡器相位噪声）会导致性能瓶颈，需要建立理论框架来指导硬件高效的系统设计。

Method: 1) 建立恒定包络传输约束下的MIMO ISAC系统模型；2) 提出统一链路预算框架，集成波束斜视、孔径指向误差和有色噪声源；3) 通过Whittle-Fisher信息矩阵推导感知界限，采用恒定加速度运动学模型；4) 分析MIMO缩放规律和临界SNR特性。

Result: 1) 硬件失真导致容量天花板，无法通过增加发射功率克服；2) 感知精度随阵列尺寸改善（RMSE ∝ 1/√(N_t N_r)）；3) 临界SNR具有尺度不变性；4) 动态状态估计误差以α^{-5}缩放，存在操作不可行区域（α < α* ≈ 0.16）。

Conclusion: 该研究为硬件高效的太赫兹卫星间链路星座提供了设计指导，揭示了硬件失真对系统性能的根本限制，并确定了操作约束下的关键阈值参数。

Abstract: Terahertz inter-satellite links (THz-ISL) offer unprecedented bandwidth for future space networks but face fundamental constraints from onboard power and thermal budgets. This paper establishes theoretical performance limits for MIMO Integrated Sensing and Communication (ISAC) systems under per-element constant-envelope (CE) transmission constraints. We demonstrate that hardware distortions -- specifically power amplifier nonlinearity, ADC quantization, and oscillator phase noise -- impose a capacity ceiling that cannot be overcome by increasing transmit power. A unified link budget framework integrates wideband beam squint, aperture pointing errors, and colored noise sources through a spectral consistency principle that ensures residual phase noise is counted exactly once across communication and sensing analyses. The sensing bounds are derived via the Whittle-Fisher Information Matrix under a Constant Acceleration kinematic model with jerk noise, yielding closed-form scaling laws: residual phase noise variance scales as $α^{-1}$ while dynamic state-estimation error (DSE) variance scales as $α^{-5}$ with pilot overhead $α$. Numerical results show divergent MIMO scaling: sensing precision improves with array size ($\mathrm{RMSE} \propto 1/\sqrt{N_t N_r}$), while the critical SNR exhibits scale invariance regarding array size, implying that the distortion-limited transition point stabilizes regardless of the array scale. The steep $α^{-5}$ DSE scaling creates an operationally infeasible region at $α< α^* \approx 0.16$, where $α^* = (C_{\mathrm{DSE}}/C_{\mathrm{PN}})^{1/4}$ -- a constraint-driven threshold under the adopted baseline for LEO operation. These findings provide design guidelines for hardware-efficient THz-ISL constellations.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [23] [Differentially Private Community Detection in $h$-uniform Hypergraphs](https://arxiv.org/abs/2512.12031)
*Javad Zahedi Moghaddam,Aria Nosratinia*

Main category: cs.IT

TL;DR: 研究h-均匀超图中连接隐私保护下的精确恢复阈值，分析三种差分隐私机制在h-均匀随机块模型中的性能


<details>
  <summary>Details</summary>
Motivation: 在超图数据分析中，如何在保护连接隐私的同时实现社区检测的精确恢复是一个重要问题。现有研究主要关注普通图的边差分隐私，而超图结构更复杂，需要扩展隐私保护框架并分析不同隐私机制对恢复性能的影响。

Method: 采用h-均匀随机块模型(h-HSBM)建模超图观测，研究三种差分隐私机制：基于稳定性的机制、基于采样的机制和基于扰动的机制。分析每种机制在(ε, δ)-超边差分隐私下的精确恢复阈值，并研究隐私预算对恢复区域的影响。

Result: 基于采样的机制和随机响应机制能保证纯ε-超边差分隐私(δ=0)，而基于稳定性的机制无法达到此隐私级别。隐私预算的最小值对于稳定性机制和贝叶斯采样机制与簇内超边密度与跨簇超边密度比的对数成正比，而对于随机响应机制仅依赖于超图大小。

Conclusion: 不同差分隐私机制在超图社区检测中提供不同的隐私-效用权衡。基于稳定性和贝叶斯采样的机制需要隐私预算随信号强度对数增长，而随机响应机制对信号强度不敏感但可能效率较低。这为超图隐私保护的实际应用提供了理论指导。

Abstract: This paper studies the exact recovery threshold subject to preserving the privacy of connections in $h$-uniform hypergraphs. Privacy is characterized by the $(ε, δ)$-hyperedge differential privacy (DP), an extension of the notion of $(ε, δ)$-edge DP in the literature. The hypergraph observations are modeled through a $h$-uniform stochastic block model ($h$-HSBM) in the dense regime. We investigate three differentially private mechanisms: stability-based, sampling-based, and perturbation-based mechanisms. We calculate the exact recovery threshold for each mechanism and study the contraction of the exact recovery region due to the privacy budget, $(ε, δ)$. Sampling-based mechanisms and randomized response mechanisms guarantee pure $ε$-hyperedge DP where $δ=0$, while the stability-based mechanisms cannot achieve this level of privacy. The dependence of the limits of the privacy budget on the parameters of the $h$-uniform hypergraph is studied. More precisely, it is proven rigorously that the minimum privacy budget scales logarithmically with the ratio between the density of in-cluster hyperedges and the cross-cluster hyperedges for stability-based and Bayesian sampling-based mechanisms, while this budget depends only on the size of the hypergraph for the randomized response mechanism.

</details>


### [24] [A Framework for Scalable Digital Twin Deployment in Smart Campus Building Facility Management](https://arxiv.org/abs/2512.12149)
*Thyda Siv*

Main category: cs.IT

TL;DR: 提出一个可扩展的数字孪生框架，整合3D激光扫描、BIM建模和物联网数据可视化，用于校园建筑设施管理，并在Georgia Tech的Price Gilbert大楼进行案例验证。


<details>
  <summary>Details</summary>
Motivation: 现有数字孪生研究往往局限于孤立领域（如点云几何或能源分析），缺乏将建筑几何、设备元数据和运营数据整合到统一设施管理平台的可扩展、可互操作工作流程。

Method: 1) 使用地面激光扫描进行实景捕捉和结构化点云处理；2) 开发包含建筑、机械、电气、管道、输送和传感器系统的丰富BIM模型；3) 创建数字孪生环境，在管理平台中链接设备元数据、维护策略和模拟物联网数据。

Result: 在Georgia Tech的Price Gilbert大楼案例中，成功建模509个设备项目并嵌入OmniClass分类到数字孪生中，开发了10个交互式仪表板可视化系统性能。框架实现了集中资产文档管理、改进系统可见性，并增强了预防性和反应性维护工作流程。

Conclusion: 尽管大部分物联网数据因现有传感器基础设施有限而采用模拟数据，但原型验证了可扩展数字孪生用于设施管理的可行性，并为实时监控、分析集成和未来自主建筑运营建立了参考模型。

Abstract: Digital twin (DT) offers significant opportunities for enhancing facility management (FM) in campus environments. However, existing research often focuses narrowly on isolated domains, such as point-cloud geometry or energy analytics, without providing a scalable and interoperable workflow that integrates building geometry, equipment metadata, and operational data into a unified FM platform. This study proposes a comprehensive framework for scalable digital-twin deployment in smart campus buildings by integrating 3D laser scanning, BIM modeling, and IoT-enabled data visualization to support facility operations and maintenance. The methodology includes: (1) reality capture using terrestrial laser scanning and structured point-cloud processing; (2) development of an enriched BIM model incorporating architectural, mechanical, electrical, plumbing, conveying, and sensor systems; and (3) creation of a digital-twin environment that links equipment metadata, maintenance policies, and simulated IoT data within a digital-twin management platform. A case study of the Price Gilbert Building at Georgia Tech demonstrates the implementation of this workflow. A total of 509 equipment items were modeled and embedded with OmniClass classifications into the digital twin. Ten interactive dashboards were developed to visualize system performance. Results show that the proposed framework enables centralized asset documentation, improved system visibility, and enhanced preventive and reactive maintenance workflows. Although most IoT data were simulated due to limited existing sensor infrastructure, the prototype validates the feasibility of a scalable digital twin for facility management and establishes a reference model for real-time monitoring, analytics integration, and future autonomous building operations.

</details>


### [25] [Large and Small Model Collaboration for Air Interface](https://arxiv.org/abs/2512.12170)
*Yiming Cui,Jiajia Guo,Xiao Li,Chao-Kai Wen,Shi Jin*

Main category: cs.IT

TL;DR: 提出LASCO和E-LASCO框架，通过大模型作为通用知识库、小模型作为轻量插件，实现无线通信中CSI反馈任务的环境特定适应，降低训练成本并提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有工作主要依赖大型AI模型的通用知识，忽视了环境特定适应的潜在收益。直接微调大模型存在训练成本高、多用户场景推理效率低、灾难性遗忘风险以及模型参数访问受限等问题。

Method: 建立协作框架：大模型作为通用信道知识库，小模型作为轻量插件捕获环境特定知识。针对CSI反馈任务开发LASCO框架：大模型生成初始CSI重建，通过参考SAM和代理SAM学习环境引起的重建偏移，并将偏移传回大模型。进一步提出E-LASCO，引入可学习的协作系数来控制不同环境中大模型和小模型的贡献度。

Result: 数值结果表明，LASCO和E-LASCO使大模型能够以显著降低的训练成本、更少的数据收集需求和更快的适应速度实现环境特定的性能增益。

Conclusion: 提出的协作框架成功解决了大模型环境适应中的关键挑战，通过大小模型协作实现了高效的环境特定适应，为无线通信中的AI模型应用提供了新思路。

Abstract: Large artificial intelligence models (LAMs) have shown strong capability in wireless communications, yet existing works mainly rely on their generalized knowledge across environments while overlooking the potential gains of environment-specific adaptation. Directly fine-tuning LAMs for adaptation is often impractical due to prohibitive training costs, low inference efficiency in multi-user scenarios, and the risk of catastrophic forgetting, in addition to the limited accessibility of model parameters. To address these limitations, we establish a collaborative framework for air interface. In this framework, unlike prior approaches that either depend solely on LAMs or require direct fine-tuning, LAMs are exploited as a universal channel knowledge base while small artificial intelligence models (SAMs) are employed as lightweight plugins to capture environment-specific knowledge, facilitating efficient environment-specific adaptation of LAMs. Subsequently, we instantiate this framework for CSI feedback tasks, and develop a large and small collaboration framework for CSI feedback, referred to as LASCO. LASCO operates by letting the base LAM produce an initial CSI reconstruction, learning the environment-induced reconstruction shift through a reference SAM and a proxy SAM, and transferring this shift back to the LAM. To further enhance adaptability, we introduce elastic-LASCO (E-LASCO), which augments LASCO with learnable collaboration coefficients that control the contribution of LAMs and SAMs across different environments. Numerical results demonstrate that LASCO and E-LASCO enables LAMs to achieve environment-specific performance gains with significantly reduced training costs, lower data collection requirements, and faster adaptation speed.

</details>


### [26] [Hulls of Free Linear Codes over a Non-Unital Ring](https://arxiv.org/abs/2512.12335)
*Anup Kushwaha,Om Prakash*

Main category: cs.IT

TL;DR: 该论文研究了非幺环E上自由线性码的壳码，提出了壳码的生成矩阵形式、四种构造更大长度和壳秩码的构建方法，讨论了置换等价性，并分类了长度不超过8的最优自由E-线性码。


<details>
  <summary>Details</summary>
Motivation: 研究非幺环E上自由线性码的壳码性质，旨在理解这类特殊环上码的结构特征，为构造具有特定壳秩的码提供理论基础。

Method: 1. 分析E-线性码各种壳的剩余码和挠码；2. 推导自由E-线性码壳的生成矩阵显式形式；3. 提出四种构建更大长度和壳秩码的构造方法；4. 研究自由E-线性码的置换等价性；5. 讨论壳变化问题。

Result: 获得了自由E-线性码壳的生成矩阵显式形式，提出了有效的构建方法，通过置换等价性分析壳变化，并分类了长度不超过8的最优自由E-线性码。

Conclusion: 该研究为非幺环E上自由线性码的壳码理论提供了系统分析，提出的构建方法为构造具有特定壳性质的码提供了有效工具，最优码的分类为实际应用提供了参考。

Abstract: This paper investigates the hull codes of free linear codes over a non-unital ring $ E= \langle κ,τ\mid 2 κ=2 τ=0,~ κ^2=κ,~ τ^2=τ,~ κτ=κ,~ τκ=τ\rangle$. Initially, we examine the residue and torsion codes of various hulls of $E$-linear codes and obtain an explicit form of the generator matrix of the hull of a free $E$-linear code. Then, we propose four build-up construction methods to construct codes with a larger length and hull-rank from codes with a smaller length and hull-rank. Some illustrative examples are also given to support our build-up construction methods. Subsequently, we study the permutation equivalence of two free $E$-linear codes and discuss the hull-variation problem. As an application, we classify optimal free $E$-linear codes for lengths up to $8$.

</details>


### [27] [ElasticVR: Elastic Task Computing in Multi-User Multi-Connectivity Wireless Virtual Reality (VR) Systems](https://arxiv.org/abs/2512.12366)
*Babak Badnava,Jacob Chakareski,Morteza Hashemi*

Main category: cs.IT

TL;DR: ElasticVR框架通过可扩展的360度视频分块和边缘-客户端多连接架构，使用多智能体深度强化学习优化VR任务卸载，提升PSNR 43.21%，降低响应时间42.35%和能耗56.83%。


<details>
  <summary>Details</summary>
Motivation: 高保真360度视频流媒体VR应用需要大量计算和带宽资源，现有系统缺乏根据用户和系统资源弹性调整计算任务的能力。

Method: 提出ElasticVR框架，集成可扩展360度视频分块到边缘-客户端无线多连接架构中，使用两种多智能体深度强化学习算法：集中式训练集中式执行的CPPG和集中式训练分布式执行的IPPG。

Result: 相比无弹性VR计算，ElasticVR将PSNR提升43.21%，响应时间降低42.35%，能耗降低56.83%。IPPG在保持性能的同时减少了集中式决策的通信和计算开销。

Conclusion: ElasticVR框架通过弹性VR任务卸载和多智能体强化学习，有效平衡了通信、计算、能耗和QoE之间的权衡，为多用户VR系统提供了可扩展的优化解决方案。

Abstract: Diverse emerging VR applications integrate streaming of high fidelity 360 video content that requires ample amounts of computation and data rate. Scalable 360 video tiling enables having elastic VR computational tasks that can be scaled adaptively in computation and data rate based on the available user and system resources. We integrate scalable 360 video tiling in an edge-client wireless multi-connectivity architecture for joint elastic task computation offloading across multiple VR users called ElasticVR. To balance the trade-offs in communication, computation, energy consumption, and QoE that arise herein, we formulate a constrained QoE and energy optimization problem that integrates the multi-user/multi-connectivity action space with the elasticity of VR computational tasks. The ElasticVR framework introduces two multi-agent deep reinforcement learning solutions, namely CPPG and IPPG. CPPG adopts a centralized training and centralized execution approach to capture the coupling between users' communication and computational demands. This leads to globally coordinated decisions at the cost of increased computational overheads and limited scalability. To address the latter challenges, we also explore an alternative strategy denoted IPPG that adopts a centralized training with decentralized execution paradigm. IPPG leverages shared information and parameter sharing to learn robust policies; however, during execution, each user takes action independently based on its local state information only. The decentralized execution alleviates the communication and computation overhead of centralized decision-making and improves scalability. We show that the ElasticVR framework improves the PSNR by 43.21%, while reducing the response time and energy consumption by 42.35% and 56.83%, respectively, compared with a case where no elasticity is incorporated into VR computations.

</details>


### [28] [Linear Codes with Certain Dimension of Hermitian Hulls](https://arxiv.org/abs/2512.12519)
*Jiabin Wang,Jinquan Luo*

Main category: cs.IT

TL;DR: 研究有限域上酉空间中Hermitian ℓ-互补码的计数公式、渐近性质及自正交码的渐近行为


<details>
  <summary>Details</summary>
Motivation: 研究Hermitian ℓ-互补码的计数和渐近性质，探索Hermitian自正交码与无限制码在渐近权重分布上的相似性，以及自正交码的最小距离约束下的渐近行为

Method: 提供Hermitian ℓ-互补码计数公式的闭式表达式，分析Hermitian自正交码与无限制码的渐近权重分布相似性，研究具有最小距离约束的Hermitian自正交码的渐近行为

Result: 得到了Hermitian ℓ-互补码的闭式计数公式，发现Hermitian自正交码与无限制码在渐近权重分布上相似，证明了当字母表大小趋于无穷时，Hermitian自正交码类中的MDS码是渐近稠密的

Conclusion: Hermitian自正交码与无限制码在渐近权重分布上具有相似性，且在字母表大小趋于无穷时，Hermitian自正交码类中的MDS码是渐近稠密的，这为相关编码理论提供了重要的渐近性质

Abstract: In this paper, we study the enumerative and asymptotic properties related to Hermitian $\ell$-complementary codes on the unitary space over $\F_{q^2}$. We provide some closed form expressions for the counting formulas of Hermitian $\ell$-complementary codes. There is a similarity in the asymptotic weight distribution between Hermitian self-orthogonal codes and unrestricted codes. Furthermore, we study the asymptotic behavior of Hermitian self-orthogonal codes whose minimum distance is at least $d$. In particular, we conclude that MDS codes within the class of Hermitian self-orthogonal codes are asymptotically dense when the alphabet size approaches to infinity.

</details>


### [29] [Vertical Heterogeneous Networks Beyond 5G: CoMP Coverage Enhancement and Optimization](https://arxiv.org/abs/2512.12563)
*Tian Shi,Wenkun Wen,Peiran Wu,Minghua Xia*

Main category: cs.IT

TL;DR: 本文提出了一种基于协调多点传输的垂直异构网络框架，利用无人机作为空中基站与地面基站协同工作，通过随机和优化两种无人机部署策略来提升稀疏空中用户的覆盖性能。


<details>
  <summary>Details</summary>
Motivation: 低空无线网络对低空经济发展至关重要，但在动态三维空间中为稀疏分布的空中用户提供可靠连接面临重大挑战。现有网络难以应对非均匀用户分布和高移动性环境。

Method: 提出协调多点传输框架，使无人机空中基站和地面基站能够联合传输。考虑两种无人机部署策略：1) 随机部署，使用随机几何理论推导覆盖概率闭式表达式；2) 优化部署，采用覆盖感知的加权K-means聚类算法最大化服务不足区域的协作覆盖。

Result: 理论分析和蒙特卡洛仿真表明，所提出的CoMP-enabled VHetNet显著提高了下行覆盖概率，特别是在稀疏空中用户场景下。优化部署策略相比随机部署能提供更好的覆盖性能。

Conclusion: 智能无人机协调和几何感知部署能够为低空无线网络提供强大、自适应的连接能力，协调多点传输框架是提升稀疏空中用户覆盖性能的有效解决方案。

Abstract: Low-altitude wireless networks are increasingly vital for the low-altitude economy, enabling wireless coverage in high-mobility and hard-to-reach environments. However, providing reliable connectivity to sparsely distributed aerial users in dynamic three-dimensional (3D) spaces remains a significant challenge. This paper investigates downlink coverage enhancement in vertical heterogeneous networks (VHetNets) beyond 5G, where uncrewed aerial vehicles (UAVs) operate as emerging aerial base stations (ABSs) alongside legacy terrestrial base stations (TBSs). To improve coverage performance, we propose a coordinated multi-point (CoMP) transmission framework that enables joint transmission from ABSs and TBSs. This approach mitigates the limitations of non-uniform user distributions and enhances reliability for sparse aerial users. Two UAV deployment strategies are considered: \textit{i)} random UAV placement, analyzed using stochastic geometry to derive closed-form coverage expressions, and \textit{ii)} optimized UAV placement using a coverage-aware weighted $K$-means clustering algorithm to maximize cooperative coverage in underserved areas. Theoretical analyses and Monte Carlo simulations demonstrate that the proposed CoMP-enabled VHetNet significantly improves downlink coverage probability, particularly in scenarios with sparse aerial users. These findings highlight the potential of intelligent UAV coordination and geometry-aware deployment to enable robust, adaptive connectivity in low-altitude wireless networks.

</details>


### [30] [Linear Binary Codes Correcting One or More Errors](https://arxiv.org/abs/2512.12591)
*Timofei Izhitskii*

Main category: cs.IT

TL;DR: 论文研究了能纠正一个或多个错误的线性二进制码。对于单错误纠正码，通过构造方法达到了汉明界，并推导了最小码字长度的精确表达式。对于一般情况，通过陪集结构分析推导了线性码参数的简单下界。


<details>
  <summary>Details</summary>
Motivation: 研究线性二进制纠错码的设计与性能界限，特别是单错误纠正码的最优构造和一般线性码的参数下界，为纠错码设计提供理论指导。

Method: 对于单错误纠正码，采用构造性方法达到汉明界；对于一般线性码，通过分析陪集结构来推导参数下界。

Result: 对于单错误纠正码，证明了汉明界可以通过构造方法达到，并得到了最小码字长度的精确表达式。对于一般线性码，推导出了参数的简单下界。

Conclusion: 论文为线性二进制纠错码的设计提供了理论框架：单错误纠正码可以达到最优的汉明界，而一般线性码的参数存在基于陪集结构的下界，这对纠错码的实际设计具有指导意义。

Abstract: This paper examines linear binary codes capable of correcting one or more errors. For the single-error-correcting case, it is shown that the Hamming bound is achieved by a constructive method, and an exact expression for the minimal codeword length is derived. For the general case, a simple lower bound for the parameters of linear codes is derived from an analysis of the coset structure.

</details>


### [31] [C-PASS: Center-Fed Pinching Antenna System](https://arxiv.org/abs/2512.12619)
*Xu Gan,Yuanwei Liu*

Main category: cs.IT

TL;DR: 提出了一种新型的中心馈电夹持天线系统（C-PASS），通过从中心端口馈电信号并向波导两侧传播，在单个波导中实现空间复用增益。


<details>
  <summary>Details</summary>
Motivation: 传统端馈PASS系统在复用能力上存在限制，需要新的天线架构来提升系统容量和自由度。

Method: 提出C-PASS架构，信号从中心输入端口馈入并向波导两侧传播，推导了自由度和功率缩放定律的闭式表达式。

Result: C-PASS相比传统PASS可实现两倍的自由度，并额外获得O(P_T ln^4 N/N^2)的复用增益，数值结果验证了显著的容量提升。

Conclusion: C-PASS架构通过中心馈电设计显著提升了系统容量和复用能力，为未来无线通信系统提供了有前景的解决方案。

Abstract: A novel architecture of the center-fed pinching antenna system (C-PASS) is proposed. In contrast to the conventional end-fed PASS, signals are fed from the center input ports and propagate towards both sides of the waveguide. By doing so, spatial-multiplexing gain can be achieved in a single waveguide. Based on the proposed C-PASS, closed-form expressions for the degree of freedom (DoF) and power scaling laws are derived. These theoretical results reveal that C-PASS can achieve \emph{twice} the DoF and an additional multiplexing gain of $\mathcal{O}(P_T \ln^4 N/N^2)$ compared to the conventional PASS, where $P_T$ and $N$ represent the transmit power and pinching antenna number, respectively. Numerical results are provided to demonstrate that substantial capacity improvements can be achieved through the enhanced DoF and multiplexing gain of the C-PASS.

</details>


### [32] [From Information Freshness to Semantics of Information and Goal-oriented Communications](https://arxiv.org/abs/2512.12758)
*Jiping Luo,Erfan Delfani,Mehrdad Salimnejad,Nikolaos Pappas*

Main category: cs.IT

TL;DR: 该论文系统梳理了从传统失真度量到信息新鲜度指标（如AoI），再到面向任务的语义感知通信的演进，提出了统一的语义感知度量框架，并分析了基于MDP和Lyapunov优化的调度策略设计方法。


<details>
  <summary>Details</summary>
Motivation: 未来无线网络需要支持实时数据驱动的信息物理系统，其中通信与感知、推理、控制和决策紧密耦合。传统的以准确性、吞吐量和延迟为中心的通信范式越来越不适用于这些系统，因为信息的价值取决于其与特定任务的语义相关性。

Method: 论文通过统一阐述的方式，系统化组织了现有的语义感知度量，包括内容和版本感知度量、上下文相关的失真公式、以及捕获持久影响和紧迫性的历史相关错误持续性度量。同时回顾了基于马尔可夫决策过程（MDP）和Lyapunov优化方法的分析工具。

Result: 建立了一个连贯的语义感知通信框架，阐明了面向任务的语义感知通信系统的设计原则，展示了如何显著提高效率、可靠性和任务性能，为6G及以后语义通信架构的设计提供了指导。

Conclusion: 该论文为信息论、控制论和网络观点之间搭建了桥梁，系统化了语义感知通信的演进路径和设计方法，为未来无线网络中面向任务的通信系统设计提供了理论基础和实用框架。

Abstract: Future wireless networks must support real-time, data-driven cyber-physical systems in which communication is tightly coupled with sensing, inference, control, and decision-making. Traditional communication paradigms centered on accuracy, throughput, and latency are increasingly inadequate for these systems, where the value of information depends on its semantic relevance to a specific task. This paper provides a unified exposition of the progression from classical distortion-based frameworks, through information freshness metrics such as the Age of Information (AoI) and its variants, to the emerging paradigm of goal-oriented semantics-aware communication. We organize and systematize existing semantics-aware metrics, including content- and version-aware measures, context-dependent distortion formulations, and history-dependent error persistence metrics that capture lasting impact and urgency. Within this framework, we highlight how these metrics address the limitations of purely accuracy- or freshness-centric designs, and how they collectively enable the selective generation and transmission of only task-relevant information. We further review analytical tools based on Markov decision process (MDP) and Lyapunov optimization methods that have been employed to characterize optimal or near-optimal timing and scheduling policies under semantic performance criteria and communication constraints. By synthesizing these developments into a coherent framework, the paper clarifies the design principles underlying goal-oriented, semantics-aware communication systems. It illustrates how they can significantly improve efficiency, reliability, and task performance. The presented perspective aims to serve as a bridge between information-theoretic, control-theoretic, and networking viewpoints, and to guide the design of semantic communication architectures for 6G and beyond.

</details>


### [33] [Information-Theoretic Limits of Integrated Sensing and Communication with Finite Learning Capacity](https://arxiv.org/abs/2512.13292)
*Farshad Rostami Ghadi,F. Javier Lopez-Martinez,Kai-Kit Wong,Christos Masouros*

Main category: cs.IT

TL;DR: 本文为AI辅助的集成感知与通信(ISAC)建立了一个统一的信息论框架，引入AI容量预算概念来量化有限学习能力对联合性能的限制，推导了可达速率-感知区域的理论界限，并提出了实用的训练方法。


<details>
  <summary>Details</summary>
Motivation: 随着AI技术被集成到ISAC系统中，学习组件的有限表示能力会限制联合通信和感知性能。需要建立一个理论框架来量化这种限制，并为系统协同设计提供指导。

Method: 提出AI容量预算概念来量化学习模型的有限能力；推导了可达速率-感知区域的理论界限（上界和下界）；对于高斯信道，将有限学习能力建模为等效加性噪声；扩展到瑞利和莱斯衰落以及MIMO系统；优化了学习约束下的资源分配；建立了学习-信息权衡定律；提出了变分训练方法来实施容量约束。

Result: 建立了AI辅助ISAC的统一信息论框架；推导了理论性能界限；在高斯信道中获得了简单的解析表达式；扩展到多种信道模型和MIMO系统；获得了资源分配的闭式解；建立了学习能力与性能前沿的量化关系；提出了实用的训练方法。

Conclusion: 该框架为AI辅助ISAC系统提供了理论基础，量化了学习能力限制对性能的影响，推导的标度定律为下一代ISAC系统中模型大小、波形和硬件的协同设计提供了定量指导。

Abstract: This paper develops a unified information-theoretic framework for artificial-intelligence (AI)-aided integrated sensing and communication (ISAC), where a learning component with limited representational capacity is embedded within the transceiver loop. The study introduces the concept of an AI capacity budget to quantify how the finite ability of a learning model constrains joint communication and sensing performance. Under this framework, the paper derives both converse (upper) and achievability (lower) bounds that define the achievable rate-sensing region. For Gaussian channels, the effect of limited learning capacity is shown to behave as an equivalent additive noise, allowing simple analytical expressions for the resulting communication rate and sensing distortion. The theory is then extended to Rayleigh and Rician fading as well as to multiple-input multiple-output (MIMO) systems through new matrix inequalities and a constructive mapping between AI capacity and effective noise covariance. Resource allocation between sensing and communication is optimized under this learning constraint, yielding closed-form conditions in the Gaussian case. A general learning-information trade-off law is also established, linking the representational power of the learning module to the achievable performance frontier. Finally, a practical variational training procedure is proposed to enforce the capacity constraint and to guide empirical evaluation. The derived scaling laws provide quantitative insight for co-designing model size, waveform, and hardware in next-generation ISAC systems.

</details>


### [34] [Machine learning discovers new champion codes](https://arxiv.org/abs/2512.13370)
*Yang-Hui He,Alexander Kasprzyk,Q Le,Dmitrii Riabchenko*

Main category: cs.IT

TL;DR: 使用Transformer预测线性码的最小汉明距离，结合遗传算法搜索，开发出发现最优线性码的新方法


<details>
  <summary>Details</summary>
Motivation: 线性纠错码是现代数字通信和存储系统的数学基础，但识别最优线性码（达到或超过已知最佳最小汉明距离的码）仍然具有挑战性

Method: 训练Transformer模型预测一类线性码的最小汉明距离，并将其与遗传算法配对，在搜索空间中寻找最优码

Result: 该方法有效减少了寻找最优线性码所需的搜索空间，可应用于广义环面码、Reed-Muller码、BCH码、代数几何码以及潜在的量子码

Conclusion: 提出了一种结合深度学习和进化算法的新方法，用于发现最优线性码，为纠错码的研究和构造提供了新工具

Abstract: Linear error-correcting codes form the mathematical backbone of modern digital communication and storage systems, but identifying champion linear codes (linear codes achieving or exceeding the best known minimum Hamming distance) remains challenging. By training a transformer to predict the minimum Hamming distance of a class of linear codes and pairing it with a genetic algorithm over the search space, we develop a novel method for discovering champion codes. This model effectively reduces the search space of linear codes needed to achieve champion codes. Our results present the use of this method in the study and construction of error-correcting codes, applicable to codes such as generalised toric, Reed-Muller, Bose-Chaudhuri-Hocquenghem, algebrogeometric, and potentially quantum codes.

</details>


### [35] [Two Families of Linear Codes Containing Non-GRS MDS Codes](https://arxiv.org/abs/2512.13429)
*Kanat Abdukhalikov,Gyanendra K. Verma*

Main category: cs.IT

TL;DR: 通过修改广义Reed-Solomon码的生成矩阵构造了两类新的线性码，研究了它们的MDS性质、非GRS特性以及自正交和自对偶性质


<details>
  <summary>Details</summary>
Motivation: 在广义Reed-Solomon码的基础上构造新的线性码，探索具有MDS性质但非GRS结构的码，并研究其自正交和自对偶特性

Method: 通过修改GRS码的生成矩阵构造两类新的线性码族，显式推导校验矩阵，建立MDS性质的充要条件，分析非GRS子族，并研究自正交和自对偶性质

Result: 成功构造了两类新的线性码族，获得了它们的校验矩阵，建立了MDS性质的充要条件，发现了非GRS的MDS码子族，并给出了自正交和自对偶码的显式构造和实例

Conclusion: 通过修改GRS码生成矩阵的方法可以构造出具有良好性质的线性码，包括非GRS的MDS码以及自正交/自对偶码，为编码理论提供了新的构造方法

Abstract: We construct two new families of linear codes by modifying the generator matrices of generalized Reed-Solomon (GRS) codes. For these codes, we explicitly derive parity-check matrices and establish necessary and sufficient conditions ensuring the MDS property. Additionally, we explore subfamilies within these constructions that are non-GRS MDS codes. We also characterize their self-orthogonal and self-dual properties and present some explicit constructions and examples.

</details>


### [36] [From Zipf's Law to Neural Scaling through Heaps' Law and Hilberg's Hypothesis](https://arxiv.org/abs/2512.13491)
*Łukasz Dębowski*

Main category: cs.IT

TL;DR: 该论文证明了在特定假设下，神经缩放定律可以从Zipf定律推导出来，通过Heaps定律和Hilberg假设作为中间步骤。


<details>
  <summary>Details</summary>
Motivation: 研究神经缩放定律（描述基础模型交叉熵率随训练数据、参数和计算量的变化）与Zipf定律（描述词元分布的幂律尾部）之间的演绎关系，揭示两者之间的理论联系。

Method: 通过系统性的推导步骤：从Zipf定律推导Heaps定律（词汇增长规律），从Heaps定律推导Hilberg假设（熵缩放规律），再从Hilberg假设推导神经缩放定律。使用满足所有四个统计规律的Santa Fe过程作为示例说明。

Result: 证明了在特定宽泛假设下，神经缩放定律是Zipf定律的推论，建立了机器学习中的缩放规律与定量语言学中的分布规律之间的理论联系。

Conclusion: 神经缩放定律和Zipf定律之间存在深刻的演绎关系，这种关系通过Heaps定律和Hilberg假设连接，为理解语言模型的缩放行为提供了理论基础。

Abstract: We inspect the deductive connection between the neural scaling law and Zipf's law -- two statements discussed in machine learning and quantitative linguistics. The neural scaling law describes how the cross entropy rate of a foundation model -- such as a large language model -- changes with respect to the amount of training tokens, parameters, and compute. By contrast, Zipf's law posits that the distribution of tokens exhibits a power law tail. Whereas similar claims have been made in more specific settings, we show that the neural scaling law is a consequence of Zipf's law under certain broad assumptions that we reveal systematically. The derivation steps are as follows: We derive Heaps' law on the vocabulary growth from Zipf's law, Hilberg's hypothesis on the entropy scaling from Heaps' law, and the neural scaling from Hilberg's hypothesis. We illustrate these inference steps by a toy example of the Santa Fe process that satisfies all the four statistical laws.

</details>


### [37] [Hyper-Minrank: A Unified Hypergraph Characterization of Multi-Sender Index Coding](https://arxiv.org/abs/2512.13615)
*Ali Khalesi,Petros Elia*

Main category: cs.IT

TL;DR: 本文提出了一种超图框架，将经典索引编码推广到多发送者场景，建立了超图最小秩与最优线性广播长度的精确等价关系，并提供了计算方法和应用场景。


<details>
  <summary>Details</summary>
Motivation: 传统索引编码主要针对单发送者场景，而实际通信系统如多发送者缓存辅助通信、分布式存储、边缘/卫星系统等需要多发送者索引编码的理论框架。现有方法缺乏对多发送者场景的统一理论分析工具。

Method: 提出4-正则侧信息超图模型，定义新的邻接表示A_G和子超图拟合准则，引入能同时捕获侧信息和跨发送者信号抵消的特殊超边。建立了超图最小秩与线性广播长度的精确等价关系。

Result: 证明了每个有效拟合对应一个有效的线性多发送者索引码，反之亦然；最优标量线性广播长度等于超图最小秩。提供了超图版的Haemers型上下界，并给出了计算超图最小秩的精确算法，在某些情况下复杂度优于近似LT-CMAR解。

Conclusion: 该超图框架为多发送者索引编码提供了统一的理论基础，能够直接应用于多发送者缓存辅助通信、编码计算、分布式存储和边缘/卫星系统，超图最小秩可作为统一的设计目标。

Abstract: This work introduces a hypergraph formulation that generalizes the classical paradigm of Bar-Yossef et al. to the multi-sender index coding (MSIC) setting. Central to the model is a 4-regular side-information hypergraph G, a new adjacency representation A_G = [A_1 ... A_N], and a simple fitting criterion for sub-hypergraph validity, in the presence of specially designed hyperedges that capture both side information and cross-sender signal cancellation. This formulation establishes a tight achievability-converse equivalence for the general N-sender, K-receiver problem: every valid fitting induces a valid linear multi-sender index code, every linear code induces a valid fitting, and the optimal scalar linear broadcast length equals the hyper-minrank l**lin(G) = hyperminrank(G) = min*{A fits G} sum_{n=1}^N rank(A_n). Beyond this exact characterization, the approach yields hypergraph analogues of Haemers-type bounds on the broadcast length, including a clique-cover upper bound and a lower bound via the clique number of a carefully defined complement hypergraph. Algorithmically, we provide an exact procedure to compute hyperminrank(G), and show that in certain regimes its complexity is asymptotically better than approximate LT-CMAR solutions. The framework captures well-known settings such as embedded index coding, and applies directly to multi-sender cache-aided communications, coded computation, distributed storage, and edge/satellite systems, where hyperminrank can serve as a unified design target.

</details>
