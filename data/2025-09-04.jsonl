{"id": "2509.03034", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.03034", "abs": "https://arxiv.org/abs/2509.03034", "authors": ["Xiaofeng Liu", "Jun Zhang", "Fang-Wei Fu"], "title": "On a class of twisted elliptic curve codes", "comment": null, "summary": "Motivated by the studies of twisted generalized Reed-Solomon (TGRS) codes, we\ninitiate the study of twisted elliptic curve codes (TECCs) in this paper. In\nparticular, we study a class of TECCs with one twist. The parity-check matrices\nof the TECCs are explicitly given by computing the Weil differentials. Then the\nsufficient and necessary conditions of self-duality are presented. The minimum\ndistances of the TECCs are also determined. Moreover, examples of MDS, AMDS,\nself-dual and MDS self-dual TECCs are given. Finally, we calculate the\ndimensions of the Schur squares of TECCs and show the non-equivalence between\nTECCs and ECCs/GRS codes."}
{"id": "2509.03128", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.03128", "abs": "https://arxiv.org/abs/2509.03128", "authors": ["Zichang Ren", "Chunhang Zheng", "Dou Li", "Yuping Zhao"], "title": "Successive Cancellation Decoding For General Monotone Chain Polar Codes", "comment": null, "summary": "Monotone chain polar codes generalize classical polar codes to multivariate\nsettings, offering a flexible approach for achieving the entire admissible rate\nregion in the distributed lossless coding problem. However, this flexibility\nalso introduces significant challenges for existing successive cancellation\n(SC) based decoding schemes. Motivated by the need for a general SC decoding\nsolution, we present a comprehensive decoding strategy for monotone chain polar\ncodes that can handle arbitrary numbers of terminals, non-binary alphabets, and\ndecoding along arbitrary monotone chains. Specifically, we formulate the SC\ndecoding task as a series of inference subtasks over the polar transform and\npropose a computational graph framework based on probability propagation\nprinciples. This approach highlights the impact of variable switching during\ndecoding and shows that time complexity varies between $O(N\\log{N})$ and\n$O(N^2)$, depending on the specific chain structure. Moreover, we demonstrate\nthat the widely used $O(N)$ space optimization is not universally applicable to\nmonotone chain polar codes, which prompts us to introduce a constant-time\ndecoder forking strategy based on the proposed logical computation graphs. This\nstrategy enables time-efficient list decoding without relying on $O(N)$-space\ntechniques. Numerical results verify the superior performance of the proposed\nscheme compared with the classical lazy-copy scheme."}
{"id": "2509.03337", "categories": ["cs.IT", "math.IT", "94B05, 94B65"], "pdf": "https://arxiv.org/pdf/2509.03337", "abs": "https://arxiv.org/abs/2509.03337", "authors": ["Liren Lin", "Guanghui Zhang", "Bocong Chen", "Hongwei Liu"], "title": "New Bounds for Linear Codes with Applications", "comment": "15 pages", "summary": "Bounds on linear codes play a central role in coding theory, as they capture\nthe fundamental trade-off between error-correction capability (minimum\ndistance) and information rate (dimension relative to length). Classical\nresults characterize this trade-off solely in terms of the parameters $n$, $k$,\n$d$ and $q$. In this work we derive new bounds under the additional assumption\nthat the code contains a nonzero codeword of weight $w$.By combining\nresidual-code techniques with classical results such as the Singleton and\nGriesmer bounds,we obtain explicit inequalities linking $n$, $k$, $d$, $q$ and\n$w$. These bounds impose sharper restrictions on admissible codeword weights,\nparticularly those close to the minimum distance or to the code length.\nApplications include refined constraints on the weights of MDS codes, numerical\nrestrictions on general linear codes, and excluded weight ranges in the weight\ndistribution. Numerical comparisons across standard parameter sets demonstrate\nthat these $w$-aware bounds strictly enlarge known excluded weight ranges and\nsharpen structural limitations on linear codes."}
{"id": "2509.03481", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.03481", "abs": "https://arxiv.org/abs/2509.03481", "authors": ["Lorenzo Talamanca", "Julian Trouillon"], "title": "PoolPy: Flexible Group Testing Design for Large-Scale Screening", "comment": null, "summary": "In large screening campaigns, group testing can greatly reduce the number of\ntests needed when compared to testing each sample individually. However,\nchoosing and applying an appropriate group testing method remains challenging\ndue to the wide variety in design and performance across methods, and the lack\nof accessible tools. Here, we present PoolPy, a unified framework for designing\nand selecting optimal group testing strategies across ten different methods\naccording to user-defined constraints, such as time, cost or sample dilution.\nBy computing over 10,000 group testing designs made available through a web\ninterface, we identified key trade-offs, such as minimizing test number or\ngroup size, that define applicability to specific use cases. Overall, we show\nthat no single method is universally optimal, and provide clear indications for\nmethod choice on a case-by-case basis."}
{"id": "2509.02568", "categories": ["eess.SP", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.02568", "abs": "https://arxiv.org/abs/2509.02568", "authors": ["Mohammad Mehedi Hasan", "Pedro G. Lind", "Hernando Ombao", "Anis Yazidi", "Rabindra Khadka"], "title": "EEG-MSAF: An Interpretable Microstate Framework uncovers Default-Mode Decoherence in Early Neurodegeneration", "comment": "Dementia, EEG, Microstates, Explainable, SHAP", "summary": "Dementia (DEM) is a growing global health challenge, underscoring the need\nfor early and accurate diagnosis. Electroencephalography (EEG) provides a\nnon-invasive window into brain activity, but conventional methods struggle to\ncapture its transient complexity. We present the \\textbf{EEG Microstate\nAnalysis Framework (EEG-MSAF)}, an end-to-end pipeline that leverages EEG\nmicrostates discrete, quasi-stable topographies to identify DEM-related\nbiomarkers and distinguish DEM, mild cognitive impairment (MCI), and normal\ncognition (NC). EEG-MSAF comprises three stages: (1) automated microstate\nfeature extraction, (2) classification with machine learning (ML), and (3)\nfeature ranking using Shapley Additive Explanations (SHAP) to highlight key\nbiomarkers. We evaluate on two EEG datasets: the public Chung-Ang University\nEEG (CAUEEG) dataset and a clinical cohort from Thessaloniki Hospital. Our\nframework demonstrates strong performance and generalizability. On CAUEEG,\nEEG-MSAF-SVM achieves \\textbf{89\\% $\\pm$ 0.01 accuracy}, surpassing the deep\nlearning baseline CEEDNET by \\textbf{19.3\\%}. On the Thessaloniki dataset, it\nreaches \\textbf{95\\% $\\pm$ 0.01 accuracy}, comparable to EEGConvNeXt. SHAP\nanalysis identifies mean correlation and occurrence as the most informative\nmetrics: disruption of microstate C (salience/attention network) dominates DEM\nprediction, while microstate F, a novel default-mode pattern, emerges as a key\nearly biomarker for both MCI and DEM. By combining accuracy, generalizability,\nand interpretability, EEG-MSAF advances EEG-based dementia diagnosis and sheds\nlight on brain dynamics across the cognitive spectrum."}
{"id": "2509.02724", "categories": ["eess.SP", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.02724", "abs": "https://arxiv.org/abs/2509.02724", "authors": ["Xiang-Gen Xia"], "title": "Recall Gabor Communication Theory and Joint Time-Frequency Analysis", "comment": null, "summary": "In this article, we first briefly recall Gabor's communication theory and\nthen Gabor transform and expansion, and also its connection with joint time\nfrequency analysis."}
{"id": "2509.02724", "categories": ["eess.SP", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.02724", "abs": "https://arxiv.org/abs/2509.02724", "authors": ["Xiang-Gen Xia"], "title": "Recall Gabor Communication Theory and Joint Time-Frequency Analysis", "comment": null, "summary": "In this article, we first briefly recall Gabor's communication theory and\nthen Gabor transform and expansion, and also its connection with joint time\nfrequency analysis."}
{"id": "2509.02797", "categories": ["eess.SP", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.02797", "abs": "https://arxiv.org/abs/2509.02797", "authors": ["Sagnik Bhattacharya", "Abhiram Rao Gorle", "John M. Cioffi"], "title": "minPIC: Towards Optimal Power Allocation in Multi-User Interference Channels", "comment": "To appear in IEEE GLOBECOM 2025", "summary": "6G envisions massive cell-free networks with spatially nested multiple access\n(MAC) and broadcast (BC) channels without centralized coordination. This makes\noptimal resource allocation across power, subcarriers, and decoding orders\ncrucial for interference channels (ICs), where neither transmitters nor\nreceivers can cooperate. Current orthogonal multiple access (OMA) methods, as\nwell as non-orthogonal (NOMA) and rate-splitting (RSMA) schemes, rely on fixed\nheuristics for interference management, leading to suboptimal rates, power\ninefficiency, and scalability issues. This paper proposes a novel minPIC\nframework for optimal power, subcarrier, and decoding order allocation in\ngeneral multi-user ICs. Unlike existing methods, minPIC eliminates heuristic\nSIC order assumptions. Despite the convexity of the IC capacity region, fixing\nan SIC order induces non-convexity in resource allocation, traditionally\nrequiring heuristic approximations. We instead introduce a dual-variable-guided\nsorting criterion to identify globally optimal SIC orders, followed by convex\noptimization with auxiliary log-det constraints, efficiently solved via binary\nsearch. We also demonstrate that minPIC could potentially meet the stringent\nhigh-rate, low-power targets of immersive XR and other 6G applications. To the\nbest of our knowledge, minPIC is the first algorithmic realisation of the\nPareto boundary of the SIC-achievable rate region for Gaussian ICs, opening the\ndoor to scalable interference management in cell-free networks."}
{"id": "2509.02797", "categories": ["eess.SP", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.02797", "abs": "https://arxiv.org/abs/2509.02797", "authors": ["Sagnik Bhattacharya", "Abhiram Rao Gorle", "John M. Cioffi"], "title": "minPIC: Towards Optimal Power Allocation in Multi-User Interference Channels", "comment": "To appear in IEEE GLOBECOM 2025", "summary": "6G envisions massive cell-free networks with spatially nested multiple access\n(MAC) and broadcast (BC) channels without centralized coordination. This makes\noptimal resource allocation across power, subcarriers, and decoding orders\ncrucial for interference channels (ICs), where neither transmitters nor\nreceivers can cooperate. Current orthogonal multiple access (OMA) methods, as\nwell as non-orthogonal (NOMA) and rate-splitting (RSMA) schemes, rely on fixed\nheuristics for interference management, leading to suboptimal rates, power\ninefficiency, and scalability issues. This paper proposes a novel minPIC\nframework for optimal power, subcarrier, and decoding order allocation in\ngeneral multi-user ICs. Unlike existing methods, minPIC eliminates heuristic\nSIC order assumptions. Despite the convexity of the IC capacity region, fixing\nan SIC order induces non-convexity in resource allocation, traditionally\nrequiring heuristic approximations. We instead introduce a dual-variable-guided\nsorting criterion to identify globally optimal SIC orders, followed by convex\noptimization with auxiliary log-det constraints, efficiently solved via binary\nsearch. We also demonstrate that minPIC could potentially meet the stringent\nhigh-rate, low-power targets of immersive XR and other 6G applications. To the\nbest of our knowledge, minPIC is the first algorithmic realisation of the\nPareto boundary of the SIC-achievable rate region for Gaussian ICs, opening the\ndoor to scalable interference management in cell-free networks."}
{"id": "2509.03311", "categories": ["eess.SP", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.03311", "abs": "https://arxiv.org/abs/2509.03311", "authors": ["Penggao Yan", "Li-Ta Hsu"], "title": "Credible Uncertainty Quantification under Noise and System Model Mismatch", "comment": "This manuscript has been submitted to IEEE Signal Processing Letters", "summary": "State estimators often provide self-assessed uncertainty metrics, such as\ncovariance matrices, whose reliability is critical for downstream tasks.\nHowever, these self-assessments can be misleading due to underlying modeling\nviolations like noise or system model mismatch. This letter addresses the\nproblem of estimator credibility by introducing a unified, multi-metric\nevaluation framework. We construct a compact credibility portfolio that\nsynergistically combines traditional metrics like the Normalized Estimation\nError Squared (NEES) and the Noncredibility Index (NCI) with proper scoring\nrules, namely the Negative Log-Likelihood (NLL) and the Energy Score (ES). Our\nkey contributions are a novel energy distance-based location test to robustly\ndetect system model misspecification and a method that leverages the asymmetric\nsensitivities of NLL and ES to distinguish optimism covariance scaling from\nsystem bias. Monte Carlo simulations across six distinct credibility scenarios\ndemonstrate that our proposed method achieves high classification accuracy\n(80-100%), drastically outperforming single-metric baselines which consistently\nfail to provide a complete and correct diagnosis. This framework provides a\npractical tool for turning patterns of credibility indicators into actionable\ndiagnoses of model deficiencies."}
{"id": "2509.02819", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.02819", "abs": "https://arxiv.org/abs/2509.02819", "authors": ["Sameer Mathad", "Taejoon Kim", "David J. Love"], "title": "Protecting Legacy Wireless Systems Against Interference: Precoding and Codebook Approaches Using Massive MIMO and Region Constraints", "comment": null, "summary": "The ever-increasing demand for high-speed wireless communication has\ngenerated significant interest in utilizing frequency bands that are adjacent\nto those occupied by legacy wireless systems. Since the legacy wireless systems\nwere designed based on often decades-old assumptions about wireless\ninterference, utilizing these new bands will result in interference with the\nexisting legacy users. Many of these legacy wireless devices are used by\ncritical infrastructure networks upon which society depends. There is an urgent\nneed to develop schemes that can protect legacy users from such interference.\nFor many applications, legacy users are located within\ngeographically-constrained regions. Several studies have proposed mitigating\ninterference through the implementation of exclusion zones near these\ngeographically-constrained regions. In contrast to solutions based on\ngeographic exclusion zones, this paper presents a communication theory-based\nsolution. By leveraging knowledge of these geographically-constrained regions,\nwe aim to reduce the interference impact on legacy users. We achieve this by\nincorporating received power constraints, termed as region constraints, in our\nmassive multiple-input multiple-output (MIMO) system design. We perform a\ncapacity analysis of single-user massive MIMO and a sum-rate analysis of the\nmulti-user massive MIMO system with transmit power and region constraints. We\npresent a precoding design method that allows for the utilization of new\nfrequency bands while protecting legacy users."}
{"id": "2509.03333", "categories": ["eess.SP", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.03333", "abs": "https://arxiv.org/abs/2509.03333", "authors": ["Tianfu Qi", "Jun Wang"], "title": "Baseband Model, Cutoff Rate Bounds and Constellation Shaping for Mixed Gaussian-Impulsive Noise", "comment": null, "summary": "Mixed noise, composed of white Gaussian noise (WGN) and impulsive noise (IN),\nappears in numerous communication scenarios and can severely degrade system\nperformance. In this paper, we address this issue by optimizing the transmitted\nconstellation under mixed noise based on a theoretical analysis of the cutoff\nrate (CR). First, starting from the passband model of the mixed noise, we\nderive its corresponding baseband representation. Due to the complexity of the\nCR, an exact analytic expression is generally intractable. Therefore, the\nbaseband noise model is employed to obtain closed-form lower and upper bounds\nof the CR. A piecewise linear approximation is applied to derive efficient\nbounds by exploiting the algebraic properties of the integral terms. These\nbounds are then used as criteria to optimize the transmitted constellation\npoints in both geometric and probabilistic distributions. The projected\ngradient method is employed to solve the optimization problem, and the\nconvergence and properties of the solutions are analyzed. Numerical results\ndemonstrate that the proposed CR bounds are tight and exhibit the expected\nasymptotic behavior. Furthermore, the optimized constellation scheme achieves a\nsignificant rate improvement compared to baselines."}
{"id": "2509.03038", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.03038", "abs": "https://arxiv.org/abs/2509.03038", "authors": ["Ruihong Jiang", "Ruichen Zhang", "Yanqing Xu", "Huimin Hu", "Yang Lu", "Dusit Niyato"], "title": "Spatially Adaptive SWIPT with Pinching Antenna under Probabilistic LoS Blockage", "comment": "5 pages, 4 figures", "summary": "This paper considers a power-splitting (PS)-based simultaneous wireless\ninformation and power transfer (SWIPT) system employing a reconfigurable\npinching antenna (PA) under probabilistic line-of-sight (LoS) blockage. We\nformulate a joint optimization of the PA position and the PS ratio to maximize\nthe average signal-to-noise ratio (SNR) at a user, subject to its average\nenergy harvesting (EH) and PA placement limits. We derive a closed-form optimal\nsolution. Results demonstrate that the EH requirement has a deterministic\nimpact on the optimal PA position as well as its feasible region, requiring\ndeployment of the PA as close to the user as possible to maximize average\nchannel gain. This spatial adaptation, combined with dynamic PS, enables robust\nSWIPT performance in the presence of probabilistic LoS blockage, revealing that\nmechanical reconfigurability primarily enhances sustainability by ensuring\nenergy feasibility in dynamic environments."}
{"id": "2509.03066", "categories": ["eess.SP", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.03066", "abs": "https://arxiv.org/abs/2509.03066", "authors": ["Huaicheng Zhang", "Ruoxin Wang", "Chenlian Zhou", "Jiguang Shi", "Yue Ge", "Zhoutong Li", "Sheng Chang", "Hao Wang", "Jin He", "Qijun Huang"], "title": "S2M2ECG: Spatio-temporal bi-directional State Space Model Enabled Multi-branch Mamba for ECG", "comment": null, "summary": "As one of the most effective methods for cardiovascular disease (CVD)\ndiagnosis, multi-lead Electrocardiogram (ECG) signals present a characteristic\nmulti-sensor information fusion challenge that has been continuously researched\nin deep learning domains. Despite the numerous algorithms proposed with\ndifferent DL architectures, maintaining a balance among performance,\ncomputational complexity, and multi-source ECG feature fusion remains\nchallenging. Recently, state space models (SSMs), particularly Mamba, have\ndemonstrated remarkable effectiveness across various fields. Their inherent\ndesign for high-efficiency computation and linear complexity makes them\nparticularly suitable for low-dimensional data like ECGs. This work proposes\nS2M2ECG, an SSM architecture featuring three-level fusion mechanisms: (1)\nSpatio-temporal bi-directional SSMs with segment tokenization for low-level\nsignal fusion, (2) Intra-lead temporal information fusion with bi-directional\nscanning to enhance recognition accuracy in both forward and backward\ndirections, (3) Cross-lead feature interaction modules for spatial information\nfusion. To fully leverage the ECG-specific multi-lead mechanisms inherent in\nECG signals, a multi-branch design and lead fusion modules are incorporated,\nenabling individual analysis of each lead while ensuring seamless integration\nwith others. Experimental results reveal that S2M2ECG achieves superior\nperformance in the rhythmic, morphological, and clinical scenarios. Moreover,\nits lightweight architecture ensures it has nearly the fewest parameters among\nexisting models, making it highly suitable for efficient inference and\nconvenient deployment. Collectively, S2M2ECG offers a promising alternative\nthat strikes an excellent balance among performance, computational complexity,\nand ECG-specific characteristics, paving the way for high-performance,\nlightweight computations in CVD diagnosis."}
{"id": "2509.03070", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.03070", "abs": "https://arxiv.org/abs/2509.03070", "authors": ["Po-Heng Chou", "Wei-Lung Mao", "Ru-Ping Lin"], "title": "YOLO-based Bearing Fault Diagnosis With Continuous Wavelet Transform", "comment": "5 pages, 2 figures, 2 tables", "summary": "This letter proposes a YOLO-based framework for spatial bearing fault\ndiagnosis using time-frequency spectrograms derived from continuous wavelet\ntransform (CWT). One-dimensional vibration signals are first transformed into\ntime-frequency spectrograms using Morlet wavelets to capture transient fault\nsignatures. These spectrograms are then processed by YOLOv9, v10, and v11\nmodels to classify fault types. Evaluated on three benchmark datasets,\nincluding Case Western Reserve University (CWRU), Paderborn University (PU),\nand Intelligent Maintenance System (IMS), the proposed CWT--YOLO pipeline\nachieves significantly higher accuracy and generalizability than the baseline\nMCNN--LSTM model. Notably, YOLOv11 reaches mAP scores of 99.4% (CWRU), 97.8%\n(PU), and 99.5% (IMS). In addition, its region-aware detection mechanism\nenables direct visualization of fault locations in spectrograms, offering a\npractical solution for condition monitoring in rotating machinery."}
{"id": "2509.03077", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.03077", "abs": "https://arxiv.org/abs/2509.03077", "authors": ["Ogechukwu Kanu", "Ashkan Eshaghbeigi", "Hatem Abou-Zeid"], "title": "Self-supervised Radio Representation Learning: Can we Learn Multiple Tasks?", "comment": "7 pages, 7 figures, IEEE international conference on communication\n  2025", "summary": "Artificial intelligence (AI) is anticipated to play a pivotal role in 6G.\nHowever, a key challenge in developing AI-powered solutions is the extensive\ndata collection and labeling efforts required to train supervised deep learning\nmodels. To overcome this, self-supervised learning (SSL) approaches have\nrecently demonstrated remarkable success across various domains by leveraging\nlarge volumes of unlabeled data to achieve near-supervised performance. In this\npaper, we propose an effective SSL scheme for radio signal representation\nlearning using momentum contrast. By applying contrastive learning, our method\nextracts robust, transferable representations from a large real-world dataset.\nWe assess the generalizability of these learned representations across two\nwireless communications tasks: angle of arrival (AoA) estimation and automatic\nmodulation classification (AMC). Our results show that carefully designed\naugmentations and diverse data enable contrastive learning to produce\nhigh-quality, invariant latent representations. These representations are\neffective even with frozen encoder weights, and fine-tuning further enhances\nperformance, surpassing supervised baselines. To the best of our knowledge,\nthis is the first work to propose and demonstrate the effectiveness of\nself-supervised learning for radio signals across multiple tasks. Our findings\nhighlight the potential of self-supervised learning to transform AI for\nwireless communications by reducing dependence on labeled data and improving\nmodel generalization - paving the way for scalable foundational 6G AI models\nand solutions."}
{"id": "2509.03111", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.03111", "abs": "https://arxiv.org/abs/2509.03111", "authors": ["Hao Yang", "Guang Ouyang"], "title": "Handwriting Imagery EEG Classification based on Convolutional Neural Networks", "comment": null, "summary": "Handwriting imagery has emerged as a promising paradigm for brain-computer\ninterfaces (BCIs) aimed at translating brain activity into text output.\nCompared with invasively recorded electroencephalography (EEG), non-invasive\nrecording offers a more practical and feasible approach to capturing brain\nsignals for BCI. This study explores the limit of decoding non-invasive EEG\nassociated with handwriting imagery into English letters using deep neural\nnetworks. To this end, five participants were instructed to imagine writing the\n26 English letters with their EEG being recorded from the scalp. A measurement\nof EEG similarity across letters was conducted to investigate letter-specific\npatterns in the dataset. Subsequently, four convolutional neural network (CNN)\nmodels were trained for EEG classification. Descriptively, the EEG data clearly\nexhibited letter-specific patterns serving as a proof-of-concept for\nEEG-to-text translation. Under the chance level of accuracy at 3.85%, the CNN\nclassifiers trained on each participant reached the highest limit of around\n20%. This study marks the first attempt to decode non-invasive EEG associated\nwith handwriting imagery. Although the achieved accuracy is not sufficient for\na usable brain-to-text BCI, the model's performance is noteworthy in revealing\nthe potential for translating non-invasively recorded brain signals into text\noutputs and establishing a baseline for future research."}
{"id": "2509.03193", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.03193", "abs": "https://arxiv.org/abs/2509.03193", "authors": ["Maximilian Neidhardt", "Sarah Latus", "Tim Eixmann", "Gereon HÃ¼ttmann", "Alexander Schlaefer"], "title": "Deep Learning for High Speed Optical Coherence Elastography with a Fiber Scanning Endoscope", "comment": null, "summary": "Tissue stiffness is related to soft tissue pathologies and can be assessed\nthrough palpation or via clinical imaging systems, e.g., ultrasound or magnetic\nresonance imaging. Typically, the image based approaches are not suitable\nduring interventions, particularly for minimally invasive surgery. To this end,\nwe present a miniaturized fiber scanning endoscope for fast and localized\nelastography. Moreover, we propose a deep learning based signal processing\npipeline to account for the intricate data and the need for real-time\nestimates. Our elasticity estimation approach is based on imaging complex and\ndiffuse wave fields that encompass multiple wave frequencies and propagate in\nvarious directions. We optimize the probe design to enable different scan\npatterns. To maximize temporal sampling while maintaining three-dimensional\ninformation we define a scan pattern in a conical shape with a temporal\nfrequency of 5.05 kHz. To efficiently process the image sequences of complex\nwave fields we consider a spatio-temporal deep learning network. We train the\nnetwork in an end-to-end fashion on measurements from phantoms representing\nmultiple elasticities. The network is used to obtain localized and robust\nelasticity estimates, allowing to create elasticity maps in real-time. For 2D\nscanning, our approach results in a mean absolute error of 6.31+-5.76 kPa\ncompared to 11.33+-12.78 kPa for conventional phase tracking. For scanning\nwithout estimating the wave direction, the novel 3D method reduces the error to\n4.48+-3.63 kPa compared to 19.75+-21.82 kPa for the conventional 2D method.\nFinally, we demonstrate feasibility of elasticity estimates in ex-vivo porcine\ntissue."}
{"id": "2509.03273", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.03273", "abs": "https://arxiv.org/abs/2509.03273", "authors": ["Zeyuan Zhang", "Yue Xiu", "Zheng Dong", "Jiacheng Yin", "Maurice J. Khabbaz", "Chadi Assi", "Ning Wei"], "title": "Crosstalk-Resilient Beamforming for Movable Antenna Enabled Integrated Sensing and Communication", "comment": null, "summary": "This paper investigates a movable antenna (MA) enabled integrated sensing and\ncommunication (ISAC) system under the influence of antenna crosstalk. First, it\ngeneralizes the antenna crosstalk model from the conventional fixed-position\nantenna (FPA) system to the MA scenario. Then, a Cramer-Rao bound (CRB)\nminimization problem driven by joint beamforming and antenna position design is\npresented. Specifically, to address this highly non-convex flexible beamforming\nproblem, we deploy a deep reinforcement learning (DRL) approach to train a\nflexible beamforming agent. To ensure stability during training, a Twin Delayed\nDeep Deterministic Policy Gradient (TD3) algorithm is adopted to balance\nexploration with reward maximization for efficient and reliable learning.\nNumerical results demonstrate that the proposed crosstalk-resilient (CR)\nalgorithm enhances the overall ISAC performance compared to other benchmark\nschemes."}
{"id": "2509.03311", "categories": ["eess.SP", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.03311", "abs": "https://arxiv.org/abs/2509.03311", "authors": ["Penggao Yan", "Li-Ta Hsu"], "title": "Credible Uncertainty Quantification under Noise and System Model Mismatch", "comment": "This manuscript has been submitted to IEEE Signal Processing Letters", "summary": "State estimators often provide self-assessed uncertainty metrics, such as\ncovariance matrices, whose reliability is critical for downstream tasks.\nHowever, these self-assessments can be misleading due to underlying modeling\nviolations like noise or system model mismatch. This letter addresses the\nproblem of estimator credibility by introducing a unified, multi-metric\nevaluation framework. We construct a compact credibility portfolio that\nsynergistically combines traditional metrics like the Normalized Estimation\nError Squared (NEES) and the Noncredibility Index (NCI) with proper scoring\nrules, namely the Negative Log-Likelihood (NLL) and the Energy Score (ES). Our\nkey contributions are a novel energy distance-based location test to robustly\ndetect system model misspecification and a method that leverages the asymmetric\nsensitivities of NLL and ES to distinguish optimism covariance scaling from\nsystem bias. Monte Carlo simulations across six distinct credibility scenarios\ndemonstrate that our proposed method achieves high classification accuracy\n(80-100%), drastically outperforming single-metric baselines which consistently\nfail to provide a complete and correct diagnosis. This framework provides a\npractical tool for turning patterns of credibility indicators into actionable\ndiagnoses of model deficiencies."}
{"id": "2509.03333", "categories": ["eess.SP", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.03333", "abs": "https://arxiv.org/abs/2509.03333", "authors": ["Tianfu Qi", "Jun Wang"], "title": "Baseband Model, Cutoff Rate Bounds and Constellation Shaping for Mixed Gaussian-Impulsive Noise", "comment": null, "summary": "Mixed noise, composed of white Gaussian noise (WGN) and impulsive noise (IN),\nappears in numerous communication scenarios and can severely degrade system\nperformance. In this paper, we address this issue by optimizing the transmitted\nconstellation under mixed noise based on a theoretical analysis of the cutoff\nrate (CR). First, starting from the passband model of the mixed noise, we\nderive its corresponding baseband representation. Due to the complexity of the\nCR, an exact analytic expression is generally intractable. Therefore, the\nbaseband noise model is employed to obtain closed-form lower and upper bounds\nof the CR. A piecewise linear approximation is applied to derive efficient\nbounds by exploiting the algebraic properties of the integral terms. These\nbounds are then used as criteria to optimize the transmitted constellation\npoints in both geometric and probabilistic distributions. The projected\ngradient method is employed to solve the optimization problem, and the\nconvergence and properties of the solutions are analyzed. Numerical results\ndemonstrate that the proposed CR bounds are tight and exhibit the expected\nasymptotic behavior. Furthermore, the optimized constellation scheme achieves a\nsignificant rate improvement compared to baselines."}
{"id": "2509.03488", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.03488", "abs": "https://arxiv.org/abs/2509.03488", "authors": ["Miguel Rivas-Costa", "Carlos Mosquera"], "title": "Efficient DoA Estimation with Hybrid Linear and Rectangular Arrays Using Compact DFT Codebook", "comment": null, "summary": "Hybrid Analog and Digital (HAD) architectures provide a cost-effective\nalternative for large-scale antenna arrays, but accurate Direction-of-Arrival\n(DoA) estimation remains challenging due to limited digital dimensionality and\nconstrained beamforming design. In this work, we propose a HAD architecture\nthat employs Butler matrices to synthesize DFT beams over a uniform linear\narray. By exploiting the Cauchy-like displacement structure of the beamformed\nsignal, we introduce a second-order statistics estimation algorithm that\nachieves near-optimal accuracy, approaching the Cram\\'er-Rao Lower Bound (CRLB)\nand outperforming state-of-the-art methods in simulation."}
