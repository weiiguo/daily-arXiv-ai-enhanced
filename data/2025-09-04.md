<div id=toc></div>

# Table of Contents

- [cs.IT](#cs.IT) [Total: 4]
- [eess.SP](#eess.SP) [Total: 14]


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [1] [On a class of twisted elliptic curve codes](https://arxiv.org/abs/2509.03034)
*Xiaofeng Liu,Jun Zhang,Fang-Wei Fu*

Main category: cs.IT

TL;DR: 本文研究了带扭曲的椭圆曲线码（TECCs），特别关注单扭曲情况。给出了TECCs的奇偶校验矩阵、自对偶条件、最小距离，并提供了MDS、AMDS、自对偶和MDS自对偶TECCs的实例。最后证明了TECCs与ECCs/GRS码的非等价性。


<details>
  <summary>Details</summary>
Motivation: 受扭曲广义Reed-Solomon（TGRS）码研究的启发，本文首次研究带扭曲的椭圆曲线码（TECCs），旨在探索这类新型编码结构的性质和特点。

Method: 通过计算Weil微分显式给出TECCs的奇偶校验矩阵，分析自对偶的充分必要条件，确定最小距离，并构造具体实例。最后计算Schur平方的维数来证明非等价性。

Result: 成功建立了TECCs的理论框架，给出了自对偶的充要条件，确定了最小距离，提供了MDS、AMDS、自对偶和MDS自对偶TECCs的具体实例，并证明了TECCs与ECCs/GRS码的非等价性。

Conclusion: TECCs是一类具有良好性质的新型编码结构，在自对偶性、最小距离和与现有编码的非等价性方面表现出独特优势，为编码理论提供了新的研究方向。

Abstract: Motivated by the studies of twisted generalized Reed-Solomon (TGRS) codes, we
initiate the study of twisted elliptic curve codes (TECCs) in this paper. In
particular, we study a class of TECCs with one twist. The parity-check matrices
of the TECCs are explicitly given by computing the Weil differentials. Then the
sufficient and necessary conditions of self-duality are presented. The minimum
distances of the TECCs are also determined. Moreover, examples of MDS, AMDS,
self-dual and MDS self-dual TECCs are given. Finally, we calculate the
dimensions of the Schur squares of TECCs and show the non-equivalence between
TECCs and ECCs/GRS codes.

</details>


### [2] [Successive Cancellation Decoding For General Monotone Chain Polar Codes](https://arxiv.org/abs/2509.03128)
*Zichang Ren,Chunhang Zheng,Dou Li,Yuping Zhao*

Main category: cs.IT

TL;DR: 提出了单调链极化码的通用SC解码框架，支持多终端、非二进制字母表和任意单调链解码，时间复杂度在O(NlogN)到O(N²)之间，并引入了基于逻辑计算图的常数时间解码器分叉策略。


<details>
  <summary>Details</summary>
Motivation: 单调链极化码在分布式无损编码中提供了灵活性，但现有SC解码方案面临重大挑战，需要通用的解码解决方案来处理多终端、非二进制和任意单调链的情况。

Method: 将SC解码任务制定为极化变换上的一系列推理子任务，基于概率传播原理提出计算图框架，分析变量切换对解码的影响，并引入基于逻辑计算图的常数时间解码器分叉策略。

Result: 数值结果表明，所提方案相比经典的lazy-copy方案具有更优越的性能，时间效率更高且不依赖O(N)空间技术。

Conclusion: 提出的解码框架为单调链极化码提供了通用的SC解码解决方案，能够有效处理复杂的多终端场景，并通过创新的分叉策略实现了高效的时间性能。

Abstract: Monotone chain polar codes generalize classical polar codes to multivariate
settings, offering a flexible approach for achieving the entire admissible rate
region in the distributed lossless coding problem. However, this flexibility
also introduces significant challenges for existing successive cancellation
(SC) based decoding schemes. Motivated by the need for a general SC decoding
solution, we present a comprehensive decoding strategy for monotone chain polar
codes that can handle arbitrary numbers of terminals, non-binary alphabets, and
decoding along arbitrary monotone chains. Specifically, we formulate the SC
decoding task as a series of inference subtasks over the polar transform and
propose a computational graph framework based on probability propagation
principles. This approach highlights the impact of variable switching during
decoding and shows that time complexity varies between $O(N\log{N})$ and
$O(N^2)$, depending on the specific chain structure. Moreover, we demonstrate
that the widely used $O(N)$ space optimization is not universally applicable to
monotone chain polar codes, which prompts us to introduce a constant-time
decoder forking strategy based on the proposed logical computation graphs. This
strategy enables time-efficient list decoding without relying on $O(N)$-space
techniques. Numerical results verify the superior performance of the proposed
scheme compared with the classical lazy-copy scheme.

</details>


### [3] [New Bounds for Linear Codes with Applications](https://arxiv.org/abs/2509.03337)
*Liren Lin,Guanghui Zhang,Bocong Chen,Hongwei Liu*

Main category: cs.IT

TL;DR: 该论文在传统线性码边界理论基础上，通过考虑码字包含特定权重w的非零码字这一额外假设，推导出了连接参数n、k、d、q和w的新边界不等式。


<details>
  <summary>Details</summary>
Motivation: 传统线性码边界理论仅基于参数n、k、d和q来表征纠错能力与信息率之间的权衡关系，但忽略了码字权重分布的具体信息。本文旨在利用码字包含特定权重w的非零码字这一额外信息，获得更精确的边界限制。

Method: 结合残差码技术与经典边界方法（如Singleton边界和Griesmer边界），推导出显式的不等式关系，将码长n、维度k、最小距离d、域大小q和特定权重w联系起来。

Result: 获得了新的边界不等式，这些边界对可容许码字权重施加了更严格的限制，特别是在接近最小距离或码长的权重范围内。数值比较表明，这些w感知边界严格扩大了已知的排除权重范围。

Conclusion: 提出的w感知边界方法为线性码的结构限制提供了更精确的描述，在MDS码权重约束、一般线性码数值限制和权重分布排除范围等方面具有重要应用价值。

Abstract: Bounds on linear codes play a central role in coding theory, as they capture
the fundamental trade-off between error-correction capability (minimum
distance) and information rate (dimension relative to length). Classical
results characterize this trade-off solely in terms of the parameters $n$, $k$,
$d$ and $q$. In this work we derive new bounds under the additional assumption
that the code contains a nonzero codeword of weight $w$.By combining
residual-code techniques with classical results such as the Singleton and
Griesmer bounds,we obtain explicit inequalities linking $n$, $k$, $d$, $q$ and
$w$. These bounds impose sharper restrictions on admissible codeword weights,
particularly those close to the minimum distance or to the code length.
Applications include refined constraints on the weights of MDS codes, numerical
restrictions on general linear codes, and excluded weight ranges in the weight
distribution. Numerical comparisons across standard parameter sets demonstrate
that these $w$-aware bounds strictly enlarge known excluded weight ranges and
sharpen structural limitations on linear codes.

</details>


### [4] [PoolPy: Flexible Group Testing Design for Large-Scale Screening](https://arxiv.org/abs/2509.03481)
*Lorenzo Talamanca,Julian Trouillon*

Main category: cs.IT

TL;DR: PoolPy是一个统一的群体检测框架，提供10种不同方法的最优策略设计和选择，通过计算10,000多种设计方案帮助用户根据时间、成本等约束条件选择合适方法。


<details>
  <summary>Details</summary>
Motivation: 大规模筛查中群体检测可显著减少检测次数，但由于方法多样且缺乏易用工具，选择和实施合适的群体检测方法仍然具有挑战性。

Method: 开发PoolPy统一框架，计算10,000多种群体检测设计方案，通过web界面提供，根据用户定义的时间、成本或样本稀释等约束条件优化策略选择。

Result: 识别了关键权衡因素（如最小化检测次数或组大小），发现没有单一方法在所有情况下都是最优的，需要根据具体用例选择。

Conclusion: 群体检测方法选择应基于具体用例需求，PoolPy框架为不同约束条件下的最优方法选择提供了清晰指导。

Abstract: In large screening campaigns, group testing can greatly reduce the number of
tests needed when compared to testing each sample individually. However,
choosing and applying an appropriate group testing method remains challenging
due to the wide variety in design and performance across methods, and the lack
of accessible tools. Here, we present PoolPy, a unified framework for designing
and selecting optimal group testing strategies across ten different methods
according to user-defined constraints, such as time, cost or sample dilution.
By computing over 10,000 group testing designs made available through a web
interface, we identified key trade-offs, such as minimizing test number or
group size, that define applicability to specific use cases. Overall, we show
that no single method is universally optimal, and provide clear indications for
method choice on a case-by-case basis.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [5] [EEG-MSAF: An Interpretable Microstate Framework uncovers Default-Mode Decoherence in Early Neurodegeneration](https://arxiv.org/abs/2509.02568)
*Mohammad Mehedi Hasan,Pedro G. Lind,Hernando Ombao,Anis Yazidi,Rabindra Khadka*

Main category: eess.SP

TL;DR: EEG-MSAF是一个端到端的EEG微状态分析框架，通过机器学习分类和SHAP特征排名，在痴呆症诊断中达到89-95%的准确率，超越了深度学习基线方法。


<details>
  <summary>Details</summary>
Motivation: 痴呆症是全球性健康挑战，需要早期准确诊断。传统EEG方法难以捕捉脑电活动的瞬态复杂性，因此需要开发新的分析框架来识别痴呆相关生物标志物。

Method: EEG-MSAF包含三个阶段：1)自动微状态特征提取；2)机器学习分类；3)SHAP特征排名识别关键生物标志物。在两个EEG数据集(CAUEEG和Thessaloniki医院临床队列)上进行评估。

Result: 在CAUEEG数据集上达到89%±0.01准确率，超越CEEDNET基线19.3%；在Thessaloniki数据集上达到95%±0.01准确率，与EEGConvNeXt相当。SHAP分析识别出平均相关性和出现频率为最信息量指标。

Conclusion: EEG-MSAF结合了准确性、泛化性和可解释性，推进了基于EEG的痴呆症诊断，揭示了跨认知谱系的脑动力学特征，特别是微状态C和新型微状态F作为关键生物标志物。

Abstract: Dementia (DEM) is a growing global health challenge, underscoring the need
for early and accurate diagnosis. Electroencephalography (EEG) provides a
non-invasive window into brain activity, but conventional methods struggle to
capture its transient complexity. We present the \textbf{EEG Microstate
Analysis Framework (EEG-MSAF)}, an end-to-end pipeline that leverages EEG
microstates discrete, quasi-stable topographies to identify DEM-related
biomarkers and distinguish DEM, mild cognitive impairment (MCI), and normal
cognition (NC). EEG-MSAF comprises three stages: (1) automated microstate
feature extraction, (2) classification with machine learning (ML), and (3)
feature ranking using Shapley Additive Explanations (SHAP) to highlight key
biomarkers. We evaluate on two EEG datasets: the public Chung-Ang University
EEG (CAUEEG) dataset and a clinical cohort from Thessaloniki Hospital. Our
framework demonstrates strong performance and generalizability. On CAUEEG,
EEG-MSAF-SVM achieves \textbf{89\% $\pm$ 0.01 accuracy}, surpassing the deep
learning baseline CEEDNET by \textbf{19.3\%}. On the Thessaloniki dataset, it
reaches \textbf{95\% $\pm$ 0.01 accuracy}, comparable to EEGConvNeXt. SHAP
analysis identifies mean correlation and occurrence as the most informative
metrics: disruption of microstate C (salience/attention network) dominates DEM
prediction, while microstate F, a novel default-mode pattern, emerges as a key
early biomarker for both MCI and DEM. By combining accuracy, generalizability,
and interpretability, EEG-MSAF advances EEG-based dementia diagnosis and sheds
light on brain dynamics across the cognitive spectrum.

</details>


### [6] [Recall Gabor Communication Theory and Joint Time-Frequency Analysis](https://arxiv.org/abs/2509.02724)
*Xiang-Gen Xia*

Main category: eess.SP

TL;DR: 本文回顾了Gabor的通信理论、Gabor变换和展开，以及其与联合时频分析的联系


<details>
  <summary>Details</summary>
Motivation: 重新审视和总结Gabor在通信理论方面的基础工作，特别是Gabor变换与时频分析的关系

Method: 采用文献回顾和理论分析的方法，系统梳理Gabor通信理论、变换和展开技术

Result: 建立了Gabor变换与联合时频分析之间的理论联系框架

Conclusion: Gabor的理论为现代时频分析奠定了重要基础，其变换方法在信号处理领域具有持续影响力

Abstract: In this article, we first briefly recall Gabor's communication theory and
then Gabor transform and expansion, and also its connection with joint time
frequency analysis.

</details>


### [7] [minPIC: Towards Optimal Power Allocation in Multi-User Interference Channels](https://arxiv.org/abs/2509.02797)
*Sagnik Bhattacharya,Abhiram Rao Gorle,John M. Cioffi*

Main category: eess.SP

TL;DR: minPIC框架：首个实现高斯干扰信道SIC可达速率区域帕累托边界的算法，通过双变量引导排序和凸优化解决6G无蜂窝网络中功率、子载波和解码顺序的联合优化问题


<details>
  <summary>Details</summary>
Motivation: 6G无蜂窝网络需要处理空间嵌套的多址接入和广播信道，现有OMA、NOMA和RSMA方案依赖固定启发式干扰管理，导致速率次优、功率效率低下和可扩展性问题

Method: 提出minPIC框架，引入双变量引导排序准则识别全局最优SIC顺序，然后使用辅助对数行列式约束进行凸优化，通过二分搜索高效求解

Result: minPIC能够实现高斯干扰信道SIC可达速率区域的帕累托边界，有望满足沉浸式XR等6G应用的高速率、低功耗要求

Conclusion: minPIC是首个算法实现高斯干扰信道SIC可达速率区域帕累托边界的方法，为无蜂窝网络的可扩展干扰管理开辟了新途径

Abstract: 6G envisions massive cell-free networks with spatially nested multiple access
(MAC) and broadcast (BC) channels without centralized coordination. This makes
optimal resource allocation across power, subcarriers, and decoding orders
crucial for interference channels (ICs), where neither transmitters nor
receivers can cooperate. Current orthogonal multiple access (OMA) methods, as
well as non-orthogonal (NOMA) and rate-splitting (RSMA) schemes, rely on fixed
heuristics for interference management, leading to suboptimal rates, power
inefficiency, and scalability issues. This paper proposes a novel minPIC
framework for optimal power, subcarrier, and decoding order allocation in
general multi-user ICs. Unlike existing methods, minPIC eliminates heuristic
SIC order assumptions. Despite the convexity of the IC capacity region, fixing
an SIC order induces non-convexity in resource allocation, traditionally
requiring heuristic approximations. We instead introduce a dual-variable-guided
sorting criterion to identify globally optimal SIC orders, followed by convex
optimization with auxiliary log-det constraints, efficiently solved via binary
search. We also demonstrate that minPIC could potentially meet the stringent
high-rate, low-power targets of immersive XR and other 6G applications. To the
best of our knowledge, minPIC is the first algorithmic realisation of the
Pareto boundary of the SIC-achievable rate region for Gaussian ICs, opening the
door to scalable interference management in cell-free networks.

</details>


### [8] [Credible Uncertainty Quantification under Noise and System Model Mismatch](https://arxiv.org/abs/2509.03311)
*Penggao Yan,Li-Ta Hsu*

Main category: eess.SP

TL;DR: 提出一个统一的多指标评估框架，结合传统指标和适当评分规则来评估状态估计器的可信度，能够高精度诊断模型缺陷


<details>
  <summary>Details</summary>
Motivation: 状态估计器提供的自评估不确定性指标（如协方差矩阵）可能由于噪声或系统模型不匹配等建模违规而产生误导，需要可靠的可信度评估方法

Method: 构建紧凑的可信度组合，结合NEES、NCI等传统指标与NLL、ES等适当评分规则，提出基于能量距离的位置测试来检测系统模型误设，利用NLL和ES的不对称敏感性区分乐观协方差缩放和系统偏差

Result: 在六个不同可信度场景的蒙特卡洛模拟中，该方法达到80-100%的分类准确率，显著优于单指标基线方法

Conclusion: 该框架提供了一个实用工具，能够将可信度指标的模式转化为对模型缺陷的可操作诊断

Abstract: State estimators often provide self-assessed uncertainty metrics, such as
covariance matrices, whose reliability is critical for downstream tasks.
However, these self-assessments can be misleading due to underlying modeling
violations like noise or system model mismatch. This letter addresses the
problem of estimator credibility by introducing a unified, multi-metric
evaluation framework. We construct a compact credibility portfolio that
synergistically combines traditional metrics like the Normalized Estimation
Error Squared (NEES) and the Noncredibility Index (NCI) with proper scoring
rules, namely the Negative Log-Likelihood (NLL) and the Energy Score (ES). Our
key contributions are a novel energy distance-based location test to robustly
detect system model misspecification and a method that leverages the asymmetric
sensitivities of NLL and ES to distinguish optimism covariance scaling from
system bias. Monte Carlo simulations across six distinct credibility scenarios
demonstrate that our proposed method achieves high classification accuracy
(80-100%), drastically outperforming single-metric baselines which consistently
fail to provide a complete and correct diagnosis. This framework provides a
practical tool for turning patterns of credibility indicators into actionable
diagnoses of model deficiencies.

</details>


### [9] [Protecting Legacy Wireless Systems Against Interference: Precoding and Codebook Approaches Using Massive MIMO and Region Constraints](https://arxiv.org/abs/2509.02819)
*Sameer Mathad,Taejoon Kim,David J. Love*

Main category: eess.SP

TL;DR: 本文提出了一种基于通信理论的解决方案，通过在大规模MIMO系统设计中加入接收功率约束（区域约束），在利用新频段的同时保护传统用户免受干扰。


<details>
  <summary>Details</summary>
Motivation: 随着高速无线通信需求的增长，使用与传统无线系统相邻频段会导致对关键基础设施网络中传统用户的干扰，需要开发保护方案。

Method: 在大规模MIMO系统设计中加入接收功率约束（区域约束），进行单用户容量分析和多用户和速率分析，提出预编码设计方法。

Result: 提出的方法能够在利用新频段的同时有效保护传统用户免受干扰。

Conclusion: 基于通信理论的区域约束方法比地理隔离区方案更有效地解决了新频段使用中的传统用户保护问题。

Abstract: The ever-increasing demand for high-speed wireless communication has
generated significant interest in utilizing frequency bands that are adjacent
to those occupied by legacy wireless systems. Since the legacy wireless systems
were designed based on often decades-old assumptions about wireless
interference, utilizing these new bands will result in interference with the
existing legacy users. Many of these legacy wireless devices are used by
critical infrastructure networks upon which society depends. There is an urgent
need to develop schemes that can protect legacy users from such interference.
For many applications, legacy users are located within
geographically-constrained regions. Several studies have proposed mitigating
interference through the implementation of exclusion zones near these
geographically-constrained regions. In contrast to solutions based on
geographic exclusion zones, this paper presents a communication theory-based
solution. By leveraging knowledge of these geographically-constrained regions,
we aim to reduce the interference impact on legacy users. We achieve this by
incorporating received power constraints, termed as region constraints, in our
massive multiple-input multiple-output (MIMO) system design. We perform a
capacity analysis of single-user massive MIMO and a sum-rate analysis of the
multi-user massive MIMO system with transmit power and region constraints. We
present a precoding design method that allows for the utilization of new
frequency bands while protecting legacy users.

</details>


### [10] [Baseband Model, Cutoff Rate Bounds and Constellation Shaping for Mixed Gaussian-Impulsive Noise](https://arxiv.org/abs/2509.03333)
*Tianfu Qi,Jun Wang*

Main category: eess.SP

TL;DR: 论文提出基于截止率分析的混合噪声下星座图优化方法，通过推导基带噪声模型获得截止率的紧致上下界，并以此优化星座点的几何和概率分布，显著提升传输速率。


<details>
  <summary>Details</summary>
Motivation: 混合噪声（高斯白噪声+脉冲噪声）在通信场景中普遍存在且严重降低系统性能，需要针对此类噪声优化传输星座设计。

Method: 1) 推导混合噪声的基带表示模型；2) 利用分段线性近似获得截止率的闭式上下界；3) 以这些界限为准则优化星座点的几何和概率分布；4) 使用投影梯度法求解优化问题。

Result: 数值结果表明提出的截止率界限紧致且具有预期的渐近行为，优化后的星座方案相比基线实现了显著的速率提升。

Conclusion: 该方法有效解决了混合噪声下的星座优化问题，通过理论分析和数值验证证明了其优越性能，为实际通信系统设计提供了有效解决方案。

Abstract: Mixed noise, composed of white Gaussian noise (WGN) and impulsive noise (IN),
appears in numerous communication scenarios and can severely degrade system
performance. In this paper, we address this issue by optimizing the transmitted
constellation under mixed noise based on a theoretical analysis of the cutoff
rate (CR). First, starting from the passband model of the mixed noise, we
derive its corresponding baseband representation. Due to the complexity of the
CR, an exact analytic expression is generally intractable. Therefore, the
baseband noise model is employed to obtain closed-form lower and upper bounds
of the CR. A piecewise linear approximation is applied to derive efficient
bounds by exploiting the algebraic properties of the integral terms. These
bounds are then used as criteria to optimize the transmitted constellation
points in both geometric and probabilistic distributions. The projected
gradient method is employed to solve the optimization problem, and the
convergence and properties of the solutions are analyzed. Numerical results
demonstrate that the proposed CR bounds are tight and exhibit the expected
asymptotic behavior. Furthermore, the optimized constellation scheme achieves a
significant rate improvement compared to baselines.

</details>


### [11] [Spatially Adaptive SWIPT with Pinching Antenna under Probabilistic LoS Blockage](https://arxiv.org/abs/2509.03038)
*Ruihong Jiang,Ruichen Zhang,Yanqing Xu,Huimin Hu,Yang Lu,Dusit Niyato*

Main category: eess.SP

TL;DR: 这篇论文研究了在概率性视线阻塞环境下，使用可重配制拉抛天线的力量分割型同时无线信息与能量传输系统，通过关键参数优化提升平均信器噪声比和能量收集性能。


<details>
  <summary>Details</summary>
Motivation: 解决概率性视线阻塞环境下SWIPT系统的性能优化问题，通过天线位置和力量分割比的动态调整来应对渠道动态性带来的挑战。

Method: 构建关于可重配制拉抛天线位置和力量分割比的聚合优化问题，以最大化用户平均信器噪声比为目标，同时满足平均能量收集要求和天线部署限制条件，并求解出闭式最优解。

Result: 结果显示能量收集要求对最优天线位置及其可行域有确定性影响，需要将天线尽可能接近用户以最大化平均渠道增益。这种空间适应结合动态力量分割，能够在概率性视线阻塞环境下实现稳健的SWIPT性能。

Conclusion: 机械可重配制性主要通过确保动态环境下的能量可行性来增强系统的可持续性，证明了空间适应和动态资源分配在应对环境不确定性时的关键作用。

Abstract: This paper considers a power-splitting (PS)-based simultaneous wireless
information and power transfer (SWIPT) system employing a reconfigurable
pinching antenna (PA) under probabilistic line-of-sight (LoS) blockage. We
formulate a joint optimization of the PA position and the PS ratio to maximize
the average signal-to-noise ratio (SNR) at a user, subject to its average
energy harvesting (EH) and PA placement limits. We derive a closed-form optimal
solution. Results demonstrate that the EH requirement has a deterministic
impact on the optimal PA position as well as its feasible region, requiring
deployment of the PA as close to the user as possible to maximize average
channel gain. This spatial adaptation, combined with dynamic PS, enables robust
SWIPT performance in the presence of probabilistic LoS blockage, revealing that
mechanical reconfigurability primarily enhances sustainability by ensuring
energy feasibility in dynamic environments.

</details>


### [12] [S2M2ECG: Spatio-temporal bi-directional State Space Model Enabled Multi-branch Mamba for ECG](https://arxiv.org/abs/2509.03066)
*Huaicheng Zhang,Ruoxin Wang,Chenlian Zhou,Jiguang Shi,Yue Ge,Zhoutong Li,Sheng Chang,Hao Wang,Jin He,Qijun Huang*

Main category: eess.SP

TL;DR: S2M2ECG是一种基于状态空间模型(SSM)的新型心电图分析架构，通过三级融合机制实现多导联ECG信号的高效处理，在性能、计算复杂度和特征融合之间取得良好平衡。


<details>
  <summary>Details</summary>
Motivation: 多导联心电图(CVD诊断的重要方法)存在多传感器信息融合挑战，现有深度学习算法难以在性能、计算复杂度和多源ECG特征融合之间保持平衡。状态空间模型(特别是Mamba)在高效计算和线性复杂度方面的优势使其特别适合ECG这类低维数据。

Method: 提出S2M2ECG架构，包含三级融合机制：(1)时空双向SSM与分段标记化的低层信号融合；(2)导联内双向扫描的时间信息融合；(3)跨导联特征交互模块的空间信息融合。采用多分支设计和导联融合模块，实现各导联独立分析的同时确保无缝集成。

Result: S2M2ECG在节律、形态和临床场景中均取得优异性能，其轻量级架构具有几乎最少的参数量，非常适合高效推理和便捷部署。

Conclusion: S2M2ECG在性能、计算复杂度和ECG特定特征之间实现了出色的平衡，为CVD诊断中的高性能轻量级计算开辟了新途径。

Abstract: As one of the most effective methods for cardiovascular disease (CVD)
diagnosis, multi-lead Electrocardiogram (ECG) signals present a characteristic
multi-sensor information fusion challenge that has been continuously researched
in deep learning domains. Despite the numerous algorithms proposed with
different DL architectures, maintaining a balance among performance,
computational complexity, and multi-source ECG feature fusion remains
challenging. Recently, state space models (SSMs), particularly Mamba, have
demonstrated remarkable effectiveness across various fields. Their inherent
design for high-efficiency computation and linear complexity makes them
particularly suitable for low-dimensional data like ECGs. This work proposes
S2M2ECG, an SSM architecture featuring three-level fusion mechanisms: (1)
Spatio-temporal bi-directional SSMs with segment tokenization for low-level
signal fusion, (2) Intra-lead temporal information fusion with bi-directional
scanning to enhance recognition accuracy in both forward and backward
directions, (3) Cross-lead feature interaction modules for spatial information
fusion. To fully leverage the ECG-specific multi-lead mechanisms inherent in
ECG signals, a multi-branch design and lead fusion modules are incorporated,
enabling individual analysis of each lead while ensuring seamless integration
with others. Experimental results reveal that S2M2ECG achieves superior
performance in the rhythmic, morphological, and clinical scenarios. Moreover,
its lightweight architecture ensures it has nearly the fewest parameters among
existing models, making it highly suitable for efficient inference and
convenient deployment. Collectively, S2M2ECG offers a promising alternative
that strikes an excellent balance among performance, computational complexity,
and ECG-specific characteristics, paving the way for high-performance,
lightweight computations in CVD diagnosis.

</details>


### [13] [YOLO-based Bearing Fault Diagnosis With Continuous Wavelet Transform](https://arxiv.org/abs/2509.03070)
*Po-Heng Chou,Wei-Lung Mao,Ru-Ping Lin*

Main category: eess.SP

TL;DR: 本文提出了一种基于YOLO的空间轴承故障诊断框架，利用连续小波变换得到的时频谱图进行故障分类，在多个数据集上实现了超过基线模型的高精度和通用性。


<details>
  <summary>Details</summary>
Motivation: 传统的轴承故障诊断方法在准确性和通用性方面有限，需要一种能够有效捕捉过渡故障特征并直接可视化故障位置的方法。

Method: 将一维震动信号通过Morlet小波进行连续小波变换生成时频谱图，然后使用YOLOv9、v10和v11模型对谱图进行故障分类检测。

Result: 在CWRU、PU和IMS三个标准数据集上，YOLOv11分别达到了99.4%、97.8%和99.5%的mAP分数，显著超过基线MCNN-LSTM模型。同时具备区域感知能力，可直接可视化故障位置。

Conclusion: 该CWT-YOLO流水线为旋转机械状态监控提供了一种准确、通用性强且可解释性好的实用解决方案。

Abstract: This letter proposes a YOLO-based framework for spatial bearing fault
diagnosis using time-frequency spectrograms derived from continuous wavelet
transform (CWT). One-dimensional vibration signals are first transformed into
time-frequency spectrograms using Morlet wavelets to capture transient fault
signatures. These spectrograms are then processed by YOLOv9, v10, and v11
models to classify fault types. Evaluated on three benchmark datasets,
including Case Western Reserve University (CWRU), Paderborn University (PU),
and Intelligent Maintenance System (IMS), the proposed CWT--YOLO pipeline
achieves significantly higher accuracy and generalizability than the baseline
MCNN--LSTM model. Notably, YOLOv11 reaches mAP scores of 99.4% (CWRU), 97.8%
(PU), and 99.5% (IMS). In addition, its region-aware detection mechanism
enables direct visualization of fault locations in spectrograms, offering a
practical solution for condition monitoring in rotating machinery.

</details>


### [14] [Self-supervised Radio Representation Learning: Can we Learn Multiple Tasks?](https://arxiv.org/abs/2509.03077)
*Ogechukwu Kanu,Ashkan Eshaghbeigi,Hatem Abou-Zeid*

Main category: eess.SP

TL;DR: 本文提出了一种基于动量对比的自监督学习方案，用于无线电信号表征学习，在AoA估计和AMC任务上超越了监督学习基线。


<details>
  <summary>Details</summary>
Motivation: 解决6G中AI应用需要大量标签数据的挑战，减少对标签数据的依赖并提高模型的通用性。

Method: 使用动量对比学习方法，通过设计恰当的数据增帿和多样化数据来学习无线电信号的稳健、可转移表征。

Result: 学习到的表征在冻结编码器权重时仍有效，细调后性能更优，在AoA估计和AMC任务上超过监督学习基线。

Conclusion: 自监督学习有潜力改变无线通信AI，减少对标签数据的依赖，为可扩展的6G AI模型铺平道路。

Abstract: Artificial intelligence (AI) is anticipated to play a pivotal role in 6G.
However, a key challenge in developing AI-powered solutions is the extensive
data collection and labeling efforts required to train supervised deep learning
models. To overcome this, self-supervised learning (SSL) approaches have
recently demonstrated remarkable success across various domains by leveraging
large volumes of unlabeled data to achieve near-supervised performance. In this
paper, we propose an effective SSL scheme for radio signal representation
learning using momentum contrast. By applying contrastive learning, our method
extracts robust, transferable representations from a large real-world dataset.
We assess the generalizability of these learned representations across two
wireless communications tasks: angle of arrival (AoA) estimation and automatic
modulation classification (AMC). Our results show that carefully designed
augmentations and diverse data enable contrastive learning to produce
high-quality, invariant latent representations. These representations are
effective even with frozen encoder weights, and fine-tuning further enhances
performance, surpassing supervised baselines. To the best of our knowledge,
this is the first work to propose and demonstrate the effectiveness of
self-supervised learning for radio signals across multiple tasks. Our findings
highlight the potential of self-supervised learning to transform AI for
wireless communications by reducing dependence on labeled data and improving
model generalization - paving the way for scalable foundational 6G AI models
and solutions.

</details>


### [15] [Handwriting Imagery EEG Classification based on Convolutional Neural Networks](https://arxiv.org/abs/2509.03111)
*Hao Yang,Guang Ouyang*

Main category: eess.SP

TL;DR: 本研究探索使用深度神经网络解码与非侵入式脑电图（EEG）相关的手写想象，将其转换为英文字母的极限，最高准确率达到约20%，为脑机接口文本输出提供了概念验证和基准。


<details>
  <summary>Details</summary>
Motivation: 手写想象已成为脑机接口（BCI）的有前景范式，相比侵入式EEG记录，非侵入式记录提供了更实用可行的方法来捕获脑信号进行文本输出转换。

Method: 5名参与者想象书写26个英文字母时记录头皮EEG，测量EEG跨字母相似性，然后训练4个卷积神经网络（CNN）模型进行EEG分类。

Result: EEG数据明显表现出字母特异性模式，CNN分类器在3.85%的随机水平下达到约20%的最高准确率，首次成功解码与非侵入式EEG相关的手写想象。

Conclusion: 虽然准确率尚不足以构建实用的脑到文本BCI，但模型性能显著，揭示了将非侵入式脑信号转换为文本输出的潜力，为未来研究建立了基准。

Abstract: Handwriting imagery has emerged as a promising paradigm for brain-computer
interfaces (BCIs) aimed at translating brain activity into text output.
Compared with invasively recorded electroencephalography (EEG), non-invasive
recording offers a more practical and feasible approach to capturing brain
signals for BCI. This study explores the limit of decoding non-invasive EEG
associated with handwriting imagery into English letters using deep neural
networks. To this end, five participants were instructed to imagine writing the
26 English letters with their EEG being recorded from the scalp. A measurement
of EEG similarity across letters was conducted to investigate letter-specific
patterns in the dataset. Subsequently, four convolutional neural network (CNN)
models were trained for EEG classification. Descriptively, the EEG data clearly
exhibited letter-specific patterns serving as a proof-of-concept for
EEG-to-text translation. Under the chance level of accuracy at 3.85%, the CNN
classifiers trained on each participant reached the highest limit of around
20%. This study marks the first attempt to decode non-invasive EEG associated
with handwriting imagery. Although the achieved accuracy is not sufficient for
a usable brain-to-text BCI, the model's performance is noteworthy in revealing
the potential for translating non-invasively recorded brain signals into text
outputs and establishing a baseline for future research.

</details>


### [16] [Deep Learning for High Speed Optical Coherence Elastography with a Fiber Scanning Endoscope](https://arxiv.org/abs/2509.03193)
*Maximilian Neidhardt,Sarah Latus,Tim Eixmann,Gereon Hüttmann,Alexander Schlaefer*

Main category: eess.SP

TL;DR: 开发了一种运用深度学习的小型化光纤扫描内镜系统，能够在微估手术中实现快速、局部化的弹性成像，在胴体和离体组织中进行了验证。


<details>
  <summary>Details</summary>
Motivation: 现有的图像基于的组织硬度评估方法在介入性手术特别是微估手术中不适用，需要一种能够实现快速、局部化弹性测量的方法。

Method: 设计了小型化光纤扫描内镜，采用锥形扫描模式（5.05 kHz），通过深度学习空间-时间网络处理复杂的多频率多方向波场图像序列，在代表不同弹性的胴体上进行端到端训练。

Result: 在2D扫描中，新方法的平均绝对误差为6.31±5.76 kPa，显著低于传统相位跟踪方法的11.33±12.78 kPa。在不估计波方向的3D扫描中，锐减错误至4.48±3.63 kPa，而传统2D方法为19.75±21.82 kPa。在离体猪组织中进行了可行性验证。

Conclusion: 该研究开发的深度学习基于光纤扫描内镜的弹性成像系统能够在微估手术中实现实时、准确的局部组织弹性测量，为软组织病理识别提供了新的技术手段。

Abstract: Tissue stiffness is related to soft tissue pathologies and can be assessed
through palpation or via clinical imaging systems, e.g., ultrasound or magnetic
resonance imaging. Typically, the image based approaches are not suitable
during interventions, particularly for minimally invasive surgery. To this end,
we present a miniaturized fiber scanning endoscope for fast and localized
elastography. Moreover, we propose a deep learning based signal processing
pipeline to account for the intricate data and the need for real-time
estimates. Our elasticity estimation approach is based on imaging complex and
diffuse wave fields that encompass multiple wave frequencies and propagate in
various directions. We optimize the probe design to enable different scan
patterns. To maximize temporal sampling while maintaining three-dimensional
information we define a scan pattern in a conical shape with a temporal
frequency of 5.05 kHz. To efficiently process the image sequences of complex
wave fields we consider a spatio-temporal deep learning network. We train the
network in an end-to-end fashion on measurements from phantoms representing
multiple elasticities. The network is used to obtain localized and robust
elasticity estimates, allowing to create elasticity maps in real-time. For 2D
scanning, our approach results in a mean absolute error of 6.31+-5.76 kPa
compared to 11.33+-12.78 kPa for conventional phase tracking. For scanning
without estimating the wave direction, the novel 3D method reduces the error to
4.48+-3.63 kPa compared to 19.75+-21.82 kPa for the conventional 2D method.
Finally, we demonstrate feasibility of elasticity estimates in ex-vivo porcine
tissue.

</details>


### [17] [Crosstalk-Resilient Beamforming for Movable Antenna Enabled Integrated Sensing and Communication](https://arxiv.org/abs/2509.03273)
*Zeyuan Zhang,Yue Xiu,Zheng Dong,Jiacheng Yin,Maurice J. Khabbaz,Chadi Assi,Ning Wei*

Main category: eess.SP

TL;DR: 本文研究了在天线交象影响下的可移动天线集成感知通信系统，通过深度强化学习策略优化材料和天线位置设计，提高了系统性能。


<details>
  <summary>Details</summary>
Motivation: 解决可移动天线系统中天线交象问题对集成感知通信性能的负面影响，提高系统的性能和稳定性。

Method: 将天线交象模型扩展到MA场景，采用深度强化学习方法（TD3算法）进行联合材料和天线位置设计优化，最小化Cramer-Rao边界。

Result: 数值结果表明，所提出的抗交象算法在集成感知通信性能方面显著优于其他基准方案。

Conclusion: 通过DRL策略有效解决了非凸优化问题，提高了MA-ISAC系统在存在天线交象情况下的性能和稳定性。

Abstract: This paper investigates a movable antenna (MA) enabled integrated sensing and
communication (ISAC) system under the influence of antenna crosstalk. First, it
generalizes the antenna crosstalk model from the conventional fixed-position
antenna (FPA) system to the MA scenario. Then, a Cramer-Rao bound (CRB)
minimization problem driven by joint beamforming and antenna position design is
presented. Specifically, to address this highly non-convex flexible beamforming
problem, we deploy a deep reinforcement learning (DRL) approach to train a
flexible beamforming agent. To ensure stability during training, a Twin Delayed
Deep Deterministic Policy Gradient (TD3) algorithm is adopted to balance
exploration with reward maximization for efficient and reliable learning.
Numerical results demonstrate that the proposed crosstalk-resilient (CR)
algorithm enhances the overall ISAC performance compared to other benchmark
schemes.

</details>


### [18] [Efficient DoA Estimation with Hybrid Linear and Rectangular Arrays Using Compact DFT Codebook](https://arxiv.org/abs/2509.03488)
*Miguel Rivas-Costa,Carlos Mosquera*

Main category: eess.SP

TL;DR: 提出了一种采用Butler矩阵的混合模拟数字架构，通过利用波束成形信号的Cauchy-like位移结构，实现了接近CRLB的近乎最优DoA估计精度。


<details>
  <summary>Details</summary>
Motivation: 混合模拟数字架构在大规模天线阵列中具有成本效益，但由于有限的数字维度和受约束的波束成形设计，准确的波达方向估计仍然具有挑战性。

Method: 使用Butler矩阵在均匀线性阵列上合成DFT波束，并利用波束成形信号的Cauchy-like位移结构开发二阶统计量估计算法。

Result: 算法实现了近乎最优的精度，接近克拉美-罗下界(CRLB)，在仿真中优于现有最先进方法。

Conclusion: 所提出的HAD架构和估计算法能够有效解决大规模天线阵列中DoA估计的挑战，提供接近理论极限的性能。

Abstract: Hybrid Analog and Digital (HAD) architectures provide a cost-effective
alternative for large-scale antenna arrays, but accurate Direction-of-Arrival
(DoA) estimation remains challenging due to limited digital dimensionality and
constrained beamforming design. In this work, we propose a HAD architecture
that employs Butler matrices to synthesize DFT beams over a uniform linear
array. By exploiting the Cauchy-like displacement structure of the beamformed
signal, we introduce a second-order statistics estimation algorithm that
achieves near-optimal accuracy, approaching the Cram\'er-Rao Lower Bound (CRLB)
and outperforming state-of-the-art methods in simulation.

</details>
