{"id": "2601.10727", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.10727", "abs": "https://arxiv.org/abs/2601.10727", "authors": ["Sanghyun Kim", "Jiwon Seo"], "title": "Zonotope Shadow and Reflection Matching: A Novel GNSS Reflection-Based Framework for Enhanced Positioning Accuracy in Urban Areas", "comment": "Submitted to IEEE T-ITS", "summary": "In urban areas, signal reception conditions are often poor due to reflections from buildings, resulting in inaccurate global navigation satellite system (GNSS)-based positioning. Various 3D-mapping-aided (3DMA) GNSS techniques, including shadow matching, have been proposed to address this issue. However, conventional shadow matching estimates positions in a discretized manner. The accuracy of this approach is limited by the resolution of the grid points representing the candidate receiver positions, making it difficult to achieve robust urban positioning and to ensure that the position estimate satisfies user-specified protection levels or safety bounds. To overcome these limitations, zonotope shadow matching (ZSM) has been proposed, which utilizes a set-based position estimate rather than grid-based estimates. ZSM calculates the GNSS shadow--an area on the ground where the line-of-sight (LOS) is blocked and only non-line-of-sight (NLOS) signals can be received--to estimate the receiver's position set. ZSM distinguishes between LOS and NLOS satellites, determining that the receiver is inside the GNSS shadow if the satellite is NLOS and outside if the satellite is LOS. However, relying solely on GNSS shadows limits the ability to sufficiently reduce the size of the receiver position set and to precisely estimate the receiver's location. To address this, we propose zonotope shadow and reflection matching (ZSRM) to enhance positioning accuracy in urban areas. The proposed ZSRM technique is validated through field tests using GNSS signals collected in an urban environment. Consequently, the RMS horizontal position error of ZSRM improved by 10.0% to 53.6% compared with ZSM, while the RMS cross-street and along-street position bounds improved by 18.0% to 50.1% and 30.7% to 59.3%, respectively."}
{"id": "2601.10733", "categories": ["eess.SP", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.10733", "abs": "https://arxiv.org/abs/2601.10733", "authors": ["Jakob Struye", "Nabeel Nisar Bhat", "Siddhartha Kumar", "Mohammad Hossein Moghaddam", "Jeroen Famaey"], "title": "Millimeter-Wave Gesture Recognition in ISAC: Does Reducing Sensing Airtime Hamper Accuracy?", "comment": null, "summary": "Most Integrated Sensing and Communications (ISAC) systems require dividing airtime across their two modes. However, the specific impact of this decision on sensing performance remains unclear and underexplored. In this paper, we therefore investigate the impact on a gesture recognition system using a Millimeter-Wave (mmWave) ISAC system. With our dataset of power per beam pair gathered with two mmWave devices performing constant beam sweeps while test subjects performed distinct gestures, we train a gesture classifier using Convolutional Neural Networks. We then subsample these measurements, emulating reduced sensing airtime, showing that a sensing airtime of 25 % only reduces classification accuracy by 0.15 percentage points from full-time sensing. Alongside this high-quality sensing at low airtime, mmWave systems are known to provide extremely high data throughputs, making mmWave ISAC a prime enabler for applications such as truly wireless Extended Reality."}
{"id": "2601.10735", "categories": ["eess.SP", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.10735", "abs": "https://arxiv.org/abs/2601.10735", "authors": ["Lizy Abraham", "Siobhan Coughlan", "Kritika Rajain", "Changhong Li", "Saji Philip", "Adam James"], "title": "SSC-UNet: UNet with Self-Supervised Contrastive Learning for Phonocardiography Noise Reduction", "comment": "Accepted by IEEE Healthcom 2025", "summary": "Congenital Heart Disease (CHD) remains a significant global health concern affecting approximately 1\\% of births worldwide. Phonocardiography has emerged as a supplementary tool to diagnose CHD cost-effectively. However, the performance of these diagnostic models highly depends on the quality of the phonocardiography, thus, noise reduction is particularly critical. Supervised UNet effectively improves noise reduction capabilities, but limited clean data hinders its application. The complex time-frequency characteristics of phonocardiography further complicate finding the balance between effectively removing noise and preserving pathological features. In this study, we proposed a self-supervised phonocardiography noise reduction model based on Noise2Noise to enable training without clean data. Augmentation and contrastive learning are applied to enhance its performance. We obtained an average SNR of 12.98 dB after filtering under 10~dB of hospital noise. Classification sensitivity after filtering was improved from 27\\% to 88\\%, indicating its promising pathological feature retention capabilities in practical noisy environments."}
{"id": "2601.10737", "categories": ["eess.SP", "cond-mat.mtrl-sci", "cs.CV", "math.OC"], "pdf": "https://arxiv.org/pdf/2601.10737", "abs": "https://arxiv.org/abs/2601.10737", "authors": ["Giuseppe Romano", "Rodrigo Arrieta", "Steven G. Johnson"], "title": "Differentiating through binarized topology changes: Second-order subpixel-smoothed projection", "comment": null, "summary": "A key challenge in topology optimization (TopOpt) is that manufacturable structures, being inherently binary, are non-differentiable, creating a fundamental tension with gradient-based optimization. The subpixel-smoothed projection (SSP) method addresses this issue by smoothing sharp interfaces at the subpixel level through a first-order expansion of the filtered field. However, SSP does not guarantee differentiability under topology changes, such as the merging of two interfaces, and therefore violates the convergence guarantees of many popular gradient-based optimization algorithms. We overcome this limitation by regularizing SSP with the Hessian of the filtered field, resulting in a twice-differentiable projected density during such transitions, while still guaranteeing an almost-everywhere binary structure. We demonstrate the effectiveness of our second-order SSP (SSP2) methodology on both thermal and photonic problems, showing that SSP2 has faster convergence than SSP for connectivity-dominant cases -- where frequent topology changes occur -- while exhibiting comparable performance otherwise. Beyond improving convergence guarantees for CCSA optimizers, SSP2 enables the use of a broader class of optimization algorithms with stronger theoretical guarantees, such as interior-point methods. Since SSP2 adds minimal complexity relative to SSP or traditional projection schemes, it can be used as a drop-in replacement in existing TopOpt codes."}
{"id": "2601.10778", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.10778", "abs": "https://arxiv.org/abs/2601.10778", "authors": ["Praneeth Kumar Vippathalla", "Justin P. Coon", "Mihai-Alin Badiu"], "title": "On the Entropy of a Random Geometric Graph", "comment": "13 pages, 2 figures", "summary": "In this paper, we study the entropy of a hard random geometric graph (RGG), a commonly used model for spatial networks, where the connectivity is governed by the distances between the nodes. Formally, given a connection range $r$, a hard RGG $G_m$ on $m$ vertices is formed by drawing $m$ random points from a spatial domain, and then connecting any two points with an edge when they are within a distance $r$ from each other. The two domains we consider are the $d$-dimensional unit cube $[0,1]^d$ and the $d$-dimensional unit torus $\\mathbb{T}^d$. We derive upper bounds on the entropy $H(G_m)$ for both these domains and for all possible values of $r$. In a few cases, we obtain an exact asymptotic characterization of the entropy by proving a tight lower bound. Our main results are that $H(G_m) \\sim dm \\log_2m$ for $0 < r \\leq 1/4$ in the case of $\\mathbb{T}^d$ and that the entropy of a one-dimensional RGG on $[0,1]$ behaves like $m\\log m$ for all $0<r<1$. As a consequence, we can infer that the asymptotic structural entropy of an RGG on $\\mathbb{T}^d$, which is the entropy of an unlabelled RGG, is $Ω((d-1)m \\log_2m)$ for $0 < r \\leq 1/4$. For the rest of the cases, we conjecture that the entropy behaves asymptotically as the leading order terms of our derived upper bounds."}
{"id": "2601.10743", "categories": ["eess.SP", "cs.LG", "cs.NI"], "pdf": "https://arxiv.org/pdf/2601.10743", "abs": "https://arxiv.org/abs/2601.10743", "authors": ["Ayesh Abu Lehyeh", "Anastassia Gharib", "Tian Xia", "Dryver Huston", "Safwan Wshah"], "title": "UBiGTLoc: A Unified BiLSTM-Graph Transformer Localization Framework for IoT Sensor Networks", "comment": "Accepted and published in IEEE Internet of Things Journal", "summary": "Sensor nodes localization in wireless Internet of Things (IoT) sensor networks is crucial for the effective operation of diverse applications, such as smart cities and smart agriculture. Existing sensor nodes localization approaches heavily rely on anchor nodes within wireless sensor networks (WSNs). Anchor nodes are sensor nodes equipped with global positioning system (GPS) receivers and thus, have known locations. These anchor nodes operate as references to localize other sensor nodes. However, the presence of anchor nodes may not always be feasible in real-world IoT scenarios. Additionally, localization accuracy can be compromised by fluctuations in Received Signal Strength Indicator (RSSI), particularly under non-line-of-sight (NLOS) conditions. To address these challenges, we propose UBiGTLoc, a Unified Bidirectional Long Short-Term Memory (BiLSTM)-Graph Transformer Localization framework. The proposed UBiGTLoc framework effectively localizes sensor nodes in both anchor-free and anchor-presence WSNs. The framework leverages BiLSTM networks to capture temporal variations in RSSI data and employs Graph Transformer layers to model spatial relationships between sensor nodes. Extensive simulations demonstrate that UBiGTLoc consistently outperforms existing methods and provides robust localization across both dense and sparse WSNs while relying solely on cost-effective RSSI data."}
{"id": "2601.10808", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.10808", "abs": "https://arxiv.org/abs/2601.10808", "authors": ["Mikhail Chernikov", "Peter Trifonov"], "title": "Efficient LLR-Domain Decoding of ABS+ Polar Codes", "comment": null, "summary": "ABS+ polar codes are a generalization of Arikan polar codes that provides much faster polarization. We present an LLR-domain implementation of the SCL decoder of ABS+ polar codes. Furthermore, we optimize the SCL algorithm in order to reduce the complexity requirements for the LLRs computation. In comparison with classical polar codes, the proposed approach requires less number of arithmetic operations in the SCL decoder to obtain the fixed frame error rate (FER) at high-SNR region."}
{"id": "2601.10745", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.10745", "abs": "https://arxiv.org/abs/2601.10745", "authors": ["Shivam Kumar", "Himanshu Singh"], "title": "An IoT-Based Controlled Environment Storage for Prevention of Spoilage of Onion (Allium Cepa) During Post-Harvest with UV-C Disinfection", "comment": "8 pages, 7 figures. Undergraduate Research Project", "summary": "India is the second largest producer of onions in the world, contributing over 26 million tonnes annually. However, during storage, approximately 30-40% of onions are lost due to rotting, sprouting, and weight loss. Despite being a major producer, conventional storage methods are either low-cost but ineffective (traditional storage with 40% spoilage) or highly effective but prohibitively expensive for small farmers (cold storage). This paper presents a low-cost IoT-based smart onion storage system that monitors and automatically regulates environmental parameters including temperature, humidity, and spoilage gases using ESP32 microcontroller, DHT22 sensor, MQ-135 gas sensor, and UV-C disinfection technology. The proposed system aims to reduce onion spoilage to 15-20% from the current 40-45% wastage rate while remaining affordable for small and marginal farmers who constitute the majority in India. The system is designed to be cost-effective (estimated 60k-70k INR), energy-efficient, farmer-friendly, and solar-powered."}
{"id": "2601.10883", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.10883", "abs": "https://arxiv.org/abs/2601.10883", "authors": ["Andrea Rondelli"], "title": "A Differential Geometry and Algebraic Topology Based Public-Key Cryptographic Algorithm in Presence of Quantum Adversaries", "comment": null, "summary": "In antiquity, the seal embodied trust, secrecy, and integrity in safeguarding the exchange of letters and messages. The purpose of this work is to continue this tradition in the contemporary era, characterized by the presence of quantum computers, classical supercomputers, and increasingly sophisticated artificial intelligence. We introduce Z-Sigil, an asymmetric public-key cryptographic algorithm grounded in functional analysis, differential geometry, and algebraic topology, with the explicit goal of achieving resistance against both classical and quantum attacks. The construction operates over the tangent fiber bundle of a compact Calabi-Yau manifold [13], where cryptographic keys are elements of vector tangent fibers, with a binary operation defined on tangent spaces of the base manifold giving rise to a groupoid structure. Encryption and decryption are performed iteratively on message blocks, enforcing a serial architecture designed to limit quantum parallelism [9,10]. Each block depends on secret geometric and analytic data, including a randomly chosen base point on the manifold, a selected section of the tangent fiber bundle, and auxiliary analytic data derived from operator determinants and Zeta function regularization [11]. The correctness and invertibility of the proposed algorithm are proven analytically. Furthermore, any adversarial attempt to recover the plaintext without the private key leads to an exponential growth of the adversarial search space,even under quantum speedups. The use of continuous geometric structures,non-linear operator compositions,and enforced blockwise serialization distinguishes this approach from existing quantum-safe cryptographic proposals based on primary discrete algebraic assumptions."}
{"id": "2601.10746", "categories": ["eess.SP", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.10746", "abs": "https://arxiv.org/abs/2601.10746", "authors": ["Yuxin Yang", "Hang Zhou", "Hourong Song", "Branislav Hredzak"], "title": "On the static and small signal analysis of DAB converter", "comment": null, "summary": "This document develops a method to solve the periodic operating point of Dual-Active-Bridge (DAB)."}
{"id": "2601.10915", "categories": ["cs.IT", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.10915", "abs": "https://arxiv.org/abs/2601.10915", "authors": ["Yangshuo He", "Guanding Yu", "Jingge Zhu"], "title": "A PAC-Bayesian Analysis of Channel-Induced Degradation in Edge Inference", "comment": null, "summary": "In the emerging paradigm of edge inference, neural networks (NNs) are partitioned across distributed edge devices that collaboratively perform inference via wireless transmission. However, standard NNs are generally trained in a noiseless environment, creating a mismatch with the noisy channels during edge deployment. In this paper, we address this issue by characterizing the channel-induced performance deterioration as a generalization error against unseen channels. We introduce an augmented NN model that incorporates channel statistics directly into the weight space, allowing us to derive PAC-Bayesian generalization bounds that explicitly quantifies the impact of wireless distortion. We further provide closed-form expressions for practical channels to demonstrate the tractability of these bounds. Inspired by the theoretical results, we propose a channel-aware training algorithm that minimizes a surrogate objective based on the derived bound. Simulations show that the proposed algorithm can effectively improve inference accuracy by leveraging channel statistics, without end-to-end re-training."}
{"id": "2601.10747", "categories": ["eess.SP", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.10747", "abs": "https://arxiv.org/abs/2601.10747", "authors": ["Silke K. Kaiser"], "title": "Sensor Placement for Urban Traffic Interpolation: A Data-Driven Evaluation to Inform Policy", "comment": null, "summary": "Data on citywide street-segment traffic volumes are essential for urban planning and sustainable mobility management. Yet such data are available only for a limited subset of streets due to the high costs of sensor deployment and maintenance. Traffic volumes on the remaining network are therefore interpolated based on existing sensor measurements. However, current sensor locations are often determined by administrative priorities rather than by data-driven optimization, leading to biased coverage and reduced estimation performance. This study provides a large-scale, real-world benchmarking of easily implementable, data-driven strategies for optimizing the placement of permanent and temporary traffic sensors, using segment-level data from Berlin (Strava bicycle counts) and Manhattan (taxi counts). It compares spatial placement strategies based on network centrality, spatial coverage, feature coverage, and active learning. In addition, the study examines temporal deployment schemes for temporary sensors. The findings highlight that spatial placement strategies that emphasize even spatial coverage and employ active learning achieve the lowest prediction errors. With only 10 sensors, they reduce the mean absolute error by over 60% in Berlin and 70% in Manhattan compared to alternatives. Temporal deployment choices further improve performance: distributing measurements evenly across weekdays reduces error by an additional 7% in Berlin and 21% in Manhattan. Together, these spatial and temporal principles allow temporary deployments to closely approximate the performance of optimally placed permanent deployments. From a policy perspective, the results indicate that cities can substantially improve data usefulness by adopting data-driven sensor placement strategies, while retaining flexibility in choosing between temporary and permanent deployments."}
{"id": "2601.10958", "categories": ["cs.IT", "cs.NI"], "pdf": "https://arxiv.org/pdf/2601.10958", "abs": "https://arxiv.org/abs/2601.10958", "authors": ["Christo Kurisummoottil Thomas", "Mingzhe Chen"], "title": "Fundamental Limits of Quantum Semantic Communication via Sheaf Cohomology", "comment": null, "summary": "Semantic communication (SC) enables bandwidth-efficient coordination in multi-agent systems by transmitting meaning rather than raw bits. However, when agents employ heterogeneous sensing modalities and AI architectures, perfect bit-level transmission no longer guarantees mutual understanding. Although deep learning methods for semantic compression have advanced, the information-theoretic limits of semantic alignment under heterogeneity remain poorly understood. Notably, semantic ambiguity shares the same mathematical structure as quantum contextuality, as both arise from cohomological obstructions, motivating a quantum formulation of SC. In this paper, an information-theoretic framework for quantum semantic communication is proposed using sheaf cohomology. Multi-agent semantic networks are modeled as quantum sheaves, where agents meaning spaces are Hilbert spaces connected by quantum channels. The first sheaf cohomology group is shown to characterize irreducible semantic ambiguity, representing a fundamental obstruction to alignment that no local processing can resolve. The minimum communication rate required for semantic alignment is proven to scale with the logarithm of the dimension of the cohomological space, establishing a semantic analog of Shannon limits. For entanglement-assisted channels, the achievable capacity is shown to strictly exceed classical bounds, with each shared ebit reducing the required classical communication by one bit, providing a rigorous interpretation of shared context. Additionally, quantum contextuality is shown to reduce cohomological obstructions, and a duality between quantum discord and integrated semantic information is established, linking quantum correlations to irreducible semantic content. This framework provides rigorous foundations for quantum-enhanced semantic communication in autonomous multi-agent systems."}
{"id": "2601.10748", "categories": ["eess.SP", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.10748", "abs": "https://arxiv.org/abs/2601.10748", "authors": ["Jun Li", "Hongling Zhu", "Yujie Xiao", "Qinghao Zhao", "Yalei Ke", "Gongzheng Tang", "Guangkun Nie", "Deyun Zhang", "Jin Li", "Canqing Yu", "Shenda Hong"], "title": "AnyECG: Evolved ECG Foundation Model for Holistic Health Profiling", "comment": "in progress", "summary": "Background: Artificial intelligence enabled electrocardiography (AI-ECG) has demonstrated the ability to detect diverse pathologies, but most existing models focus on single disease identification, neglecting comorbidities and future risk prediction. Although ECGFounder expanded cardiac disease coverage, a holistic health profiling model remains needed.\n  Methods: We constructed a large multicenter dataset comprising 13.3 million ECGs from 2.98 million patients. Using transfer learning, ECGFounder was fine-tuned to develop AnyECG, a foundation model for holistic health profiling. Performance was evaluated using external validation cohorts and a 10-year longitudinal cohort for current diagnosis, future risk prediction, and comorbidity identification.\n  Results: AnyECG demonstrated systemic predictive capability across 1172 conditions, achieving an AUROC greater than 0.7 for 306 diseases. The model revealed novel disease associations, robust comorbidity patterns, and future disease risks. Representative examples included high diagnostic performance for hyperparathyroidism (AUROC 0.941), type 2 diabetes (0.803), Crohn disease (0.817), lymphoid leukemia (0.856), and chronic obstructive pulmonary disease (0.773).\n  Conclusion: The AnyECG foundation model provides substantial evidence that AI-ECG can serve as a systemic tool for concurrent disease detection and long-term risk prediction."}
{"id": "2601.10991", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.10991", "abs": "https://arxiv.org/abs/2601.10991", "authors": ["Hirosuke Yamamoto", "Ken-ichi Iwata"], "title": "Asymmetric Encoding-Decoding Schemes for Lossless Data Compression", "comment": "24 pages, 19 figures, Submitted to the IEEE Transactions on Information Theory", "summary": "This paper proposes a new lossless data compression coding scheme named an asymmetric encoding-decoding scheme (AEDS), which can be considered as a generalization of tANS (tabled variant of asymmetric numeral systems). In the AEDS, a data sequence $\\bm{s}=s_1s_2\\cdots s_n$ is encoded in backward order $s_t, t=n, \\cdots, 2,1$, while $\\bm{s}$ is decoded in forward order $s_t, t=1, 2, \\cdots, n$ in the same way as the tANS. But, the code class of the AEDS is much broader than that of the tANS. We show for i.i.d.~sources that an AEDS with 2 states (resp.~5 states) can attain a shorter average code length than the Huffman code if a child of the root in the Huffman code tree has a probability weight larger than 0.61803 (resp.~0.56984). Furthermore, we derive several upper bounds on the average code length of the AEDS, which also hold for the tANS, and we show that the average code length of the optimal AEDS and tANS with $N$ states converges to the source entropy with speed $O(1/N)$ as $N$ increases."}
{"id": "2601.10761", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.10761", "abs": "https://arxiv.org/abs/2601.10761", "authors": ["Junseok Lee", "Jihye Shin", "Sangyong Lee", "Chang-Jae Chun"], "title": "LSR-Net: A Lightweight and Strong Robustness Network for Bearing Fault Diagnosis in Noise Environment", "comment": null, "summary": "Rotating bearings play an important role in modern industries, but have a high probability of occurrence of defects because they operate at high speed, high load, and poor operating environments. Therefore, if a delay time occurs when a bearing is diagnosed with a defect, this may cause economic loss and loss of life. Moreover, since the vibration sensor from which the signal is collected is highly affected by the operating environment and surrounding noise, accurate defect diagnosis in a noisy environment is also important. In this paper, we propose a lightweight and strong robustness network (LSR-Net) that is accurate in a noisy environment and enables real-time fault diagnosis. To this end, first, a denoising and feature enhancement module (DFEM) was designed to create a 3-channel 2D matrix by giving several nonlinearity to the feature-map that passed through the denoising module (DM) block composed of convolution-based denoising (CD) blocks. Moreover, adaptive pruning was applied to DM to improve denoising ability when the power of noise is strong. Second, for lightweight model design, a convolution-based efficiency shuffle (CES) block was designed using group convolution (GConv), group pointwise convolution (GPConv) and channel split that can design the model while maintaining low parameters. In addition, the trade-off between the accuracy and model computational complexity that can occur due to the lightweight design of the model was supplemented using attention mechanisms and channel shuffle. In order to verify the defect diagnosis performance of the proposed model, performance verification was conducted in a noisy environment using a vibration signal. As a result, it was confirmed that the proposed model had the best anti-noise ability compared to the benchmark models, and the computational complexity of the model was also the lowest."}
{"id": "2601.11025", "categories": ["cs.IT", "eess.SP"], "pdf": "https://arxiv.org/pdf/2601.11025", "abs": "https://arxiv.org/abs/2601.11025", "authors": ["Lei Li", "Yanqing Xu", "Ye Xue", "Feng Yin", "Chao Shen", "Rui Zhang", "Tsung-Hui Chang"], "title": "PEMNet: Towards Autonomous and Enhanced Environment-Aware Mobile Networks", "comment": null, "summary": "With 5G deployment and the evolution toward 6G, mobile networks must make decisions in highly dynamic environments under strict latency, energy, and spectrum constraints. Achieving this goal, however, depends on prior knowledge of spatial-temporal variations in wireless channels and traffic demands. This motivates a joint, site-specific representation of radio propagation and user demand that is queryable at low online overhead. In this work, we propose the perception embedding map (PEM), a localized framework that embeds fine-grained channel statistics together with grid-level spatial-temporal traffic patterns over a base station's coverage. PEM is built from standard-compliant measurements -- such as measurement report and scheduling/quality-of-service logs -- so it can be deployed and maintained at scale with low cost. Integrated into PEM, this joint knowledge supports enhanced environment-aware optimization across PHY, MAC, and network layers while substantially reducing training overhead and signaling. Compared with existing site-specific channel maps and digital-twin replicas, PEM distinctively emphasizes (i) joint channel-traffic embedding, which is essential for network optimization, and (ii) practical construction using standard measurements, enabling network autonomy while striking a favorable fidelity-cost balance."}
{"id": "2601.10771", "categories": ["eess.SP", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.10771", "abs": "https://arxiv.org/abs/2601.10771", "authors": ["Nay Klaimi", "Clément Elvira", "Philippe Mary", "Luc Le Magoarou"], "title": "Physically constrained unfolded multi-dimensional OMP for large MIMO systems", "comment": null, "summary": "Sparse recovery methods are essential for channel estimation and localization in modern communication systems, but their reliability relies on accurate physical models, which are rarely perfectly known. Their computational complexity also grows rapidly with the dictionary dimensions in large MIMO systems. In this paper, we propose MOMPnet, a novel unfolded sparse recovery framework that addresses both the reliability and complexity challenges of traditional methods. By integrating deep unfolding with data-driven dictionary learning, MOMPnet mitigates hardware impairments while preserving interpretability. Instead of a single large dictionary, multiple smaller, independent dictionaries are employed, enabling a low-complexity multidimensional Orthogonal Matching Pursuit algorithm. The proposed unfolded network is evaluated on realistic channel data against multiple baselines, demonstrating its strong performance and potential."}
{"id": "2601.11149", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.11149", "abs": "https://arxiv.org/abs/2601.11149", "authors": ["Lei Xie", "Hengtao He", "Jun Tong", "Fan Liu", "Shenghui Song"], "title": "Sensing Mutual Information for Communication Signal with Deterministic Pilots and Random Data Payloads", "comment": null, "summary": "The recent emergence of the integrated sensing and communication (ISAC) framework has sparked significant interest in quantifying the sensing capabilities inherent in communication signals. However, existing literature has mainly focused on scenarios involving either purely random or purely deterministic waveforms. This overlooks a critical reality: operational communication standards invariably utilize a hybrid structure comprising both deterministic pilots for channel estimation and random payloads for data transmission. To bridge this gap, this paper investigates the sensing mutual information (SMI) and precoding design specifically for ISAC systems employing communication signals with both pilots and data payloads. First, by utilizing random matrix theory (RMT), we derive a tractable closed-form expression for the SMI that accurately accounts for the statistical properties of the hybrid signal. Building upon this theoretical foundation, we formulate a precoding optimization problem to maximize SMI with constraints on the transmit power and communication rate, which is solved via an efficient alternating direction method of multipliers framework. Simulation results validate the accuracy of the theoretical results and demonstrate the superiority of the proposed precoding design over conventional benchmarks."}
{"id": "2601.10780", "categories": ["eess.SP", "cs.IT"], "pdf": "https://arxiv.org/pdf/2601.10780", "abs": "https://arxiv.org/abs/2601.10780", "authors": ["Nursultan Daupayev", "Christian Engel", "Ricky Bendyk", "Soeren Hirsch"], "title": "Adaptive algorithm for microsensor in sustainable environmental monitoring", "comment": null, "summary": "Traditional data collection from sensors produce a lot of data, which lead to constant power consumption and require more storage space. This study proposes an algorithm for a data acquisition and processing method based on Fourier transform (DFT), which extracts dominant frequency components using harmonic analysis (HA) to identify frequency peaks. This algorithm allows sensors to activate only when an event occurs, while preserving critical information for detecting defects, such as those in the surface structures of buildings and ensuring accuracy for further predictions."}
{"id": "2601.11179", "categories": ["cs.IT", "eess.SP"], "pdf": "https://arxiv.org/pdf/2601.11179", "abs": "https://arxiv.org/abs/2601.11179", "authors": ["Noor Ul Ain", "Lorenzo Miretti", "Renato L. G. Cavalcante", "Sławomir Stańczak"], "title": "Performance Analysis of Cell-Free Massive MIMO under Imperfect LoS Phase Tracking", "comment": "6 pages, 1 figure and 1 table", "summary": "We study the impact of imperfect line-of-sight (LoS) phase tracking on the performance of cell-free massive MIMO networks. Unlike prior works that assume perfectly known or completely unknown phases, we consider a realistic regime where LoS phases are estimated with residual uncertainty due to hardware impairments, mobility, and synchronization errors. To this end, we propose a Rician fading model where LoS components are rotated by imperfect phase estimates and attenuated by a deterministic phase-error penalty factor. We derive a linear MMSE channel estimator that captures statistical phase errors and unifies prior results, reducing to the Bayesian MMSE estimator with perfect phase knowledge and to a zero-mean model in the absence of phase knowledge. To address the non-Gaussian setting, we introduce a virtual uplink model that preserves second-order statistics of channel estimation, enabling the derivation of tractable centralized and distributed MMSE beamformers. To ensure fair assessment of the network performance, we apply these beamformers to the true uplink model and compute the spectral efficiency bounds available in the literature. Numerical results show that our framework bridges idealized assumptions and practical tracking limitations, providing rigorous performance benchmarks and design insights for 6G cell-free networks."}
{"id": "2601.10846", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.10846", "abs": "https://arxiv.org/abs/2601.10846", "authors": ["Fabiola Colone", "Filippo Costa", "Yiding Gao", "Chengpeng Hao", "Linjie Yan", "Giuliano Manara", "Danilo Orlando"], "title": "RIS-aided Radar Detection Architectures with Application to Low-RCS Targets", "comment": null, "summary": "In this paper, we address the radar detection of low observable targets with the assistance of a reconfigurable intelligent surface (RIS). Instead of using a multistatic radar network as counter-stealth strategy with its synchronization, costs, phase coherence, and energy consumption issues, we exploit a RIS to form a joint monostatic and bistatic configuration that can intercept the energy backscattered by the target along irrelevant directions different from the line-of-sight of the radar. Then, this energy is redirected towards the radar that capitalizes all the backscattered energy to detect the low observable target. To this end, five different detection architectures are devised that jointly process monostatic and bistatic echoes and exhibit the constant false alarm rate property at least with respect to the clutter power. To support the practical implementation, we also provide a guideline for the design of a RIS that satisfies the operating requirements of the considered application. The performance analysis is carried out in comparison with conventional detectors and shows that the proposed strategy leads to effective solutions to the detection of low observable targets."}
{"id": "2601.11257", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.11257", "abs": "https://arxiv.org/abs/2601.11257", "authors": ["Yu Yang", "Yingxin Zhang", "Weijie Yuan", "Lin Zhou"], "title": "Rate-Distortion-Perception Tradeoff for the Gray-Wyner Problem", "comment": "Submitted to IEEE International Symposium on Information Theory (ISIT) 2026. Contains detailed proofs and appendices not included in the conference version", "summary": "We revisit the Gray-Wyner lossy source coding problem and derive the first-order asymptotic optimal rate-distortion-perception region when additional perception constraints are imposed on reproduced source sequences. The optimal trade-off is shown to be governed by a mutual information term involving common information and two conditional rate-distortion-perception functions. The perception constraint requires that the distribution of each reproduced sequence is close to that of the original source sequence, which is motivated by practical applications in image and video compression. Prior studies usually focus on the compression and reconstruction of a single source sequence. In this paper, we generalize the prior results for point-to-point systems to the representative multi-terminal setting of the Gray-Wyner problem with two correlated source sequences. In particular, we integrate the analyses of the distortion and the perception constraints by including the random circular shift operator in the encoding and decoding process directly."}
{"id": "2601.10963", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.10963", "abs": "https://arxiv.org/abs/2601.10963", "authors": ["Xiang Cheng", "Boxun Liu", "Xuanyu Liu", "Xuesong Cai"], "title": "Large Wireless Foundation Models: Stronger over Bigger", "comment": null, "summary": "AI-communication integration is widely regarded as a core enabling technology for 6G. Most existing AI-based physical-layer designs rely on task-specific models that are separately tailored to individual modules, resulting in poor generalization. In contrast, communication systems are inherently general-purpose and should support broad applicability and robustness across diverse scenarios. Foundation models offer a promising solution through strong reasoning and generalization, yet wireless-system constraints hinder a direct transfer of large language model (LLM)-style success to the wireless domain. Therefore, we introduce the concept of large wireless foundation models (LWFMs) and present a novel framework for empowering the physical layer with foundation models under wireless constraints. Specifically, we propose two paradigms for realizing LWFMs, including leveraging existing general-purpose foundation models and building novel wireless foundation models. Based on recent progress, we distill two roadmaps for each paradigm and formulate design principles under wireless constraints. We further provide case studies of LWFM-empowered wireless systems to intuitively validate their advantages. Finally, we characterize the notion of \"large\" in LWFMs through a multidimensional analysis of existing work and outline promising directions for future research."}
{"id": "2601.11291", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.11291", "abs": "https://arxiv.org/abs/2601.11291", "authors": ["Guoying Zhang", "Qingqing Wu", "Ziyuan Zheng", "Qiaoyan Peng", "Yanze Zhu", "Wen Chen", "Penghui Huang"], "title": "Joint Antenna Rotation and IRS Beamforming for Multi-User Uplink Communications", "comment": null, "summary": "Rotatable antenna (RA) enhances wireless coverage through directional gain steering, yet suffers from performance degradation under physical blockages. Intelligent reflecting surface (IRS) establishes reflective paths to bypass obstacles, but suffers from angular mismatch when deployed in the side-lobe region of base station (BS) antennas. To address this issue, we propose a new RA-enabled IRS-assisted multi-user uplink system, in which the BS antennas are capable of flexibly adjusting their 3D orientations to align their boresights with the IRS. We formulate a sum rate maximization problem by jointly optimizing the antenna 3D rotations, receive beamforming and IRS phase shifts. To tackle this non-convex problem, we propose an efficient alternating optimization (AO) algorithm. Specifically, we iteratively update the antenna rotations via projected gradient ascent (PGA), compute the receive beamforming via a closed-form solution, and optimize the IRS phase shifts via fractional programming (FP). Numerical results demonstrate that the proposed system yields significant performance gains over conventional fixed-antenna systems, especially under large angular misalignments."}
{"id": "2601.10972", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.10972", "abs": "https://arxiv.org/abs/2601.10972", "authors": ["Mengning Li", "Wenye Wang"], "title": "DuTrack: Long-Term Indoor Human Tracking with Dual-Channel Sensing and Inference", "comment": null, "summary": "Wi-Fi tracking technology demonstrates promising potential for future smart home and intelligent family care. Currently, accurate Wi-Fi tracking methods rely primarily on fine-grained velocity features. However, such velocity-based approaches suffer from the problem of accumulative errors, making it challenging to stably track users' trajectories over a long period of time. This paper presents DuTrack, a fusion-based tracking system for stable human tracking. The fundamental idea is to leverage the ubiquitous acoustic signals in households to rectify the accumulative Wi-Fi tracking error. Theoretically, Wi-Fi sensing in line-of-sight (LoS) and non-line-of-sight (NLoS) scenarios can be modeled as elliptical Fresnel zones and hyperbolic zones, respectively. By designing acoustic sensing signals, we are able to model the acoustic sensing zones as a series of hyperbolic clusters. We reveal how to fuse the fields of electromagnetic waves and mechanical waves, and establish the optimization equation. Next, we design a data-driven architecture to solve the aforementioned optimization equation. Experimental results show that the proposed multimodal tracking scheme exhibits superior performance. We achieve a 89.37% reduction in median tracking error compared to model-based methods and a 65.02% reduction compared to data-driven methods."}
{"id": "2601.11334", "categories": ["cs.IT", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.11334", "abs": "https://arxiv.org/abs/2601.11334", "authors": ["Deborah Pereg"], "title": "Information Theoretic Perspective on Representation Learning", "comment": null, "summary": "An information-theoretic framework is introduced to analyze last-layer embedding, focusing on learned representations for regression tasks. We define representation-rate and derive limits on the reliability with which input-output information can be represented as is inherently determined by the input-source entropy. We further define representation capacity in a perturbed setting, and representation rate-distortion for a compressed output. We derive the achievable capacity, the achievable representation-rate, and their converse. Finally, we combine the results in a unified setting."}
{"id": "2601.10978", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.10978", "abs": "https://arxiv.org/abs/2601.10978", "authors": ["Nan An", "Hongyi He", "Fang Yang", "Chang Liu", "Jian Song", "Zhu Han", "Binbin Zhu"], "title": "Delay-Aware Task Offloading for Heterogeneous VLC-RF-based Vehicular Fog Computing", "comment": null, "summary": "Vehicular fog computing (VFC) is a promising paradigm for reducing the computation burden of vehicles, thus supporting delay-sensitive services in next-generation transportation networks. However, traditional VFC schemes rely on radio frequency (RF) communications, which limits their adaptability for dense vehicular environments. In this paper, a heterogeneous visible light communication (VLC)-RF architecture is designed for VFC systems to facilitate efficient task offloading. Specifically, computing tasks are dynamically partitioned and offloaded to idle vehicles via both VLC and RF links, thereby fully exploiting the interference resilience of VLC and the coverage advantage of RF. To minimize the average task processing delay (TPD), an optimization problem of task offloading and computing resource allocation is formulated, and then solved by the developed residual-based majorization-minimization (RBMM) algorithm. Simulation results confirm that the heterogeneous VLC-RF architecture with the proposed algorithm achieves a 15% average TPD reduction compared to VFC systems relying solely on VLC or RF."}
{"id": "2601.11373", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.11373", "abs": "https://arxiv.org/abs/2601.11373", "authors": ["Pin-Jing Li", "Yu-Chih Huang"], "title": "Polar Orbit Decoding: Universal Parallel Soft Decoding via Automorphism Orbits", "comment": null, "summary": "Binary linear block codes (BLBCs) form the foundation of modern communication systems, yet no single code family simultaneously optimizes all performance aspects. This leads to the widely used multi-code architecture in the standard, significantly increasing the hardware complexity since multiple decoders are required in each piece of equipment. A universal decoding framework based on polar transformations has recently been proposed to unify BLBC decoding under polar-style decoders, but its parallelization has not yet been discussed. In this work, we propose Polar Orbit Decoding (POD), a universal parallel decoding framework for BLBCs. We identify that the automorphisms of BLBCs generate an orbit of permutations that induce diverse decoding trajectories with identical dynamic-frozen constraints after the polar transformations. By decoding over this automorphism orbit in parallel, POD achieves substantial latency-performance tradeoffs without requiring frozen-set readaptation or extra exhaustive permutation searches. Moreover, to enable efficient orbit traversal in the implementation, we represent the automorphism group in a base and strong generating set (BSGS) form using Schreier-Sims algorithms, making offline systematic computation accessible in polynomial time. Simulation results on extended BCH and extended Golay codes demonstrate that POD can achieve maximum-likelihood performance while significantly reducing the decoding latency compared to conventional successive cancellation list decoding."}
{"id": "2601.10980", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.10980", "abs": "https://arxiv.org/abs/2601.10980", "authors": ["Mengning Li", "Wenye Wang"], "title": "Uni-Fi: Integrated Multi-Task Wi-Fi Sensing", "comment": null, "summary": "Wi-Fi sensing technology enables non-intrusive, continuous monitoring of user locations and activities, which supports diverse smart home applications. Since different sensing tasks exhibit contextual relationships, their integration can enhance individual module performance. However, integrating sensing tasks across different research efforts faces challenges due to the absence of two key elements. The first is a unified architecture that captures the fundamental nature shared across diverse sensing tasks. The second is an extensible pipeline that can integrate sensing methodologies proposed in potential future research. This paper presents Uni-Fi, an extensible framework for multi-task Wi-Fi sensing integration. This paper makes the following contributions. First, we propose a unified theoretical framework that reveals the fundamental differences between single-task and multi-task sensing. Second, we develop a scalable sensing pipeline that automatically generates multi-task sensing solvers, enabling seamless integration of multiple sensing models. Experimental results show that Uni-Fi achieves robust performance across tasks, with a localization error of approximately 0.54 meters, 98.34 percent accuracy for activity classification, and 98.57 percent accuracy for presence detection."}
{"id": "2601.11407", "categories": ["cs.IT", "eess.SP"], "pdf": "https://arxiv.org/pdf/2601.11407", "abs": "https://arxiv.org/abs/2601.11407", "authors": ["Cel Thys", "Rodney Martinez Alonso", "Sofie Pollin"], "title": "Efficient Channel Autoencoders for Wideband Communications leveraging Walsh-Hadamard interleaving", "comment": "16 pages, 17 figures", "summary": "This paper investigates how end-to-end (E2E) channel autoencoders (AEs) can achieve energy-efficient wideband communications by leveraging Walsh-Hadamard (WH) interleaved converters. WH interleaving enables high sampling rate analog-digital conversion with reduced power consumption using an analog WH transformation. We demonstrate that E2E-trained neural coded modulation can transparently adapt to the WH-transceiver hardware without requiring algorithmic redesign. Focusing on the short block length regime, we train WH-domain AEs and benchmark them against standard neural and conventional baselines, including 5G Polar codes. We quantify the system-level energy tradeoffs among baseband compute, channel signal-to-noise ratio (SNR), and analog converter power. Our analysis shows that the proposed WH-AE system can approach conventional Polar code SNR performance within 0.14dB while consuming comparable or lower system power. Compared to the best neural baseline, WH-AE achieves, on average, 29% higher energy efficiency (in bit/J) for the same reliability. These findings establish WH-domain learning as a viable path to energy-efficient, high-throughput wideband communications by explicitly balancing compute complexity, SNR, and analog power consumption."}
{"id": "2601.11110", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.11110", "abs": "https://arxiv.org/abs/2601.11110", "authors": ["Marcus Henninger", "Lucas Giroto", "Ahmed Elkelesh", "Silvio Mandelli"], "title": "Hybrid Resource Allocation Scheme for Bistatic ISAC with Data Channels", "comment": "6 pages, 5 figures. This work has been submitted to the IEEE for possible publication", "summary": "Bistatic integrated sensing and communication (ISAC) enables efficient reuse of the existing cellular infrastructure and is likely to play an important role in future sensing networks. In this context, ISAC using the data channel is a promising approach to improve the bistatic sensing performance compared to relying solely on pilots. One of the challenges associated with this approach is resource allocation: the communication link aims to transmit higher modulation order (MO) symbols to maximize the throughput, whereas a lower MO is preferable for sensing to achieve a higher signal-to-noise ratio in the radar image. To address this conflict, this paper introduces a hybrid resource allocation scheme. By placing lower MO symbols as pseudo-pilots on a suitable sensing grid, we enhance the bistatic sensing performance while only slightly reducing the spectral efficiency of the communication link. Simulation results validate our approach against different baselines and provide practical insights into how decoding errors affect the sensing performance."}
{"id": "2601.11498", "categories": ["cs.IT", "cs.NI", "eess.SP", "quant-ph"], "pdf": "https://arxiv.org/pdf/2601.11498", "abs": "https://arxiv.org/abs/2601.11498", "authors": ["Alptug Aytekin", "Mohamed Nomeir", "Lei Hu", "Sennur Ulukus"], "title": "Convergence Properties of Good Quantum Codes for Classical Communication", "comment": null, "summary": "An important part of the information theory folklore had been about the output statistics of codes that achieve the capacity and how the empirical distributions compare to the output distributions induced by the optimal input in the channel capacity problem. Results for a variety of such empirical output distributions of good codes have been known in the literature, such as the comparison of the output distribution of the code to the optimal output distribution in vanishing and non-vanishing error probability cases. Motivated by these, we aim to achieve similar results for the quantum codes that are used for classical communication, that is the setting in which the classical messages are communicated through quantum codewords that pass through a noisy quantum channel. We first show the uniqueness of the optimal output distribution, to be able to talk more concretely about the optimal output distribution. Then, we extend the vanishing error probability results to the quantum case, by using techniques that are close in spirit to the classical case. We also extend non-vanishing error probability results to the quantum case on block codes, by using the second-order converses for such codes based on hypercontractivity results for the quantum generalized depolarizing semi-groups."}
{"id": "2601.11116", "categories": ["eess.SP", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.11116", "abs": "https://arxiv.org/abs/2601.11116", "authors": ["Yuki Nakamura", "Shingo Takemoto", "Shunsuke Ono"], "title": "Comprehensive Robust Dynamic Mode Decomposition from Mode Extraction to Dimensional Reduction", "comment": "Submitted to IEEE Transactions on Signal Processing. The source code is available at https://github.com/MDI-TokyoTech/Comprehensive-Robust-Dynamic-Mode-Decomposition. The project page is https://www.mdi.c.titech.ac.jp/publications/cr-dmd", "summary": "We propose Comprehensive Robust Dynamic Mode Decomposition (CR-DMD), a novel framework that robustifies the entire DMD process - from mode extraction to dimensional reduction - against mixed noise. Although standard DMD widely used for uncovering spatio-temporal patterns and constructing low-dimensional models of dynamical systems, it suffers from significant performance degradation under noise due to its reliance on least-squares estimation for computing the linear time evolution operator. Existing robust variants typically modify the least-squares formulation, but they remain unstable and fail to ensure faithful low-dimensional representations. First, we introduce a convex optimization-based preprocessing method designed to effectively remove mixed noise, achieving accurate and stable mode extraction. Second, we propose a new convex formulation for dimensional reduction that explicitly links the robustly extracted modes to the original noisy observations, constructing a faithful representation of the original data via a sparse weighted sum of the modes. Both stages are efficiently solved by a preconditioned primal-dual splitting method. Experiments on fluid dynamics datasets demonstrate that CR-DMD consistently outperforms state-of-the-art robust DMD methods in terms of mode accuracy and fidelity of low-dimensional representations under noisy conditions."}
{"id": "2601.11501", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.11501", "abs": "https://arxiv.org/abs/2601.11501", "authors": ["Frederik Walter", "Maria Abu-Sini", "Nils Weinhardt", "Antonia Wachter-Zeh"], "title": "Coding Schemes for the Noisy Torn Paper Channel", "comment": null, "summary": "To make DNA a suitable medium for archival data storage, it is essential to consider the decay process of the strands observed in DNA storage systems. This paper studies the decay process as a probabilistic noisy torn paper channel (TPC), which first corrupts the bits of the transmitted sequence in a probabilistic manner by substitutions, then breaks the sequence into a set of noisy unordered substrings. The present work devises coding schemes for the noisy TPC by embedding markers in the transmitted sequence. We investigate the use of static markers and markers connected to the data in the form of hash functions. These two tools have also been recently exploited to tackle the noiseless TPC. Simulations show that static markers excel at higher substitution probabilities, while data-dependent markers are superior at lower noise levels. Both approaches achieve reconstruction rates exceeding $99\\%$ with no false decodings observed, primarily limited by computational resources."}
{"id": "2601.11307", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.11307", "abs": "https://arxiv.org/abs/2601.11307", "authors": ["Julia Schwarzbeck", "Robin Neuder", "Marc Späth", "Alejandro Jiménez-Sáez"], "title": "Scalable mm-Wave Liquid Crystal Reconfigurable Intelligent Surfaces based on the Delay Line Architecture", "comment": null, "summary": "This paper presents the design, fabrication, and characterization of broadband liquid crystal (LC) reconfigurable intelligent surfaces (RIS) operating around 60 GHz and scaling up to 750 radiating elements. The RISs employ a delay line architecture (DLA) that decouples the phase shifting and radiating layer, enabling wide bandwidth, continuous phase control exceeding 360°, and fast response times with a micrometer-thin LC layer of 4.6 micrometer. Two prototypes with 120 and 750 elements are realized using identical unit cells and column-wise biasing. Measurements demonstrate beam steering over +-60° and -3 dB bandwidths exceeding 9% for both apertures, confirming the scalability of the proposed architecture. On top of a measured nanowatt power consumption per unit cell, aperture efficiencies above 20% are predicted by simulations. While the measured efficiencies are reduced to 9.2% and 2.6%, a detailed analysis verifies that this reduction can be attributed to technological challenges in a laboratory environment. Finally, a comprehensive comparison between the applied DLA-based LC-RIS and a conventional approach highlights the superior potential of applied architecture."}
{"id": "2601.11520", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.11520", "abs": "https://arxiv.org/abs/2601.11520", "authors": ["Mengyuan Zhao", "Maël Le Treust", "Tobias J. Oechtering"], "title": "Empirical Coordination over Markov Channel with Independent Source", "comment": null, "summary": "We study joint source-channel coding over Markov channels through the empirical coordination framework. More specifically, we aim at determining the empirical distributions of source and channel symbols that can be induced by a coding scheme. We consider strictly causal encoders that generate channel inputs, without access to the past channel states, henceforth driving the current Markov state evolution. Our main result is the single-letter inner and outer bounds of the set of achievable joint distributions, coordinating all the symbols in the network. To establish the inner bound, we introduce a new notion of typicality, the input-driven Markov typicality, and develop its fundamental properties. Contrary to the classical block-Markov coding schemes that rely on blockwise independence for discrete memoryless channels, our analysis directly exploits the Markov channel structure and improves beyond the independence-based arguments."}
{"id": "2601.11351", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.11351", "abs": "https://arxiv.org/abs/2601.11351", "authors": ["Ruifeng Zheng", "Pengjie Zhou", "Pit Hofmann", "Martín Schottlender", "Fatima Rani", "Juan A. Cabrera", "Frank H. P. Fitzek"], "title": "Modulation, ISI, and Detection for Langmuir Adsorption-Based Microfluidic Molecular Communication", "comment": "5 pages", "summary": "This paper studies microfluidic molecular communication receivers with finite-capacity Langmuir adsorption driven by an effective surface concentration. In the reaction-limited regime, we derive a closed-form single-pulse response kernel and a symbol-rate recursion for on-off keying that explicitly exposes channel memory and inter-symbol interference. We further develop short-pulse and long-pulse approximations, revealing an interference asymmetry in the long-pulse regime due to saturation. To account for stochasticity, we adopt a finite-receptor binomial counting model, employ pulse-end sampling, and propose a low-complexity midpoint-threshold detector that reduces to a fixed threshold when interference is negligible. Numerical results corroborate the proposed characterization and quantify detection performance versus pulse and symbol durations."}
{"id": "2601.10780", "categories": ["eess.SP", "cs.IT"], "pdf": "https://arxiv.org/pdf/2601.10780", "abs": "https://arxiv.org/abs/2601.10780", "authors": ["Nursultan Daupayev", "Christian Engel", "Ricky Bendyk", "Soeren Hirsch"], "title": "Adaptive algorithm for microsensor in sustainable environmental monitoring", "comment": null, "summary": "Traditional data collection from sensors produce a lot of data, which lead to constant power consumption and require more storage space. This study proposes an algorithm for a data acquisition and processing method based on Fourier transform (DFT), which extracts dominant frequency components using harmonic analysis (HA) to identify frequency peaks. This algorithm allows sensors to activate only when an event occurs, while preserving critical information for detecting defects, such as those in the surface structures of buildings and ensuring accuracy for further predictions."}
{"id": "2601.11438", "categories": ["eess.SP", "cs.IT"], "pdf": "https://arxiv.org/pdf/2601.11438", "abs": "https://arxiv.org/abs/2601.11438", "authors": ["Qiaosen Zhang", "Matteo Nerini", "Bruno Clerckx"], "title": "Channel Estimation in MIMO Systems Aided by Microwave Linear Analog Computers (MiLACs)", "comment": "Submitted to IEEE for publication", "summary": "Microwave linear analog computers (MiLACs) have recently emerged as a promising solution for future gigantic multiple-input multiple-output (MIMO) systems, enabling beamforming with greatly reduced hardware and computational cost. However, channel estimation for MiLAC-aided systems remains an open problem. Conventional least squares (LS) and minimum mean square error (MMSE) estimation rely on intensive digital computation, which undermines the benefits offered by MiLACs. In this letter, we propose efficient LS and MMSE channel estimation schemes for MiLAC-aided MIMO systems. By designing training precoders and combiners implemented by MiLACs, both LS and MMSE estimation are performed fully in the analog domain, achieving identical performance to their digital counterparts while significantly reducing computational complexity, transmit RF chains, analog-to-digital/digital-to-analog converters (ADCs/DACs) resolution requirements, and peak-to-average power ratio (PAPR). Numerical results verify the effectiveness and advantages of the proposed schemes."}
{"id": "2601.11438", "categories": ["eess.SP", "cs.IT"], "pdf": "https://arxiv.org/pdf/2601.11438", "abs": "https://arxiv.org/abs/2601.11438", "authors": ["Qiaosen Zhang", "Matteo Nerini", "Bruno Clerckx"], "title": "Channel Estimation in MIMO Systems Aided by Microwave Linear Analog Computers (MiLACs)", "comment": "Submitted to IEEE for publication", "summary": "Microwave linear analog computers (MiLACs) have recently emerged as a promising solution for future gigantic multiple-input multiple-output (MIMO) systems, enabling beamforming with greatly reduced hardware and computational cost. However, channel estimation for MiLAC-aided systems remains an open problem. Conventional least squares (LS) and minimum mean square error (MMSE) estimation rely on intensive digital computation, which undermines the benefits offered by MiLACs. In this letter, we propose efficient LS and MMSE channel estimation schemes for MiLAC-aided MIMO systems. By designing training precoders and combiners implemented by MiLACs, both LS and MMSE estimation are performed fully in the analog domain, achieving identical performance to their digital counterparts while significantly reducing computational complexity, transmit RF chains, analog-to-digital/digital-to-analog converters (ADCs/DACs) resolution requirements, and peak-to-average power ratio (PAPR). Numerical results verify the effectiveness and advantages of the proposed schemes."}
{"id": "2601.11025", "categories": ["cs.IT", "eess.SP"], "pdf": "https://arxiv.org/pdf/2601.11025", "abs": "https://arxiv.org/abs/2601.11025", "authors": ["Lei Li", "Yanqing Xu", "Ye Xue", "Feng Yin", "Chao Shen", "Rui Zhang", "Tsung-Hui Chang"], "title": "PEMNet: Towards Autonomous and Enhanced Environment-Aware Mobile Networks", "comment": null, "summary": "With 5G deployment and the evolution toward 6G, mobile networks must make decisions in highly dynamic environments under strict latency, energy, and spectrum constraints. Achieving this goal, however, depends on prior knowledge of spatial-temporal variations in wireless channels and traffic demands. This motivates a joint, site-specific representation of radio propagation and user demand that is queryable at low online overhead. In this work, we propose the perception embedding map (PEM), a localized framework that embeds fine-grained channel statistics together with grid-level spatial-temporal traffic patterns over a base station's coverage. PEM is built from standard-compliant measurements -- such as measurement report and scheduling/quality-of-service logs -- so it can be deployed and maintained at scale with low cost. Integrated into PEM, this joint knowledge supports enhanced environment-aware optimization across PHY, MAC, and network layers while substantially reducing training overhead and signaling. Compared with existing site-specific channel maps and digital-twin replicas, PEM distinctively emphasizes (i) joint channel-traffic embedding, which is essential for network optimization, and (ii) practical construction using standard measurements, enabling network autonomy while striking a favorable fidelity-cost balance."}
{"id": "2601.11179", "categories": ["cs.IT", "eess.SP"], "pdf": "https://arxiv.org/pdf/2601.11179", "abs": "https://arxiv.org/abs/2601.11179", "authors": ["Noor Ul Ain", "Lorenzo Miretti", "Renato L. G. Cavalcante", "Sławomir Stańczak"], "title": "Performance Analysis of Cell-Free Massive MIMO under Imperfect LoS Phase Tracking", "comment": "6 pages, 1 figure and 1 table", "summary": "We study the impact of imperfect line-of-sight (LoS) phase tracking on the performance of cell-free massive MIMO networks. Unlike prior works that assume perfectly known or completely unknown phases, we consider a realistic regime where LoS phases are estimated with residual uncertainty due to hardware impairments, mobility, and synchronization errors. To this end, we propose a Rician fading model where LoS components are rotated by imperfect phase estimates and attenuated by a deterministic phase-error penalty factor. We derive a linear MMSE channel estimator that captures statistical phase errors and unifies prior results, reducing to the Bayesian MMSE estimator with perfect phase knowledge and to a zero-mean model in the absence of phase knowledge. To address the non-Gaussian setting, we introduce a virtual uplink model that preserves second-order statistics of channel estimation, enabling the derivation of tractable centralized and distributed MMSE beamformers. To ensure fair assessment of the network performance, we apply these beamformers to the true uplink model and compute the spectral efficiency bounds available in the literature. Numerical results show that our framework bridges idealized assumptions and practical tracking limitations, providing rigorous performance benchmarks and design insights for 6G cell-free networks."}
{"id": "2601.11407", "categories": ["cs.IT", "eess.SP"], "pdf": "https://arxiv.org/pdf/2601.11407", "abs": "https://arxiv.org/abs/2601.11407", "authors": ["Cel Thys", "Rodney Martinez Alonso", "Sofie Pollin"], "title": "Efficient Channel Autoencoders for Wideband Communications leveraging Walsh-Hadamard interleaving", "comment": "16 pages, 17 figures", "summary": "This paper investigates how end-to-end (E2E) channel autoencoders (AEs) can achieve energy-efficient wideband communications by leveraging Walsh-Hadamard (WH) interleaved converters. WH interleaving enables high sampling rate analog-digital conversion with reduced power consumption using an analog WH transformation. We demonstrate that E2E-trained neural coded modulation can transparently adapt to the WH-transceiver hardware without requiring algorithmic redesign. Focusing on the short block length regime, we train WH-domain AEs and benchmark them against standard neural and conventional baselines, including 5G Polar codes. We quantify the system-level energy tradeoffs among baseband compute, channel signal-to-noise ratio (SNR), and analog converter power. Our analysis shows that the proposed WH-AE system can approach conventional Polar code SNR performance within 0.14dB while consuming comparable or lower system power. Compared to the best neural baseline, WH-AE achieves, on average, 29% higher energy efficiency (in bit/J) for the same reliability. These findings establish WH-domain learning as a viable path to energy-efficient, high-throughput wideband communications by explicitly balancing compute complexity, SNR, and analog power consumption."}
{"id": "2601.11498", "categories": ["cs.IT", "cs.NI", "eess.SP", "quant-ph"], "pdf": "https://arxiv.org/pdf/2601.11498", "abs": "https://arxiv.org/abs/2601.11498", "authors": ["Alptug Aytekin", "Mohamed Nomeir", "Lei Hu", "Sennur Ulukus"], "title": "Convergence Properties of Good Quantum Codes for Classical Communication", "comment": null, "summary": "An important part of the information theory folklore had been about the output statistics of codes that achieve the capacity and how the empirical distributions compare to the output distributions induced by the optimal input in the channel capacity problem. Results for a variety of such empirical output distributions of good codes have been known in the literature, such as the comparison of the output distribution of the code to the optimal output distribution in vanishing and non-vanishing error probability cases. Motivated by these, we aim to achieve similar results for the quantum codes that are used for classical communication, that is the setting in which the classical messages are communicated through quantum codewords that pass through a noisy quantum channel. We first show the uniqueness of the optimal output distribution, to be able to talk more concretely about the optimal output distribution. Then, we extend the vanishing error probability results to the quantum case, by using techniques that are close in spirit to the classical case. We also extend non-vanishing error probability results to the quantum case on block codes, by using the second-order converses for such codes based on hypercontractivity results for the quantum generalized depolarizing semi-groups."}
